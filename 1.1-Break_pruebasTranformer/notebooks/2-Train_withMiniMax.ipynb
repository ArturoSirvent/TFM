{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear unos datos MUYYY sencillitos, y vamos a entrenar el modelo en RECONSTRUIRLOS solo. No vamos a pretender que haga nada más.   \n",
    "Luego le meteremos lo de al AssDis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model import AnomalyTransformer\n",
    "import gc\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los datos sinteticos SIN ANOMALÍAS\n",
    "\n",
    "Voy a hacer un generador que nos de una secuencia regular, con puntos de anomalia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinne(lenght=100,amp=1,sf=0.1,f=2,phase=0):\n",
    "    x = torch.arange(0,lenght*sf, sf)\n",
    "    return amp*torch.sin(x*sf*2*torch.pi/f+phase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd107688150>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y=sinne(380,sf=0.1,f=1,phase=4)\n",
    "plt.plot(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora el generador de datos. Le decimos que nos devuelva un batch de datos y nos lo da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    #esta es la clase de los datos que seran secuencias de senos de freq aleatoria \n",
    "    def __init__(self,lenght,num_samples,amp_random=True,freq_random=True,phase_random=True,sf=0.1):\n",
    "        super().__init__()\n",
    "        self.amp_random=amp_random\n",
    "        self.freq_random=freq_random\n",
    "        self.phase_random=phase_random\n",
    "        self.num_samples=num_samples\n",
    "        self.sf=0.1\n",
    "        self.lenght=lenght\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        amp=float(np.random.randint(1,300,1)*0.01)\n",
    "        phase=np.random.randint(0,100,1)*0.02\n",
    "        f=np.random.randint(1,200,1)*0.01\n",
    "        y=sinne(lenght=self.lenght,amp=amp,sf=0.1,f=f,phase=phase)\n",
    "        y=y.unsqueeze(-1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=600\n",
    "data=Data(win_size,4000)\n",
    "\n",
    "dataloader=DataLoader(data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es todo lo personalizable que querria, pero bien, ahora creamos la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdel\u001b[39;00m modelo\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelo' is not defined"
     ]
    }
   ],
   "source": [
    "del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnomalyTransformer(\n",
       "  (embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (inner_attention): AnomalyAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (sigma_projection): Linear(in_features=32, out_features=2, bias=True)\n",
       "          (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo=AnomalyTransformer.AnomalyTransformer(win_size, 1, 1, d_model=32, n_heads=2, e_layers=2, d_ff=32,\n",
    "                          dropout=0.0, activation='gelu', output_attention=True)\n",
    "modelo.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_and_decay_learning_rate(optimizer, epoch, init_lr, warmup_epochs, total_epochs):\n",
    "    if epoch <= warmup_epochs:\n",
    "        lr = init_lr * (epoch / warmup_epochs)\n",
    "        print('Warmup: Updating learning rate to {}'.format(lr))\n",
    "    else:\n",
    "        decay_epochs = total_epochs - warmup_epochs\n",
    "        decay_rate = 1e-7+(epoch - warmup_epochs) / decay_epochs\n",
    "        lr = init_lr * (1 - decay_rate)\n",
    "        print('Decay: Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \n",
    "    total=sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total}\")\n",
    "    return total\n",
    "#count_parameters(modelo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "Añadimos en el entrenamiendo dos fases, una de mini y otra de max\n",
    "\n",
    "Con el output tenemos que sacar: el error de reconstrucción y el AssDiss, y luego sacar dos function loses, una donde se minimiza y otra donde de maximiza.  \n",
    "\n",
    "El calculo de las assdis lo vamos a poner en una funcion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clip_gradients(model, max_norm, norm_type=2):\n",
    "    \"\"\"\n",
    "    Clip gradients of the model parameters.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        max_norm (float): The maximum allowed norm for the gradients.\n",
    "        norm_type (float): The type of the norm calculation (default: 2 for L2 norm).\n",
    "    \"\"\"\n",
    "    # Recupera todos los gradientes de los parámetros del modelo\n",
    "    gradients = [param.grad for param in model.parameters() if param.grad is not None]\n",
    "\n",
    "    # Calcula la norma total de los gradientes\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(grad, norm_type) for grad in gradients]), norm_type)\n",
    "\n",
    "    # Calcula el factor de escalado para recortar los gradientes\n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    if clip_coef < 1:\n",
    "        # Aplica el factor de escalado a los gradientes\n",
    "        for grad in gradients:\n",
    "            grad.mul_(clip_coef)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def layer_association_discrepancy( Pl, Sl):\n",
    "#     #Pl y Sl viene con dimension B,Head,Height,Width\n",
    "#     B,Head,Height,_ = Pl.shape\n",
    "#     result=torch.zeros(B,Head,Height)\n",
    "#     for batch_size in range(B):\n",
    "#         for head_size in range(Head):\n",
    "#             rowwise_kl = lambda row: (F.kl_div(Pl[batch_size,head_size,row, :], Sl[batch_size,head_size,row, :]) + F.kl_div(Sl[batch_size,head_size,row, :], Pl[batch_size,head_size,row, :]))\n",
    "#             ad_vector = torch.concat([rowwise_kl(row).unsqueeze(0) for row in range(Height)])\n",
    "#             result[batch_size,head_size,:]=ad_vector\n",
    "#     return result\n",
    "\n",
    "def my_kl_loss(p, q):\n",
    "    res = p * (torch.log(p + 0.0001) - torch.log(q + 0.0001))\n",
    "    return torch.mean(torch.sum(res, dim=-1), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# def layer_association_discrepancy(Pl, Sl):\n",
    "#     # Pl y Sl vienen con dimension B, Head, Height, Width\n",
    "#     B, Head, Height, _ = Pl.shape\n",
    "\n",
    "#     # Calcular el KL Divergence entre Pl y Sl a lo largo del último eje (Width)\n",
    "#     kl1 = F.kl_div(Pl, Sl, reduction='none').mean(dim=-1)\n",
    "#     kl2 = F.kl_div(Sl, Pl, reduction='none').mean(dim=-1)\n",
    "\n",
    "#     # Sumar los KL Divergence calculados\n",
    "#     ad_vector = kl1 + kl2\n",
    "\n",
    "#     return ad_vector\n",
    "\n",
    "def layer_association_discrepancy(Pl, Sl):\n",
    "    # Pl y Sl vienen con dimension B, Head, Height, Width\n",
    "    B, Head, Height, _ = Pl.shape\n",
    "\n",
    "    # Calcular el KL Divergence entre Pl y Sl a lo largo del último eje (Width)\n",
    "    kl1 = my_kl_loss(Pl.view(B, Head, Height, -1), Sl.view(B, Head, Height, -1))\n",
    "    kl2 = my_kl_loss(Sl.view(B, Head, Height, -1), Pl.view(B, Head, Height, -1))\n",
    "\n",
    "    # Sumar los KL Divergence calculados\n",
    "    ad_vector = kl1 + kl2\n",
    "\n",
    "    return ad_vector\n",
    "\n",
    "\n",
    "\n",
    "def association_discrepancy( P_list, S_list):\n",
    "\n",
    "    return torch.stack([layer_association_discrepancy(j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600),i) for i, j in zip(S_list,P_list)]).mean(axis=[0])\n",
    "\n",
    "# (1 / len(P_list)) * sum(\n",
    "#         [\n",
    "#             torch.mean(layer_association_discrepancy(P, S),axis=0)#hacemos la media sobre todas las cabezas\n",
    "#             for P, S in zip(P_list, S_list)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "def loss_function( x_hat, P_list, S_list, lambda_, x):\n",
    "    frob_norm = ((x_hat - x)**2).mean()   #usamo MSE  #torch.linalg.matrix_norm(x_hat - x, ord=\"fro\").mean() #norm L2 \n",
    "    diss_norm=torch.mean(association_discrepancy(P_list, S_list))#torch.linalg.norm(, ord=1) # le añado esto para que se normaliza acros muestras \n",
    "    print(frob_norm,diss_norm)\n",
    "    return frob_norm - (lambda_* diss_norm) #hacemos la suma de todos los valores absolutos y dividimos todo por el batchsize\n",
    "    \n",
    "\n",
    "def min_loss(output,P_layers,S_layers, x,lambda_):\n",
    "    P_list = P_layers\n",
    "    S_list = [S.detach() for S in S_layers]\n",
    "    lambda_ = -lambda_\n",
    "    return loss_function(output, P_list, S_list, lambda_, x)\n",
    "\n",
    "def max_loss(output,P_layers,S_layers,x,lambda_):\n",
    "    P_list = [P.detach() for P in P_layers]\n",
    "    S_list = S_layers\n",
    "    lambda_ = lambda_\n",
    "    return loss_function(output, P_list, S_list, lambda_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 600, 1])\n"
     ]
    }
   ],
   "source": [
    "x_aux=next(iter(dataloader))\n",
    "x_aux=x_aux.float().cuda()\n",
    "print(x_aux.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas mal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x_aux,axis=[2,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 600, 1])\n"
     ]
    }
   ],
   "source": [
    "#pruebas porque salen nans\n",
    "y_aux,series,prior,_=modelo(x_aux)\n",
    "print(y_aux.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 600, 600])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 600, 600])\n"
     ]
    }
   ],
   "source": [
    "print(series[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f056b8e9b50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_aux[7].squeeze().detach().cpu().numpy())\n",
    "plt.plot(x_aux[7].squeeze().detach().cpu().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿¿COmo aplicar esto si tenemos batches y heads??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1=torch.stack([layer_association_discrepancy(j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600),i) for i, j in zip(series,prior)]).mean(axis=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.5167, 8.0619, 7.9459, 7.8272, 7.5951, 7.3470, 7.1753, 7.1732, 7.3331,\n",
       "        7.5755, 7.6740, 7.6553, 7.6207, 7.6757, 7.7317, 7.7407, 7.7063, 7.6611,\n",
       "        7.5831, 7.5725, 7.6031, 7.6509, 7.6954, 7.6624, 7.5563, 7.4805, 7.4611,\n",
       "        7.4680, 7.5398, 7.6066, 7.6018, 7.6263, 7.7376, 7.9838, 8.1917, 8.1954,\n",
       "        8.0682, 7.9680, 7.9309, 7.9060, 7.8921, 7.8816, 7.8546, 7.8492, 7.8920,\n",
       "        7.9543, 8.0408, 7.9970, 7.9013, 7.8024, 7.7025, 7.6858, 7.7606, 7.8253,\n",
       "        7.8701, 7.8784, 7.8894, 7.9707, 8.0772, 8.1321, 8.1559, 8.1326, 8.0805,\n",
       "        8.0412, 8.1200, 8.2622, 8.4153, 8.5139, 8.5051, 8.4191, 8.3663, 8.3589,\n",
       "        8.3874, 8.4304, 8.3722, 8.3203, 8.3221, 8.3011, 8.3049, 8.3353, 8.3722,\n",
       "        8.3108, 8.2373, 8.1566, 8.1356, 8.2207, 8.2873, 8.3069, 8.2825, 8.2096,\n",
       "        8.1612, 8.2069, 8.2371, 8.2405, 8.2124, 8.1797, 8.2020, 8.2781, 8.3595,\n",
       "        8.3988, 8.4022, 8.3016, 8.2313, 8.2909, 8.3949, 8.4419, 8.3301, 8.1789,\n",
       "        8.1233, 8.1868, 8.2971, 8.3485, 8.3348, 8.2589, 8.2566, 8.2863, 8.3401,\n",
       "        8.3436, 8.2509, 8.1247, 8.0655, 8.1122, 8.2155, 8.3397, 8.3682, 8.2756,\n",
       "        8.1490, 8.1164, 8.1314, 8.1429, 8.1589, 8.1508, 8.1902, 8.3178, 8.4657,\n",
       "        8.5562, 8.5916, 8.5183, 8.4224, 8.3753, 8.3910, 8.4067, 8.4115, 8.3889,\n",
       "        8.3189, 8.2376, 8.2205, 8.2092, 8.1686, 8.0544, 7.8921, 7.8502, 7.8898,\n",
       "        7.9068, 7.8572, 7.7916, 7.7958, 7.8575, 7.9262, 7.8711, 7.6859, 7.5572,\n",
       "        7.4777, 7.4666, 7.4574, 7.5280, 7.6327, 7.7077, 7.7153, 7.6827, 7.6890,\n",
       "        7.7420, 7.8170, 7.8451, 7.8584, 7.8360, 7.8451, 7.9532, 8.1087, 8.1961,\n",
       "        8.1408, 8.0646, 7.9811, 7.9130, 7.8815, 7.9045, 7.9197, 7.9293, 7.9140,\n",
       "        7.9655, 8.0864, 8.1368, 8.1380, 8.0643, 7.9679, 7.9244, 7.9332, 7.9402,\n",
       "        7.9225, 7.9305, 7.9254, 7.9625, 8.0766, 8.1648, 8.1815, 8.1117, 7.9845,\n",
       "        7.9037, 7.9260, 8.0496, 8.1774, 8.2991, 8.3826, 8.4362, 8.5069, 8.5506,\n",
       "        8.5016, 8.3783, 8.1961, 8.0721, 8.0647, 8.1382, 8.2006, 8.2781, 8.3538,\n",
       "        8.3324, 8.2652, 8.1795, 8.0778, 7.9727, 7.9380, 7.9515, 7.9971, 8.1380,\n",
       "        8.3040, 8.4040, 8.3950, 8.3601, 8.2797, 8.2007, 8.1115, 8.0472, 8.1062,\n",
       "        8.1781, 8.2322, 8.3249, 8.4279, 8.5289, 8.6229, 8.6648, 8.5920, 8.4879,\n",
       "        8.4543, 8.5115, 8.5408, 8.5666, 8.6035, 8.6040, 8.6233, 8.6324, 8.5735,\n",
       "        8.4151, 8.1775, 7.9715, 7.8513, 7.8962, 7.9936, 8.1039, 8.1807, 8.1538,\n",
       "        8.1352, 8.2242, 8.2638, 8.2137, 8.1396, 8.0819, 8.0496, 8.1077, 8.1834,\n",
       "        8.2008, 8.1976, 8.1702, 8.1049, 8.0808, 8.0269, 7.9706, 7.8477, 7.7687,\n",
       "        7.7022, 7.7424, 7.8508, 7.9393, 7.9736, 7.9080, 7.8350, 7.7822, 7.7312,\n",
       "        7.6477, 7.6361, 7.6621, 7.6853, 7.7598, 7.8556, 7.9670, 8.0405, 8.0276,\n",
       "        7.8912, 7.7431, 7.6590, 7.7268, 7.8744, 8.0518, 8.1494, 8.1648, 8.1733,\n",
       "        8.2138, 8.2351, 8.2209, 8.1482, 8.0535, 7.9673, 7.9969, 8.0451, 8.1397,\n",
       "        8.1688, 8.1361, 8.0618, 8.0040, 8.0087, 8.0467, 8.0785, 8.0809, 8.0834,\n",
       "        8.1368, 8.2449, 8.2527, 8.1785, 8.1256, 8.0685, 8.0042, 7.9259, 7.8493,\n",
       "        7.8189, 7.8549, 7.8761, 7.8815, 7.9446, 8.0478, 8.0997, 8.1163, 8.0585,\n",
       "        7.9649, 7.8984, 7.8915, 7.8737, 7.9140, 7.9968, 8.0791, 8.1433, 8.1471,\n",
       "        8.0421, 7.8739, 7.7002, 7.5746, 7.4431, 7.3865, 7.4294, 7.5641, 7.6860,\n",
       "        7.7191, 7.6948, 7.6788, 7.6922, 7.7068, 7.7500, 7.8021, 7.7776, 7.7260,\n",
       "        7.6875, 7.7072, 7.7390, 7.7657, 7.6969, 7.5883, 7.5322, 7.5147, 7.5428,\n",
       "        7.5747, 7.5418, 7.5016, 7.5821, 7.8123, 7.9570, 7.9700, 7.8646, 7.7282,\n",
       "        7.6300, 7.5549, 7.4613, 7.4209, 7.4219, 7.4102, 7.4691, 7.6038, 7.6928,\n",
       "        7.6618, 7.6033, 7.5292, 7.4992, 7.5670, 7.6834, 7.8330, 7.9207, 7.9202,\n",
       "        7.9123, 7.9714, 8.0282, 8.0851, 8.0906, 8.0099, 7.9080, 7.8865, 7.9628,\n",
       "        8.1219, 8.2224, 8.2896, 8.2597, 8.2080, 8.1539, 8.1583, 8.1785, 8.1805,\n",
       "        8.0997, 8.0616, 8.0842, 8.1679, 8.2784, 8.3547, 8.3367, 8.2451, 8.1383,\n",
       "        8.1178, 8.1364, 8.1756, 8.2463, 8.3145, 8.3803, 8.4410, 8.5161, 8.6345,\n",
       "        8.6981, 8.7022, 8.6358, 8.6287, 8.6366, 8.6654, 8.6887, 8.7620, 8.7456,\n",
       "        8.6395, 8.5493, 8.4681, 8.4074, 8.4145, 8.3832, 8.3502, 8.3347, 8.3303,\n",
       "        8.3064, 8.3277, 8.3215, 8.3453, 8.3759, 8.3624, 8.3537, 8.3152, 8.2525,\n",
       "        8.2389, 8.2464, 8.2680, 8.2614, 8.3167, 8.3759, 8.3689, 8.2758, 8.2136,\n",
       "        8.1887, 8.2016, 8.2123, 8.1904, 8.2155, 8.2753, 8.3290, 8.3940, 8.4358,\n",
       "        8.3922, 8.2794, 8.1478, 8.0619, 8.0850, 8.1642, 8.1925, 8.0991, 8.0188,\n",
       "        8.0130, 8.0645, 8.1166, 8.0703, 7.9419, 7.8244, 7.8218, 7.9134, 8.0403,\n",
       "        8.0916, 8.0850, 8.0529, 8.0319, 8.0160, 7.9881, 7.9357, 7.8009, 7.6903,\n",
       "        7.7013, 7.8526, 8.0478, 8.1438, 8.1077, 7.9924, 7.9056, 7.9057, 7.9560,\n",
       "        7.9970, 7.9557, 7.9143, 7.9148, 8.0044, 8.0873, 8.1461, 8.1246, 8.0020,\n",
       "        7.8075, 7.6820, 7.6472, 7.6344, 7.6235, 7.6123, 7.5911, 7.6530, 7.7972,\n",
       "        7.9361, 7.9394, 7.8508, 7.7363, 7.6985, 7.7215, 7.8472, 7.9541, 8.0208,\n",
       "        8.0206, 8.0021, 8.0354, 8.1455, 8.1931, 8.1546, 8.0275, 7.9028, 7.8865,\n",
       "        7.9842, 8.1202, 8.2383, 8.2800, 8.2665, 8.2387, 8.2741, 8.2141, 8.1072,\n",
       "        7.9712, 7.8704, 7.8112, 7.7861, 7.8213, 7.8854, 7.9039, 7.8521, 7.7665,\n",
       "        7.7412, 7.7557, 7.7608, 7.7923, 7.8552, 7.8849, 7.9566, 8.0473, 8.1250,\n",
       "        8.1045, 8.0572, 8.0136, 8.0448, 8.1717, 8.5095], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1.mean(axis=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m assdis\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39;49mtensor([layer_association_discrepancy(j\u001b[39m/\u001b[39;49mtorch\u001b[39m.\u001b[39;49munsqueeze(torch\u001b[39m.\u001b[39;49msum(j, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mrepeat(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m600\u001b[39;49m),i) \u001b[39mfor\u001b[39;49;00m i, j \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(series,prior)]))\n\u001b[1;32m      2\u001b[0m assdis\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "assdis=torch.sum([layer_association_discrepancy(j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600),i) for i, j in zip(series,prior)])\n",
    "assdis.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.7781, 8.3854, 8.1935, 8.2383, 8.2531, 8.2740, 8.1185, 8.0714, 8.1005,\n",
       "        8.1421, 8.2736, 8.4015, 8.3808, 8.2557, 8.1092, 8.1217, 8.1415, 8.1938,\n",
       "        8.2265, 8.1540, 8.0823, 8.0458, 8.0808, 8.2399, 8.2134, 8.1882, 8.0741,\n",
       "        8.0729, 8.1667, 8.2378, 8.4418, 8.4803, 8.4404, 8.4173, 8.4018, 8.5221,\n",
       "        8.5236, 8.5149, 8.3987, 8.2740, 8.2826, 8.3613, 8.5215, 8.5841, 8.5256,\n",
       "        8.4795, 8.3633, 8.4117, 8.4708, 8.5043, 8.4745, 8.3196, 8.2556, 8.2725,\n",
       "        8.4438, 8.5826, 8.5476, 8.4119, 8.2342, 8.1248, 8.0634, 8.0909, 8.0973,\n",
       "        8.1339, 8.1624, 8.2762, 8.3033, 8.3648, 8.4618, 8.4877, 8.4908, 8.3868,\n",
       "        8.2993, 8.3569, 8.4370, 8.5755, 8.4773, 8.3829, 8.3128, 8.3061, 8.3689,\n",
       "        8.3384, 8.2801, 8.3131, 8.3066, 8.4263, 8.4025, 8.4745, 8.5000, 8.4145,\n",
       "        8.3942, 8.3723, 8.3879, 8.3895, 8.2586, 8.1863, 8.1157, 8.1453, 8.2991,\n",
       "        8.5042, 8.5707, 8.3827, 8.2897, 8.3082, 8.3576, 8.4437, 8.3720, 8.3499,\n",
       "        8.3553, 8.4424, 8.6077, 8.7945, 8.9107, 8.8537, 8.6762, 8.4596, 8.3965,\n",
       "        8.4743, 8.4732, 8.4745, 8.4137, 8.3783, 8.4187, 8.5172, 8.5542, 8.5001,\n",
       "        8.3513, 8.3412, 8.3639, 8.3685, 8.4492, 8.5203, 8.5225, 8.4767, 8.4430,\n",
       "        8.4803, 8.4840, 8.4778, 8.3981, 8.2585, 8.2641, 8.3165, 8.4523, 8.6655,\n",
       "        8.6922, 8.6528, 8.5731, 8.5963, 8.6090, 8.5750, 8.5017, 8.3122, 8.2172,\n",
       "        8.2305, 8.3152, 8.4151, 8.3799, 8.3377, 8.2219, 8.1541, 8.1940, 8.1860,\n",
       "        8.1818, 8.1487, 8.1003, 8.1385, 8.2044, 8.3073, 8.3408, 8.3432, 8.3064,\n",
       "        8.2343, 8.2306, 8.2340, 8.3174, 8.4087, 8.3673, 8.3396, 8.3185, 8.3351,\n",
       "        8.3812, 8.4043, 8.3169, 8.2507, 8.2548, 8.3025, 8.3032, 8.4400, 8.5054,\n",
       "        8.4615, 8.4789, 8.4405, 8.3606, 8.3309, 8.2811, 8.2527, 8.1935, 8.0921,\n",
       "        8.0603, 8.0643, 8.1371, 8.1597, 8.1923, 8.2566, 8.2350, 8.2766, 8.2200,\n",
       "        8.2105, 8.1901, 8.1692, 8.2243, 8.2696, 8.3784, 8.4270, 8.3297, 8.2606,\n",
       "        8.1895, 8.2298, 8.2817, 8.3382, 8.3131, 8.1945, 8.2162, 8.3071, 8.3950,\n",
       "        8.4717, 8.3877, 8.3424, 8.3004, 8.2554, 8.2501, 8.2556, 8.2842, 8.2008,\n",
       "        8.1936, 8.1797, 8.1650, 8.1882, 8.1151, 7.9904, 7.9645, 8.0153, 8.1139,\n",
       "        8.3036, 8.4288, 8.4634, 8.4314, 8.4792, 8.4846, 8.4590, 8.4230, 8.3480,\n",
       "        8.2549, 8.2556, 8.2682, 8.4277, 8.4924, 8.5005, 8.3672, 8.2593, 8.2575,\n",
       "        8.2358, 8.2484, 8.2928, 8.2244, 8.2807, 8.3239, 8.4206, 8.4575, 8.4366,\n",
       "        8.4217, 8.3268, 8.2591, 8.2391, 8.1488, 8.2404, 8.2285, 8.2274, 8.2008,\n",
       "        8.2400, 8.3494, 8.4042, 8.3536, 8.3053, 8.2886, 8.3697, 8.3163, 8.4621,\n",
       "        8.5762, 8.5867, 8.5139, 8.4465, 8.4775, 8.5353, 8.5258, 8.4248, 8.2366,\n",
       "        8.1806, 8.1940, 8.3164, 8.4453, 8.4165, 8.3284, 8.3828, 8.4249, 8.4153,\n",
       "        8.3516, 8.3773, 8.3893, 8.3911, 8.4163, 8.4334, 8.4920, 8.5898, 8.5169,\n",
       "        8.4587, 8.3965, 8.3922, 8.3982, 8.4813, 8.5149, 8.3891, 8.3136, 8.4242,\n",
       "        8.4333, 8.5037, 8.4392, 8.4740, 8.4810, 8.3873, 8.3490, 8.4261, 8.5913,\n",
       "        8.6368, 8.5349, 8.4835, 8.4255, 8.4884, 8.4607, 8.3561, 8.2155, 8.1046,\n",
       "        8.1613, 8.3496, 8.4897, 8.5761, 8.4592, 8.4446, 8.4498, 8.5074, 8.6303,\n",
       "        8.6711, 8.5995, 8.5150, 8.5125, 8.6228, 8.6313, 8.6553, 8.5716, 8.5314,\n",
       "        8.5060, 8.5123, 8.5549, 8.6520, 8.5993, 8.5470, 8.5099, 8.6330, 8.6990,\n",
       "        8.6727, 8.6567, 8.5921, 8.4656, 8.3872, 8.3067, 8.3528, 8.3158, 8.2958,\n",
       "        8.2536, 8.2491, 8.2610, 8.2860, 8.3016, 8.3635, 8.3185, 8.3735, 8.3922,\n",
       "        8.5648, 8.6918, 8.6860, 8.6972, 8.6288, 8.5422, 8.5233, 8.4503, 8.4646,\n",
       "        8.2686, 8.1693, 8.1365, 8.2116, 8.3195, 8.3290, 8.2490, 8.2663, 8.2499,\n",
       "        8.3156, 8.3058, 8.3515, 8.2892, 8.1742, 8.1510, 8.1762, 8.2484, 8.3566,\n",
       "        8.3101, 8.2472, 8.1334, 8.1256, 8.1612, 8.2252, 8.2864, 8.2457, 8.2287,\n",
       "        8.3535, 8.4104, 8.5214, 8.5000, 8.5427, 8.4744, 8.4141, 8.4322, 8.4927,\n",
       "        8.5700, 8.5236, 8.3806, 8.3406, 8.2160, 8.1975, 8.1427, 8.0859, 8.0827,\n",
       "        8.0864, 8.0914, 8.2057, 8.2324, 8.3257, 8.2988, 8.3558, 8.3478, 8.2656,\n",
       "        8.2276, 8.2010, 8.1673, 8.1501, 8.0668, 8.1675, 8.2998, 8.5149, 8.5226,\n",
       "        8.4534, 8.4283, 8.4091, 8.3732, 8.4700, 8.4649, 8.4699, 8.3644, 8.3901,\n",
       "        8.4362, 8.5747, 8.7092, 8.6909, 8.4671, 8.2831, 8.1250, 8.1565, 8.2686,\n",
       "        8.3426, 8.2706, 8.2402, 8.3303, 8.4585, 8.4720, 8.4587, 8.3992, 8.4024,\n",
       "        8.3888, 8.4580, 8.5595, 8.7199, 8.8228, 8.7820, 8.7289, 8.7132, 8.6285,\n",
       "        8.6293, 8.5200, 8.3937, 8.3213, 8.3844, 8.5634, 8.6962, 8.6929, 8.6526,\n",
       "        8.5797, 8.5278, 8.4470, 8.4266, 8.4518, 8.3931, 8.3483, 8.3403, 8.3592,\n",
       "        8.4043, 8.4023, 8.3682, 8.3072, 8.2377, 8.1815, 8.1423, 8.1586, 8.1902,\n",
       "        8.2641, 8.3887, 8.4059, 8.4524, 8.4658, 8.4601, 8.4406, 8.3926, 8.3742,\n",
       "        8.3587, 8.4128, 8.5300, 8.4965, 8.4757, 8.4081, 8.4439, 8.4355, 8.4042,\n",
       "        8.3397, 8.2686, 8.3085, 8.4040, 8.4297, 8.4562, 8.4666, 8.4645, 8.4462,\n",
       "        8.4309, 8.4497, 8.3802, 8.2826, 8.1773, 8.1387, 8.1863, 8.2431, 8.3727,\n",
       "        8.4586, 8.4498, 8.4664, 8.5059, 8.5100, 8.5170, 8.4283, 8.4719, 8.4876,\n",
       "        8.5590, 8.6290, 8.6589, 8.7833, 8.8403, 8.7654, 8.5755, 8.4317, 8.3786,\n",
       "        8.3206, 8.3993, 8.4273, 8.4234, 8.4873, 8.5258, 8.6243, 8.6964, 8.6558,\n",
       "        8.6121, 8.5484, 8.5289, 8.4580, 8.4529, 8.5457, 8.4855, 8.3990, 8.3682,\n",
       "        8.3480, 8.4050, 8.3661, 8.3367, 8.3654, 8.6515], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assdis2=association_discrepancy(prior,series)\n",
    "assdis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5026.4385, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(assdis2,ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.norm(association_discrepancy(P_list, S_list), ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b11a86450>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assdis2=association_discrepancy(prior,series)\n",
    "plt.plot(assdis2.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0124, -0.0116, -0.0109,  ..., -0.0137, -0.0137, -0.0123],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([-0.0124, -0.0116, -0.0109,  ..., -0.0137, -0.0137, -0.0123],\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(assdis2[assdis2.cpu()!=assdis.cpu()])\n",
    "print(assdis[assdis2.cpu()!=assdis.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8152, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assdis[0,0,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7941e+01, 3.4628e+05, 3.4967e+05,  ..., 7.1304e+00, 6.7978e+00,\n",
       "         6.6801e+00],\n",
       "        [2.1250e+01, 4.8721e+01, 7.5540e+01,  ..., 1.2235e+01, 1.0733e+01,\n",
       "         1.0075e+01],\n",
       "        [3.5049e+05, 1.5828e+04, 1.0170e+05,  ..., 3.6465e+05, 3.6183e+05,\n",
       "         3.4732e+05],\n",
       "        ...,\n",
       "        [6.0611e+01, 2.9842e+02, 5.5153e+02,  ..., 2.0121e+01, 1.6669e+01,\n",
       "         3.6993e+01],\n",
       "        [9.0725e+03, 3.5250e+05, 3.5192e+05,  ..., 1.2228e+01, 1.2015e+01,\n",
       "         5.8743e+03],\n",
       "        [2.5932e+01, 2.9729e+05, 3.4705e+05,  ..., 7.3222e+00, 6.9563e+00,\n",
       "         7.2937e+00]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f50fc7aa350>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prior[0][12,1,9].cpu().detach().numpy()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5104984650>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(assdis[12].cpu().detach().numpy()-8)\n",
    "plt.plot(x_aux[12].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturoSF/.conda/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0560fa7b90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assdis=layer_association_discrepancy(prior[0][0,0],series[0][0,0])\n",
    "print(assdis.shape)\n",
    "plt.plot(assdis.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[39m=\u001b[39massociation_discrepancy(prior,series)\n\u001b[1;32m      2\u001b[0m a\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prior' is not defined"
     ]
    }
   ],
   "source": [
    "a=association_discrepancy(prior,series)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 600, 600])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 600, 600])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux=prior[0]/torch.unsqueeze(torch.sum(prior[0], dim=-1), dim=-1).repeat(1, 1, 1, 600)\n",
    "aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f510ad21090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(aux[3,1].cpu().detach().numpy()[:400,:400])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seguimos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnomalyTransformer(\n",
       "  (embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (inner_attention): AnomalyAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (sigma_projection): Linear(in_features=32, out_features=2, bias=True)\n",
       "          (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo=AnomalyTransformer.AnomalyTransformer(600, 1, 1, d_model=32, n_heads=2, e_layers=2, d_ff=32,\n",
    "                          dropout=0.0, activation='gelu', output_attention=True)\n",
    "modelo.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veamos a ver si hay nans en los parámetros \n",
    "a=list(modelo.parameters())\n",
    "if len([i for i in a if i.isnan().sum().item()!=0])>0:\n",
    "    print(\"HAY NANS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(modelo.parameters(), lr=1e-4)\n",
    "modelo.train();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 600, 1])\n",
      "torch.Size([32, 600, 1]) 2 torch.Size([32, 2, 600, 600]) 2 torch.Size([32, 2, 600, 600])\n"
     ]
    }
   ],
   "source": [
    "#lo vamos a hacer paso por paso\n",
    "\n",
    "\n",
    "x_aux=next(iter(dataloader))\n",
    "x_aux=x_aux.float().cuda()\n",
    "print(x_aux.shape)\n",
    "\n",
    "outputs, series, prior, _ = modelo(x_aux)\n",
    "prior=[j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600) for j in prior]\n",
    "\n",
    "print(outputs.shape,len(series),series[0].shape ,len(prior) , prior[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2457],\n",
      "         [-0.7826],\n",
      "         [-0.8106],\n",
      "         ...,\n",
      "         [-0.0089],\n",
      "         [ 0.1240],\n",
      "         [-0.3946]],\n",
      "\n",
      "        [[-1.2956],\n",
      "         [-0.7836],\n",
      "         [-0.7987],\n",
      "         ...,\n",
      "         [ 0.1260],\n",
      "         [ 0.2409],\n",
      "         [-0.3168]],\n",
      "\n",
      "        [[-0.8853],\n",
      "         [-0.6177],\n",
      "         [-0.7039],\n",
      "         ...,\n",
      "         [-0.5409],\n",
      "         [-0.3251],\n",
      "         [-0.6104]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0066],\n",
      "         [-0.7840],\n",
      "         [-0.7939],\n",
      "         ...,\n",
      "         [-0.8743],\n",
      "         [-0.8345],\n",
      "         [-0.9007]],\n",
      "\n",
      "        [[-1.4423],\n",
      "         [-0.7885],\n",
      "         [-0.7953],\n",
      "         ...,\n",
      "         [ 0.1939],\n",
      "         [ 0.3084],\n",
      "         [-0.3306]],\n",
      "\n",
      "        [[-1.3037],\n",
      "         [-0.8210],\n",
      "         [-0.8248],\n",
      "         ...,\n",
      "         [ 0.1094],\n",
      "         [ 0.1808],\n",
      "         [-0.3736]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f68743df890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(outputs)\n",
    "plt.imshow(outputs.squeeze().cpu().detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(275.9006, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(831.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(275.9006, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(-824.1691, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_min_1 = min_loss(outputs,prior,series, x_aux,3)\n",
    "loss_min=loss_min_1\n",
    "print(loss_min)\n",
    "\n",
    "\n",
    "loss_max_1 = max_loss(outputs,prior,series, x_aux,3)\n",
    "loss_max=loss_max_1\n",
    "print(loss_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3818, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_crit=criterion(outputs,x_aux)\n",
    "loss_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_crit.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossmse(x,x_hat):\n",
    "    return ((x - x_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d64350510>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prior[0][1,1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior[0].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(256.4609, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-768.7944, device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=loss_function(x_hat=outputs, P_list=prior, S_list=series, lambda_=3, x=x_aux) #x_hat, P_list, S_list, lambda_, x \n",
    "#loss=((outputs - x_aux)**2).mean()\n",
    "#loss=lossmse(outputs, x_aux)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.5651, device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(outputs[13].squeeze().detach().cpu().numpy())\n",
    "plt.plot(x_aux[13].squeeze().detach().cpu().numpy())\n",
    "print(torch.sqrt(((outputs[13]-x_aux[13])**2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min.backward(retain_graph=True)\n",
    "loss_max.backward()\n",
    "#loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_gradients(modelo, max_norm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "#optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2429],\n",
       "          [-0.7732],\n",
       "          [-0.8010],\n",
       "          ...,\n",
       "          [-0.0130],\n",
       "          [ 0.1199],\n",
       "          [-0.3954]],\n",
       " \n",
       "         [[-1.2936],\n",
       "          [-0.7734],\n",
       "          [-0.7882],\n",
       "          ...,\n",
       "          [ 0.1198],\n",
       "          [ 0.2347],\n",
       "          [-0.3192]],\n",
       " \n",
       "         [[-0.8820],\n",
       "          [-0.6110],\n",
       "          [-0.6965],\n",
       "          ...,\n",
       "          [-0.5382],\n",
       "          [-0.3231],\n",
       "          [-0.6072]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.9932],\n",
       "          [-0.7700],\n",
       "          [-0.7800],\n",
       "          ...,\n",
       "          [-0.8590],\n",
       "          [-0.8189],\n",
       "          [-0.8858]],\n",
       " \n",
       "         [[-1.4403],\n",
       "          [-0.7741],\n",
       "          [-0.7812],\n",
       "          ...,\n",
       "          [ 0.1823],\n",
       "          [ 0.2968],\n",
       "          [-0.3337]],\n",
       " \n",
       "         [[-1.3014],\n",
       "          [-0.8111],\n",
       "          [-0.8147],\n",
       "          ...,\n",
       "          [ 0.1034],\n",
       "          [ 0.1749],\n",
       "          [-0.3756]]], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " [tensor([[[[1.8798e-03, 9.9098e-04, 9.2239e-04,  ..., 3.0771e-03,\n",
       "             2.7537e-03, 2.1140e-03],\n",
       "            [8.6156e-04, 2.4344e-03, 2.1151e-03,  ..., 1.5432e-03,\n",
       "             1.2627e-03, 1.1145e-03],\n",
       "            [8.2955e-04, 2.5179e-03, 2.2042e-03,  ..., 1.4955e-03,\n",
       "             1.2207e-03, 1.1224e-03],\n",
       "            ...,\n",
       "            [2.7996e-03, 8.9090e-04, 1.0271e-03,  ..., 1.6727e-03,\n",
       "             1.9302e-03, 2.0767e-03],\n",
       "            [2.4958e-03, 9.5195e-04, 1.1105e-03,  ..., 1.6982e-03,\n",
       "             1.9823e-03, 2.4054e-03],\n",
       "            [3.8923e-03, 9.8446e-04, 1.1547e-03,  ..., 1.5703e-03,\n",
       "             1.7994e-03, 1.6495e-03]],\n",
       "  \n",
       "           [[9.3450e-04, 2.9784e-03, 2.6745e-03,  ..., 8.7740e-04,\n",
       "             8.9559e-04, 1.3984e-03],\n",
       "            [1.6871e-03, 1.7542e-03, 1.5177e-03,  ..., 2.3740e-03,\n",
       "             2.2998e-03, 1.9123e-03],\n",
       "            [1.6888e-03, 1.6372e-03, 1.3723e-03,  ..., 2.4611e-03,\n",
       "             2.3554e-03, 1.7827e-03],\n",
       "            ...,\n",
       "            [1.8631e-03, 2.0523e-03, 2.0996e-03,  ..., 8.5517e-04,\n",
       "             8.4948e-04, 1.4003e-03],\n",
       "            [1.8974e-03, 2.1351e-03, 2.1184e-03,  ..., 8.6879e-04,\n",
       "             8.5005e-04, 1.2319e-03],\n",
       "            [2.2518e-03, 2.8820e-03, 2.8348e-03,  ..., 6.0517e-04,\n",
       "             6.1082e-04, 1.5914e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[2.4006e-03, 7.5573e-04, 7.0879e-04,  ..., 3.7486e-03,\n",
       "             3.3405e-03, 2.1911e-03],\n",
       "            [4.7926e-04, 3.0625e-03, 2.5319e-03,  ..., 1.0843e-03,\n",
       "             8.4278e-04, 6.9835e-04],\n",
       "            [4.6297e-04, 3.1215e-03, 2.6078e-03,  ..., 1.0442e-03,\n",
       "             8.1333e-04, 7.1626e-04],\n",
       "            ...,\n",
       "            [4.1494e-03, 5.4528e-04, 6.6607e-04,  ..., 1.9012e-03,\n",
       "             2.3377e-03, 2.7057e-03],\n",
       "            [3.6073e-03, 5.9132e-04, 7.3120e-04,  ..., 1.9319e-03,\n",
       "             2.4065e-03, 3.2782e-03],\n",
       "            [6.9601e-03, 4.7275e-04, 5.9875e-04,  ..., 1.6723e-03,\n",
       "             2.0521e-03, 1.6173e-03]],\n",
       "  \n",
       "           [[5.0754e-04, 3.4822e-03, 2.9860e-03,  ..., 4.9185e-04,\n",
       "             5.0121e-04, 1.0502e-03],\n",
       "            [1.4931e-03, 1.4686e-03, 1.2562e-03,  ..., 2.8991e-03,\n",
       "             2.8170e-03, 2.0133e-03],\n",
       "            [1.4761e-03, 1.3511e-03, 1.1240e-03,  ..., 2.9986e-03,\n",
       "             2.8797e-03, 1.8242e-03],\n",
       "            ...,\n",
       "            [1.8508e-03, 2.3495e-03, 2.4281e-03,  ..., 5.5940e-04,\n",
       "             5.5132e-04, 1.1734e-03],\n",
       "            [1.8575e-03, 2.4608e-03, 2.4685e-03,  ..., 5.6386e-04,\n",
       "             5.4727e-04, 9.8867e-04],\n",
       "            [2.1098e-03, 3.5040e-03, 3.4634e-03,  ..., 2.6885e-04,\n",
       "             2.7205e-04, 1.4855e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[1.5523e-03, 1.3899e-03, 1.3019e-03,  ..., 2.1727e-03,\n",
       "             2.0043e-03, 1.8762e-03],\n",
       "            [1.5797e-03, 1.6448e-03, 1.5562e-03,  ..., 2.1590e-03,\n",
       "             1.9446e-03, 1.8669e-03],\n",
       "            [1.5639e-03, 1.6832e-03, 1.6024e-03,  ..., 2.2022e-03,\n",
       "             1.9660e-03, 1.9097e-03],\n",
       "            ...,\n",
       "            [1.6631e-03, 1.5647e-03, 1.6067e-03,  ..., 1.4769e-03,\n",
       "             1.4605e-03, 1.4412e-03],\n",
       "            [1.6017e-03, 1.5716e-03, 1.6474e-03,  ..., 1.5291e-03,\n",
       "             1.5462e-03, 1.6055e-03],\n",
       "            [1.7095e-03, 1.6737e-03, 1.7533e-03,  ..., 1.4950e-03,\n",
       "             1.5162e-03, 1.5707e-03]],\n",
       "  \n",
       "           [[1.7201e-03, 2.0156e-03, 1.9231e-03,  ..., 1.9181e-03,\n",
       "             1.8662e-03, 1.9078e-03],\n",
       "            [1.9400e-03, 1.9511e-03, 1.7724e-03,  ..., 2.0160e-03,\n",
       "             1.9261e-03, 1.8382e-03],\n",
       "            [1.9912e-03, 1.9059e-03, 1.6756e-03,  ..., 1.9948e-03,\n",
       "             1.8926e-03, 1.7626e-03],\n",
       "            ...,\n",
       "            [1.8130e-03, 1.6437e-03, 1.5726e-03,  ..., 1.3856e-03,\n",
       "             1.3846e-03, 1.5295e-03],\n",
       "            [1.8961e-03, 1.7107e-03, 1.5984e-03,  ..., 1.3946e-03,\n",
       "             1.3695e-03, 1.4410e-03],\n",
       "            [2.0057e-03, 1.8333e-03, 1.7002e-03,  ..., 1.3379e-03,\n",
       "             1.3125e-03, 1.4329e-03]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[2.0475e-03, 6.5287e-03, 4.6025e-03,  ..., 2.2246e-03,\n",
       "             1.5340e-03, 9.7459e-04],\n",
       "            [1.4299e-03, 8.0639e-03, 5.6262e-03,  ..., 1.2442e-03,\n",
       "             8.6286e-04, 6.0394e-04],\n",
       "            [1.3359e-03, 8.0849e-03, 5.6674e-03,  ..., 1.1540e-03,\n",
       "             7.9962e-04, 5.7372e-04],\n",
       "            ...,\n",
       "            [2.9120e-03, 6.4333e-03, 5.4653e-03,  ..., 1.6728e-03,\n",
       "             1.3959e-03, 1.0498e-03],\n",
       "            [2.5945e-03, 6.8823e-03, 5.8440e-03,  ..., 1.5784e-03,\n",
       "             1.3238e-03, 1.0511e-03],\n",
       "            [2.9286e-03, 7.9157e-03, 6.5748e-03,  ..., 1.4848e-03,\n",
       "             1.1970e-03, 8.7497e-04]],\n",
       "  \n",
       "           [[1.3415e-04, 1.3882e-04, 1.0409e-04,  ..., 3.3399e-04,\n",
       "             3.1726e-04, 2.6826e-04],\n",
       "            [1.2267e-05, 8.2813e-06, 5.8183e-06,  ..., 3.9575e-05,\n",
       "             3.3768e-05, 2.1709e-05],\n",
       "            [7.5216e-06, 4.7530e-06, 3.2137e-06,  ..., 2.5010e-05,\n",
       "             2.0835e-05, 1.2583e-05],\n",
       "            ...,\n",
       "            [7.1899e-05, 4.9419e-05, 4.0057e-05,  ..., 1.1741e-04,\n",
       "             1.0748e-04, 1.0074e-04],\n",
       "            [5.3249e-05, 3.5758e-05, 2.7775e-05,  ..., 8.9502e-05,\n",
       "             8.0108e-05, 6.8292e-05],\n",
       "            [7.0340e-05, 4.7996e-05, 3.6546e-05,  ..., 1.0150e-04,\n",
       "             9.2326e-05, 8.8798e-05]]],\n",
       "  \n",
       "  \n",
       "          [[[4.8243e-03, 3.3531e-04, 2.8660e-04,  ..., 4.5986e-03,\n",
       "             3.8901e-03, 9.4716e-04],\n",
       "            [7.3022e-06, 5.2112e-03, 4.0589e-03,  ..., 7.5554e-05,\n",
       "             3.9849e-05, 1.5456e-05],\n",
       "            [5.1267e-06, 5.2509e-03, 4.1068e-03,  ..., 5.5980e-05,\n",
       "             2.8775e-05, 1.1836e-05],\n",
       "            ...,\n",
       "            [7.3759e-03, 1.0729e-04, 1.2751e-04,  ..., 1.3105e-03,\n",
       "             1.8688e-03, 2.8071e-03],\n",
       "            [6.3557e-03, 9.5821e-05, 1.1710e-04,  ..., 1.3119e-03,\n",
       "             1.9439e-03, 4.0976e-03],\n",
       "            [1.1983e-02, 5.1194e-06, 6.2301e-06,  ..., 3.3164e-04,\n",
       "             5.4233e-04, 1.7933e-04]],\n",
       "  \n",
       "           [[2.9822e-05, 4.7365e-03, 4.0468e-03,  ..., 7.5744e-05,\n",
       "             6.9808e-05, 4.7234e-04],\n",
       "            [2.2301e-04, 1.1590e-04, 8.4579e-05,  ..., 3.5128e-03,\n",
       "             3.8263e-03, 1.3204e-03],\n",
       "            [1.6194e-04, 7.0615e-05, 4.9341e-05,  ..., 3.2869e-03,\n",
       "             3.5881e-03, 9.4213e-04],\n",
       "            ...,\n",
       "            [1.9601e-03, 3.3792e-03, 3.7940e-03,  ..., 2.0991e-04,\n",
       "             1.9040e-04, 7.0319e-04],\n",
       "            [1.7444e-03, 3.5718e-03, 3.9484e-03,  ..., 1.6963e-04,\n",
       "             1.5013e-04, 4.4634e-04],\n",
       "            [1.3127e-03, 5.9571e-03, 6.8746e-03,  ..., 9.6346e-06,\n",
       "             8.5913e-06, 1.0792e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[2.1452e-03, 8.3667e-04, 7.7077e-04,  ..., 3.6018e-03,\n",
       "             3.1458e-03, 2.1229e-03],\n",
       "            [5.8949e-04, 2.9546e-03, 2.5362e-03,  ..., 1.0902e-03,\n",
       "             8.6967e-04, 7.4063e-04],\n",
       "            [5.4511e-04, 3.0904e-03, 2.6702e-03,  ..., 1.0135e-03,\n",
       "             8.0754e-04, 7.2772e-04],\n",
       "            ...,\n",
       "            [3.8335e-03, 5.3845e-04, 6.3903e-04,  ..., 2.0789e-03,\n",
       "             2.5127e-03, 2.7918e-03],\n",
       "            [3.3526e-03, 6.1535e-04, 7.3503e-04,  ..., 2.0845e-03,\n",
       "             2.5323e-03, 3.1820e-03],\n",
       "            [5.6023e-03, 5.7978e-04, 6.9027e-04,  ..., 1.9044e-03,\n",
       "             2.2046e-03, 1.7536e-03]],\n",
       "  \n",
       "           [[6.6260e-04, 3.4560e-03, 3.0816e-03,  ..., 5.4747e-04,\n",
       "             5.8433e-04, 1.1510e-03],\n",
       "            [1.5069e-03, 1.5120e-03, 1.2884e-03,  ..., 2.7926e-03,\n",
       "             2.6634e-03, 1.9937e-03],\n",
       "            [1.4759e-03, 1.3453e-03, 1.1112e-03,  ..., 2.9823e-03,\n",
       "             2.7907e-03, 1.8202e-03],\n",
       "            ...,\n",
       "            [1.8910e-03, 2.4964e-03, 2.6133e-03,  ..., 5.3001e-04,\n",
       "             5.4752e-04, 1.1829e-03],\n",
       "            [1.8969e-03, 2.5795e-03, 2.6115e-03,  ..., 5.5271e-04,\n",
       "             5.6126e-04, 1.0424e-03],\n",
       "            [2.2718e-03, 3.6600e-03, 3.6300e-03,  ..., 3.3150e-04,\n",
       "             3.5742e-04, 1.5547e-03]]]], device='cuda:0',\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[[[0.0012, 0.0015, 0.0015,  ..., 0.0008, 0.0008, 0.0009],\n",
       "            [0.0025, 0.0020, 0.0022,  ..., 0.0006, 0.0006, 0.0008],\n",
       "            [0.0021, 0.0021, 0.0023,  ..., 0.0004, 0.0005, 0.0007],\n",
       "            ...,\n",
       "            [0.0014, 0.0015, 0.0014,  ..., 0.0019, 0.0017, 0.0021],\n",
       "            [0.0012, 0.0015, 0.0014,  ..., 0.0017, 0.0016, 0.0020],\n",
       "            [0.0007, 0.0015, 0.0015,  ..., 0.0006, 0.0006, 0.0008]],\n",
       "  \n",
       "           [[0.0023, 0.0024, 0.0024,  ..., 0.0014, 0.0015, 0.0010],\n",
       "            [0.0021, 0.0026, 0.0027,  ..., 0.0010, 0.0011, 0.0012],\n",
       "            [0.0019, 0.0025, 0.0026,  ..., 0.0010, 0.0011, 0.0012],\n",
       "            ...,\n",
       "            [0.0011, 0.0012, 0.0012,  ..., 0.0014, 0.0014, 0.0013],\n",
       "            [0.0011, 0.0011, 0.0011,  ..., 0.0015, 0.0015, 0.0015],\n",
       "            [0.0014, 0.0014, 0.0013,  ..., 0.0015, 0.0015, 0.0013]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0012, 0.0015, 0.0015,  ..., 0.0009, 0.0009, 0.0010],\n",
       "            [0.0027, 0.0021, 0.0023,  ..., 0.0006, 0.0006, 0.0009],\n",
       "            [0.0023, 0.0022, 0.0023,  ..., 0.0005, 0.0005, 0.0008],\n",
       "            ...,\n",
       "            [0.0013, 0.0015, 0.0014,  ..., 0.0020, 0.0019, 0.0022],\n",
       "            [0.0011, 0.0015, 0.0014,  ..., 0.0019, 0.0018, 0.0022],\n",
       "            [0.0007, 0.0016, 0.0016,  ..., 0.0007, 0.0006, 0.0008]],\n",
       "  \n",
       "           [[0.0021, 0.0024, 0.0024,  ..., 0.0014, 0.0014, 0.0009],\n",
       "            [0.0020, 0.0026, 0.0027,  ..., 0.0009, 0.0010, 0.0011],\n",
       "            [0.0019, 0.0025, 0.0027,  ..., 0.0009, 0.0010, 0.0011],\n",
       "            ...,\n",
       "            [0.0011, 0.0011, 0.0011,  ..., 0.0017, 0.0017, 0.0016],\n",
       "            [0.0011, 0.0010, 0.0010,  ..., 0.0018, 0.0017, 0.0017],\n",
       "            [0.0014, 0.0013, 0.0013,  ..., 0.0017, 0.0017, 0.0014]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0015, 0.0015, 0.0015,  ..., 0.0009, 0.0009, 0.0010],\n",
       "            [0.0017, 0.0017, 0.0018,  ..., 0.0008, 0.0008, 0.0009],\n",
       "            [0.0014, 0.0016, 0.0018,  ..., 0.0007, 0.0006, 0.0007],\n",
       "            ...,\n",
       "            [0.0021, 0.0016, 0.0017,  ..., 0.0009, 0.0008, 0.0011],\n",
       "            [0.0015, 0.0013, 0.0014,  ..., 0.0012, 0.0010, 0.0013],\n",
       "            [0.0008, 0.0010, 0.0011,  ..., 0.0009, 0.0007, 0.0009]],\n",
       "  \n",
       "           [[0.0027, 0.0027, 0.0027,  ..., 0.0018, 0.0018, 0.0015],\n",
       "            [0.0021, 0.0024, 0.0027,  ..., 0.0014, 0.0015, 0.0016],\n",
       "            [0.0017, 0.0022, 0.0025,  ..., 0.0014, 0.0016, 0.0017],\n",
       "            ...,\n",
       "            [0.0014, 0.0016, 0.0017,  ..., 0.0009, 0.0008, 0.0009],\n",
       "            [0.0012, 0.0014, 0.0015,  ..., 0.0008, 0.0008, 0.0009],\n",
       "            [0.0013, 0.0014, 0.0015,  ..., 0.0008, 0.0008, 0.0009]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[0.0024, 0.0022, 0.0023,  ..., 0.0017, 0.0018, 0.0020],\n",
       "            [0.0025, 0.0023, 0.0024,  ..., 0.0018, 0.0019, 0.0021],\n",
       "            [0.0025, 0.0024, 0.0024,  ..., 0.0018, 0.0019, 0.0021],\n",
       "            ...,\n",
       "            [0.0025, 0.0023, 0.0024,  ..., 0.0019, 0.0019, 0.0021],\n",
       "            [0.0025, 0.0023, 0.0024,  ..., 0.0019, 0.0020, 0.0022],\n",
       "            [0.0025, 0.0024, 0.0025,  ..., 0.0019, 0.0020, 0.0022]],\n",
       "  \n",
       "           [[0.0027, 0.0027, 0.0027,  ..., 0.0025, 0.0026, 0.0024],\n",
       "            [0.0027, 0.0026, 0.0027,  ..., 0.0024, 0.0025, 0.0025],\n",
       "            [0.0026, 0.0026, 0.0027,  ..., 0.0024, 0.0025, 0.0025],\n",
       "            ...,\n",
       "            [0.0026, 0.0026, 0.0026,  ..., 0.0023, 0.0024, 0.0023],\n",
       "            [0.0026, 0.0025, 0.0026,  ..., 0.0023, 0.0023, 0.0023],\n",
       "            [0.0025, 0.0025, 0.0025,  ..., 0.0022, 0.0023, 0.0023]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0015, 0.0016, 0.0017,  ..., 0.0009, 0.0010, 0.0011],\n",
       "            [0.0026, 0.0023, 0.0024,  ..., 0.0006, 0.0007, 0.0010],\n",
       "            [0.0025, 0.0023, 0.0024,  ..., 0.0006, 0.0006, 0.0010],\n",
       "            ...,\n",
       "            [0.0014, 0.0015, 0.0014,  ..., 0.0021, 0.0020, 0.0022],\n",
       "            [0.0013, 0.0015, 0.0015,  ..., 0.0021, 0.0019, 0.0022],\n",
       "            [0.0010, 0.0019, 0.0019,  ..., 0.0007, 0.0007, 0.0008]],\n",
       "  \n",
       "           [[0.0019, 0.0023, 0.0023,  ..., 0.0013, 0.0013, 0.0009],\n",
       "            [0.0018, 0.0026, 0.0026,  ..., 0.0008, 0.0008, 0.0009],\n",
       "            [0.0018, 0.0026, 0.0026,  ..., 0.0008, 0.0008, 0.0009],\n",
       "            ...,\n",
       "            [0.0011, 0.0010, 0.0010,  ..., 0.0021, 0.0021, 0.0021],\n",
       "            [0.0011, 0.0009, 0.0009,  ..., 0.0021, 0.0021, 0.0022],\n",
       "            [0.0014, 0.0014, 0.0014,  ..., 0.0018, 0.0019, 0.0015]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0012, 0.0015, 0.0015,  ..., 0.0008, 0.0009, 0.0010],\n",
       "            [0.0027, 0.0021, 0.0023,  ..., 0.0006, 0.0006, 0.0009],\n",
       "            [0.0023, 0.0022, 0.0023,  ..., 0.0005, 0.0005, 0.0008],\n",
       "            ...,\n",
       "            [0.0012, 0.0015, 0.0014,  ..., 0.0020, 0.0019, 0.0021],\n",
       "            [0.0011, 0.0015, 0.0014,  ..., 0.0018, 0.0017, 0.0020],\n",
       "            [0.0007, 0.0016, 0.0016,  ..., 0.0006, 0.0006, 0.0008]],\n",
       "  \n",
       "           [[0.0022, 0.0024, 0.0024,  ..., 0.0013, 0.0014, 0.0009],\n",
       "            [0.0021, 0.0026, 0.0027,  ..., 0.0010, 0.0010, 0.0012],\n",
       "            [0.0019, 0.0026, 0.0027,  ..., 0.0010, 0.0010, 0.0012],\n",
       "            ...,\n",
       "            [0.0011, 0.0011, 0.0011,  ..., 0.0017, 0.0017, 0.0015],\n",
       "            [0.0011, 0.0011, 0.0011,  ..., 0.0018, 0.0017, 0.0016],\n",
       "            [0.0014, 0.0013, 0.0013,  ..., 0.0017, 0.0017, 0.0014]]]],\n",
       "         device='cuda:0', grad_fn=<SoftmaxBackward0>)],\n",
       " [tensor([[[[3.4003e-01, 2.3647e-01, 7.9526e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.6450e-02, 1.1644e+00, 1.6450e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [5.0090e-11, 3.3931e-03, 1.3832e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1833e+00,\n",
       "             4.7515e-14, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3276e-19,\n",
       "             3.7760e+00, 1.3276e-19],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 6.3325e+00]],\n",
       "  \n",
       "           [[7.0283e-01, 1.4890e-01, 1.4158e-03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 3.8745e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 1.3817e+01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1617e-01,\n",
       "             1.8665e-01, 1.2016e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.8240e-01,\n",
       "             2.0932e-01, 1.8240e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.1965e-02,\n",
       "             2.3921e-01, 3.5700e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[3.0689e-01, 2.2829e-01, 9.3969e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.5896e-03, 1.4748e+00, 1.5896e-03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.3519e-16, 1.6179e-04, 1.7178e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3138e+00,\n",
       "             1.1475e-07, 1.3996e-29],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9350e-10,\n",
       "             2.7024e+00, 2.9350e-10],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             1.0719e-38, 5.3256e+00]],\n",
       "  \n",
       "           [[3.7427e-01, 2.4103e-01, 6.4374e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 8.6079e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 2.8026e+01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0538e-01,\n",
       "             1.7989e-01, 1.2088e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7824e-01,\n",
       "             2.0283e-01, 1.7824e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.8062e-02,\n",
       "             2.4182e-01, 3.8907e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[4.3555e-01, 2.4000e-01, 4.0152e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.4973e-01, 7.0096e-01, 1.4973e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.4932e-04, 9.5975e-02, 8.2828e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.7414e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             8.6212e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 9.4619e+00]],\n",
       "  \n",
       "           [[4.0277e+00, 2.9611e-22, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 5.7866e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [4.6632e-28, 2.7017e-07, 2.2523e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6306e-01,\n",
       "             2.3609e-01, 3.1292e-02],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3300e-01,\n",
       "             3.2409e-01, 2.3300e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.7873e-02,\n",
       "             2.3227e-01, 3.2114e-01]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[3.0279e+00, 9.3788e-13, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 9.8240e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 1.2508e+01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6222e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             6.3430e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 9.5060e+01]],\n",
       "  \n",
       "           [[4.4384e+03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 1.8592e+04, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 1.0795e+04,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.5581e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             6.7542e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 2.5255e+02]]],\n",
       "  \n",
       "  \n",
       "          [[[2.8008e-01, 2.1890e-01, 1.0451e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [2.4158e-36, 5.1602e+00, 2.4158e-36,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 6.7465e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7170e+00,\n",
       "             1.6312e-04, 1.3987e-16],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.2076e-05,\n",
       "             1.7720e+00, 9.2076e-05],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             3.4806e-38, 5.2901e+00]],\n",
       "  \n",
       "           [[2.4397e-01, 2.0236e-01, 1.1548e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 4.6351e+03, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 2.1974e+03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0146e-01,\n",
       "             1.7735e-01, 1.2097e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7654e-01,\n",
       "             2.0023e-01, 1.7654e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.1028e-20,\n",
       "             2.6279e-05, 1.8866e+00]]],\n",
       "  \n",
       "  \n",
       "          [[[3.2231e-01, 2.3256e-01, 8.7362e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [2.3270e-03, 1.4296e+00, 2.3270e-03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [7.7091e-17, 1.4140e-04, 1.7309e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2117e+00,\n",
       "             4.6871e-07, 4.4613e-27],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4601e-10,\n",
       "             2.7441e+00, 1.4601e-10],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             1.2089e-39, 5.3908e+00]],\n",
       "  \n",
       "           [[4.9744e-01, 2.2863e-01, 2.2198e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 7.8708e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 2.8717e+01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0492e-01,\n",
       "             1.7960e-01, 1.2090e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7855e-01,\n",
       "             2.0331e-01, 1.7855e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.4533e-02,\n",
       "             2.3838e-01, 3.5123e-01]]]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[[3.1775e+00, 5.3304e-14, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.1590e-03, 1.5110e+00, 1.1590e-03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [4.1972e-08, 1.6081e-02, 1.1679e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4624e-01,\n",
       "             2.0353e-01, 1.1493e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9809e-01,\n",
       "             2.3595e-01, 1.9809e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.6197e-02,\n",
       "             2.4193e-01, 3.9355e-01]],\n",
       "  \n",
       "           [[2.1240e-01, 1.8433e-01, 1.2049e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7765e-01, 2.0193e-01, 1.7765e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2095e-01, 1.7819e-01, 2.0276e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.9004e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             4.5632e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.5715e-18,\n",
       "             6.2447e-05, 1.8084e+00]]],\n",
       "  \n",
       "  \n",
       "          [[[4.0089e+00, 4.7413e-22, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [4.3569e-03, 1.3514e+00, 4.3569e-03,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [5.2603e-07, 2.8438e-02, 1.0753e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.5546e-01,\n",
       "             2.0811e-01, 1.1250e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0327e-01,\n",
       "             2.4573e-01, 2.0327e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1546e-02,\n",
       "             2.1082e-01, 5.5515e-01]],\n",
       "  \n",
       "           [[2.1390e-01, 1.8526e-01, 1.2037e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7770e-01, 2.0200e-01, 1.7770e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2095e-01, 1.7818e-01, 2.0274e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.8229e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             4.0196e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6805e-09,\n",
       "             1.0563e-02, 1.2306e+00]]],\n",
       "  \n",
       "  \n",
       "          [[[1.2283e+00, 1.0735e-02, 7.1651e-09,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.1824e-02, 1.2142e+00, 1.1824e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [2.5024e-04, 1.0654e-01, 8.0146e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0967e-01,\n",
       "             2.2912e-01, 9.2800e-02],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0430e-01,\n",
       "             2.4774e-01, 2.0430e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1864e-01,\n",
       "             1.9364e-01, 2.2799e-01]],\n",
       "  \n",
       "           [[2.1212e-01, 1.8416e-01, 1.2051e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7868e-01, 2.0351e-01, 1.7868e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2089e-01, 1.7971e-01, 2.0510e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.8052e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             1.2506e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 5.8249e+00]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[1.2517e+00, 9.1165e-03, 3.5222e-09,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [2.8352e-02, 1.0758e+00, 2.8352e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [3.5963e-06, 4.3506e-02, 9.9872e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.3620e-01,\n",
       "             2.1730e-01, 1.4462e-02],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3027e-01,\n",
       "             4.9083e-01, 2.3027e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2281e-02,\n",
       "             2.1262e-01, 5.5005e-01]],\n",
       "  \n",
       "           [[2.0265e-01, 1.7812e-01, 1.2095e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7811e-01, 2.0264e-01, 1.7811e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2095e-01, 1.7837e-01, 2.0304e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2863e-01,\n",
       "             1.9401e-01, 1.1854e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.8982e-01,\n",
       "             2.2143e-01, 1.8982e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2039e-01,\n",
       "             1.8510e-01, 2.1364e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[7.3591e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [3.3418e-02, 1.0471e+00, 3.3418e-02,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [9.6124e-06, 5.3875e-02, 9.5698e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1123e-01,\n",
       "             2.2957e-01, 9.2139e-02],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2308e-01,\n",
       "             2.9116e-01, 2.2308e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3053e-16,\n",
       "             2.0045e-04, 1.6967e+00]],\n",
       "  \n",
       "           [[2.0818e-01, 1.8168e-01, 1.2076e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7796e-01, 2.0240e-01, 1.7796e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2095e-01, 1.7828e-01, 2.0290e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3859e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             3.1422e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4907e-02,\n",
       "             2.4116e-01, 4.2231e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[4.0401e+00, 2.1697e-22, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [9.8066e-04, 1.5298e+00, 9.8066e-04,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [2.9906e-08, 1.4886e-02, 1.1798e+00,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6239e-01,\n",
       "             2.1135e-01, 1.1046e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0708e-01,\n",
       "             2.5335e-01, 2.0708e-01],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3887e-02,\n",
       "             2.1615e-01, 5.3968e-01]],\n",
       "  \n",
       "           [[2.1180e-01, 1.8396e-01, 1.2053e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.7761e-01, 2.0187e-01, 1.7761e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [1.2095e-01, 1.7814e-01, 2.0267e-01,  ..., 0.0000e+00,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0849e+01,\n",
       "             0.0000e+00, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "             3.5468e+01, 0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8059e-10,\n",
       "             5.4461e-03, 1.3222e+00]]]], device='cuda:0', grad_fn=<MulBackward0>)],\n",
       " [tensor([[[[1.1732e+00, 1.1732e+00, 1.1732e+00,  ..., 1.1732e+00,\n",
       "             1.1732e+00, 1.1732e+00],\n",
       "            [3.4261e-01, 3.4261e-01, 3.4261e-01,  ..., 3.4261e-01,\n",
       "             3.4261e-01, 3.4261e-01],\n",
       "            [2.8843e-01, 2.8843e-01, 2.8843e-01,  ..., 2.8843e-01,\n",
       "             2.8843e-01, 2.8843e-01],\n",
       "            ...,\n",
       "            [1.2532e-01, 1.2532e-01, 1.2532e-01,  ..., 1.2532e-01,\n",
       "             1.2532e-01, 1.2532e-01],\n",
       "            [1.0565e-01, 1.0565e-01, 1.0565e-01,  ..., 1.0565e-01,\n",
       "             1.0565e-01, 1.0565e-01],\n",
       "            [6.2999e-02, 6.2999e-02, 6.2999e-02,  ..., 6.2999e-02,\n",
       "             6.2999e-02, 6.2999e-02]],\n",
       "  \n",
       "           [[5.6762e-01, 5.6762e-01, 5.6762e-01,  ..., 5.6762e-01,\n",
       "             5.6762e-01, 5.6762e-01],\n",
       "            [1.0297e-02, 1.0297e-02, 1.0297e-02,  ..., 1.0297e-02,\n",
       "             1.0297e-02, 1.0297e-02],\n",
       "            [2.8874e-02, 2.8874e-02, 2.8874e-02,  ..., 2.8874e-02,\n",
       "             2.8874e-02, 2.8874e-02],\n",
       "            ...,\n",
       "            [1.8455e+00, 1.8455e+00, 1.8455e+00,  ..., 1.8455e+00,\n",
       "             1.8455e+00, 1.8455e+00],\n",
       "            [1.9059e+00, 1.9059e+00, 1.9059e+00,  ..., 1.9059e+00,\n",
       "             1.9059e+00, 1.9059e+00],\n",
       "            [1.1175e+00, 1.1175e+00, 1.1175e+00,  ..., 1.1175e+00,\n",
       "             1.1175e+00, 1.1175e+00]]],\n",
       "  \n",
       "  \n",
       "          [[[1.3000e+00, 1.3000e+00, 1.3000e+00,  ..., 1.3000e+00,\n",
       "             1.3000e+00, 1.3000e+00],\n",
       "            [2.7051e-01, 2.7051e-01, 2.7051e-01,  ..., 2.7051e-01,\n",
       "             2.7051e-01, 2.7051e-01],\n",
       "            [2.3224e-01, 2.3224e-01, 2.3224e-01,  ..., 2.3224e-01,\n",
       "             2.3224e-01, 2.3224e-01],\n",
       "            ...,\n",
       "            [1.7242e-01, 1.7242e-01, 1.7242e-01,  ..., 1.7242e-01,\n",
       "             1.7242e-01, 1.7242e-01],\n",
       "            [1.4762e-01, 1.4762e-01, 1.4762e-01,  ..., 1.4762e-01,\n",
       "             1.4762e-01, 1.4762e-01],\n",
       "            [7.4911e-02, 7.4911e-02, 7.4911e-02,  ..., 7.4911e-02,\n",
       "             7.4911e-02, 7.4911e-02]],\n",
       "  \n",
       "           [[1.0659e+00, 1.0659e+00, 1.0659e+00,  ..., 1.0659e+00,\n",
       "             1.0659e+00, 1.0659e+00],\n",
       "            [4.6346e-03, 4.6346e-03, 4.6346e-03,  ..., 4.6346e-03,\n",
       "             4.6346e-03, 4.6346e-03],\n",
       "            [1.4235e-02, 1.4235e-02, 1.4235e-02,  ..., 1.4235e-02,\n",
       "             1.4235e-02, 1.4235e-02],\n",
       "            ...,\n",
       "            [1.9425e+00, 1.9425e+00, 1.9425e+00,  ..., 1.9425e+00,\n",
       "             1.9425e+00, 1.9425e+00],\n",
       "            [1.9669e+00, 1.9669e+00, 1.9669e+00,  ..., 1.9669e+00,\n",
       "             1.9669e+00, 1.9669e+00],\n",
       "            [1.0254e+00, 1.0254e+00, 1.0254e+00,  ..., 1.0254e+00,\n",
       "             1.0254e+00, 1.0254e+00]]],\n",
       "  \n",
       "  \n",
       "          [[[9.1594e-01, 9.1594e-01, 9.1594e-01,  ..., 9.1594e-01,\n",
       "             9.1594e-01, 9.1594e-01],\n",
       "            [5.6914e-01, 5.6914e-01, 5.6914e-01,  ..., 5.6914e-01,\n",
       "             5.6914e-01, 5.6914e-01],\n",
       "            [4.8165e-01, 4.8165e-01, 4.8165e-01,  ..., 4.8165e-01,\n",
       "             4.8165e-01, 4.8165e-01],\n",
       "            ...,\n",
       "            [5.1533e-02, 5.1533e-02, 5.1533e-02,  ..., 5.1533e-02,\n",
       "             5.1533e-02, 5.1533e-02],\n",
       "            [4.6275e-02, 4.6275e-02, 4.6275e-02,  ..., 4.6275e-02,\n",
       "             4.6275e-02, 4.6275e-02],\n",
       "            [4.2163e-02, 4.2163e-02, 4.2163e-02,  ..., 4.2163e-02,\n",
       "             4.2163e-02, 4.2163e-02]],\n",
       "  \n",
       "           [[9.9049e-02, 9.9049e-02, 9.9049e-02,  ..., 9.9049e-02,\n",
       "             9.9049e-02, 9.9049e-02],\n",
       "            [6.8942e-02, 6.8942e-02, 6.8942e-02,  ..., 6.8942e-02,\n",
       "             6.8942e-02, 6.8942e-02],\n",
       "            [1.7713e-01, 1.7713e-01, 1.7713e-01,  ..., 1.7713e-01,\n",
       "             1.7713e-01, 1.7713e-01],\n",
       "            ...,\n",
       "            [8.6154e-01, 8.6154e-01, 8.6154e-01,  ..., 8.6154e-01,\n",
       "             8.6154e-01, 8.6154e-01],\n",
       "            [1.2309e+00, 1.2309e+00, 1.2309e+00,  ..., 1.2309e+00,\n",
       "             1.2309e+00, 1.2309e+00],\n",
       "            [1.2423e+00, 1.2423e+00, 1.2423e+00,  ..., 1.2423e+00,\n",
       "             1.2423e+00, 1.2423e+00]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[1.3175e-01, 1.3175e-01, 1.3175e-01,  ..., 1.3175e-01,\n",
       "             1.3175e-01, 1.3175e-01],\n",
       "            [4.0609e-02, 4.0609e-02, 4.0609e-02,  ..., 4.0609e-02,\n",
       "             4.0609e-02, 4.0609e-02],\n",
       "            [3.1895e-02, 3.1895e-02, 3.1895e-02,  ..., 3.1895e-02,\n",
       "             3.1895e-02, 3.1895e-02],\n",
       "            ...,\n",
       "            [8.6310e-03, 8.6310e-03, 8.6310e-03,  ..., 8.6310e-03,\n",
       "             8.6310e-03, 8.6310e-03],\n",
       "            [6.2895e-03, 6.2895e-03, 6.2895e-03,  ..., 6.2895e-03,\n",
       "             6.2895e-03, 6.2895e-03],\n",
       "            [4.1968e-03, 4.1968e-03, 4.1968e-03,  ..., 4.1968e-03,\n",
       "             4.1968e-03, 4.1968e-03]],\n",
       "  \n",
       "           [[8.9884e-05, 8.9884e-05, 8.9884e-05,  ..., 8.9884e-05,\n",
       "             8.9884e-05, 8.9884e-05],\n",
       "            [2.1458e-05, 2.1458e-05, 2.1458e-05,  ..., 2.1458e-05,\n",
       "             2.1458e-05, 2.1458e-05],\n",
       "            [3.6955e-05, 3.6955e-05, 3.6955e-05,  ..., 3.6955e-05,\n",
       "             3.6955e-05, 3.6955e-05],\n",
       "            ...,\n",
       "            [5.2783e-03, 5.2783e-03, 5.2783e-03,  ..., 5.2783e-03,\n",
       "             5.2783e-03, 5.2783e-03],\n",
       "            [5.9066e-03, 5.9066e-03, 5.9066e-03,  ..., 5.9066e-03,\n",
       "             5.9066e-03, 5.9066e-03],\n",
       "            [1.5796e-03, 1.5796e-03, 1.5796e-03,  ..., 1.5796e-03,\n",
       "             1.5796e-03, 1.5796e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[1.4244e+00, 1.4244e+00, 1.4244e+00,  ..., 1.4244e+00,\n",
       "             1.4244e+00, 1.4244e+00],\n",
       "            [7.7312e-02, 7.7312e-02, 7.7312e-02,  ..., 7.7312e-02,\n",
       "             7.7312e-02, 7.7312e-02],\n",
       "            [5.9133e-02, 5.9133e-02, 5.9133e-02,  ..., 5.9133e-02,\n",
       "             5.9133e-02, 5.9133e-02],\n",
       "            ...,\n",
       "            [2.3235e-01, 2.3235e-01, 2.3235e-01,  ..., 2.3235e-01,\n",
       "             2.3235e-01, 2.3235e-01],\n",
       "            [2.2513e-01, 2.2513e-01, 2.2513e-01,  ..., 2.2513e-01,\n",
       "             2.2513e-01, 2.2513e-01],\n",
       "            [7.5413e-02, 7.5413e-02, 7.5413e-02,  ..., 7.5413e-02,\n",
       "             7.5413e-02, 7.5413e-02]],\n",
       "  \n",
       "           [[1.6352e+00, 1.6352e+00, 1.6352e+00,  ..., 1.6352e+00,\n",
       "             1.6352e+00, 1.6352e+00],\n",
       "            [8.6069e-05, 8.6069e-05, 8.6069e-05,  ..., 8.6069e-05,\n",
       "             8.6069e-05, 8.6069e-05],\n",
       "            [1.8156e-04, 1.8156e-04, 1.8156e-04,  ..., 1.8156e-04,\n",
       "             1.8156e-04, 1.8156e-04],\n",
       "            ...,\n",
       "            [1.9802e+00, 1.9802e+00, 1.9802e+00,  ..., 1.9802e+00,\n",
       "             1.9802e+00, 1.9802e+00],\n",
       "            [1.9924e+00, 1.9924e+00, 1.9924e+00,  ..., 1.9924e+00,\n",
       "             1.9924e+00, 1.9924e+00],\n",
       "            [2.1146e-01, 2.1146e-01, 2.1146e-01,  ..., 2.1146e-01,\n",
       "             2.1146e-01, 2.1146e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[1.2377e+00, 1.2377e+00, 1.2377e+00,  ..., 1.2377e+00,\n",
       "             1.2377e+00, 1.2377e+00],\n",
       "            [2.7906e-01, 2.7906e-01, 2.7906e-01,  ..., 2.7906e-01,\n",
       "             2.7906e-01, 2.7906e-01],\n",
       "            [2.3048e-01, 2.3048e-01, 2.3048e-01,  ..., 2.3048e-01,\n",
       "             2.3048e-01, 2.3048e-01],\n",
       "            ...,\n",
       "            [1.8038e-01, 1.8038e-01, 1.8038e-01,  ..., 1.8038e-01,\n",
       "             1.8038e-01, 1.8038e-01],\n",
       "            [1.4538e-01, 1.4538e-01, 1.4538e-01,  ..., 1.4538e-01,\n",
       "             1.4538e-01, 1.4538e-01],\n",
       "            [7.4005e-02, 7.4005e-02, 7.4005e-02,  ..., 7.4005e-02,\n",
       "             7.4005e-02, 7.4005e-02]],\n",
       "  \n",
       "           [[8.0200e-01, 8.0200e-01, 8.0200e-01,  ..., 8.0200e-01,\n",
       "             8.0200e-01, 8.0200e-01],\n",
       "            [5.0687e-03, 5.0687e-03, 5.0687e-03,  ..., 5.0687e-03,\n",
       "             5.0687e-03, 5.0687e-03],\n",
       "            [1.3892e-02, 1.3892e-02, 1.3892e-02,  ..., 1.3892e-02,\n",
       "             1.3892e-02, 1.3892e-02],\n",
       "            ...,\n",
       "            [1.9468e+00, 1.9468e+00, 1.9468e+00,  ..., 1.9468e+00,\n",
       "             1.9468e+00, 1.9468e+00],\n",
       "            [1.9622e+00, 1.9622e+00, 1.9622e+00,  ..., 1.9622e+00,\n",
       "             1.9622e+00, 1.9622e+00],\n",
       "            [1.1359e+00, 1.1359e+00, 1.1359e+00,  ..., 1.1359e+00,\n",
       "             1.1359e+00, 1.1359e+00]]]], device='cuda:0',\n",
       "         grad_fn=<RepeatBackward0>),\n",
       "  tensor([[[[0.1256, 0.1256, 0.1256,  ..., 0.1256, 0.1256, 0.1256],\n",
       "            [0.2640, 0.2640, 0.2640,  ..., 0.2640, 0.2640, 0.2640],\n",
       "            [0.3416, 0.3416, 0.3416,  ..., 0.3416, 0.3416, 0.3416],\n",
       "            ...,\n",
       "            [1.6202, 1.6202, 1.6202,  ..., 1.6202, 1.6202, 1.6202],\n",
       "            [1.6908, 1.6908, 1.6908,  ..., 1.6908, 1.6908, 1.6908],\n",
       "            [1.0137, 1.0137, 1.0137,  ..., 1.0137, 1.0137, 1.0137]],\n",
       "  \n",
       "           [[1.8782, 1.8782, 1.8782,  ..., 1.8782, 1.8782, 1.8782],\n",
       "            [1.9757, 1.9757, 1.9757,  ..., 1.9757, 1.9757, 1.9757],\n",
       "            [1.9675, 1.9675, 1.9675,  ..., 1.9675, 1.9675, 1.9675],\n",
       "            ...,\n",
       "            [0.0058, 0.0058, 0.0058,  ..., 0.0058, 0.0058, 0.0058],\n",
       "            [0.0087, 0.0087, 0.0087,  ..., 0.0087, 0.0087, 0.0087],\n",
       "            [0.2206, 0.2206, 0.2206,  ..., 0.2206, 0.2206, 0.2206]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0995, 0.0995, 0.0995,  ..., 0.0995, 0.0995, 0.0995],\n",
       "            [0.2952, 0.2952, 0.2952,  ..., 0.2952, 0.2952, 0.2952],\n",
       "            [0.3710, 0.3710, 0.3710,  ..., 0.3710, 0.3710, 0.3710],\n",
       "            ...,\n",
       "            [1.5616, 1.5616, 1.5616,  ..., 1.5616, 1.5616, 1.5616],\n",
       "            [1.6235, 1.6235, 1.6235,  ..., 1.6235, 1.6235, 1.6235],\n",
       "            [0.7186, 0.7186, 0.7186,  ..., 0.7186, 0.7186, 0.7186]],\n",
       "  \n",
       "           [[1.8650, 1.8650, 1.8650,  ..., 1.8650, 1.8650, 1.8650],\n",
       "            [1.9750, 1.9750, 1.9750,  ..., 1.9750, 1.9750, 1.9750],\n",
       "            [1.9677, 1.9677, 1.9677,  ..., 1.9677, 1.9677, 1.9677],\n",
       "            ...,\n",
       "            [0.0069, 0.0069, 0.0069,  ..., 0.0069, 0.0069, 0.0069],\n",
       "            [0.0099, 0.0099, 0.0099,  ..., 0.0099, 0.0099, 0.0099],\n",
       "            [0.3242, 0.3242, 0.3242,  ..., 0.3242, 0.3242, 0.3242]]],\n",
       "  \n",
       "  \n",
       "          [[[0.3248, 0.3248, 0.3248,  ..., 0.3248, 0.3248, 0.3248],\n",
       "            [0.3286, 0.3286, 0.3286,  ..., 0.3286, 0.3286, 0.3286],\n",
       "            [0.4978, 0.4978, 0.4978,  ..., 0.4978, 0.4978, 0.4978],\n",
       "            ...,\n",
       "            [1.2883, 1.2883, 1.2883,  ..., 1.2883, 1.2883, 1.2883],\n",
       "            [1.6103, 1.6103, 1.6103,  ..., 1.6103, 1.6103, 1.6103],\n",
       "            [1.7498, 1.7498, 1.7498,  ..., 1.7498, 1.7498, 1.7498]],\n",
       "  \n",
       "           [[1.8808, 1.8808, 1.8808,  ..., 1.8808, 1.8808, 1.8808],\n",
       "            [1.9603, 1.9603, 1.9603,  ..., 1.9603, 1.9603, 1.9603],\n",
       "            [1.9451, 1.9451, 1.9451,  ..., 1.9451, 1.9451, 1.9451],\n",
       "            ...,\n",
       "            [0.0407, 0.0407, 0.0407,  ..., 0.0407, 0.0407, 0.0407],\n",
       "            [0.0319, 0.0319, 0.0319,  ..., 0.0319, 0.0319, 0.0319],\n",
       "            [0.0685, 0.0685, 0.0685,  ..., 0.0685, 0.0685, 0.0685]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[0.3187, 0.3187, 0.3187,  ..., 0.3187, 0.3187, 0.3187],\n",
       "            [0.3708, 0.3708, 0.3708,  ..., 0.3708, 0.3708, 0.3708],\n",
       "            [0.3995, 0.3995, 0.3995,  ..., 0.3995, 0.3995, 0.3995],\n",
       "            ...,\n",
       "            [0.7440, 0.7440, 0.7440,  ..., 0.7440, 0.7440, 0.7440],\n",
       "            [0.8128, 0.8128, 0.8128,  ..., 0.8128, 0.8128, 0.8128],\n",
       "            [0.7253, 0.7253, 0.7253,  ..., 0.7253, 0.7253, 0.7253]],\n",
       "  \n",
       "           [[1.9686, 1.9686, 1.9686,  ..., 1.9686, 1.9686, 1.9686],\n",
       "            [1.9688, 1.9688, 1.9688,  ..., 1.9688, 1.9688, 1.9688],\n",
       "            [1.9649, 1.9649, 1.9649,  ..., 1.9649, 1.9649, 1.9649],\n",
       "            ...,\n",
       "            [1.7449, 1.7449, 1.7449,  ..., 1.7449, 1.7449, 1.7449],\n",
       "            [1.8016, 1.8016, 1.8016,  ..., 1.8016, 1.8016, 1.8016],\n",
       "            [1.8673, 1.8673, 1.8673,  ..., 1.8673, 1.8673, 1.8673]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0542, 0.0542, 0.0542,  ..., 0.0542, 0.0542, 0.0542],\n",
       "            [0.3810, 0.3810, 0.3810,  ..., 0.3810, 0.3810, 0.3810],\n",
       "            [0.4169, 0.4169, 0.4169,  ..., 0.4169, 0.4169, 0.4169],\n",
       "            ...,\n",
       "            [1.2818, 1.2818, 1.2818,  ..., 1.2818, 1.2818, 1.2818],\n",
       "            [1.3702, 1.3702, 1.3702,  ..., 1.3702, 1.3702, 1.3702],\n",
       "            [0.2351, 0.2351, 0.2351,  ..., 0.2351, 0.2351, 0.2351]],\n",
       "  \n",
       "           [[1.9164, 1.9164, 1.9164,  ..., 1.9164, 1.9164, 1.9164],\n",
       "            [1.9711, 1.9711, 1.9711,  ..., 1.9711, 1.9711, 1.9711],\n",
       "            [1.9662, 1.9662, 1.9662,  ..., 1.9662, 1.9662, 1.9662],\n",
       "            ...,\n",
       "            [0.0091, 0.0091, 0.0091,  ..., 0.0091, 0.0091, 0.0091],\n",
       "            [0.0127, 0.0127, 0.0127,  ..., 0.0127, 0.0127, 0.0127],\n",
       "            [0.9447, 0.9447, 0.9447,  ..., 0.9447, 0.9447, 0.9447]]],\n",
       "  \n",
       "  \n",
       "          [[[0.0987, 0.0987, 0.0987,  ..., 0.0987, 0.0987, 0.0987],\n",
       "            [0.2608, 0.2608, 0.2608,  ..., 0.2608, 0.2608, 0.2608],\n",
       "            [0.3382, 0.3382, 0.3382,  ..., 0.3382, 0.3382, 0.3382],\n",
       "            ...,\n",
       "            [1.5204, 1.5204, 1.5204,  ..., 1.5204, 1.5204, 1.5204],\n",
       "            [1.5747, 1.5747, 1.5747,  ..., 1.5747, 1.5747, 1.5747],\n",
       "            [0.7392, 0.7392, 0.7392,  ..., 0.7392, 0.7392, 0.7392]],\n",
       "  \n",
       "           [[1.8836, 1.8836, 1.8836,  ..., 1.8836, 1.8836, 1.8836],\n",
       "            [1.9763, 1.9763, 1.9763,  ..., 1.9763, 1.9763, 1.9763],\n",
       "            [1.9684, 1.9684, 1.9684,  ..., 1.9684, 1.9684, 1.9684],\n",
       "            ...,\n",
       "            [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "            [0.0112, 0.0112, 0.0112,  ..., 0.0112, 0.0112, 0.0112],\n",
       "            [0.3017, 0.3017, 0.3017,  ..., 0.3017, 0.3017, 0.3017]]]],\n",
       "         device='cuda:0', grad_fn=<RepeatBackward0>)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo(x_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.0854, -0.0863, -0.0838]],\n",
       " \n",
       "         [[ 0.0166,  0.0138,  0.0125]],\n",
       " \n",
       "         [[-0.0097, -0.0110, -0.0120]],\n",
       " \n",
       "         [[ 0.0034,  0.0021, -0.0010]],\n",
       " \n",
       "         [[ 0.0961,  0.0987,  0.0969]],\n",
       " \n",
       "         [[ 0.0046,  0.0064,  0.0075]],\n",
       " \n",
       "         [[-0.1254, -0.1217, -0.1139]],\n",
       " \n",
       "         [[ 0.0492,  0.0489,  0.0462]],\n",
       " \n",
       "         [[ 0.0855,  0.0855,  0.0804]],\n",
       " \n",
       "         [[-0.1180, -0.1164, -0.1117]],\n",
       " \n",
       "         [[-0.1250, -0.1225, -0.1154]],\n",
       " \n",
       "         [[ 0.0524,  0.0501,  0.0472]],\n",
       " \n",
       "         [[-0.0536, -0.0506, -0.0472]],\n",
       " \n",
       "         [[-0.0488, -0.0503, -0.0486]],\n",
       " \n",
       "         [[ 0.0715,  0.0669,  0.0624]],\n",
       " \n",
       "         [[-0.0340, -0.0336, -0.0326]],\n",
       " \n",
       "         [[-0.1149, -0.1094, -0.1018]],\n",
       " \n",
       "         [[ 0.0313,  0.0285,  0.0263]],\n",
       " \n",
       "         [[-0.0653, -0.0609, -0.0560]],\n",
       " \n",
       "         [[ 0.0148,  0.0177,  0.0194]],\n",
       " \n",
       "         [[ 0.0117,  0.0084,  0.0055]],\n",
       " \n",
       "         [[-0.0639, -0.0627, -0.0597]],\n",
       " \n",
       "         [[ 0.1189,  0.1142,  0.1101]],\n",
       " \n",
       "         [[-0.0020, -0.0016, -0.0012]],\n",
       " \n",
       "         [[ 0.0479,  0.0415,  0.0371]],\n",
       " \n",
       "         [[ 0.0242,  0.0238,  0.0225]],\n",
       " \n",
       "         [[ 0.0201,  0.0209,  0.0206]],\n",
       " \n",
       "         [[ 0.0267,  0.0230,  0.0212]],\n",
       " \n",
       "         [[-0.0024, -0.0020, -0.0041]],\n",
       " \n",
       "         [[ 0.0208,  0.0164,  0.0138]],\n",
       " \n",
       "         [[ 0.0098,  0.0106,  0.0110]],\n",
       " \n",
       "         [[ 0.1423,  0.1420,  0.1364]]], device='cuda:0'),\n",
       " tensor([[-0.0037,  0.0047, -0.0091,  ...,  0.0094,  0.0140,  0.0304],\n",
       "         [ 0.0109, -0.0168,  0.0333,  ..., -0.0317, -0.0472, -0.1051],\n",
       "         [-0.0116,  0.0172, -0.0340,  ...,  0.0327,  0.0489,  0.1082],\n",
       "         ...,\n",
       "         [ 0.0188, -0.0356,  0.0675,  ..., -0.0326, -0.0907, -0.1808],\n",
       "         [ 0.0120, -0.0226,  0.0428,  ..., -0.0208, -0.0577, -0.1150],\n",
       "         [ 0.0080, -0.0155,  0.0288,  ..., -0.0140, -0.0392, -0.0778]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0098, -0.0337,  0.0347, -0.0338,  0.0148, -0.0113, -0.0241,  0.0075,\n",
       "         -0.0119, -0.0308, -0.0396, -0.0117,  0.0096, -0.0131,  0.0323, -0.0212,\n",
       "          0.0395, -0.0014,  0.0129, -0.0262,  0.0121,  0.0112, -0.0345,  0.0333,\n",
       "          0.0179,  0.0228,  0.0269,  0.0093, -0.0374, -0.0372, -0.0238, -0.0159],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0021,  0.0102, -0.0170,  ..., -0.0015,  0.0202,  0.0346],\n",
       "         [-0.0006,  0.0024, -0.0040,  ..., -0.0003,  0.0049,  0.0083],\n",
       "         [-0.0059,  0.0243, -0.0409,  ..., -0.0034,  0.0497,  0.0845],\n",
       "         ...,\n",
       "         [-0.0113,  0.0280, -0.0573,  ..., -0.0049,  0.0632,  0.1096],\n",
       "         [-0.0110,  0.0289, -0.0580,  ..., -0.0050,  0.0641,  0.1113],\n",
       "         [ 0.0129, -0.0325,  0.0663,  ...,  0.0056, -0.0735, -0.1272]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 8.7311e-11,  7.2760e-12,  1.1642e-10, -7.2760e-11, -2.9104e-11,\n",
       "          0.0000e+00, -6.9122e-11,  2.9104e-11,  2.6921e-10,  2.9104e-11,\n",
       "          0.0000e+00, -1.7462e-10,  4.3656e-11,  1.3097e-10,  2.9104e-11,\n",
       "          1.4552e-11,  1.6735e-10, -3.4197e-10,  0.0000e+00,  3.6380e-11,\n",
       "          2.4784e-11,  0.0000e+00,  6.5484e-11,  4.3656e-11,  7.2760e-12,\n",
       "          1.4552e-11,  8.7311e-11,  1.1278e-10,  2.9104e-11, -2.9104e-11,\n",
       "          4.3656e-11,  1.4552e-11], device='cuda:0'),\n",
       " tensor([[ 0.0001,  0.0037, -0.0085,  ...,  0.0128,  0.0093,  0.0286],\n",
       "         [-0.0003, -0.0033,  0.0072,  ..., -0.0254, -0.0087, -0.0391],\n",
       "         [-0.0002,  0.0023, -0.0053,  ...,  0.0020,  0.0058,  0.0120],\n",
       "         ...,\n",
       "         [-0.0075, -0.0109,  0.0149,  ..., -0.0422,  0.0016, -0.0537],\n",
       "         [-0.0081, -0.0084,  0.0109,  ..., -0.0366,  0.0059, -0.0399],\n",
       "         [-0.0019, -0.0015,  0.0018,  ..., -0.0045,  0.0022, -0.0040]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0136, -0.0262,  0.0024,  0.0299,  0.0398, -0.0169,  0.0150,  0.0266,\n",
       "         -0.0239,  0.0550, -0.0305,  0.0140, -0.0359,  0.0007,  0.0109,  0.0026,\n",
       "          0.0005,  0.0040, -0.0322,  0.0093, -0.0107,  0.0333, -0.0095,  0.0526,\n",
       "         -0.0191, -0.0154, -0.0302,  0.0086, -0.0551, -0.0462, -0.0400, -0.0052],\n",
       "        device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([0., 0.], device='cuda:0'),\n",
       " tensor([[-2.2089e-02, -5.2520e-02,  1.2280e-02,  ...,  4.6123e-03,\n",
       "           6.5437e-03,  6.8450e-05],\n",
       "         [ 1.3804e-02,  3.1554e-02, -4.2534e-03,  ..., -2.7681e-03,\n",
       "          -2.8618e-03,  1.4247e-03],\n",
       "         [ 1.9376e-02,  4.8179e-02, -1.6713e-02,  ..., -7.2652e-03,\n",
       "          -7.1269e-03, -5.1056e-03],\n",
       "         ...,\n",
       "         [ 1.8496e-02,  4.4473e-02, -1.1704e-02,  ..., -7.6327e-03,\n",
       "          -5.1342e-03, -3.7070e-03],\n",
       "         [ 4.8451e-03,  8.6939e-03,  5.0438e-03,  ...,  5.7114e-03,\n",
       "          -1.9910e-04,  8.9050e-03],\n",
       "         [ 2.3640e-02,  5.5458e-02, -1.1036e-02,  ..., -4.5600e-03,\n",
       "          -7.1848e-03,  3.2146e-03]], device='cuda:0'),\n",
       " tensor([-0.0467,  0.0140,  0.0666,  0.0458, -0.0226, -0.0257, -0.0843,  0.0367,\n",
       "          0.0403, -0.0340, -0.1035,  0.0379, -0.0075,  0.0037,  0.0581, -0.0127,\n",
       "         -0.0755,  0.0289, -0.0459, -0.0450,  0.0507, -0.0223,  0.0218, -0.0436,\n",
       "          0.0311,  0.0040, -0.0443,  0.0472,  0.0653,  0.0449, -0.0236,  0.0404],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-3.3337e-03],\n",
       "          [-6.7682e-03],\n",
       "          [ 4.7559e-03],\n",
       "          ...,\n",
       "          [ 1.2152e-03],\n",
       "          [-8.8611e-03],\n",
       "          [-1.2277e-02]],\n",
       " \n",
       "         [[-4.0446e-03],\n",
       "          [ 8.3182e-03],\n",
       "          [-1.2577e-02],\n",
       "          ...,\n",
       "          [ 6.5808e-03],\n",
       "          [ 2.1191e-02],\n",
       "          [ 4.2472e-02]],\n",
       " \n",
       "         [[ 5.4361e-03],\n",
       "          [-6.5420e-03],\n",
       "          [ 1.4913e-02],\n",
       "          ...,\n",
       "          [-1.0171e-02],\n",
       "          [-2.4173e-02],\n",
       "          [-5.1642e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.9805e-07],\n",
       "          [ 3.0128e-03],\n",
       "          [-6.6065e-03],\n",
       "          ...,\n",
       "          [ 2.3906e-03],\n",
       "          [ 6.1959e-03],\n",
       "          [ 1.6243e-02]],\n",
       " \n",
       "         [[-9.1828e-04],\n",
       "          [-5.2356e-03],\n",
       "          [ 6.7088e-03],\n",
       "          ...,\n",
       "          [ 9.0798e-04],\n",
       "          [-1.4327e-02],\n",
       "          [-2.0831e-02]],\n",
       " \n",
       "         [[-2.4318e-03],\n",
       "          [-2.1051e-03],\n",
       "          [-2.2273e-03],\n",
       "          ...,\n",
       "          [ 3.4700e-03],\n",
       "          [ 2.5286e-03],\n",
       "          [ 9.4401e-03]]], device='cuda:0'),\n",
       " tensor([-0.0038,  0.0172, -0.0185, -0.0002,  0.0130, -0.0174, -0.0062, -0.0077,\n",
       "          0.0201, -0.0127, -0.0091, -0.0234, -0.0039,  0.0311,  0.0032,  0.0028,\n",
       "         -0.0168,  0.0012, -0.0297,  0.0002,  0.0056,  0.0205, -0.0359,  0.0112,\n",
       "          0.0036,  0.0323, -0.0113,  0.0441, -0.0161,  0.0044,  0.0113,  0.0046],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.0052],\n",
       "          [-0.0112],\n",
       "          [-0.0130],\n",
       "          ...,\n",
       "          [ 0.0082],\n",
       "          [ 0.0193],\n",
       "          [ 0.0124]],\n",
       " \n",
       "         [[ 0.0039],\n",
       "          [ 0.0062],\n",
       "          [ 0.0057],\n",
       "          ...,\n",
       "          [-0.0052],\n",
       "          [-0.0115],\n",
       "          [-0.0065]],\n",
       " \n",
       "         [[ 0.0088],\n",
       "          [ 0.0177],\n",
       "          [ 0.0209],\n",
       "          ...,\n",
       "          [-0.0118],\n",
       "          [-0.0295],\n",
       "          [-0.0179]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0091],\n",
       "          [ 0.0163],\n",
       "          [ 0.0165],\n",
       "          ...,\n",
       "          [-0.0107],\n",
       "          [-0.0251],\n",
       "          [-0.0159]],\n",
       " \n",
       "         [[-0.0014],\n",
       "          [-0.0018],\n",
       "          [-0.0038],\n",
       "          ...,\n",
       "          [-0.0019],\n",
       "          [-0.0082],\n",
       "          [-0.0032]],\n",
       " \n",
       "         [[ 0.0074],\n",
       "          [ 0.0122],\n",
       "          [ 0.0096],\n",
       "          ...,\n",
       "          [-0.0101],\n",
       "          [-0.0248],\n",
       "          [-0.0141]]], device='cuda:0'),\n",
       " tensor([-0.0455,  0.0232,  0.0785,  0.0262, -0.0313, -0.0176, -0.0893,  0.0271,\n",
       "          0.0543, -0.0590, -0.1204,  0.0353, -0.0055,  0.0080,  0.0767, -0.0224,\n",
       "         -0.1056,  0.0393, -0.0523, -0.0512,  0.0587, -0.0201,  0.0296, -0.0449,\n",
       "          0.0463,  0.0174, -0.0474,  0.0726,  0.0434,  0.0705, -0.0307,  0.0362],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0034,  0.0111, -0.0632, -0.0904,  0.0242, -0.0118,  0.0571,  0.0200,\n",
       "         -0.0868, -0.0130,  0.0169, -0.0462, -0.0166, -0.0129,  0.1630, -0.0112,\n",
       "          0.0610, -0.0721, -0.1482,  0.0482, -0.0313, -0.0284, -0.0343,  0.0003,\n",
       "         -0.0167, -0.0108,  0.0364,  0.0841,  0.0040,  0.0257,  0.0013,  0.1644],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0528,  0.0174,  0.0717,  0.0442, -0.0239, -0.0125, -0.0964,  0.0293,\n",
       "          0.0367, -0.0477, -0.1169,  0.0412, -0.0075,  0.0175,  0.0645, -0.0279,\n",
       "         -0.0980,  0.0250, -0.0447, -0.0506,  0.0640, -0.0264,  0.0319, -0.0480,\n",
       "          0.0282,  0.0119, -0.0576,  0.0748,  0.0549,  0.0592, -0.0401,  0.0522],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0023,  0.0195, -0.0783, -0.0432,  0.0168, -0.0276,  0.0633,  0.0203,\n",
       "         -0.1420, -0.0304,  0.0015, -0.0337, -0.0198, -0.0117,  0.1705, -0.0109,\n",
       "          0.1047, -0.0886, -0.1494,  0.0430, -0.0266, -0.0347, -0.0313,  0.0079,\n",
       "         -0.0341, -0.0188,  0.0421,  0.0665, -0.0132,  0.0339,  0.0118,  0.1266],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0438,  0.0208,  0.0794,  0.0323, -0.0356, -0.0199, -0.0828,  0.0252,\n",
       "          0.0582, -0.0563, -0.1177,  0.0384, -0.0054,  0.0073,  0.0697, -0.0217,\n",
       "         -0.0989,  0.0460, -0.0532, -0.0468,  0.0614, -0.0232,  0.0314, -0.0415,\n",
       "          0.0463,  0.0204, -0.0436,  0.0697,  0.0435,  0.0689, -0.0336,  0.0294],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0008,  0.0045, -0.0039,  ...,  0.0022,  0.0063,  0.0128],\n",
       "         [ 0.0002, -0.0017,  0.0012,  ..., -0.0006, -0.0026, -0.0043],\n",
       "         [ 0.0004,  0.0048, -0.0037,  ...,  0.0009,  0.0068,  0.0104],\n",
       "         ...,\n",
       "         [-0.0006,  0.0043, -0.0036,  ...,  0.0020,  0.0058,  0.0115],\n",
       "         [-0.0003,  0.0046, -0.0039,  ...,  0.0019,  0.0061,  0.0117],\n",
       "         [-0.0005,  0.0043, -0.0036,  ...,  0.0019,  0.0056,  0.0112]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 3.8246e-03, -1.0662e-03,  1.4993e-03, -3.2921e-03,  4.9359e-03,\n",
       "          5.1894e-03,  2.8125e-03, -4.0883e-03, -4.3773e-03, -1.7431e-04,\n",
       "         -5.5925e-03,  2.0117e-04,  3.6992e-03,  3.2524e-03,  3.4378e-04,\n",
       "          4.8664e-04, -1.3001e-03, -9.1114e-05,  2.3685e-03, -3.4146e-03,\n",
       "          1.0420e-04, -2.2504e-03,  2.3688e-03,  4.9448e-03, -1.5288e-03,\n",
       "         -3.9259e-03, -2.5699e-03, -1.3682e-03,  1.2495e-03,  4.8913e-03,\n",
       "          4.7309e-03,  4.7686e-03], device='cuda:0'),\n",
       " tensor([[ 0.0004,  0.0163, -0.0128,  ...,  0.0037,  0.0295,  0.0459],\n",
       "         [-0.0003, -0.0014,  0.0012,  ..., -0.0005, -0.0026, -0.0045],\n",
       "         [ 0.0005,  0.0020, -0.0019,  ...,  0.0002,  0.0028,  0.0049],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0024, -0.0024,  ...,  0.0002,  0.0034,  0.0051],\n",
       "         [ 0.0019,  0.0036, -0.0036,  ...,  0.0003,  0.0044,  0.0072],\n",
       "         [ 0.0012,  0.0023, -0.0024,  ...,  0.0002,  0.0030,  0.0047]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 2.9104e-11, -7.2760e-12, -1.4552e-11,  5.0932e-11,  1.2733e-11,\n",
       "         -3.6380e-11, -7.2760e-12, -1.4552e-11,  7.2760e-11,  2.9104e-11,\n",
       "         -4.3656e-11, -8.7311e-11,  2.9104e-11, -2.4738e-10,  1.8190e-12,\n",
       "          0.0000e+00, -9.0949e-13,  1.4552e-11,  5.4570e-12,  2.9104e-11,\n",
       "          1.8190e-12, -2.0009e-11,  1.3097e-10, -5.8208e-11,  1.0914e-11,\n",
       "          1.4552e-11,  7.2760e-12, -1.0914e-11, -7.2760e-11, -1.0914e-11,\n",
       "         -9.0949e-12, -2.0009e-11], device='cuda:0'),\n",
       " tensor([[-0.0035, -0.0009, -0.0038,  ...,  0.0064, -0.0023,  0.0115],\n",
       "         [ 0.0060,  0.0012,  0.0069,  ..., -0.0123,  0.0053, -0.0205],\n",
       "         [ 0.0005, -0.0008,  0.0005,  ..., -0.0017, -0.0003, -0.0023],\n",
       "         ...,\n",
       "         [-0.0006, -0.0156,  0.0342,  ..., -0.0184, -0.0106, -0.0730],\n",
       "         [-0.0006,  0.0021, -0.0081,  ...,  0.0054, -0.0001,  0.0170],\n",
       "         [-0.0002, -0.0105,  0.0241,  ..., -0.0128, -0.0074, -0.0516]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0150, -0.0322, -0.0062,  0.0001,  0.0408,  0.0018, -0.0524, -0.0441,\n",
       "         -0.0120, -0.0139,  0.0314,  0.0253, -0.0873, -0.0019, -0.0331, -0.0199,\n",
       "         -0.0072,  0.0118,  0.0223, -0.0020, -0.0081, -0.0218,  0.0141,  0.0087,\n",
       "          0.0334, -0.0206, -0.0258,  0.0211, -0.0062, -0.0444,  0.0138, -0.0303],\n",
       "        device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([0., 0.], device='cuda:0'),\n",
       " tensor([[ 0.0080,  0.0130,  0.0131,  ..., -0.0088, -0.0215, -0.0208],\n",
       "         [-0.0061, -0.0078, -0.0099,  ...,  0.0051,  0.0150,  0.0155],\n",
       "         [-0.0132, -0.0250, -0.0264,  ...,  0.0163,  0.0367,  0.0310],\n",
       "         ...,\n",
       "         [-0.0130, -0.0183, -0.0226,  ...,  0.0117,  0.0329,  0.0320],\n",
       "         [-0.0009, -0.0043,  0.0004,  ...,  0.0039,  0.0048,  0.0046],\n",
       "         [-0.0073, -0.0087, -0.0075,  ...,  0.0067,  0.0190,  0.0225]],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0320,  0.0257,  0.0654,  0.0277,  0.0023, -0.0093, -0.1054,  0.0072,\n",
       "          0.0702, -0.0748, -0.0907,  0.0137, -0.0208, -0.0096,  0.0702, -0.0017,\n",
       "         -0.1058,  0.0428, -0.0833, -0.0471,  0.0386, -0.0310,  0.0376, -0.0256,\n",
       "          0.0524,  0.0282, -0.0145,  0.0762,  0.0222,  0.0587, -0.0049,  0.0172],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 7.6757e-04],\n",
       "          [-7.3934e-03],\n",
       "          [ 4.3717e-03],\n",
       "          ...,\n",
       "          [-3.1268e-03],\n",
       "          [-4.1510e-03],\n",
       "          [-1.0896e-02]],\n",
       " \n",
       "         [[ 8.7042e-03],\n",
       "          [-1.6911e-02],\n",
       "          [ 1.4928e-02],\n",
       "          ...,\n",
       "          [-1.3752e-02],\n",
       "          [-1.0095e-02],\n",
       "          [-3.9039e-02]],\n",
       " \n",
       "         [[ 5.0050e-05],\n",
       "          [ 2.9182e-03],\n",
       "          [-2.3781e-03],\n",
       "          ...,\n",
       "          [ 9.4508e-04],\n",
       "          [ 9.3062e-04],\n",
       "          [ 3.9500e-03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.7258e-03],\n",
       "          [-1.7826e-02],\n",
       "          [ 1.0561e-02],\n",
       "          ...,\n",
       "          [-1.1253e-02],\n",
       "          [-6.2039e-03],\n",
       "          [-2.8156e-02]],\n",
       " \n",
       "         [[-4.5737e-03],\n",
       "          [ 5.2447e-03],\n",
       "          [-7.9349e-03],\n",
       "          ...,\n",
       "          [ 5.4731e-03],\n",
       "          [ 8.0820e-03],\n",
       "          [ 1.8452e-02]],\n",
       " \n",
       "         [[-2.0038e-03],\n",
       "          [ 7.5487e-03],\n",
       "          [-5.4663e-03],\n",
       "          ...,\n",
       "          [ 5.2309e-03],\n",
       "          [ 4.6556e-03],\n",
       "          [ 1.4806e-02]]], device='cuda:0'),\n",
       " tensor([-0.0057, -0.0097,  0.0020, -0.0012,  0.0140,  0.0043,  0.0004,  0.0035,\n",
       "         -0.0003, -0.0137,  0.0095, -0.0313, -0.0077, -0.0258, -0.0279, -0.0284,\n",
       "          0.0044,  0.0048,  0.0072, -0.0006,  0.0111,  0.0100, -0.0002, -0.0470,\n",
       "         -0.0117, -0.0016,  0.0501,  0.0448, -0.0045, -0.0178, -0.0036,  0.0050],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-5.0370e-03],\n",
       "          [ 2.7096e-03],\n",
       "          [-1.2386e-02],\n",
       "          ...,\n",
       "          [-2.6405e-02],\n",
       "          [ 1.8217e-02],\n",
       "          [-1.1732e-02]],\n",
       " \n",
       "         [[ 3.1234e-03],\n",
       "          [-3.2275e-03],\n",
       "          [ 3.6702e-03],\n",
       "          ...,\n",
       "          [ 1.1119e-02],\n",
       "          [-6.2345e-03],\n",
       "          [-1.8157e-03]],\n",
       " \n",
       "         [[ 4.6207e-03],\n",
       "          [ 5.3480e-04],\n",
       "          [ 1.3172e-02],\n",
       "          ...,\n",
       "          [ 2.6306e-02],\n",
       "          [-1.6993e-02],\n",
       "          [ 1.7672e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 4.7715e-03],\n",
       "          [-3.5548e-03],\n",
       "          [ 8.5610e-03],\n",
       "          ...,\n",
       "          [ 2.0554e-02],\n",
       "          [-1.2373e-02],\n",
       "          [ 4.1114e-03]],\n",
       " \n",
       "         [[ 1.3283e-03],\n",
       "          [-5.5728e-05],\n",
       "          [ 4.2484e-03],\n",
       "          ...,\n",
       "          [ 8.0560e-03],\n",
       "          [-7.5810e-03],\n",
       "          [ 6.4660e-03]],\n",
       " \n",
       "         [[ 4.9422e-03],\n",
       "          [-6.6292e-03],\n",
       "          [ 8.0250e-03],\n",
       "          ...,\n",
       "          [ 1.9244e-02],\n",
       "          [-1.4002e-02],\n",
       "          [-2.4657e-03]]], device='cuda:0'),\n",
       " tensor([-0.0452,  0.0177,  0.0549,  0.0316,  0.0018, -0.0004, -0.1081,  0.0312,\n",
       "          0.0665, -0.0792, -0.0814,  0.0099, -0.0164, -0.0055,  0.0834, -0.0102,\n",
       "         -0.0862,  0.0310, -0.0949, -0.0404,  0.0472, -0.0218,  0.0246, -0.0227,\n",
       "          0.0480,  0.0066, -0.0131,  0.0734,  0.0290,  0.0369,  0.0117,  0.0202],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0049,  0.0397, -0.0723, -0.0537,  0.0043, -0.0186,  0.0919,  0.0200,\n",
       "         -0.1309, -0.0232, -0.0051, -0.0175, -0.0104, -0.0085,  0.1587, -0.0116,\n",
       "          0.1014, -0.0680, -0.1425,  0.0511, -0.0358, -0.0367, -0.0205,  0.0094,\n",
       "         -0.0321, -0.0119,  0.0246,  0.0867, -0.0114,  0.0472,  0.0098,  0.1072],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0297,  0.0304,  0.0658,  0.0249,  0.0076, -0.0041, -0.1033,  0.0114,\n",
       "          0.0679, -0.0711, -0.0875,  0.0147, -0.0168, -0.0058,  0.0754,  0.0012,\n",
       "         -0.1039,  0.0392, -0.0764, -0.0459,  0.0386, -0.0238,  0.0387, -0.0244,\n",
       "          0.0533,  0.0287, -0.0146,  0.0800,  0.0246,  0.0621, -0.0007,  0.0237],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0083,  0.0228, -0.0644, -0.0714,  0.0155,  0.0018,  0.0623,  0.0263,\n",
       "         -0.1051, -0.0116, -0.0266, -0.0115, -0.0093, -0.0094,  0.1733, -0.0061,\n",
       "          0.1053, -0.0586, -0.1679,  0.0370, -0.0608, -0.0259, -0.0090,  0.0085,\n",
       "         -0.0310, -0.0012,  0.0154,  0.0799, -0.0152,  0.0242,  0.0080,  0.0966],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0460,  0.0180,  0.0561,  0.0322,  0.0017, -0.0004, -0.1101,  0.0317,\n",
       "          0.0679, -0.0807, -0.0829,  0.0101, -0.0168, -0.0055,  0.0848, -0.0104,\n",
       "         -0.0875,  0.0318, -0.0969, -0.0410,  0.0481, -0.0224,  0.0251, -0.0232,\n",
       "          0.0489,  0.0069, -0.0133,  0.0749,  0.0294,  0.0377,  0.0117,  0.0203],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0083,  0.0408, -0.0847, -0.1854,  0.0223,  0.0158,  0.0589,  0.0393,\n",
       "         -0.1718, -0.0052, -0.0172, -0.0311, -0.0013,  0.0034,  0.1877, -0.0006,\n",
       "          0.0876, -0.2248, -0.1576,  0.0230, -0.0966, -0.0333,  0.0005, -0.0021,\n",
       "         -0.0435, -0.0305, -0.0059,  0.1012, -0.0203,  0.0410,  0.0137,  0.1017],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0330,  0.0282,  0.0764,  0.0641,  0.0134,  0.0107, -0.0931,  0.0474,\n",
       "          0.0887, -0.0648, -0.0704,  0.0322, -0.0023,  0.0051,  0.1012,  0.0020,\n",
       "         -0.0788,  0.0656, -0.0805, -0.0258,  0.0807, -0.0140,  0.0514,  0.0039,\n",
       "          0.0712,  0.0301,  0.0062,  0.0893,  0.0496,  0.0545,  0.0279,  0.0375],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1456, -0.8338,  0.6398,  1.6685, -0.9597, -0.8457,  0.3649, -0.4777,\n",
       "           1.1174, -0.0460, -0.1413,  0.5573, -0.3173, -0.3865, -1.0702,  0.1790,\n",
       "           0.6415,  1.9761, -1.1303,  0.5127,  0.6907, -1.3727, -0.0058,  0.3142,\n",
       "           0.3525,  0.5845,  0.5438, -0.6539,  0.2356, -0.4342, -0.2838, -1.5652]],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.5768], device='cuda:0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gradients(model):\n",
    "    \"\"\"\n",
    "    Get all gradients of the model parameters.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        List[Tensor]: A list of gradient tensors for each model parameter.\n",
    "    \"\"\"\n",
    "    gradients = [param.grad for param in model.parameters() if param.grad is not None]\n",
    "    return gradients\n",
    "\n",
    "gradients = get_gradients(modelo)\n",
    "gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0045, -0.0011, -0.0052, -0.0046, -0.0025,  0.0034, -0.0015,  0.0076,\n",
       "        -0.0022,  0.0010, -0.0003, -0.0070,  0.0080, -0.0009,  0.0052, -0.0044,\n",
       "        -0.0052,  0.0033,  0.0053, -0.0038,  0.0046, -0.0008, -0.0044, -0.0090,\n",
       "         0.0060, -0.0042, -0.0024,  0.0008, -0.0023,  0.0046, -0.0035, -0.0055],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients[-17]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer entrenamiento sin nada, solo con lambda 3 y sin lr schecdule ni clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "tensor(1.5456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.1723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.1723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [1/125], Loss_min: 26.0625, Loss_max: -22.9713\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [2/125], Loss_min: 25.8928, Loss_max: -23.6319\n",
      "tensor(1.2706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [3/125], Loss_min: 26.5983, Loss_max: -24.0571\n",
      "tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [4/125], Loss_min: 25.9961, Loss_max: -24.4772\n",
      "tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [5/125], Loss_min: 26.1608, Loss_max: -24.8184\n",
      "tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [6/125], Loss_min: 26.9861, Loss_max: -25.5471\n",
      "tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [7/125], Loss_min: 27.2228, Loss_max: -25.9144\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [8/125], Loss_min: 26.8283, Loss_max: -25.9060\n",
      "tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [9/125], Loss_min: 28.0255, Loss_max: -26.8295\n",
      "tensor(0.5224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [10/125], Loss_min: 27.9788, Loss_max: -26.9340\n",
      "tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [11/125], Loss_min: 28.3415, Loss_max: -27.4680\n",
      "tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [12/125], Loss_min: 28.1348, Loss_max: -26.7168\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [13/125], Loss_min: 28.5948, Loss_max: -27.6026\n",
      "tensor(0.4789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [14/125], Loss_min: 28.9423, Loss_max: -27.9846\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [15/125], Loss_min: 28.6913, Loss_max: -27.8212\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [16/125], Loss_min: 29.4002, Loss_max: -28.5659\n",
      "tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [17/125], Loss_min: 29.9776, Loss_max: -29.0714\n",
      "tensor(0.4079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [18/125], Loss_min: 30.4400, Loss_max: -29.6242\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [19/125], Loss_min: 28.9520, Loss_max: -28.2973\n",
      "tensor(0.3787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [20/125], Loss_min: 29.5496, Loss_max: -28.7922\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [21/125], Loss_min: 30.1596, Loss_max: -29.4734\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [22/125], Loss_min: 30.8042, Loss_max: -30.1168\n",
      "tensor(0.3284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [23/125], Loss_min: 31.0678, Loss_max: -30.4111\n",
      "tensor(0.2988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [24/125], Loss_min: 30.9625, Loss_max: -30.3649\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [25/125], Loss_min: 31.1211, Loss_max: -30.5921\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [26/125], Loss_min: 31.7475, Loss_max: -31.0732\n",
      "tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [27/125], Loss_min: 31.4231, Loss_max: -30.8131\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [28/125], Loss_min: 30.6888, Loss_max: -30.2583\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [29/125], Loss_min: 30.9950, Loss_max: -30.5364\n",
      "tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [30/125], Loss_min: 30.5924, Loss_max: -30.1741\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [31/125], Loss_min: 33.5036, Loss_max: -32.8305\n",
      "tensor(0.3101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [32/125], Loss_min: 33.9257, Loss_max: -33.3056\n",
      "tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [33/125], Loss_min: 30.7847, Loss_max: -30.2994\n",
      "tensor(0.2605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [34/125], Loss_min: 32.8259, Loss_max: -32.3049\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [35/125], Loss_min: 31.5740, Loss_max: -31.0858\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [36/125], Loss_min: 31.9199, Loss_max: -31.4418\n",
      "tensor(0.1833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [37/125], Loss_min: 31.5397, Loss_max: -31.1730\n",
      "tensor(0.2281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [38/125], Loss_min: 31.6318, Loss_max: -31.1756\n",
      "tensor(0.2013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [39/125], Loss_min: 33.3456, Loss_max: -32.9430\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [40/125], Loss_min: 31.9300, Loss_max: -31.4956\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [41/125], Loss_min: 32.9248, Loss_max: -32.5000\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [42/125], Loss_min: 32.3369, Loss_max: -31.8836\n",
      "tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [43/125], Loss_min: 32.8713, Loss_max: -32.0514\n",
      "tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [44/125], Loss_min: 33.5315, Loss_max: -33.0959\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [45/125], Loss_min: 32.6509, Loss_max: -32.2584\n",
      "tensor(0.3798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [46/125], Loss_min: 32.2738, Loss_max: -31.5142\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [47/125], Loss_min: 31.9389, Loss_max: -31.5756\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [48/125], Loss_min: 33.0403, Loss_max: -32.6860\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [49/125], Loss_min: 33.7716, Loss_max: -33.4536\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [50/125], Loss_min: 33.7499, Loss_max: -33.2631\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [51/125], Loss_min: 32.8361, Loss_max: -32.2668\n",
      "tensor(0.1736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [52/125], Loss_min: 33.2569, Loss_max: -32.9097\n",
      "tensor(0.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [53/125], Loss_min: 32.9654, Loss_max: -32.6437\n",
      "tensor(0.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [54/125], Loss_min: 35.5519, Loss_max: -35.2403\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [55/125], Loss_min: 32.8022, Loss_max: -32.5245\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [56/125], Loss_min: 32.9939, Loss_max: -32.6798\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [57/125], Loss_min: 32.7095, Loss_max: -32.4881\n",
      "tensor(0.1825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [58/125], Loss_min: 33.9116, Loss_max: -33.5466\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [59/125], Loss_min: 34.5510, Loss_max: -34.2993\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [60/125], Loss_min: 34.4438, Loss_max: -34.1827\n",
      "tensor(0.1323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [61/125], Loss_min: 34.5231, Loss_max: -34.2586\n",
      "tensor(0.1384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [62/125], Loss_min: 34.5580, Loss_max: -34.2812\n",
      "tensor(0.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [63/125], Loss_min: 35.0241, Loss_max: -34.7389\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [64/125], Loss_min: 35.2233, Loss_max: -35.0051\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [65/125], Loss_min: 34.3680, Loss_max: -34.0969\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [66/125], Loss_min: 33.7480, Loss_max: -33.5581\n",
      "tensor(0.1667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [67/125], Loss_min: 35.2328, Loss_max: -34.8994\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [68/125], Loss_min: 34.8009, Loss_max: -34.5995\n",
      "tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [69/125], Loss_min: 35.6398, Loss_max: -35.4138\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [70/125], Loss_min: 35.4982, Loss_max: -35.3228\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [71/125], Loss_min: 34.4496, Loss_max: -34.1393\n",
      "tensor(0.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [72/125], Loss_min: 34.2712, Loss_max: -33.9595\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [73/125], Loss_min: 35.3883, Loss_max: -35.1290\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [74/125], Loss_min: 35.8155, Loss_max: -35.6126\n",
      "tensor(0.1318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [75/125], Loss_min: 34.5412, Loss_max: -34.2776\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [76/125], Loss_min: 35.7090, Loss_max: -35.4728\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [77/125], Loss_min: 35.0570, Loss_max: -34.8493\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [78/125], Loss_min: 36.0303, Loss_max: -35.8421\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [79/125], Loss_min: 35.7025, Loss_max: -35.5498\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [80/125], Loss_min: 34.9549, Loss_max: -34.7569\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [81/125], Loss_min: 34.7214, Loss_max: -34.5773\n",
      "tensor(0.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [82/125], Loss_min: 34.6395, Loss_max: -34.5035\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [83/125], Loss_min: 34.9259, Loss_max: -34.7909\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [84/125], Loss_min: 35.8064, Loss_max: -35.6835\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [85/125], Loss_min: 34.1493, Loss_max: -34.0491\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [86/125], Loss_min: 36.0610, Loss_max: -35.9157\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [87/125], Loss_min: 36.8321, Loss_max: -36.7000\n",
      "tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [88/125], Loss_min: 36.4812, Loss_max: -35.7746\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [89/125], Loss_min: 36.4210, Loss_max: -36.2862\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [90/125], Loss_min: 36.2280, Loss_max: -36.1154\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [91/125], Loss_min: 36.5002, Loss_max: -36.3875\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [92/125], Loss_min: 36.5976, Loss_max: -36.4938\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [93/125], Loss_min: 35.8587, Loss_max: -35.7645\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [94/125], Loss_min: 37.3379, Loss_max: -37.2367\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [95/125], Loss_min: 36.2726, Loss_max: -36.1747\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [96/125], Loss_min: 36.8047, Loss_max: -36.7035\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [97/125], Loss_min: 37.3679, Loss_max: -37.2847\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [98/125], Loss_min: 37.4559, Loss_max: -37.3749\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [99/125], Loss_min: 37.2074, Loss_max: -37.0848\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [100/125], Loss_min: 36.7430, Loss_max: -36.6493\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [101/125], Loss_min: 37.9484, Loss_max: -37.7020\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [102/125], Loss_min: 37.5657, Loss_max: -37.4702\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [103/125], Loss_min: 37.3891, Loss_max: -37.3016\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [104/125], Loss_min: 38.1698, Loss_max: -38.0518\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [105/125], Loss_min: 37.7899, Loss_max: -37.6973\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [106/125], Loss_min: 37.7858, Loss_max: -37.3480\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [107/125], Loss_min: 37.4041, Loss_max: -37.3335\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [108/125], Loss_min: 37.0947, Loss_max: -36.9863\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [109/125], Loss_min: 38.4739, Loss_max: -38.3491\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.5619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [110/125], Loss_min: 37.7440, Loss_max: -37.6275\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [111/125], Loss_min: 38.7356, Loss_max: -38.6494\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [112/125], Loss_min: 39.1231, Loss_max: -39.0341\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [113/125], Loss_min: 38.8490, Loss_max: -38.7550\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [114/125], Loss_min: 39.0965, Loss_max: -38.9979\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [115/125], Loss_min: 38.7598, Loss_max: -38.6423\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [116/125], Loss_min: 39.3293, Loss_max: -39.2043\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [117/125], Loss_min: 38.8708, Loss_max: -38.7908\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [118/125], Loss_min: 39.6165, Loss_max: -39.5343\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [119/125], Loss_min: 39.3106, Loss_max: -39.2347\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [120/125], Loss_min: 39.8255, Loss_max: -39.7009\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [121/125], Loss_min: 39.4533, Loss_max: -39.3382\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [122/125], Loss_min: 39.2531, Loss_max: -39.1887\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [123/125], Loss_min: 39.9294, Loss_max: -39.8514\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.3712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.3712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [124/125], Loss_min: 40.1558, Loss_max: -40.0714\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [125/125], Loss_min: 40.2362, Loss_max: -40.1642\n",
      "Epoch: 1\n",
      "tensor(0.0710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [1/125], Loss_min: 39.7045, Loss_max: -39.5625\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [2/125], Loss_min: 40.3246, Loss_max: -40.2410\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [3/125], Loss_min: 40.2583, Loss_max: -40.1846\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [4/125], Loss_min: 40.4667, Loss_max: -40.3665\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [5/125], Loss_min: 40.8230, Loss_max: -40.7360\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [6/125], Loss_min: 40.6203, Loss_max: -40.5359\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [7/125], Loss_min: 40.9075, Loss_max: -40.8108\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [8/125], Loss_min: 41.1200, Loss_max: -41.0474\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [9/125], Loss_min: 40.3120, Loss_max: -40.2463\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [10/125], Loss_min: 40.9631, Loss_max: -40.8662\n",
      "tensor(0.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [11/125], Loss_min: 40.5854, Loss_max: -40.4123\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [12/125], Loss_min: 41.3775, Loss_max: -41.2837\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [13/125], Loss_min: 41.2650, Loss_max: -41.1612\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [14/125], Loss_min: 40.4636, Loss_max: -40.3226\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [15/125], Loss_min: 42.1761, Loss_max: -42.0654\n",
      "tensor(0.1880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [16/125], Loss_min: 42.0684, Loss_max: -41.6925\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [17/125], Loss_min: 41.9030, Loss_max: -41.6212\n",
      "tensor(0.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [18/125], Loss_min: 43.0674, Loss_max: -42.8863\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [19/125], Loss_min: 42.4602, Loss_max: -42.2134\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [20/125], Loss_min: 43.0769, Loss_max: -42.8521\n",
      "tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [21/125], Loss_min: 42.7156, Loss_max: -42.5024\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [22/125], Loss_min: 44.0984, Loss_max: -43.8422\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [23/125], Loss_min: 43.1669, Loss_max: -42.9428\n",
      "tensor(0.1016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [24/125], Loss_min: 44.0855, Loss_max: -43.8823\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [25/125], Loss_min: 44.3985, Loss_max: -44.1495\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [26/125], Loss_min: 44.0383, Loss_max: -43.7933\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [27/125], Loss_min: 44.3067, Loss_max: -44.0706\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [28/125], Loss_min: 44.9281, Loss_max: -44.6963\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [29/125], Loss_min: 44.5398, Loss_max: -44.2852\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [30/125], Loss_min: 44.8120, Loss_max: -44.5713\n",
      "tensor(0.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [31/125], Loss_min: 44.5613, Loss_max: -44.3512\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [32/125], Loss_min: 44.5554, Loss_max: -44.3782\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [33/125], Loss_min: 44.6428, Loss_max: -44.4512\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [34/125], Loss_min: 44.1489, Loss_max: -43.9607\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [35/125], Loss_min: 44.4017, Loss_max: -44.2001\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [36/125], Loss_min: 45.3530, Loss_max: -45.0636\n",
      "tensor(0.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [37/125], Loss_min: 44.2014, Loss_max: -43.9475\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [38/125], Loss_min: 45.0436, Loss_max: -44.5437\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [39/125], Loss_min: 43.8826, Loss_max: -43.7415\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [40/125], Loss_min: 44.7785, Loss_max: -44.6503\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [41/125], Loss_min: 44.2456, Loss_max: -44.0370\n",
      "tensor(0.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [42/125], Loss_min: 44.0838, Loss_max: -43.9528\n",
      "tensor(0.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [43/125], Loss_min: 45.0431, Loss_max: -44.7566\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [44/125], Loss_min: 45.1192, Loss_max: -45.0080\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [45/125], Loss_min: 44.9822, Loss_max: -44.8434\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [46/125], Loss_min: 44.7324, Loss_max: -44.4317\n",
      "tensor(0.1579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [47/125], Loss_min: 44.7704, Loss_max: -44.4545\n",
      "tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [48/125], Loss_min: 45.3769, Loss_max: -45.1567\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [49/125], Loss_min: 45.0417, Loss_max: -44.9504\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [50/125], Loss_min: 44.9154, Loss_max: -44.8408\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [51/125], Loss_min: 44.8700, Loss_max: -44.7814\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [52/125], Loss_min: 45.3941, Loss_max: -45.2905\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [53/125], Loss_min: 45.8168, Loss_max: -45.7132\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [54/125], Loss_min: 45.3849, Loss_max: -45.3107\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [55/125], Loss_min: 45.8268, Loss_max: -45.7088\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [56/125], Loss_min: 46.0757, Loss_max: -45.9815\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [57/125], Loss_min: 45.0681, Loss_max: -44.9846\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [58/125], Loss_min: 45.5459, Loss_max: -45.4518\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [59/125], Loss_min: 45.1855, Loss_max: -45.0848\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [60/125], Loss_min: 45.3268, Loss_max: -45.2321\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [61/125], Loss_min: 45.3587, Loss_max: -45.2698\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [62/125], Loss_min: 44.3569, Loss_max: -44.2969\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [63/125], Loss_min: 44.8051, Loss_max: -44.7384\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [64/125], Loss_min: 45.8117, Loss_max: -45.7499\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [65/125], Loss_min: 44.3909, Loss_max: -44.3305\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [66/125], Loss_min: 45.7353, Loss_max: -45.6598\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [67/125], Loss_min: 45.0264, Loss_max: -44.9574\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [68/125], Loss_min: 45.6188, Loss_max: -45.5579\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [69/125], Loss_min: 45.4996, Loss_max: -45.4470\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [70/125], Loss_min: 45.0090, Loss_max: -44.9546\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [71/125], Loss_min: 46.2547, Loss_max: -46.1346\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [72/125], Loss_min: 44.8416, Loss_max: -44.6009\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [73/125], Loss_min: 45.9135, Loss_max: -45.5447\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [74/125], Loss_min: 46.1950, Loss_max: -46.1258\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [75/125], Loss_min: 45.0902, Loss_max: -45.0177\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [76/125], Loss_min: 45.4288, Loss_max: -45.3671\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [77/125], Loss_min: 45.1252, Loss_max: -45.0573\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [78/125], Loss_min: 45.8889, Loss_max: -45.7843\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [79/125], Loss_min: 45.0466, Loss_max: -44.9876\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [80/125], Loss_min: 46.2334, Loss_max: -46.1581\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [81/125], Loss_min: 45.2309, Loss_max: -45.1484\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [82/125], Loss_min: 46.4677, Loss_max: -46.3837\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [83/125], Loss_min: 45.9728, Loss_max: -45.9075\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [84/125], Loss_min: 44.8772, Loss_max: -44.8133\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [85/125], Loss_min: 46.0118, Loss_max: -45.9408\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [86/125], Loss_min: 46.4521, Loss_max: -46.3596\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [87/125], Loss_min: 46.5628, Loss_max: -46.4764\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [88/125], Loss_min: 45.6853, Loss_max: -45.6038\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [89/125], Loss_min: 45.2739, Loss_max: -45.2190\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [90/125], Loss_min: 46.0287, Loss_max: -45.8629\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [91/125], Loss_min: 46.0988, Loss_max: -46.0393\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [92/125], Loss_min: 45.9715, Loss_max: -45.8965\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [93/125], Loss_min: 46.4828, Loss_max: -46.4152\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [94/125], Loss_min: 45.8857, Loss_max: -45.8271\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [95/125], Loss_min: 45.2115, Loss_max: -45.1529\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [96/125], Loss_min: 45.9431, Loss_max: -45.8841\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [97/125], Loss_min: 46.6305, Loss_max: -46.5668\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [98/125], Loss_min: 45.4943, Loss_max: -45.4297\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [99/125], Loss_min: 45.3984, Loss_max: -45.3244\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [100/125], Loss_min: 45.2128, Loss_max: -45.1378\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [101/125], Loss_min: 46.3177, Loss_max: -46.2387\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [102/125], Loss_min: 45.7876, Loss_max: -45.7188\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [103/125], Loss_min: 45.3508, Loss_max: -45.2453\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [104/125], Loss_min: 45.4622, Loss_max: -45.3963\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [105/125], Loss_min: 46.1368, Loss_max: -46.0319\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [106/125], Loss_min: 46.3399, Loss_max: -46.2694\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [107/125], Loss_min: 46.3164, Loss_max: -46.2543\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [108/125], Loss_min: 45.2812, Loss_max: -45.2043\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [109/125], Loss_min: 45.8711, Loss_max: -45.7963\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [110/125], Loss_min: 46.6108, Loss_max: -46.5464\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [111/125], Loss_min: 46.2648, Loss_max: -46.1534\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [112/125], Loss_min: 46.1590, Loss_max: -46.0911\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [113/125], Loss_min: 45.1169, Loss_max: -44.9427\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [114/125], Loss_min: 46.2270, Loss_max: -46.1645\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [115/125], Loss_min: 46.0697, Loss_max: -46.0068\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [116/125], Loss_min: 46.1163, Loss_max: -46.0504\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [117/125], Loss_min: 46.2804, Loss_max: -46.2079\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [118/125], Loss_min: 46.6053, Loss_max: -46.5471\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [119/125], Loss_min: 45.0466, Loss_max: -44.9977\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [120/125], Loss_min: 46.3194, Loss_max: -46.2594\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [121/125], Loss_min: 46.1412, Loss_max: -46.0702\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [122/125], Loss_min: 46.0732, Loss_max: -46.0137\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [123/125], Loss_min: 46.0749, Loss_max: -46.0119\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [124/125], Loss_min: 45.3609, Loss_max: -45.2335\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [125/125], Loss_min: 46.2273, Loss_max: -46.1680\n",
      "Epoch: 2\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [1/125], Loss_min: 46.6826, Loss_max: -46.6263\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [2/125], Loss_min: 45.9969, Loss_max: -45.9358\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [3/125], Loss_min: 46.4118, Loss_max: -46.3510\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [4/125], Loss_min: 45.7157, Loss_max: -45.6652\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [5/125], Loss_min: 46.4749, Loss_max: -46.4068\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [6/125], Loss_min: 45.5233, Loss_max: -45.4278\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [7/125], Loss_min: 46.2046, Loss_max: -46.1486\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [8/125], Loss_min: 46.5908, Loss_max: -46.5226\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [9/125], Loss_min: 45.5660, Loss_max: -45.4941\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [10/125], Loss_min: 45.7358, Loss_max: -45.6840\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [11/125], Loss_min: 46.2696, Loss_max: -46.2143\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [12/125], Loss_min: 46.1015, Loss_max: -46.0598\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [13/125], Loss_min: 46.2675, Loss_max: -46.2162\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [14/125], Loss_min: 47.0016, Loss_max: -46.9371\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [15/125], Loss_min: 45.9387, Loss_max: -45.8888\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [16/125], Loss_min: 45.9844, Loss_max: -45.9393\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [17/125], Loss_min: 46.3912, Loss_max: -46.2578\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [18/125], Loss_min: 46.8420, Loss_max: -46.7864\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [19/125], Loss_min: 46.6491, Loss_max: -46.5759\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [20/125], Loss_min: 46.1666, Loss_max: -46.0904\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [21/125], Loss_min: 46.2188, Loss_max: -46.1669\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [22/125], Loss_min: 46.5347, Loss_max: -46.4844\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [23/125], Loss_min: 46.2532, Loss_max: -46.2023\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [24/125], Loss_min: 46.0606, Loss_max: -45.9658\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [25/125], Loss_min: 46.6358, Loss_max: -46.5815\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [26/125], Loss_min: 46.5159, Loss_max: -46.4576\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [27/125], Loss_min: 45.6412, Loss_max: -45.6005\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [28/125], Loss_min: 46.5638, Loss_max: -46.4998\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [29/125], Loss_min: 45.9779, Loss_max: -45.9313\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [30/125], Loss_min: 46.6327, Loss_max: -46.5823\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [31/125], Loss_min: 46.5624, Loss_max: -46.5197\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [32/125], Loss_min: 46.6729, Loss_max: -46.6222\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [33/125], Loss_min: 46.3608, Loss_max: -46.3159\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [34/125], Loss_min: 46.7175, Loss_max: -46.6683\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [35/125], Loss_min: 47.1455, Loss_max: -47.0935\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [36/125], Loss_min: 46.5080, Loss_max: -46.4606\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [37/125], Loss_min: 46.0881, Loss_max: -46.0390\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [38/125], Loss_min: 45.9133, Loss_max: -45.8718\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [39/125], Loss_min: 46.4322, Loss_max: -46.3789\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [40/125], Loss_min: 46.1076, Loss_max: -46.0616\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [41/125], Loss_min: 46.6151, Loss_max: -46.5550\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [42/125], Loss_min: 46.3406, Loss_max: -46.2904\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [43/125], Loss_min: 46.6592, Loss_max: -46.6042\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [44/125], Loss_min: 45.9439, Loss_max: -45.8968\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [45/125], Loss_min: 45.8445, Loss_max: -45.7972\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [46/125], Loss_min: 46.1557, Loss_max: -46.0866\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [47/125], Loss_min: 45.9760, Loss_max: -45.9333\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [48/125], Loss_min: 46.5703, Loss_max: -46.4965\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [49/125], Loss_min: 46.4636, Loss_max: -46.4229\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [50/125], Loss_min: 45.9113, Loss_max: -45.8741\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [51/125], Loss_min: 46.6908, Loss_max: -46.6481\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [52/125], Loss_min: 46.2234, Loss_max: -46.1694\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [53/125], Loss_min: 47.0628, Loss_max: -47.0109\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [54/125], Loss_min: 46.7737, Loss_max: -46.7219\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [55/125], Loss_min: 46.2932, Loss_max: -46.2391\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [56/125], Loss_min: 46.5282, Loss_max: -46.4712\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [57/125], Loss_min: 47.2020, Loss_max: -47.1502\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [58/125], Loss_min: 46.5146, Loss_max: -46.4671\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [59/125], Loss_min: 46.2798, Loss_max: -46.2374\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [60/125], Loss_min: 46.4527, Loss_max: -46.3974\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [61/125], Loss_min: 46.5191, Loss_max: -46.4679\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [62/125], Loss_min: 47.1998, Loss_max: -47.1511\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [63/125], Loss_min: 46.6329, Loss_max: -46.5472\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [64/125], Loss_min: 45.5618, Loss_max: -45.4738\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [65/125], Loss_min: 46.6564, Loss_max: -46.5874\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [66/125], Loss_min: 46.8831, Loss_max: -46.8361\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [67/125], Loss_min: 46.2614, Loss_max: -46.2102\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [68/125], Loss_min: 46.9211, Loss_max: -46.8271\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [69/125], Loss_min: 46.0754, Loss_max: -46.0240\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [70/125], Loss_min: 46.8091, Loss_max: -46.7532\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [71/125], Loss_min: 46.5686, Loss_max: -46.5183\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [72/125], Loss_min: 46.7405, Loss_max: -46.6942\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [73/125], Loss_min: 46.6046, Loss_max: -46.5514\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [74/125], Loss_min: 46.8411, Loss_max: -46.7925\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [75/125], Loss_min: 46.5317, Loss_max: -46.4866\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [76/125], Loss_min: 46.0931, Loss_max: -46.0459\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [77/125], Loss_min: 46.5482, Loss_max: -46.5028\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [78/125], Loss_min: 46.6692, Loss_max: -46.6276\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [79/125], Loss_min: 46.6287, Loss_max: -46.5945\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [80/125], Loss_min: 46.1013, Loss_max: -46.0582\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [81/125], Loss_min: 47.0208, Loss_max: -46.9631\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [82/125], Loss_min: 46.4946, Loss_max: -46.4412\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [83/125], Loss_min: 46.5455, Loss_max: -46.5094\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [84/125], Loss_min: 46.5100, Loss_max: -46.4674\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [85/125], Loss_min: 46.2568, Loss_max: -46.2244\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [86/125], Loss_min: 46.4461, Loss_max: -46.4048\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [87/125], Loss_min: 46.7367, Loss_max: -46.6762\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [88/125], Loss_min: 46.4833, Loss_max: -46.4488\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [89/125], Loss_min: 46.9306, Loss_max: -46.8404\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [90/125], Loss_min: 46.4906, Loss_max: -46.4202\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [91/125], Loss_min: 46.4969, Loss_max: -46.4559\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [92/125], Loss_min: 46.4862, Loss_max: -46.3951\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [93/125], Loss_min: 46.3391, Loss_max: -46.2893\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [94/125], Loss_min: 47.3207, Loss_max: -47.2597\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [95/125], Loss_min: 46.6052, Loss_max: -46.4924\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [96/125], Loss_min: 46.8932, Loss_max: -46.8581\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [97/125], Loss_min: 46.8502, Loss_max: -46.8065\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [98/125], Loss_min: 47.1155, Loss_max: -47.0718\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [99/125], Loss_min: 46.9905, Loss_max: -46.9589\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [100/125], Loss_min: 46.6547, Loss_max: -46.5824\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [101/125], Loss_min: 46.2997, Loss_max: -46.2650\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [102/125], Loss_min: 47.1132, Loss_max: -47.0651\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [103/125], Loss_min: 46.7925, Loss_max: -46.7455\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [104/125], Loss_min: 46.3878, Loss_max: -46.3538\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [105/125], Loss_min: 46.7590, Loss_max: -46.7174\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [106/125], Loss_min: 46.3164, Loss_max: -46.2430\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [107/125], Loss_min: 47.0283, Loss_max: -46.9856\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [108/125], Loss_min: 46.9197, Loss_max: -46.8772\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [109/125], Loss_min: 47.1847, Loss_max: -47.1399\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [110/125], Loss_min: 46.7803, Loss_max: -46.7421\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [111/125], Loss_min: 47.3552, Loss_max: -47.3137\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [112/125], Loss_min: 46.6803, Loss_max: -46.6509\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [113/125], Loss_min: 46.5035, Loss_max: -46.4735\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [114/125], Loss_min: 46.3100, Loss_max: -46.2384\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [115/125], Loss_min: 47.0327, Loss_max: -46.9399\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [116/125], Loss_min: 46.6133, Loss_max: -46.5787\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [117/125], Loss_min: 45.7763, Loss_max: -45.7342\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [118/125], Loss_min: 46.7988, Loss_max: -46.7570\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [119/125], Loss_min: 47.1877, Loss_max: -47.1360\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [120/125], Loss_min: 46.6853, Loss_max: -46.6507\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [121/125], Loss_min: 46.0185, Loss_max: -45.9607\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [122/125], Loss_min: 46.5501, Loss_max: -46.5184\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [123/125], Loss_min: 46.9721, Loss_max: -46.9315\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [124/125], Loss_min: 46.7534, Loss_max: -46.7118\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [125/125], Loss_min: 46.6039, Loss_max: -46.5672\n",
      "Epoch: 3\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [1/125], Loss_min: 47.0991, Loss_max: -47.0489\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [2/125], Loss_min: 46.6004, Loss_max: -46.5558\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [3/125], Loss_min: 46.8134, Loss_max: -46.7731\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [4/125], Loss_min: 46.8334, Loss_max: -46.7835\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [5/125], Loss_min: 47.0862, Loss_max: -47.0289\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [6/125], Loss_min: 46.1579, Loss_max: -46.1106\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [7/125], Loss_min: 47.0215, Loss_max: -46.9647\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [8/125], Loss_min: 46.7409, Loss_max: -46.7000\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [9/125], Loss_min: 46.5022, Loss_max: -46.4709\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [10/125], Loss_min: 46.8014, Loss_max: -46.7633\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [11/125], Loss_min: 47.3874, Loss_max: -47.3386\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [12/125], Loss_min: 46.5545, Loss_max: -46.5163\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [13/125], Loss_min: 46.7535, Loss_max: -46.7203\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [14/125], Loss_min: 47.2489, Loss_max: -47.2142\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [15/125], Loss_min: 46.4134, Loss_max: -46.3785\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [16/125], Loss_min: 47.1334, Loss_max: -47.0975\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [17/125], Loss_min: 46.8897, Loss_max: -46.8518\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [18/125], Loss_min: 46.8353, Loss_max: -46.7215\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [19/125], Loss_min: 46.8923, Loss_max: -46.8552\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [20/125], Loss_min: 47.3328, Loss_max: -47.1557\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [21/125], Loss_min: 47.2320, Loss_max: -47.1887\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [22/125], Loss_min: 47.0573, Loss_max: -47.0067\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [23/125], Loss_min: 45.8696, Loss_max: -45.8376\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [24/125], Loss_min: 46.9745, Loss_max: -46.9290\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [25/125], Loss_min: 47.3801, Loss_max: -47.3417\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [26/125], Loss_min: 47.1423, Loss_max: -47.1052\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [27/125], Loss_min: 46.9021, Loss_max: -46.8687\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [28/125], Loss_min: 47.5534, Loss_max: -47.5136\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [29/125], Loss_min: 46.4187, Loss_max: -46.3841\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [30/125], Loss_min: 46.8731, Loss_max: -46.8422\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [31/125], Loss_min: 47.1058, Loss_max: -47.0730\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [32/125], Loss_min: 46.8401, Loss_max: -46.8085\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [33/125], Loss_min: 47.1300, Loss_max: -47.0895\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [34/125], Loss_min: 46.4050, Loss_max: -46.3670\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [35/125], Loss_min: 47.1582, Loss_max: -47.1288\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [36/125], Loss_min: 46.8187, Loss_max: -46.7862\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [37/125], Loss_min: 46.8681, Loss_max: -46.8325\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [38/125], Loss_min: 47.1046, Loss_max: -47.0648\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [39/125], Loss_min: 46.8722, Loss_max: -46.8448\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [40/125], Loss_min: 47.2015, Loss_max: -47.1503\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [41/125], Loss_min: 46.2166, Loss_max: -46.1846\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [42/125], Loss_min: 47.0758, Loss_max: -47.0406\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [43/125], Loss_min: 46.8275, Loss_max: -46.8005\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [44/125], Loss_min: 46.7831, Loss_max: -46.7544\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [45/125], Loss_min: 47.1508, Loss_max: -47.1251\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [46/125], Loss_min: 46.9657, Loss_max: -46.8834\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [47/125], Loss_min: 46.2872, Loss_max: -46.2587\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [48/125], Loss_min: 46.9489, Loss_max: -46.9138\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [49/125], Loss_min: 47.0845, Loss_max: -47.0485\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [50/125], Loss_min: 47.3052, Loss_max: -47.2641\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [51/125], Loss_min: 46.9575, Loss_max: -46.9148\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [52/125], Loss_min: 46.0845, Loss_max: -46.0323\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [53/125], Loss_min: 47.4631, Loss_max: -47.4289\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [54/125], Loss_min: 46.9911, Loss_max: -46.9614\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [55/125], Loss_min: 47.1135, Loss_max: -47.0803\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [56/125], Loss_min: 46.8655, Loss_max: -46.8340\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [57/125], Loss_min: 47.2868, Loss_max: -47.1858\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [58/125], Loss_min: 47.3372, Loss_max: -47.3027\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [59/125], Loss_min: 46.6895, Loss_max: -46.6623\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [60/125], Loss_min: 46.6421, Loss_max: -46.6134\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [61/125], Loss_min: 47.1276, Loss_max: -47.0991\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [62/125], Loss_min: 47.2273, Loss_max: -47.1916\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [63/125], Loss_min: 47.3505, Loss_max: -47.3155\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [64/125], Loss_min: 47.5598, Loss_max: -47.4914\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [65/125], Loss_min: 46.6160, Loss_max: -46.5873\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [66/125], Loss_min: 46.8871, Loss_max: -46.8514\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [67/125], Loss_min: 47.5267, Loss_max: -47.4908\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [68/125], Loss_min: 47.3612, Loss_max: -47.3199\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [69/125], Loss_min: 46.4755, Loss_max: -46.4436\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [70/125], Loss_min: 47.4293, Loss_max: -47.3976\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [71/125], Loss_min: 46.9402, Loss_max: -46.8977\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [72/125], Loss_min: 46.7373, Loss_max: -46.7096\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [73/125], Loss_min: 47.2782, Loss_max: -47.2481\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [74/125], Loss_min: 46.6553, Loss_max: -46.6218\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [75/125], Loss_min: 47.3501, Loss_max: -47.2761\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [76/125], Loss_min: 46.3817, Loss_max: -46.3152\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [77/125], Loss_min: 46.9086, Loss_max: -46.8848\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [78/125], Loss_min: 46.7848, Loss_max: -46.7518\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [79/125], Loss_min: 47.0133, Loss_max: -46.9859\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [80/125], Loss_min: 47.1910, Loss_max: -47.1582\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [81/125], Loss_min: 46.7657, Loss_max: -46.7132\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [82/125], Loss_min: 46.7198, Loss_max: -46.6882\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [83/125], Loss_min: 47.4865, Loss_max: -47.4559\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [84/125], Loss_min: 46.2825, Loss_max: -46.2560\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [85/125], Loss_min: 46.6935, Loss_max: -46.6709\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [86/125], Loss_min: 47.0055, Loss_max: -46.9761\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [87/125], Loss_min: 47.3342, Loss_max: -47.3026\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [88/125], Loss_min: 47.2453, Loss_max: -47.2156\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [89/125], Loss_min: 47.1440, Loss_max: -47.0766\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [90/125], Loss_min: 47.1954, Loss_max: -47.1438\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [91/125], Loss_min: 47.5373, Loss_max: -47.4995\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [92/125], Loss_min: 46.3420, Loss_max: -46.3138\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [93/125], Loss_min: 46.7085, Loss_max: -46.6696\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [94/125], Loss_min: 47.1215, Loss_max: -47.0909\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [95/125], Loss_min: 46.8704, Loss_max: -46.8404\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [96/125], Loss_min: 46.9462, Loss_max: -46.9068\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [97/125], Loss_min: 47.1399, Loss_max: -47.1152\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [98/125], Loss_min: 47.5352, Loss_max: -47.4985\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [99/125], Loss_min: 46.7291, Loss_max: -46.7019\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [100/125], Loss_min: 47.2264, Loss_max: -47.1940\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [101/125], Loss_min: 46.4938, Loss_max: -46.4716\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [102/125], Loss_min: 46.4471, Loss_max: -46.4132\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [103/125], Loss_min: 47.3019, Loss_max: -47.2682\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [104/125], Loss_min: 46.9557, Loss_max: -46.9160\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [105/125], Loss_min: 47.2420, Loss_max: -47.2065\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [106/125], Loss_min: 47.1907, Loss_max: -47.1569\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [107/125], Loss_min: 47.2655, Loss_max: -47.2274\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [108/125], Loss_min: 46.7366, Loss_max: -46.7047\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [109/125], Loss_min: 47.3194, Loss_max: -47.2753\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [110/125], Loss_min: 47.1024, Loss_max: -47.0712\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [111/125], Loss_min: 46.8950, Loss_max: -46.8613\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [112/125], Loss_min: 46.7698, Loss_max: -46.7315\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [113/125], Loss_min: 47.1360, Loss_max: -47.0907\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [114/125], Loss_min: 47.2275, Loss_max: -47.1993\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [115/125], Loss_min: 47.5179, Loss_max: -47.4920\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [116/125], Loss_min: 46.7798, Loss_max: -46.7543\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [117/125], Loss_min: 46.8991, Loss_max: -46.8514\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [118/125], Loss_min: 47.5247, Loss_max: -47.4896\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [119/125], Loss_min: 46.8126, Loss_max: -46.7895\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [120/125], Loss_min: 47.1895, Loss_max: -47.1637\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [121/125], Loss_min: 47.2493, Loss_max: -47.2198\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [122/125], Loss_min: 47.0226, Loss_max: -46.9867\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [123/125], Loss_min: 47.5035, Loss_max: -47.4633\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [124/125], Loss_min: 46.6784, Loss_max: -46.6177\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [125/125], Loss_min: 47.2544, Loss_max: -47.2272\n",
      "Epoch: 4\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [1/125], Loss_min: 47.2237, Loss_max: -47.1850\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [2/125], Loss_min: 47.2841, Loss_max: -47.2536\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [3/125], Loss_min: 47.5202, Loss_max: -47.3704\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [4/125], Loss_min: 47.4513, Loss_max: -47.4234\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [5/125], Loss_min: 47.2969, Loss_max: -47.2124\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [6/125], Loss_min: 47.1068, Loss_max: -47.0817\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [7/125], Loss_min: 46.8095, Loss_max: -46.7777\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [8/125], Loss_min: 46.4735, Loss_max: -46.4409\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [9/125], Loss_min: 47.1816, Loss_max: -47.1500\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [10/125], Loss_min: 47.3373, Loss_max: -47.2754\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [11/125], Loss_min: 47.5197, Loss_max: -47.4931\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [12/125], Loss_min: 47.3715, Loss_max: -47.3413\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [13/125], Loss_min: 47.2552, Loss_max: -47.2117\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [14/125], Loss_min: 47.2324, Loss_max: -47.1550\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [15/125], Loss_min: 47.4281, Loss_max: -47.3899\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [16/125], Loss_min: 46.9284, Loss_max: -46.8997\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [17/125], Loss_min: 47.0247, Loss_max: -46.9883\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [18/125], Loss_min: 47.1228, Loss_max: -47.0860\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [19/125], Loss_min: 46.9311, Loss_max: -46.8934\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [20/125], Loss_min: 47.3112, Loss_max: -47.2693\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [21/125], Loss_min: 47.2763, Loss_max: -47.2382\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [22/125], Loss_min: 47.4410, Loss_max: -47.4110\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [23/125], Loss_min: 47.0974, Loss_max: -47.0051\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [24/125], Loss_min: 47.3289, Loss_max: -47.2610\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [25/125], Loss_min: 47.1074, Loss_max: -47.0843\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [26/125], Loss_min: 47.1540, Loss_max: -47.1148\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [27/125], Loss_min: 47.0862, Loss_max: -47.0554\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [28/125], Loss_min: 47.0534, Loss_max: -47.0181\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [29/125], Loss_min: 47.3446, Loss_max: -47.3086\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [30/125], Loss_min: 47.3486, Loss_max: -47.3235\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [31/125], Loss_min: 47.4210, Loss_max: -47.3895\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [32/125], Loss_min: 47.2266, Loss_max: -47.1871\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [33/125], Loss_min: 47.1666, Loss_max: -47.1275\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [34/125], Loss_min: 47.4443, Loss_max: -47.4088\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [35/125], Loss_min: 47.0260, Loss_max: -46.9985\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [36/125], Loss_min: 47.5243, Loss_max: -47.4976\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [37/125], Loss_min: 47.2661, Loss_max: -47.2420\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [38/125], Loss_min: 47.2935, Loss_max: -47.2707\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [39/125], Loss_min: 47.1986, Loss_max: -47.1576\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [40/125], Loss_min: 47.2876, Loss_max: -47.2505\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [41/125], Loss_min: 47.0316, Loss_max: -46.9964\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [42/125], Loss_min: 46.9453, Loss_max: -46.9103\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [43/125], Loss_min: 47.1663, Loss_max: -47.1408\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [44/125], Loss_min: 47.1825, Loss_max: -47.1579\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [45/125], Loss_min: 46.9828, Loss_max: -46.9580\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [46/125], Loss_min: 47.2413, Loss_max: -47.1985\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [47/125], Loss_min: 47.1557, Loss_max: -47.1039\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [48/125], Loss_min: 47.4135, Loss_max: -47.3753\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [49/125], Loss_min: 47.0228, Loss_max: -46.9810\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [50/125], Loss_min: 47.5974, Loss_max: -47.5707\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [51/125], Loss_min: 46.9485, Loss_max: -46.9275\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [52/125], Loss_min: 47.5638, Loss_max: -47.5389\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [53/125], Loss_min: 47.6849, Loss_max: -47.6571\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [54/125], Loss_min: 47.2237, Loss_max: -47.2000\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [55/125], Loss_min: 47.4045, Loss_max: -47.3831\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [56/125], Loss_min: 47.5454, Loss_max: -47.5202\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [57/125], Loss_min: 47.3687, Loss_max: -47.3410\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [58/125], Loss_min: 47.2986, Loss_max: -47.2707\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [59/125], Loss_min: 47.4410, Loss_max: -47.4203\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [60/125], Loss_min: 47.3468, Loss_max: -47.3212\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [61/125], Loss_min: 47.3634, Loss_max: -47.3319\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [62/125], Loss_min: 47.4046, Loss_max: -47.3758\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [63/125], Loss_min: 47.3180, Loss_max: -47.2838\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [64/125], Loss_min: 47.3397, Loss_max: -47.3189\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [65/125], Loss_min: 47.0027, Loss_max: -46.9802\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [66/125], Loss_min: 47.6348, Loss_max: -47.6006\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [67/125], Loss_min: 47.5130, Loss_max: -47.4849\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [68/125], Loss_min: 47.6675, Loss_max: -47.6447\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [69/125], Loss_min: 47.4608, Loss_max: -47.4330\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [70/125], Loss_min: 47.3759, Loss_max: -47.3256\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [71/125], Loss_min: 47.4867, Loss_max: -47.4348\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [72/125], Loss_min: 47.4262, Loss_max: -47.4011\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [73/125], Loss_min: 47.4013, Loss_max: -47.3778\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [74/125], Loss_min: 46.8689, Loss_max: -46.8465\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [75/125], Loss_min: 47.2700, Loss_max: -47.1742\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [76/125], Loss_min: 47.5443, Loss_max: -47.4779\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [77/125], Loss_min: 47.4907, Loss_max: -47.4651\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [78/125], Loss_min: 47.6455, Loss_max: -47.6155\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [79/125], Loss_min: 47.8130, Loss_max: -47.7818\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [80/125], Loss_min: 47.0034, Loss_max: -46.9662\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [81/125], Loss_min: 47.4721, Loss_max: -47.4442\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [82/125], Loss_min: 47.5957, Loss_max: -47.5671\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [83/125], Loss_min: 47.4894, Loss_max: -47.4688\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [84/125], Loss_min: 47.3428, Loss_max: -47.2977\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [85/125], Loss_min: 47.5423, Loss_max: -47.4485\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [86/125], Loss_min: 47.3261, Loss_max: -47.2936\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [87/125], Loss_min: 47.3617, Loss_max: -47.2685\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [88/125], Loss_min: 47.0495, Loss_max: -46.9517\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [89/125], Loss_min: 47.3505, Loss_max: -47.2966\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [90/125], Loss_min: 47.2124, Loss_max: -47.1728\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [91/125], Loss_min: 47.0374, Loss_max: -47.0031\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [92/125], Loss_min: 47.2906, Loss_max: -47.2514\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [93/125], Loss_min: 47.4084, Loss_max: -47.3726\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [94/125], Loss_min: 46.8401, Loss_max: -46.7875\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [95/125], Loss_min: 46.9009, Loss_max: -46.8621\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [96/125], Loss_min: 47.5336, Loss_max: -47.5012\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [97/125], Loss_min: 47.1084, Loss_max: -47.0724\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [98/125], Loss_min: 46.9132, Loss_max: -46.8692\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [99/125], Loss_min: 47.3981, Loss_max: -47.3442\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [100/125], Loss_min: 47.3747, Loss_max: -47.2966\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [101/125], Loss_min: 47.4239, Loss_max: -47.3612\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [102/125], Loss_min: 47.3511, Loss_max: -47.3115\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [103/125], Loss_min: 47.4104, Loss_max: -47.3627\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [104/125], Loss_min: 47.3760, Loss_max: -47.3336\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [105/125], Loss_min: 47.2838, Loss_max: -47.2377\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [106/125], Loss_min: 47.0842, Loss_max: -47.0528\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [107/125], Loss_min: 47.6184, Loss_max: -47.5670\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [108/125], Loss_min: 47.6380, Loss_max: -47.5868\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [109/125], Loss_min: 47.2102, Loss_max: -47.1664\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [110/125], Loss_min: 47.3491, Loss_max: -47.3109\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [111/125], Loss_min: 47.3910, Loss_max: -47.3511\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [112/125], Loss_min: 47.7938, Loss_max: -47.7381\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [113/125], Loss_min: 47.6021, Loss_max: -47.5658\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [114/125], Loss_min: 47.4687, Loss_max: -47.4401\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [115/125], Loss_min: 47.6031, Loss_max: -47.5736\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [116/125], Loss_min: 47.6324, Loss_max: -47.5996\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [117/125], Loss_min: 47.0806, Loss_max: -47.0491\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [118/125], Loss_min: 46.8729, Loss_max: -46.8449\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [119/125], Loss_min: 47.0655, Loss_max: -47.0376\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [120/125], Loss_min: 47.5108, Loss_max: -47.4830\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [121/125], Loss_min: 47.5166, Loss_max: -47.4814\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [122/125], Loss_min: 47.7129, Loss_max: -47.6850\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [123/125], Loss_min: 47.5898, Loss_max: -47.5612\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [124/125], Loss_min: 47.3634, Loss_max: -47.3354\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [125/125], Loss_min: 47.1259, Loss_max: -47.1016\n",
      "Epoch: 5\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [1/125], Loss_min: 47.4785, Loss_max: -47.4498\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [2/125], Loss_min: 47.4845, Loss_max: -47.4590\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [3/125], Loss_min: 47.2519, Loss_max: -47.1438\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [4/125], Loss_min: 47.2866, Loss_max: -47.2626\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [5/125], Loss_min: 47.2759, Loss_max: -47.2532\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [6/125], Loss_min: 47.5850, Loss_max: -47.5578\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [7/125], Loss_min: 47.4574, Loss_max: -47.3560\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [8/125], Loss_min: 47.4731, Loss_max: -47.4297\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [9/125], Loss_min: 47.4102, Loss_max: -47.3765\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [10/125], Loss_min: 47.6952, Loss_max: -47.6628\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [11/125], Loss_min: 47.5945, Loss_max: -47.5685\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [12/125], Loss_min: 47.4144, Loss_max: -47.3852\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [13/125], Loss_min: 47.5595, Loss_max: -47.5329\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [14/125], Loss_min: 47.1064, Loss_max: -47.0825\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [15/125], Loss_min: 47.2756, Loss_max: -47.2523\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [16/125], Loss_min: 47.5390, Loss_max: -47.5168\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [17/125], Loss_min: 47.2130, Loss_max: -47.1915\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [18/125], Loss_min: 47.6296, Loss_max: -47.6023\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [19/125], Loss_min: 47.8017, Loss_max: -47.7519\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [20/125], Loss_min: 47.6636, Loss_max: -47.6420\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [21/125], Loss_min: 47.4316, Loss_max: -47.4128\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [22/125], Loss_min: 47.2729, Loss_max: -47.2525\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [23/125], Loss_min: 47.7133, Loss_max: -47.6836\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [24/125], Loss_min: 47.5674, Loss_max: -47.5426\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [25/125], Loss_min: 47.1478, Loss_max: -47.1206\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [26/125], Loss_min: 47.4283, Loss_max: -47.3950\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [27/125], Loss_min: 47.2094, Loss_max: -47.1836\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [28/125], Loss_min: 47.5126, Loss_max: -47.4846\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [29/125], Loss_min: 47.4131, Loss_max: -47.3856\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [30/125], Loss_min: 47.1981, Loss_max: -47.1672\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [31/125], Loss_min: 47.2230, Loss_max: -47.2005\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [32/125], Loss_min: 47.6598, Loss_max: -47.6342\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [33/125], Loss_min: 47.4844, Loss_max: -47.4533\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [34/125], Loss_min: 47.2504, Loss_max: -47.2272\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [35/125], Loss_min: 47.4165, Loss_max: -47.3888\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [36/125], Loss_min: 47.5853, Loss_max: -47.5543\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [37/125], Loss_min: 47.6621, Loss_max: -47.6358\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [38/125], Loss_min: 47.7361, Loss_max: -47.7108\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [39/125], Loss_min: 47.7780, Loss_max: -47.7551\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [40/125], Loss_min: 47.4343, Loss_max: -47.4048\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [41/125], Loss_min: 47.3795, Loss_max: -47.3586\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [42/125], Loss_min: 47.3219, Loss_max: -47.3045\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [43/125], Loss_min: 47.6208, Loss_max: -47.5439\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [44/125], Loss_min: 47.6308, Loss_max: -47.6022\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [45/125], Loss_min: 47.5005, Loss_max: -47.4738\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [46/125], Loss_min: 47.7014, Loss_max: -47.6718\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [47/125], Loss_min: 47.2434, Loss_max: -47.2201\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [48/125], Loss_min: 47.4971, Loss_max: -47.4629\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [49/125], Loss_min: 47.5204, Loss_max: -47.4709\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [50/125], Loss_min: 47.7025, Loss_max: -47.6730\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [51/125], Loss_min: 47.7709, Loss_max: -47.7503\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [52/125], Loss_min: 47.5142, Loss_max: -47.4914\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [53/125], Loss_min: 47.6929, Loss_max: -47.6608\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [54/125], Loss_min: 47.5684, Loss_max: -47.5428\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [55/125], Loss_min: 47.3901, Loss_max: -47.3642\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [56/125], Loss_min: 47.5053, Loss_max: -47.4728\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [57/125], Loss_min: 47.7736, Loss_max: -47.7389\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [58/125], Loss_min: 47.7800, Loss_max: -47.7502\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [59/125], Loss_min: 47.1761, Loss_max: -47.1500\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [60/125], Loss_min: 47.9509, Loss_max: -47.9175\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [61/125], Loss_min: 47.4343, Loss_max: -47.3726\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [62/125], Loss_min: 47.3825, Loss_max: -47.3572\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [63/125], Loss_min: 47.2077, Loss_max: -47.1704\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [64/125], Loss_min: 47.6173, Loss_max: -47.5739\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [65/125], Loss_min: 47.7838, Loss_max: -47.7370\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [66/125], Loss_min: 47.5375, Loss_max: -47.5096\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [67/125], Loss_min: 47.7336, Loss_max: -47.7026\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [68/125], Loss_min: 47.5515, Loss_max: -47.5242\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [69/125], Loss_min: 47.4003, Loss_max: -47.3786\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [70/125], Loss_min: 47.6170, Loss_max: -47.5937\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [71/125], Loss_min: 47.6299, Loss_max: -47.6062\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [72/125], Loss_min: 47.5503, Loss_max: -47.5200\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [73/125], Loss_min: 47.4572, Loss_max: -47.4257\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [74/125], Loss_min: 48.0073, Loss_max: -47.9806\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [75/125], Loss_min: 47.1982, Loss_max: -47.1690\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [76/125], Loss_min: 47.6774, Loss_max: -47.6532\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [77/125], Loss_min: 47.6664, Loss_max: -47.6456\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [78/125], Loss_min: 47.6321, Loss_max: -47.6022\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [79/125], Loss_min: 47.6207, Loss_max: -47.5977\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [80/125], Loss_min: 47.5320, Loss_max: -47.4695\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [81/125], Loss_min: 47.4236, Loss_max: -47.4001\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [82/125], Loss_min: 47.8591, Loss_max: -47.8356\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [83/125], Loss_min: 47.9340, Loss_max: -47.8993\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [84/125], Loss_min: 47.3437, Loss_max: -47.3246\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [85/125], Loss_min: 47.6705, Loss_max: -47.6415\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [86/125], Loss_min: 47.9752, Loss_max: -47.9487\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [87/125], Loss_min: 47.1881, Loss_max: -47.1656\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [88/125], Loss_min: 47.5961, Loss_max: -47.5619\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [89/125], Loss_min: 47.5685, Loss_max: -47.5415\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [90/125], Loss_min: 47.6082, Loss_max: -47.5863\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [91/125], Loss_min: 47.6910, Loss_max: -47.6708\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [92/125], Loss_min: 47.8160, Loss_max: -47.7917\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [93/125], Loss_min: 47.5143, Loss_max: -47.4895\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [94/125], Loss_min: 47.6254, Loss_max: -47.6021\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [95/125], Loss_min: 47.3252, Loss_max: -47.3083\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [96/125], Loss_min: 47.5506, Loss_max: -47.5295\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [97/125], Loss_min: 47.8438, Loss_max: -47.8125\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [98/125], Loss_min: 47.4775, Loss_max: -47.4524\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [99/125], Loss_min: 47.5093, Loss_max: -47.4874\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [100/125], Loss_min: 47.4769, Loss_max: -47.4599\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [101/125], Loss_min: 47.8428, Loss_max: -47.8156\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [102/125], Loss_min: 47.9017, Loss_max: -47.8716\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [103/125], Loss_min: 47.5148, Loss_max: -47.4923\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [104/125], Loss_min: 47.6232, Loss_max: -47.5974\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [105/125], Loss_min: 47.4796, Loss_max: -47.4500\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [106/125], Loss_min: 47.6433, Loss_max: -47.5880\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [107/125], Loss_min: 47.9326, Loss_max: -47.9004\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [108/125], Loss_min: 47.8594, Loss_max: -47.8296\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [109/125], Loss_min: 47.5196, Loss_max: -47.4948\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [110/125], Loss_min: 47.5488, Loss_max: -47.5192\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [111/125], Loss_min: 47.3778, Loss_max: -47.3531\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [112/125], Loss_min: 47.6851, Loss_max: -47.6556\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [113/125], Loss_min: 47.5794, Loss_max: -47.5544\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [114/125], Loss_min: 47.7105, Loss_max: -47.6892\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [115/125], Loss_min: 47.6745, Loss_max: -47.6515\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [116/125], Loss_min: 47.7550, Loss_max: -47.7179\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [117/125], Loss_min: 47.5234, Loss_max: -47.4986\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [118/125], Loss_min: 47.7494, Loss_max: -47.7230\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [119/125], Loss_min: 47.5160, Loss_max: -47.4918\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [120/125], Loss_min: 47.5355, Loss_max: -47.5010\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [121/125], Loss_min: 47.4704, Loss_max: -47.4476\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [122/125], Loss_min: 47.5711, Loss_max: -47.5465\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [123/125], Loss_min: 47.5383, Loss_max: -47.5170\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [124/125], Loss_min: 47.7507, Loss_max: -47.7278\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [125/125], Loss_min: 47.7751, Loss_max: -47.7513\n",
      "Epoch: 6\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [1/125], Loss_min: 47.6958, Loss_max: -47.6581\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [2/125], Loss_min: 47.4953, Loss_max: -47.4715\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [3/125], Loss_min: 47.8524, Loss_max: -47.8283\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [4/125], Loss_min: 47.8245, Loss_max: -47.8030\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [5/125], Loss_min: 47.8858, Loss_max: -47.8634\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [6/125], Loss_min: 47.6095, Loss_max: -47.5893\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [7/125], Loss_min: 47.8494, Loss_max: -47.8263\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [8/125], Loss_min: 47.6345, Loss_max: -47.5472\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [9/125], Loss_min: 47.7763, Loss_max: -47.7516\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [10/125], Loss_min: 47.3724, Loss_max: -47.3515\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [11/125], Loss_min: 47.8603, Loss_max: -47.8368\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [12/125], Loss_min: 47.8171, Loss_max: -47.7930\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [13/125], Loss_min: 47.5736, Loss_max: -47.5382\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [14/125], Loss_min: 47.8418, Loss_max: -47.8096\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [15/125], Loss_min: 47.6421, Loss_max: -47.6106\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [16/125], Loss_min: 47.6956, Loss_max: -47.6722\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [17/125], Loss_min: 47.5473, Loss_max: -47.5233\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [18/125], Loss_min: 47.6397, Loss_max: -47.6151\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [19/125], Loss_min: 47.6356, Loss_max: -47.5959\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [20/125], Loss_min: 47.5333, Loss_max: -47.5027\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [21/125], Loss_min: 47.5211, Loss_max: -47.4306\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [22/125], Loss_min: 47.6678, Loss_max: -47.5748\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [23/125], Loss_min: 47.7754, Loss_max: -47.6852\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [24/125], Loss_min: 47.6245, Loss_max: -47.5006\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [25/125], Loss_min: 47.5494, Loss_max: -47.4628\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [26/125], Loss_min: 47.6666, Loss_max: -47.5435\n",
      "tensor(0.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [27/125], Loss_min: 47.5310, Loss_max: -47.3751\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [28/125], Loss_min: 47.6190, Loss_max: -47.5218\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [29/125], Loss_min: 47.5079, Loss_max: -47.4209\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [30/125], Loss_min: 47.3305, Loss_max: -47.2640\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [31/125], Loss_min: 47.3869, Loss_max: -47.2867\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [32/125], Loss_min: 47.7516, Loss_max: -47.6500\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [33/125], Loss_min: 47.4753, Loss_max: -47.3302\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [34/125], Loss_min: 47.6241, Loss_max: -47.4869\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [35/125], Loss_min: 47.6250, Loss_max: -47.4924\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [36/125], Loss_min: 47.6315, Loss_max: -47.5213\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [37/125], Loss_min: 47.3591, Loss_max: -47.2893\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [38/125], Loss_min: 47.6460, Loss_max: -47.5868\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [39/125], Loss_min: 47.1946, Loss_max: -47.1210\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [40/125], Loss_min: 47.6033, Loss_max: -47.5170\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [41/125], Loss_min: 47.5141, Loss_max: -47.4568\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [42/125], Loss_min: 47.7990, Loss_max: -47.7453\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [43/125], Loss_min: 47.6641, Loss_max: -47.6176\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [44/125], Loss_min: 47.3380, Loss_max: -47.2919\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [45/125], Loss_min: 47.5151, Loss_max: -47.4629\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [46/125], Loss_min: 47.5420, Loss_max: -47.4827\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [47/125], Loss_min: 47.7794, Loss_max: -47.7033\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [48/125], Loss_min: 47.7832, Loss_max: -47.7188\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [49/125], Loss_min: 48.0457, Loss_max: -47.9103\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [50/125], Loss_min: 47.6062, Loss_max: -47.5530\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [51/125], Loss_min: 47.5220, Loss_max: -47.4626\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [52/125], Loss_min: 47.1713, Loss_max: -47.1230\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [53/125], Loss_min: 47.2804, Loss_max: -47.2475\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [54/125], Loss_min: 47.7554, Loss_max: -47.7057\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [55/125], Loss_min: 47.6264, Loss_max: -47.5806\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [56/125], Loss_min: 47.6234, Loss_max: -47.5659\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [57/125], Loss_min: 47.7163, Loss_max: -47.6645\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [58/125], Loss_min: 47.7931, Loss_max: -47.7413\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [59/125], Loss_min: 47.5887, Loss_max: -47.5422\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [60/125], Loss_min: 47.5019, Loss_max: -47.4572\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [61/125], Loss_min: 47.5437, Loss_max: -47.5011\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [62/125], Loss_min: 47.2583, Loss_max: -47.2203\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [63/125], Loss_min: 47.6074, Loss_max: -47.5658\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [64/125], Loss_min: 47.7630, Loss_max: -47.7178\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [65/125], Loss_min: 47.6051, Loss_max: -47.5554\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [66/125], Loss_min: 47.6861, Loss_max: -47.6433\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [67/125], Loss_min: 47.5456, Loss_max: -47.4879\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [68/125], Loss_min: 47.5985, Loss_max: -47.5588\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [69/125], Loss_min: 47.5577, Loss_max: -47.5103\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [70/125], Loss_min: 47.7958, Loss_max: -47.7456\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [71/125], Loss_min: 47.6616, Loss_max: -47.6127\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [72/125], Loss_min: 47.6531, Loss_max: -47.5961\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [73/125], Loss_min: 47.8273, Loss_max: -47.7701\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [74/125], Loss_min: 47.7676, Loss_max: -47.7389\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [75/125], Loss_min: 47.5843, Loss_max: -47.5365\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [76/125], Loss_min: 47.8977, Loss_max: -47.8361\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [77/125], Loss_min: 47.6066, Loss_max: -47.5651\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [78/125], Loss_min: 47.6600, Loss_max: -47.6115\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [79/125], Loss_min: 47.9116, Loss_max: -47.8700\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [80/125], Loss_min: 47.9221, Loss_max: -47.8816\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [81/125], Loss_min: 47.3532, Loss_max: -47.3058\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [82/125], Loss_min: 47.5810, Loss_max: -47.5506\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [83/125], Loss_min: 47.7513, Loss_max: -47.7027\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [84/125], Loss_min: 47.6533, Loss_max: -47.6215\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [85/125], Loss_min: 47.5871, Loss_max: -47.5570\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [86/125], Loss_min: 47.7461, Loss_max: -47.7135\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [87/125], Loss_min: 47.6630, Loss_max: -47.6348\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [88/125], Loss_min: 47.5035, Loss_max: -47.4654\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [89/125], Loss_min: 47.5749, Loss_max: -47.5396\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [90/125], Loss_min: 47.8268, Loss_max: -47.7962\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [91/125], Loss_min: 47.7052, Loss_max: -47.6656\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [92/125], Loss_min: 47.7796, Loss_max: -47.7490\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [93/125], Loss_min: 47.7410, Loss_max: -47.6911\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [94/125], Loss_min: 47.7428, Loss_max: -47.7109\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [95/125], Loss_min: 47.9567, Loss_max: -47.9132\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [96/125], Loss_min: 48.0155, Loss_max: -47.9660\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [97/125], Loss_min: 47.5471, Loss_max: -47.5129\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [98/125], Loss_min: 47.9432, Loss_max: -47.9042\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [99/125], Loss_min: 47.7070, Loss_max: -47.6730\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [100/125], Loss_min: 47.7437, Loss_max: -47.7072\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [101/125], Loss_min: 47.8078, Loss_max: -47.7580\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [102/125], Loss_min: 48.0645, Loss_max: -48.0342\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [103/125], Loss_min: 47.7649, Loss_max: -47.7196\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [104/125], Loss_min: 47.6711, Loss_max: -47.6440\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [105/125], Loss_min: 47.7031, Loss_max: -47.6755\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [106/125], Loss_min: 47.6126, Loss_max: -47.5412\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [107/125], Loss_min: 47.7882, Loss_max: -47.7579\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [108/125], Loss_min: 47.8258, Loss_max: -47.8016\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [109/125], Loss_min: 48.0391, Loss_max: -47.9843\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [110/125], Loss_min: 47.5707, Loss_max: -47.5270\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [111/125], Loss_min: 47.5769, Loss_max: -47.5498\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [112/125], Loss_min: 47.3388, Loss_max: -47.2991\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [113/125], Loss_min: 47.8781, Loss_max: -47.8295\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [114/125], Loss_min: 47.8160, Loss_max: -47.7613\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [115/125], Loss_min: 47.6840, Loss_max: -47.6263\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [116/125], Loss_min: 47.7774, Loss_max: -47.7238\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [117/125], Loss_min: 47.8428, Loss_max: -47.7845\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [118/125], Loss_min: 47.6609, Loss_max: -47.6308\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [119/125], Loss_min: 47.7995, Loss_max: -47.7519\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [120/125], Loss_min: 47.6523, Loss_max: -47.6087\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [121/125], Loss_min: 47.3239, Loss_max: -47.2941\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [122/125], Loss_min: 47.7848, Loss_max: -47.7369\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [123/125], Loss_min: 47.5325, Loss_max: -47.4911\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [124/125], Loss_min: 47.7702, Loss_max: -47.7231\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [125/125], Loss_min: 47.8091, Loss_max: -47.7739\n",
      "Epoch: 7\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [1/125], Loss_min: 47.8651, Loss_max: -47.8301\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [2/125], Loss_min: 47.7757, Loss_max: -47.7287\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [3/125], Loss_min: 47.6871, Loss_max: -47.6416\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [4/125], Loss_min: 47.6774, Loss_max: -47.6413\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [5/125], Loss_min: 47.9033, Loss_max: -47.8317\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [6/125], Loss_min: 47.3357, Loss_max: -47.2747\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [7/125], Loss_min: 47.5321, Loss_max: -47.4953\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [8/125], Loss_min: 47.8233, Loss_max: -47.7743\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [9/125], Loss_min: 47.5760, Loss_max: -47.5484\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [10/125], Loss_min: 47.7626, Loss_max: -47.7325\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [11/125], Loss_min: 47.9465, Loss_max: -47.9174\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [12/125], Loss_min: 47.5150, Loss_max: -47.4713\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [13/125], Loss_min: 47.5087, Loss_max: -47.4806\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [14/125], Loss_min: 47.8030, Loss_max: -47.7766\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [15/125], Loss_min: 47.8447, Loss_max: -47.8058\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [16/125], Loss_min: 47.7306, Loss_max: -47.6961\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [17/125], Loss_min: 47.9243, Loss_max: -47.8877\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [18/125], Loss_min: 47.5819, Loss_max: -47.5540\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [19/125], Loss_min: 47.8735, Loss_max: -47.7860\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [20/125], Loss_min: 47.8431, Loss_max: -47.8148\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [21/125], Loss_min: 47.6226, Loss_max: -47.5580\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [22/125], Loss_min: 47.7937, Loss_max: -47.7590\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [23/125], Loss_min: 47.5684, Loss_max: -47.5281\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [24/125], Loss_min: 47.6290, Loss_max: -47.6079\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [25/125], Loss_min: 47.8856, Loss_max: -47.8589\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [26/125], Loss_min: 47.8867, Loss_max: -47.8346\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [27/125], Loss_min: 47.5218, Loss_max: -47.4990\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [28/125], Loss_min: 47.6135, Loss_max: -47.5753\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [29/125], Loss_min: 47.6629, Loss_max: -47.6418\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [30/125], Loss_min: 47.8013, Loss_max: -47.7391\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [31/125], Loss_min: 47.5231, Loss_max: -47.4996\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [32/125], Loss_min: 48.0537, Loss_max: -48.0238\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [33/125], Loss_min: 47.6241, Loss_max: -47.6020\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [34/125], Loss_min: 47.6994, Loss_max: -47.6704\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [35/125], Loss_min: 47.7036, Loss_max: -47.6814\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [36/125], Loss_min: 47.8107, Loss_max: -47.7902\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [37/125], Loss_min: 48.0221, Loss_max: -47.9719\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [38/125], Loss_min: 47.6324, Loss_max: -47.5990\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [39/125], Loss_min: 47.6773, Loss_max: -47.6533\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [40/125], Loss_min: 47.6910, Loss_max: -47.6701\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [41/125], Loss_min: 47.6656, Loss_max: -47.6365\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [42/125], Loss_min: 47.5428, Loss_max: -47.5142\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [43/125], Loss_min: 47.6917, Loss_max: -47.6316\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [44/125], Loss_min: 47.6513, Loss_max: -47.6275\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [45/125], Loss_min: 47.8264, Loss_max: -47.8011\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [46/125], Loss_min: 47.5289, Loss_max: -47.4383\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [47/125], Loss_min: 47.6147, Loss_max: -47.5915\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [48/125], Loss_min: 47.5855, Loss_max: -47.5488\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [49/125], Loss_min: 47.6203, Loss_max: -47.6003\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [50/125], Loss_min: 47.5269, Loss_max: -47.5016\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [51/125], Loss_min: 47.8192, Loss_max: -47.7876\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [52/125], Loss_min: 47.6385, Loss_max: -47.6106\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [53/125], Loss_min: 47.6854, Loss_max: -47.6554\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [54/125], Loss_min: 47.6981, Loss_max: -47.6558\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [55/125], Loss_min: 47.8889, Loss_max: -47.8413\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [56/125], Loss_min: 47.6419, Loss_max: -47.6087\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [57/125], Loss_min: 47.8359, Loss_max: -47.7983\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [58/125], Loss_min: 47.7380, Loss_max: -47.7186\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [59/125], Loss_min: 47.5870, Loss_max: -47.5539\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [60/125], Loss_min: 48.0214, Loss_max: -47.9662\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [61/125], Loss_min: 47.7038, Loss_max: -47.6815\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [62/125], Loss_min: 47.9970, Loss_max: -47.9624\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [63/125], Loss_min: 47.8557, Loss_max: -47.8337\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [64/125], Loss_min: 47.8057, Loss_max: -47.7614\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [65/125], Loss_min: 47.8134, Loss_max: -47.7514\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [66/125], Loss_min: 47.7613, Loss_max: -47.7237\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [67/125], Loss_min: 47.8289, Loss_max: -47.7998\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [68/125], Loss_min: 47.7386, Loss_max: -47.6744\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [69/125], Loss_min: 47.6394, Loss_max: -47.5870\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [70/125], Loss_min: 47.6674, Loss_max: -47.6273\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [71/125], Loss_min: 47.7799, Loss_max: -47.7334\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [72/125], Loss_min: 47.7342, Loss_max: -47.6931\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [73/125], Loss_min: 47.7415, Loss_max: -47.6979\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [74/125], Loss_min: 47.5740, Loss_max: -47.5357\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [75/125], Loss_min: 47.8544, Loss_max: -47.8092\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [76/125], Loss_min: 47.8304, Loss_max: -47.7987\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [77/125], Loss_min: 47.7297, Loss_max: -47.7062\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [78/125], Loss_min: 47.8519, Loss_max: -47.8163\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [79/125], Loss_min: 48.0837, Loss_max: -48.0271\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [80/125], Loss_min: 47.7979, Loss_max: -47.7664\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [81/125], Loss_min: 47.8687, Loss_max: -47.8275\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [82/125], Loss_min: 47.7165, Loss_max: -47.6872\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [83/125], Loss_min: 47.6005, Loss_max: -47.5743\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [84/125], Loss_min: 48.0864, Loss_max: -48.0520\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [85/125], Loss_min: 47.5145, Loss_max: -47.4834\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [86/125], Loss_min: 48.1629, Loss_max: -48.1154\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [87/125], Loss_min: 47.8352, Loss_max: -47.8045\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [88/125], Loss_min: 47.7115, Loss_max: -47.6749\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [89/125], Loss_min: 47.6817, Loss_max: -47.6552\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [90/125], Loss_min: 48.1173, Loss_max: -48.0833\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [91/125], Loss_min: 47.8088, Loss_max: -47.7791\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [92/125], Loss_min: 47.7452, Loss_max: -47.7106\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [93/125], Loss_min: 47.8594, Loss_max: -47.8202\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [94/125], Loss_min: 47.5218, Loss_max: -47.4861\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [95/125], Loss_min: 47.6274, Loss_max: -47.6030\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [96/125], Loss_min: 47.8673, Loss_max: -47.8352\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [97/125], Loss_min: 47.6117, Loss_max: -47.5852\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [98/125], Loss_min: 47.7945, Loss_max: -47.7669\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [99/125], Loss_min: 48.1388, Loss_max: -48.1093\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [100/125], Loss_min: 47.8781, Loss_max: -47.8440\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [101/125], Loss_min: 47.7768, Loss_max: -47.7292\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [102/125], Loss_min: 47.6878, Loss_max: -47.6659\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [103/125], Loss_min: 47.9440, Loss_max: -47.9163\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [104/125], Loss_min: 47.9681, Loss_max: -47.9393\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [105/125], Loss_min: 47.7747, Loss_max: -47.7536\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [106/125], Loss_min: 47.7561, Loss_max: -47.7323\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [107/125], Loss_min: 47.9887, Loss_max: -47.9643\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [108/125], Loss_min: 47.7344, Loss_max: -47.7065\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [109/125], Loss_min: 47.8796, Loss_max: -47.8424\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [110/125], Loss_min: 47.7807, Loss_max: -47.7543\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [111/125], Loss_min: 47.6927, Loss_max: -47.6666\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [112/125], Loss_min: 47.8737, Loss_max: -47.8449\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [113/125], Loss_min: 47.8179, Loss_max: -47.7836\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [114/125], Loss_min: 47.8386, Loss_max: -47.7964\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [115/125], Loss_min: 47.8662, Loss_max: -47.8282\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [116/125], Loss_min: 48.0669, Loss_max: -48.0409\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [117/125], Loss_min: 47.9076, Loss_max: -47.8801\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [118/125], Loss_min: 47.7414, Loss_max: -47.7222\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [119/125], Loss_min: 47.7403, Loss_max: -47.7129\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [120/125], Loss_min: 47.9457, Loss_max: -47.9154\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [121/125], Loss_min: 47.9958, Loss_max: -47.9678\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [122/125], Loss_min: 47.8692, Loss_max: -47.8390\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [123/125], Loss_min: 47.8499, Loss_max: -47.8191\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [124/125], Loss_min: 47.7329, Loss_max: -47.7118\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [125/125], Loss_min: 48.0406, Loss_max: -48.0124\n",
      "Epoch: 8\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [1/125], Loss_min: 47.8053, Loss_max: -47.7763\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [2/125], Loss_min: 47.6236, Loss_max: -47.6059\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [3/125], Loss_min: 47.8296, Loss_max: -47.8068\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [4/125], Loss_min: 47.7560, Loss_max: -47.7304\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [5/125], Loss_min: 47.7502, Loss_max: -47.7255\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [6/125], Loss_min: 47.7120, Loss_max: -47.6786\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [7/125], Loss_min: 47.7430, Loss_max: -47.7000\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [8/125], Loss_min: 47.7577, Loss_max: -47.7151\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [9/125], Loss_min: 47.8936, Loss_max: -47.8635\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [10/125], Loss_min: 47.7023, Loss_max: -47.6761\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [11/125], Loss_min: 47.7698, Loss_max: -47.7409\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [12/125], Loss_min: 47.7026, Loss_max: -47.6691\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [13/125], Loss_min: 47.9611, Loss_max: -47.9161\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [14/125], Loss_min: 47.9498, Loss_max: -47.9190\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [15/125], Loss_min: 47.8420, Loss_max: -47.8119\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [16/125], Loss_min: 47.8942, Loss_max: -47.8495\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [17/125], Loss_min: 47.8411, Loss_max: -47.8068\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [18/125], Loss_min: 48.0116, Loss_max: -47.9785\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [19/125], Loss_min: 47.5917, Loss_max: -47.5542\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [20/125], Loss_min: 47.7259, Loss_max: -47.6896\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [21/125], Loss_min: 47.9517, Loss_max: -47.9015\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [22/125], Loss_min: 47.8373, Loss_max: -47.7854\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [23/125], Loss_min: 47.6873, Loss_max: -47.6537\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [24/125], Loss_min: 48.0019, Loss_max: -47.9818\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [25/125], Loss_min: 47.9761, Loss_max: -47.9384\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [26/125], Loss_min: 47.7943, Loss_max: -47.7668\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [27/125], Loss_min: 47.7210, Loss_max: -47.6959\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [28/125], Loss_min: 47.5137, Loss_max: -47.4960\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [29/125], Loss_min: 48.0221, Loss_max: -47.9816\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [30/125], Loss_min: 47.9609, Loss_max: -47.9355\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [31/125], Loss_min: 47.8632, Loss_max: -47.8397\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [32/125], Loss_min: 47.9363, Loss_max: -47.9036\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [33/125], Loss_min: 47.9783, Loss_max: -47.9531\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [34/125], Loss_min: 47.8902, Loss_max: -47.8651\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [35/125], Loss_min: 47.8653, Loss_max: -47.8379\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [36/125], Loss_min: 47.9576, Loss_max: -47.9287\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [37/125], Loss_min: 47.8665, Loss_max: -47.8421\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [38/125], Loss_min: 47.6941, Loss_max: -47.6677\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [39/125], Loss_min: 47.8323, Loss_max: -47.8059\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [40/125], Loss_min: 47.8533, Loss_max: -47.8286\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [41/125], Loss_min: 47.7009, Loss_max: -47.6673\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [42/125], Loss_min: 47.8272, Loss_max: -47.8024\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [43/125], Loss_min: 47.8688, Loss_max: -47.8330\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [44/125], Loss_min: 47.9688, Loss_max: -47.9368\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [45/125], Loss_min: 47.7208, Loss_max: -47.6882\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [46/125], Loss_min: 47.7617, Loss_max: -47.7414\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [47/125], Loss_min: 47.8398, Loss_max: -47.8196\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [48/125], Loss_min: 47.8165, Loss_max: -47.7892\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [49/125], Loss_min: 47.8233, Loss_max: -47.7906\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [50/125], Loss_min: 47.7329, Loss_max: -47.7018\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [51/125], Loss_min: 47.7584, Loss_max: -47.7315\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [52/125], Loss_min: 47.7780, Loss_max: -47.7203\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [53/125], Loss_min: 47.5709, Loss_max: -47.5238\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [54/125], Loss_min: 47.9641, Loss_max: -47.9362\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [55/125], Loss_min: 48.1400, Loss_max: -48.1038\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [56/125], Loss_min: 47.9399, Loss_max: -47.9073\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [57/125], Loss_min: 47.8749, Loss_max: -47.8466\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [58/125], Loss_min: 47.5854, Loss_max: -47.5569\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [59/125], Loss_min: 47.5505, Loss_max: -47.5149\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [60/125], Loss_min: 47.6568, Loss_max: -47.6339\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [61/125], Loss_min: 47.5812, Loss_max: -47.5605\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [62/125], Loss_min: 47.6641, Loss_max: -47.6413\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [63/125], Loss_min: 47.7259, Loss_max: -47.7000\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [64/125], Loss_min: 48.0519, Loss_max: -48.0235\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [65/125], Loss_min: 47.7553, Loss_max: -47.7317\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [66/125], Loss_min: 47.8053, Loss_max: -47.7810\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [67/125], Loss_min: 47.8497, Loss_max: -47.8099\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [68/125], Loss_min: 47.5386, Loss_max: -47.5163\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [69/125], Loss_min: 47.2071, Loss_max: -47.1865\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [70/125], Loss_min: 47.6271, Loss_max: -47.6030\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [71/125], Loss_min: 48.0059, Loss_max: -47.9512\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [72/125], Loss_min: 47.8652, Loss_max: -47.8192\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [73/125], Loss_min: 47.8770, Loss_max: -47.8491\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [74/125], Loss_min: 47.6847, Loss_max: -47.6476\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [75/125], Loss_min: 47.8278, Loss_max: -47.7855\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [76/125], Loss_min: 47.8232, Loss_max: -47.7935\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [77/125], Loss_min: 47.7498, Loss_max: -47.7266\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [78/125], Loss_min: 47.7513, Loss_max: -47.7328\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [79/125], Loss_min: 47.9979, Loss_max: -47.9593\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [80/125], Loss_min: 47.8725, Loss_max: -47.8450\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [81/125], Loss_min: 47.6996, Loss_max: -47.6797\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [82/125], Loss_min: 47.6785, Loss_max: -47.6488\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [83/125], Loss_min: 47.7221, Loss_max: -47.7009\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [84/125], Loss_min: 47.7064, Loss_max: -47.6768\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [85/125], Loss_min: 47.9722, Loss_max: -47.9419\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [86/125], Loss_min: 47.7178, Loss_max: -47.6967\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [87/125], Loss_min: 48.1226, Loss_max: -48.1002\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [88/125], Loss_min: 47.7489, Loss_max: -47.7264\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [89/125], Loss_min: 48.0361, Loss_max: -48.0072\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [90/125], Loss_min: 48.0485, Loss_max: -48.0253\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [91/125], Loss_min: 47.8264, Loss_max: -47.8012\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [92/125], Loss_min: 47.5597, Loss_max: -47.5449\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [93/125], Loss_min: 47.8899, Loss_max: -47.8629\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [94/125], Loss_min: 47.8651, Loss_max: -47.8436\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [95/125], Loss_min: 47.7912, Loss_max: -47.7676\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [96/125], Loss_min: 47.7293, Loss_max: -47.7105\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [97/125], Loss_min: 47.6520, Loss_max: -47.6282\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [98/125], Loss_min: 47.7438, Loss_max: -47.7230\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [99/125], Loss_min: 47.8494, Loss_max: -47.8266\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [100/125], Loss_min: 47.6779, Loss_max: -47.6564\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [101/125], Loss_min: 47.8502, Loss_max: -47.8223\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [102/125], Loss_min: 47.8495, Loss_max: -47.8261\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [103/125], Loss_min: 47.7453, Loss_max: -47.7231\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [104/125], Loss_min: 47.8159, Loss_max: -47.8014\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [105/125], Loss_min: 47.8911, Loss_max: -47.8691\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [106/125], Loss_min: 47.9248, Loss_max: -47.9060\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [107/125], Loss_min: 47.8112, Loss_max: -47.7926\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [108/125], Loss_min: 47.8216, Loss_max: -47.8020\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [109/125], Loss_min: 47.4565, Loss_max: -47.4409\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [110/125], Loss_min: 47.9661, Loss_max: -47.9437\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [111/125], Loss_min: 47.7622, Loss_max: -47.7483\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [112/125], Loss_min: 47.7079, Loss_max: -47.6811\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [113/125], Loss_min: 47.9763, Loss_max: -47.9542\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [114/125], Loss_min: 47.8706, Loss_max: -47.8524\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [115/125], Loss_min: 47.7550, Loss_max: -47.7345\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [116/125], Loss_min: 47.4688, Loss_max: -47.4568\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [117/125], Loss_min: 47.7195, Loss_max: -47.7011\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [118/125], Loss_min: 47.8041, Loss_max: -47.7828\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [119/125], Loss_min: 48.0152, Loss_max: -47.9943\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [120/125], Loss_min: 47.7682, Loss_max: -47.7479\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [121/125], Loss_min: 47.8346, Loss_max: -47.8133\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [122/125], Loss_min: 47.8086, Loss_max: -47.7920\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [123/125], Loss_min: 47.7830, Loss_max: -47.7584\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [124/125], Loss_min: 47.8371, Loss_max: -47.8194\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [125/125], Loss_min: 47.8724, Loss_max: -47.8377\n",
      "Epoch: 9\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [1/125], Loss_min: 47.8908, Loss_max: -47.8703\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [2/125], Loss_min: 47.8470, Loss_max: -47.8229\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [3/125], Loss_min: 47.8369, Loss_max: -47.8121\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [4/125], Loss_min: 47.8838, Loss_max: -47.8641\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [5/125], Loss_min: 47.7183, Loss_max: -47.7006\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [6/125], Loss_min: 47.9372, Loss_max: -47.9171\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [7/125], Loss_min: 47.9209, Loss_max: -47.8951\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [8/125], Loss_min: 47.6417, Loss_max: -47.6210\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [9/125], Loss_min: 47.9691, Loss_max: -47.9512\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [10/125], Loss_min: 47.6012, Loss_max: -47.5703\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [11/125], Loss_min: 47.8141, Loss_max: -47.7985\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [12/125], Loss_min: 47.8383, Loss_max: -47.8222\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [13/125], Loss_min: 47.8825, Loss_max: -47.8587\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [14/125], Loss_min: 47.7732, Loss_max: -47.7537\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [15/125], Loss_min: 47.8982, Loss_max: -47.8748\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [16/125], Loss_min: 47.9188, Loss_max: -47.8968\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [17/125], Loss_min: 48.0099, Loss_max: -47.9864\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [18/125], Loss_min: 47.8601, Loss_max: -47.8430\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [19/125], Loss_min: 47.9640, Loss_max: -47.9459\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [20/125], Loss_min: 47.9191, Loss_max: -47.8996\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [21/125], Loss_min: 47.9067, Loss_max: -47.8896\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [22/125], Loss_min: 47.9852, Loss_max: -47.9596\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [23/125], Loss_min: 48.0372, Loss_max: -48.0169\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [24/125], Loss_min: 47.7567, Loss_max: -47.7336\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [25/125], Loss_min: 48.1358, Loss_max: -48.1050\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [26/125], Loss_min: 47.8827, Loss_max: -47.8570\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [27/125], Loss_min: 47.8692, Loss_max: -47.8411\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [28/125], Loss_min: 48.0130, Loss_max: -47.9962\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [29/125], Loss_min: 47.6397, Loss_max: -47.6131\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [30/125], Loss_min: 47.9655, Loss_max: -47.9446\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [31/125], Loss_min: 47.8523, Loss_max: -47.8318\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [32/125], Loss_min: 47.8216, Loss_max: -47.8044\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [33/125], Loss_min: 47.9421, Loss_max: -47.9236\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [34/125], Loss_min: 47.8872, Loss_max: -47.8644\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [35/125], Loss_min: 47.8380, Loss_max: -47.8213\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [36/125], Loss_min: 48.0480, Loss_max: -48.0290\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [37/125], Loss_min: 47.7794, Loss_max: -47.7623\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [38/125], Loss_min: 48.0668, Loss_max: -48.0501\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [39/125], Loss_min: 47.9437, Loss_max: -47.9069\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [40/125], Loss_min: 47.7673, Loss_max: -47.7471\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [41/125], Loss_min: 47.9262, Loss_max: -47.9095\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [42/125], Loss_min: 47.8389, Loss_max: -47.8170\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [43/125], Loss_min: 47.8330, Loss_max: -47.8149\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [44/125], Loss_min: 48.0273, Loss_max: -48.0030\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [45/125], Loss_min: 47.8574, Loss_max: -47.8381\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [46/125], Loss_min: 48.0089, Loss_max: -47.9784\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [47/125], Loss_min: 48.1162, Loss_max: -48.0888\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [48/125], Loss_min: 47.8872, Loss_max: -47.8689\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [49/125], Loss_min: 47.5817, Loss_max: -47.5665\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [50/125], Loss_min: 47.9681, Loss_max: -47.9359\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [51/125], Loss_min: 47.9723, Loss_max: -47.9218\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [52/125], Loss_min: 47.9531, Loss_max: -47.9164\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [53/125], Loss_min: 48.0414, Loss_max: -48.0100\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [54/125], Loss_min: 47.8517, Loss_max: -47.8271\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [55/125], Loss_min: 47.7200, Loss_max: -47.6816\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [56/125], Loss_min: 47.9883, Loss_max: -47.9448\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [57/125], Loss_min: 47.9883, Loss_max: -47.9518\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [58/125], Loss_min: 47.8952, Loss_max: -47.8463\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [59/125], Loss_min: 47.8293, Loss_max: -47.8020\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [60/125], Loss_min: 47.8717, Loss_max: -47.8467\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [61/125], Loss_min: 47.8615, Loss_max: -47.8166\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [62/125], Loss_min: 47.7175, Loss_max: -47.6685\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [63/125], Loss_min: 47.8654, Loss_max: -47.8319\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [64/125], Loss_min: 47.8338, Loss_max: -47.8041\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [65/125], Loss_min: 47.9673, Loss_max: -47.9372\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [66/125], Loss_min: 47.7163, Loss_max: -47.6830\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [67/125], Loss_min: 48.0294, Loss_max: -48.0001\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [68/125], Loss_min: 47.8016, Loss_max: -47.7766\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [69/125], Loss_min: 48.0383, Loss_max: -48.0133\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [70/125], Loss_min: 47.5481, Loss_max: -47.5308\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [71/125], Loss_min: 47.4008, Loss_max: -47.3727\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [72/125], Loss_min: 47.9108, Loss_max: -47.8771\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [73/125], Loss_min: 47.8488, Loss_max: -47.8190\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [74/125], Loss_min: 47.7375, Loss_max: -47.7073\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [75/125], Loss_min: 47.6363, Loss_max: -47.6208\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [76/125], Loss_min: 47.7971, Loss_max: -47.7702\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [77/125], Loss_min: 47.6234, Loss_max: -47.6022\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [78/125], Loss_min: 47.5543, Loss_max: -47.5352\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [79/125], Loss_min: 47.9918, Loss_max: -47.9621\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [80/125], Loss_min: 47.8397, Loss_max: -47.8221\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [81/125], Loss_min: 47.8887, Loss_max: -47.8667\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [82/125], Loss_min: 47.8977, Loss_max: -47.8580\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [83/125], Loss_min: 47.8513, Loss_max: -47.8196\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [84/125], Loss_min: 47.8921, Loss_max: -47.8751\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [85/125], Loss_min: 47.9367, Loss_max: -47.9199\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [86/125], Loss_min: 47.7374, Loss_max: -47.7195\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [87/125], Loss_min: 47.7510, Loss_max: -47.7337\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [88/125], Loss_min: 47.9818, Loss_max: -47.9540\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [89/125], Loss_min: 48.0262, Loss_max: -48.0047\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [90/125], Loss_min: 47.8484, Loss_max: -47.8263\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [91/125], Loss_min: 47.8110, Loss_max: -47.7933\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [92/125], Loss_min: 47.6266, Loss_max: -47.6019\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [93/125], Loss_min: 48.0124, Loss_max: -47.9920\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [94/125], Loss_min: 47.8176, Loss_max: -47.8011\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [95/125], Loss_min: 47.9442, Loss_max: -47.9259\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [96/125], Loss_min: 47.6774, Loss_max: -47.6617\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [97/125], Loss_min: 47.8131, Loss_max: -47.7865\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [98/125], Loss_min: 47.7365, Loss_max: -47.6683\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [99/125], Loss_min: 47.8972, Loss_max: -47.8649\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [100/125], Loss_min: 47.8372, Loss_max: -47.8079\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [101/125], Loss_min: 47.9365, Loss_max: -47.9027\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [102/125], Loss_min: 47.8086, Loss_max: -47.7859\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [103/125], Loss_min: 47.9509, Loss_max: -47.9255\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [104/125], Loss_min: 47.4421, Loss_max: -47.4172\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [105/125], Loss_min: 47.9907, Loss_max: -47.9646\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [106/125], Loss_min: 48.0854, Loss_max: -48.0472\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [107/125], Loss_min: 47.8855, Loss_max: -47.8581\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [108/125], Loss_min: 47.8797, Loss_max: -47.8518\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [109/125], Loss_min: 47.9591, Loss_max: -47.9271\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [110/125], Loss_min: 47.9654, Loss_max: -47.9390\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [111/125], Loss_min: 47.9346, Loss_max: -47.8989\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [112/125], Loss_min: 47.8613, Loss_max: -47.8314\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [113/125], Loss_min: 47.8395, Loss_max: -47.8237\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [114/125], Loss_min: 48.0068, Loss_max: -47.9766\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [115/125], Loss_min: 47.9070, Loss_max: -47.8692\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [116/125], Loss_min: 47.9134, Loss_max: -47.8834\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [117/125], Loss_min: 47.9337, Loss_max: -47.9114\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [118/125], Loss_min: 47.9243, Loss_max: -47.8935\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [119/125], Loss_min: 47.8201, Loss_max: -47.7971\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [120/125], Loss_min: 47.8359, Loss_max: -47.8091\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [121/125], Loss_min: 47.9843, Loss_max: -47.9557\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [122/125], Loss_min: 47.7951, Loss_max: -47.7716\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [123/125], Loss_min: 48.1634, Loss_max: -48.1324\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [124/125], Loss_min: 47.9042, Loss_max: -47.8795\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [125/125], Loss_min: 47.7612, Loss_max: -47.7285\n",
      "Entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "modelo.train()\n",
    "lambda_=3\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i, (inputs) in enumerate(dataloader):\n",
    "        # Forward\n",
    "        inputs=inputs.float().to(\"cuda:0\")\n",
    "        outputs, series, prior, _ = modelo(inputs)\n",
    "        prior=[j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600) for j in prior]\n",
    "        loss_min = min_loss(outputs,prior,series, inputs,lambda_)\n",
    "        loss_max = max_loss(outputs,prior,series, inputs,lambda_)\n",
    "\n",
    "        # Backward y optimización\n",
    "        loss_min.backward(retain_graph=True)\n",
    "        loss_max.backward()\n",
    "        #clip_gradients(modelo, max_norm=1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        del inputs \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        #warmup_and_decay_learning_rate(optimizer, epoch, 1e-2,15 , num_epochs)\n",
    "        # Printear resultados\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss_min: {loss_min.item():.4f}, Loss_max: {loss_max.item():.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2639"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del modelo\n",
    "del inputs\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo.cuda()\n",
    "a=next(iter(dataloader))\n",
    "a1=a.float().to(\"cuda:0\")\n",
    "modelo.eval()\n",
    "y=modelo(a1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=y[0].squeeze().cpu().detach().numpy()\n",
    "series_aux=y[1][0].squeeze().cpu().detach().numpy()\n",
    "prior_aux=y[2][0].squeeze().cpu().detach().numpy()\n",
    "b=a1.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd1003a7e90>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACUGUlEQVR4nOzdd3hkZdn48e+ZmcykzaT3nmzvy+4CS11g6YIooiK+CiqKgoqgAuoL6u9VbFhQrChYAUFAkCa9LLts75vNpveeTJJJpp/fH2dmkrCFLZk5U+7PdeXaZGYyc+/s7Dn3uZ/nuR9FVVUVIYQQQggdGPQOQAghhBCJSxIRIYQQQuhGEhEhhBBC6EYSESGEEELoRhIRIYQQQuhGEhEhhBBC6EYSESGEEELoRhIRIYQQQujGpHcAR+L3++ns7MRqtaIoit7hCCGEEOIoqKrK6OgoxcXFGAxHrnlEdSLS2dlJWVmZ3mEIIYQQ4ji0tbVRWlp6xMdEdSJitVoB7S9is9l0jkYIIYQQR2NkZISysrLQefxIojoRCQ7H2Gw2SUSEEEKIGHM00ypksqoQQgghdCOJiBBCCCF0I4mIEEIIIXQjiYgQQgghdCOJiBBCCCF0I4mIEEIIIXQjiYgQQgghdCOJiBBCCCF0I4mIEEIIIXQjiYgQQgghdCOJiBBCCCF0I4mIEEIIIXQjichxGh53o6qq3mEIIRLMxqZBHt/arncYQsyYqN59Nxqpqsodj+/i4U1tfO3Cudx4ziy9QxJCJAi318+Hf7cegPLsVFZWZusckRAnTioix2hD4yAPb2oD4OFNrVIVEQfx+1Xu+e9+ntzWoXcoIsY8sK6Ju/69G4/PD2iV128/tYdd7XYA3m7oDz12Xf2ALjEKMdMkETlGO9qHQ9+3DU7Q0DfG399p4XN/3UzfqEu/wETU2Ng8yC9fqefmR7bz93da9A5HxAiHy8t3nt7Ln9e38PcN2ufmd2808uDbzVz2q7fotjt5aV9P6PHrpiQlQsQySUSOYNDh5muP7uBjf9gQSjJ2ddinPeazf93CN5/YzQt7enhsi4zbCqjtGgl9/9yubh0jEbFkW+tw6Ps/r29BVdVpc0Ee2tg67TG72u1SkRVxQRKRI3hgXROPbmnn7YYB/hU4IOwOJCKXLC4EoLHPEXr8lpbByAcpos7+ntHQ93u7RuRkIY7KxubJ40dTv4MNjYP0jExWWf+7t4e6KZ+tCY8P+4QnojEKEQ6SiBzBpikHhvUNAzhcXloGxgH40nmzD3r8lpYhOekI9ndPniwGHe7QyaRtcJz6Xu0+VVX589vN/Oa1BobH3brEKaLLrinDvgB/Cwzr1eSlAbCvawSPTyUzNYms1CQAuuzOiMYootNTOzr50G/epjVwfoo1kogchtfnZ0fb5DDMpubB0JVubrqZeYU2vrCmhsqcVD53djVmk4GhcQ+tg7H5QRAzQ1VVDvSMTbttb5edJ7d1sOYnr3HJvW/R0DfGlpYh7npqDz98vpbvPbNPp2hFNGkbmgAgO80MwDM7uwBYO7+AZWWZocctLLZRlJECQJd9IrJBiqizv3uULz20jc0tQ/zxrUa9wzkukohMMeH2ccfjO3lsSzu13aNMeHykW0xYLSbG3T6eDRwYavLSAfj6RfN47WvncMfF86nK0a5amvodh31+Ef+Gxz2MurwAXLxIG77b2znCva8cwOdXcXv93P9mI28emJxouKV1SJdYRfRQVZX2Ie0iJjjsG7S4NIOrTy4L/fzhlWUUZyYD0DksFZFE9989k/PQ3qqPzQnMkohM8dcNzTy0sY2vPrqDHz5fC8DKyiyWBq5GgvNEZuWnH/S75TmpAFIRSXAdw9oVam66mZPKswB4bnf3tLlET27r5OXaydUPTf0OxgLJi0hM/WNunB4/BgU+dnLFtPuWlWVy+dISzpuXz6dOr+LypcWhiki3DM0kvIa+sSnfO+gYnqCxb4x3Gqcv7+62O7n/zUYm3L5Ih/iepKFZgN+v8qe3mkM/B69YT6vJYXjcw1v1/QyNaxPDghWRqSoDiUhzvyQiiaw9UF4vyUxhQbENgD2d2iqaU6qy6RieoH1ogt0dkytrVBX2dNg5pTon8gGLqNAWqIYU2pJDnxuAxSUZlGZpx5Y/XrsqdHthRqAiIkMzCa+hb3oVfn3DAD94rpb+MRf//NxqTq7Smt595ZHtrG8coKHPwd0fXKxHqIclFZGAtqFxuke0qwuTQQndflpNbqgiErSiIuug368IDM20DsrQTCILVkRKslKYX2Sbdt8FCwu5ZHFR6OclpRmsnV8AaKtrROIKJrCl2VrScf8nVnLm7Fx+fc1Jh3x8cGhGKiKJTVVVGgMVkdNqtAuZ7zy9h/4xbYL8T1/cD4B9wsP6QIXkoY2tUVcVkUQkYG/gqnVxSQb/+74FVOak8qEVpSwosoX+gYOWlGYc9PsVgYqIzBFJbB1TKiLZaeZpycj7lhRx3emV5FstAHxoRSlzCrTqWn3v2MFPJuJac7+Dbz+1h/3do7QEjhtlgerH2gUF/PXTp1AWSEzerdAWnKwqiUgi6xlx4XD7MBoULltaDMCoc3KY952mQcZcXl7b3zvt97a0RNe8NBmaCQiWzxcU2fjkaZV88rTK0H3W5CS+94FFfPOJ3dx6/hwURTno96sDwzWtg+N4fH62tgzh9vk5rSYXo+Hgx4v41DGsldhLMrUTxe//ZwWf+fNmVlVlUWDTrmKfuukM1tX38/5lxTy1oxOYHOfd3DxIx/AE719WokP0IlKGx92s/enreP0qB3pHyU7TktNgYvpeJierTqCq6iGPSSL+BashFdmpnFI1fd8hs8mA2+tnV7v9oIrrvq4RzpidG7E430tCJyLrGwZ4va6Pr5w/O/QPtbDEdsjHXnNKBefMzacwcDJ5t+KMZNLMRhxuH//d08NND21FVeGGs2u4/eJ5Yfs7iOgSrGxU5mpDdWXZqbzwlbOmPaYwI5krV5QCk/ON6nsdDDrcfOi32oZmeekWTpsVPQcKMbPeaRrE69d6Dq2rH8CarB2K5xRaj+r3g0mty+tneNxDVmDJr0gswQuY6rw0qvPS+eiqMh7e1Mba+fkkGQ08t7ubHe3D1AV6GxXYLPSMuNgXON/1j7mwmAxYk5N0+ztAAg/NtA2Oc/UfNvDb1xv45+b20NDMgqJDJyIAxZkpGA5T3VAUJbSa5r5X6wn2NVsXo8upxLFzenw0BxoKzSs8/OdoqprAZ6Z/zMW9Lx8I3f7g280zHp+IHlOb3sFkOX1uwdElIslJRnICyYdMWE0sW1uHeG5XF6qqhiaqBi9o/t8Vi/jFR5dx9weXhHrPbG8dpi7Q2+iKQKV1b9cIr9T2cPoPXuH9963TvRFnwlZE/rZhcjOyB9Y10T3iRFFg3hESkZA9T8BoNyz9KKRMTlydlW9lx7vKYPu7R3F7/ZhNCZvzJYz63jF8fq3zZYFNK7WjqnDgv1D3PEwMQc4sWPIRyNU686ZbTJRmpdA+NDEt+Xi9rg+/Xz1s4itiW7A54qz89FAVzWoxUZQxpeLaXw+5syZ/9vtBUbQvoCgzmQGHm65hJwuLD563JuKP2+vnugc2YZ/w8M1L5k+riAAkGQ28f5YZdvyWK5s2kW2ys71+EX2uU4AkPnBSCb97o5Ha7lGu/8sWfH6Vxj4HvaOuUJVNDwl7dgzOCYHJ/WIqc9JItxwiN+urm/5z3Qvw/O3wi2Ww99+hm+cWTo7vBods3T7/tP0hRPwKXuXOLbBqY/b2dnjgYvjHh2Hzn7QE9o0fw30nw2s/CP3eqYdYtuvy+uVKN44FPytfWTuHVLMRgE+eVql9brwueOZW+NVKGGqe/KVNf4C/fwjG+gBCvUSCK7VE/NvaOhTaX+ieF/eH9j4LtZToq4NfLIUX7yS3+WmuMr3B95Rf86L5a6y1tTGv0EZ5YAK0zz9ZBant1vccFdZE5O6772bVqlVYrVby8/O54oor2L9/fzhf8qjVdmuJSJJx8orzkMMy9S/Db06DHQ9P3lZzHuTNB+cw/PMT2kkGuHzp5ATD5WWZodU2eztlaWYieHGv1qRsSWkGjA/CHy+A1vWQlAan3AAX3g2zLwDVD7bi0O+dPmsyETm5Kjs0xPfu/gAiPri8vtDqupMqMnnwupO59+rl3HrBHPC64aGPwqb7ARW6dmq/5PPCunuh/iV44CIY7Q4N4+zptB/mlUS8eaOuL/S90+NnaNyDyaAwNzi3KHc2zF4LRctg7Xf4h+UjdKtZVBh6+bXnTmh8/aBVoAD7u/U9R4U1EXn99de58cYb2bBhAy+++CIej4cLLrgAh0PfA2zfqIv+MTcGBW45f27o9suWFk1/YMcWePga8Hug8bXJ25dcBTe8CSd/Vvv5mVuh6U0KM5JDVzjfet8CZgdPKP2yNDPeNfSN8eI+LRH50IoySM2G8+7UDghfeBsu/iGs/gJc8yh85mVY/j+h310zJ58Cm4XijGS+ecl8qgMTXRv75HMTjxp6Hfj8KrZkE4W2ZE6uyubypcVaNeT526HhFS15veYxWHC59ktGE3z8Mcgog4F6+OcnWVaifU7WNw7wl/XNNEvrgLi3rXUYgMzUycmlKyuzJiebKgpc8Vu4/lU442aaltzM+a4f86pvKWpSCqh+LgpsPZGZmsSlgb5GeldEwjpH5Pnnn5/284MPPkh+fj5btmzhrLPOOsxvhV9wxnBlbhrXnFrOxqYBVtfkcNGiKYmIZwIe/yx4J2DWWrjs3ulPYkyCi38EzhHY+TA8dh3c8BZfXjubL6/Vxv93tg0DyAEizrm8Pq7/y2Z8fpUzZuVOXp0s/ag2H+TdSytLV0755VGyhg/w9u3nYVC0Sc/aUvCeaW3hRfwIDtXOLbROX3a742HY/EdAgasehNnnT//F/PnwiX/D79dA2wZOy78XOJu2wQnu/PcectMtPP3F00NDNiL+BCtp3//AYm5+ZDtur5+rKl3w32/BuXeCyQzmyd4zt5w/l47hCX7aexerrqnBkl/JGuClW86iwJbM2w0DPLOr66CNOiMtopNV7XathJidnX3I+10uFy6XK/TzyEh4ykVZqWauWlFKntWCLTmJB647+eAHvfz/tCsPaxFceb/2D/xuigLv+xn07Na+Xvk/eP+vQndXBcbtpMlZfHtgXTONfQ7yrRbuXZsCTjskByYPHqm/g70d/voB8ExgvHFj6AAS3Pa9USppcSl49Tl36lLd8UGtGgJw9m0w54JD/3JODXzgt/Dwx0jd8nsuzpnLcwPaFW7/mItHNrVx89o54Qxf6GTc7Q11/z6tJoeXvnI2r+zr5gMNX4Gm17Thu4t/MO13UsxGfn3NioOea1ZuGhgMrK7J4dkvnUlNflok/gqHFbHJqn6/n5tvvpnTTz+dRYsWHfIxd999NxkZGaGvsrKyQz7uRC0uzeDHVy3l6xcdpr9H33545zfa95fdO21lzEHMqfD+++CkT8Lab0+7K7gjb/PAOH6/vsujRPg8HtgM8Wtrq8h++lPwyxXQtum9fzE1BzxOsLfBul+Ebg42x5OKSHza3qZ1tZy2VHfdz7VVVfkL4ayvHfkJ5l0Kiz8MqPzC9g++f8UirjxJ60sTbR0zxcwJ7mOWnWYmM9VMeU4q1+bswdD0GhjNcPL17/0kqqpV3n61Eka6sCUnsaDYhsVkDG/w7yFiiciNN97I7t27efjhhw/7mDvuuAO73R76amtri1R4073yf9qEwrmXHv7KZKriZXD5vZA2vQFVSVYKZqPW3U5mtsen/jFXaI3+pe7nYSDQCySwPPeIklLgwv/Tvl/3cxjRuqwGKyJddicO2ZU3bri8Pm55ZDsbGgcBOHtO/uSdZ98GZ94Kl/xImw/yXs7/DqRkYa4+g4+tLOTTZ1QBWs8In1z0xKVgZb0qMIcMn1cbkgE47Utatey9qKo2EXqwQTvPRYmIJCI33XQT//nPf3j11VcpLS097OMsFgs2m23aV8SpKhQv16og537r+J7DoyUdRsNkk7M9snImLm1s0k4qiwqSSd10n3bjmtshJfPonmD+5VC+GrxOWK/9fmaqOdSsSob14sft/9rF49s6ADhjVi7lOVP2kTGnaZObK884uiezFcPNu7SExGRhbqGVNLORUZeXA73SLiAeBecWBSezs/tf2vLu1Fw485ajexKDAS4KDN/sfBiGW2c+0OMQ1kREVVVuuukmnnjiCV555RWqqqrC+XIzQ1G0f9Rb9kHBgmP73f4D8NcPwt8+FLopuEHero7hGQxSRIutgVL4pzM2w0gHpBfCso8f/RMoCpz5Ve37zQ9ocwWYbFDUICtn4oLD5eWJQBJy3rx8vvP+hdodHiccb1dLy+TQjtGgsKw8E5DhmXi1K9AzZFFJhtbc7q2faXes/oKWyB6t0pVQdTb4vfD2L8MQ6bELayJy44038re//Y1//OMfWK1Wuru76e7uZmIiBoYpko5j5nlSKjS9AS1vQdtGQJuPArCzXdb6x6O9XSMo+Dlv4CHthtU3QtIxdiicdR4ULgGPAzb+HoA5gfkDwYZFIrYFr2bzrRb+eO2qyQZUL/4v3L8WWjcc/5O3boAX72RFuTaXbUvLEPW9o7z6rh1XRexSVTV0DllUkgEHXoC+fWCxwarPHPsTBisoW/8CDv23IQlrIvKb3/wGu93OmjVrKCoqCn098sgj4XzZ47ftb7D/eS3bPB4ZJdpyTQg0JIKlpZkAbG4eom/UdZhfFLFIVVX2do1wqmEfNkcTmK2w8rpjfyJFgdO/rH3fsxuAFRXaSWVTs1zdxoOpS3ZD3A7Y/hB0bA4N5x4zxwA8+D5Y9wvOtHUD8EZdPx/9/Qaue2ATr9ZKMhIPWgbG6R9zYTQoWuNNWwksvgpO+dzkCr1jUXW21uPI64Ttf5/xeI9V2IdmDvV17bXXhvNlj4/HCS98Ex76CDS8fPzPs/JT2p97noTxQRYW21hamsGEx8cdj+/E7T3OJEdEnS67k+FxDysM9agosOTD08rlx2T+5fD5t+EjfwNgVaW2xH1Pp50Jt2+mQhY6CS7ZnTN1pczux8E9CtnV2onheKTlaKtogKW9/8ZiMtA/pjVsBPjpi3VH+m0RA+p6Rvn0n7VVeKsqs0gxG6FoidZW4njnMSrK5Llq61+Of3hwhiTsXjMHqXtOa9luK4Gac4//eUpOgoLF4HPBzn+iKAr/+74FJBkVXtrXyyObdVoJJGbcpmZtPscref+D8uXtcMZXjv/JTGYoWBj6sTQrhaKMZDw+lZcCHVtF7ApubDenYHI/KrY8oP150ie1SYTHa8W1AJj3PMYHFk3v0bSrQxLZWKaqKl96aBsNfQ6sFhPf/8DimXvyRVfC0qu1Xlg6k0QkaHtgjH/JR8BwAmuqFQVWfFL7futfAFhZmc0Xz9WWc/53T/eJRCl0pqoqP3uxjtV3v8yXH94OwFlz8iCrEjJnqO+NcwTFNcpVK7Xn++v6lvf4BRHteke0YdnizMDcs5492hYShiRYds2JPXnV2ZBZAS47t5buY16hlTsunoctWVsG3Do4fmLPL3TzdsMAtd2jmE0G/n3T6VTnpMDL34XefSf+5JZ0rTle1VlHbrwYAZKIAIz1aptJASz72Ik/3+KrtAYzvXugZy8A71uitY/f0DjAqNNz4q8hdLG+cYBfvHyALrvW4dCGg3Pn5b/Hbx2DV++GH8+CrX/ho6u0RGRTy2Box00Rm/rGtEQkz2rRbtj1mPbnnAshPe/EntxggOXaSq285qd5/uaz+NzZNVTmBhsqyhLwWPXGAW2Tuw8sK9EaHba8DW/eA3+6CHzxc0yQRAS0g4Lqg5KVR9eI6r2kZGrNiS7/pTaBFa1bZklmCh6fKrvxxrBg3xCAeUm9bE2+gZVv3wD+GSp/p+Vqw3q7/0VxZgoVOamoKmxrlUmrscrj8zPo0OZs5KVbtPH43f/S7lx05cy8SPB5Gl4NrYIIbvfeOiAVkVhV26XNLVpSFpiQGvzczL9M2+8sTkgiArD3Se3PxVfN3HOuuR1O+sS0Gc01geZmjdKkKmZtDex++d33L+T5tX2Y8GHwe09sOG+qBVeAYoDOrTDYGFo9I70hYld/oBpiMihkpZq1rs3n3alNUJ5z0cy8SE6NtgoisxyGtKG8yhypiMS62m7tonVeoU2rgOz9t3bHTCWwUUISEY8TXIGmUcEtt8NEtnePbaqqsj1QmTipPGvy6mTxh47wW8coPW9yBcXux7XXYbKZkYg9wWX7uekWDAZFS1oXfwg+8tdpO6WesI8/Dl/aBqXaJmfBzq0yRyQ2DTrc9ATmFs0ttELjazAxCGn52ryOOCKJSFIyfOFtrV2yrXhmn3ukEzb8RutPwpRdVWUzs5jUN+pixOnFoMAcUzf01WqTDQPLJ2fMog9qf+57OrSvRPtQDDQBFIcUTERC80PCJS1n2qTDksDE2E7Z5yomBVdalWSmkG4xwb6ntTsWXD5zFdgoIYlIUGb5zD9n8zpta++3fwVM2VVVhmZiUnNgrL0kKwVz/QvajVVnHl9DoSOZczGgQNd2KpK0Ckz70Diqzmv9xfGZloj0H4C3fq79GS5eN4z2hFbodNmd8tmJQW2BSlZFTqrWZLPuee2Omb7wiQKJnYh43eANY7fT2WtBMWqteAebQm2dWwfHpbFZDGoJjLVXZKfB/me1G+deMvMvlJ4HZScDUNj9OooCTo+fgcCERxFbegOJSL7VAnuegJfughfvDM+L7XkSflwDz9xCUYa21cC428fIhOziHGvahrREpCwrFeyt2rnKbIWKo9wYMYYkdiKy/xn4YRU8d1t4nj8lCypP176ve54Cm4U0sxGfX6V1UKoisaYlUBGZn+GCtne0G2dqsuG7nfI5uPD7mOZeSKFNO6HI8ExsmlYRCSWwF4fnxbKrwDUCDa+QjCe0i3OHDM/EnOD/97LsFK1P0dca4DMvac0P40xiJyL1L2kbjRlM4XuN4BVz7TMoikJVaFdVSURiTUugVFqSkwmX/FjbbGqmmpi926IrtQ30MssozdJK7O1DMukwFgUTkfIkO3RuA5TwJbCFS7Tu0J5xaHqDokwtie2ySyISa4JDM6VZgQnNRhPkz9MxovBJ3EREVaE+sKfMrPPC9zpzLtT+bN0ArjGqcwPzRCQRiTnBoZmignwtCbn0noi8bvBAJBWR2BRsZjZ3TNuRm5KTIH0Gm+BNpSiTx5z6lyjKCExYDTTgE7EjVBHJNOu+F0y4JW4i0rsXRrsgKRXKTwvf62RXa2U1vwda1lEdqojIEt5Y0xyYZBzszxB2Y72w9a9c4HkFmLxCErGld1RLAkqGAonIiexldTSCz9/4qja/AGiVXiIxxeX1hapYs7ufgV8s0SY5x6nETUSCLd0rz9SW8IZT9RptmedQM/OLbADsape+ELFkeNzNiNNLudJDVcs/Yag5/C/auh6euonTuv8KSEUkFqmqSt+oCwU/mV3rtBur14T3RSvP1Jri9dexyKp15pSh4NjSNjiOX4V0iwlr5zoYbtXm/sSpxE1EDryo/Tlrbfhf65xvwu0tcMrnQg2q6npHZf+QGBJcuntV6lbMz90Cz349/C9aeSagkDHWSAGDMkckBo25vDg9fkqVPgyeMa0CW3pyeF80JROKTwJgqXs7IBXYWBNMHKtyUlEaX9NurD5Hv4DCLDETEdeoNmcDwjs/JCg9H8xaOT/PapH9Q2JQcH7IWcY92g01ETgopGZD8XIAzjDspn1oQvpBxJjg0t1hcwnKbc3wqecjs+ph5XVwzrfImnsmoF1hOz0ztB+SCLumwDDwGbYecPRqCWxZmBNYHSVmIuL3wTnf0FYm5NRE/LVPrcoB4MG3myP72uK4NfU7sOBmgWe3dkOkrk4CCc+Zxl24vH76x6SXSCzpGdHmh+RZLZCUAkVLI/PCyz8OZ3+NrPL5WJNN+NXJTp0i+jUFKiKnKru0GypOB1OYO/PqKDETkZRMOPMW+NCfIveaB16E354B/76Jz51djcmg8Nr+Pv65qS1yMYjjtqvdzgpDHUmqG6xFkDc3Mi8cmE9wpnEPoMrwTIwJLcHMnsE9ZY6BoiisqswG4Pnd3brEII7d5hZtl+/541u0G8I9r0hniZmI6MFohu5d0PAK1blp3Lx2NgDff24ffr+U26OZqqpsbxvmTEPg6qR6zbQ9PcKq7BRISiWHYeYqbTJhNca0DIyz2rCHH/XeAG/8JLIvPj4Ie57g+pJmAH71aj3/2dkZ2RjEMRlzeXl6RycNfQ7SjF7yBjZrd0RiKFhHkohESvmpYEqBsW7o288NZ9eQkmRkeNwjE8miXPvQBAMON6cZ9mo3RPLqxGSBCm15+WJDkyQiMaZ1cJzTDHsodDZAf11kX3z7P+DRazm5+2EWBFbr3fbYTrqlp0hU8vtVLv/lW3zxoW0ArKlMRVl+jTZpPX+BztGFlyQikWKyQOlK7fvW9ZiMBpaUapulbWsb1i8u8Z5e3d+rzQ8xtGg3VEZ4r4dLfsyvV73IY76zZWgmxrQOjnOyoVb7IdKfm8DrGds38e8vnMqiEhsOt49HN8twcDTa2zVCY78Ds9HA+QsKuPHSU7Smidf+J3IVWJ1IIhJJgStbWtcDsDywlFdWz0S3J7Z14MLMw2e/DB//F2SURjaA7Gpy84sAaJOKSMxQVZXOfjtLlQbthvLVkQ2gYJG2SZrLTtJALZcvLQagtns0snGIo/LmgX4AzpqTyx8+sZIFxTadI4ocSUQiqfxU7c9AIjKv0ApMLtUS0Wdj0yDbWocxGhQuXDkvMn1nDkH2m4k9Tf0Oyl11JCse1NRcyJkV2QCMJihbpX3fuoE5BdrxZn+PJCLR6J2mAQDOmJWrrexsfSe8u8NHEUlEIql0ldbxcLgV7B2hbbplzDZ63fvyAQA+sqqMfGuYO/AewbyuJ3nY/P9YNvSi9IOIEesaBlhl2A+AUn6qPuX1YBWmdT1zp1z4uLzyGYo2wRVWcwqs0LMH/nQB/Gwh+P06RxZ+kohEksWq7bq5+CrwOkMbUnXZndKoKgp12SdY19CPCS93Dn4DXv4uuPWpSGQ52znVsI9T2M12mVMUE16r7WVlIBGJ+LBMULAK27KeQqsFW7IJn1+VTTejjKqqdA5rF6TFmSmTDTcLl4Ah/k/T8f83jDZXPwRX3g85NeTbtAY1Lq+f4XFp9x5tntnZharCVSVDJLe9AZv+CCZ9qiJKhXYiW2WoZWPToC4xiKO3t3OEl2t76SQXj7VUv0SkZCUYTDDaiTLSQXWetvt3swwHR5XhcQ8TgUpnYUZyaPhet89NhEkioqPkJCM5aVq75y4Znok6m5q1E/7lWYHVMuWn6nd1UnYyKgrVhm5e3bJbSutR7qcvakt1N82/g6Rb90DJSfoEYk6Fqx+Gm3dDZhkVOVpjteDeSSI6dAxrk9DzrBaSTYbJRKRCEhERLn4/9OwFt0PLfoHuEVkNEW2CQyDz3IH9ZYJlbj2kZOHPmw9AwfB2/vhWk36xiCOq6xnlpX09GBS4ee0c7UY9l1/OPh8yywCoyNH2vGodlIpINAkmIsWZKTDcAqNd2o7tJSt0jiwyJBHRw/3nwm9WQ/O6KRNWE2N2dKzosk/QM+LCaIDM/kCb5fLTdI3JGLg6OtlQy69eqWdgTD4z0WhdvbYM89IqhVm5+rR2P5yKQKv5FqmIRJXOQCJSkpkMLYFqSPFybX+iBCCJiB4CV7a0b6TAFkxEpCISTXa12wE4O9eBMt6vtegvXqZvUIHx4tWWJsbdPl6v69M3HnFIW1q0vkD/b/Br8KMq6Nyub0B+P7z5U3j4GqrTvYAkItGmZ0S7qCiwJUP7Ru3GON5t990kEdFDaaDc1rElVBGROSLRpS7Qa+Fca2B+SOFi/Xe/LF0BKdkYbIWAyrr6AX3jEYe0pWWILEbIdLaDcxiyKvUNyGCArX+G2v9Q6dZW8XTZJ2SeURTpHdWO//nWZDjpk3D+/4MF79c5qsiRREQPJZOJSGGwIjIiiUg02d+j7f9TnuaHlCxt9YHesqrg6430XPxHQGF9Q7/eEYl3GXK46bI7WWpo1G7Ima3t9q23wDEnc3AnqWYjfhXZtyiK9I1qFZE8q0WrvJ7+JamIiDArWARGCzjtVBm0rbmlIhJd6gJtsH0rroOvN8Hab+sbEGgTHhWFFRVZKAp02p0yTyTKBDewPDOlWbshWiYbBuJQOrdSHpgn0irDM1EjmIjkW3WuuupEEhE9GJOgaCkApePajq7SXTV6uL3+0AllToFVSwDM0TPpMM1iYl6WtgpD9g2JLsHPzcqkQEWkNAoqaTBZ0WvfTHlgu4CWAVk5Ey2CiUjF6FbY+SjYO3SOKLIkEdFL4ACVPbQLgDGXl1GnNDWLBs0DDrx+FavFQHGGfm3dD6lrB/x0IQ94vg7Avq4RnQMSUzX0OQCV2R6tj4hu/UPerWiJ1tjM0ctiq5a8tgxKRSQaeHx+BsfdABQeeAge/wzseEjnqCJLEhG9zL0EzvoaSUuuxJZsAqQqEi32B6oMN1nfRPn5EnjzHp0jmsJWCiPtFHrasDHGvi6piESTht4xKpQeUn0j2kqrgsV6h6RJSoGChQAsNWi7AcvKmegwMOZGVcFkUDD3bNNujJYhvQiRREQvVWfCud+CitXT9pwR+guumFmZ1AD21ujaATMtJ7QKY4mhidpuqYhEk/q+MVxqEm2LvgArrgOTWe+QJpWsAKOFUpO2NL2+d0zngARMDsvUpE2gDDVrNxYv1y8gHUgiEgUKZRfeqBKsiNQEljpG3dVJYLx/mVLPgZ4xvL74350zFjg9PtoGx+kmB8uFd8ElP9I7pOnOuxPuaMd69hcBaBsaZ8ItS3j1FlwxeXpKoFVA7pzoWGkVQZKI6MkxAPuf5+QkrVQqFZHo0NTvwMo4mY5AG/WoS0S0eFaYGnH7/DTKBmZRoanfgV8FW7KJvPQoXP2QkgUmM7npZrJSk1DVycm1Qj/BZpbLg0u+o+14EwGSiOhp0x/goY9w7si/AdlvJhqoqkrH8ASLgweFzHJIy9U3qHcLHKiWGxsAVSasRon63jFMeLkqoxbFEb09XhRFYXaBFZgchhT6CVZE5vkOaDdIIiIiKjAOWDyhzbCXioj+hsc9jLt9LFIC1ZBoHKstWgKKkUz/MAUMyYTVKFHfO8ZspYP/td8Jv1wBqqp3SAdb9wv4zRlcZXoLgAMyT0R32nFfpcQZGAqOxmNOmJn0DiChBXqJ2BxNpOCUOSJRILgL5gpzK6iE/o2iSlIKLP4Q+4cVDHWqTFiNEvV9YywyBBLYoiX67rh7OGO90LOLRWULgQUckIqI7noCFZHXz3mMi7N7tIaXCUYSET1ZCyG9AGWsh/lKK40jVr0jSnjBttcDKVWQ5YzeMukHf89YyxBddW+jSkUkKjT0jvFRpVn7IRoTWAjFVeLUqrB1PVIR0ZtWEVHIKKiEmihpgBdhMjSjt8CBYYGhheFxj8xi11mwIrKu5NNw/StQvUbfgI5gbqGWuHaPOBlyuHWOJrH5/CqN/Q4WGZq1G6I8EbEO1WLALytndKaqaqgSHmzjkIgkEdFb4MCwzNQMyOZ3eusIVERKsqL/oJCuuLkwsx2APZ0yPKOn9qFxvF4vC5TAEsxoTURyZkFSKop3nGUpfbJyRmejLi/jbh9fMD5J6Y57YbBJ75B0IYmI3gIHrKVG7QDWZZeVM3pqHxonmxHKrFH+X8PtgB+U8Tvn18nBzq4Ou94RJbT93aNUKV2kKi5IStVO+NHIYIRCrdvrWdZOQDqs6ilYDflE0sskvfkDGO3SOSJ9RPnRNgGUr4Yrfssf8m4DpKmZ3jqGJ/hm0t+55pXVsPEPeodzeOY0yKwAYKGhmZ3tw/rGk+D2do1MrrQqXKyd8KPVuy5+2oYkEdFLt91JDnYKGdBuKIySLQEiTBIRvaXlwrKr8eXMB2QJr946hidYqDRjUH2QUaZ3OEcWOKEsUprZ2S4VET3t7Rxho38+byz4Npz6eb3DObLi5ZAzG1N6NgBtsvmdbrrtThYG5xXlzAJLYi5YkEQkShRJm3fdOVxenONjzFa0eRdRO84fFIhvoaGJjuEJ2b1ZR3u7Rugih6QVn4CFH9A7nCNb9jH44mY6l9wIQNuQDAfrpXvEyaJoX2kVAZKIRIPBRtYMPcqVhjekIqKjjuEJ5iltGBUV0vK05dXRLHDgWmJsBaCxT1q968E+4Qkt+15QZNM5mqNXlpUKQLtURHTTZXeyMNR7RhIRoaeOrays/TEfN70kbd511DE0MaUh1dLobEg1VeDAVUY3Nhyym6pO9nWNkM8QX0p/lYzBHXqHc9TKspJJxkX70AR+fxR2gU0A3fYJFiuSiEgiEg2KlgEwX2mhd1iuavXSPjzBgmCZtHCJrrEcldRsyCgHtD40sgxTH3s7R1hhqOMW7x/gmVv1DufovPVzSn83ly+ansDt89PvcOkdUULqHxwiXxnWfoiFY06YSCISDbKrUJNSSVY8pI+34fJKgyE9dAxNMN/Qpv1QGCNtllffyMY5X6XVny8VEZ3s7RphnkEbHouZz405DcU9xpKkDgC6hmVIONL8fpW6IT8LXX+i4+NvahcWCUoSkWhgMEK+tmpmntJK74hcneihY3iCJ32nc6Dg0tjZeOrUG3Cc9Dk6yZVJhzqp7R5hvhJIRGJln5CChYB2vAHpX6SH3lEXLq8fDCbyq2LkcxMmkohECSV4YDC0SndVnXQMjfNn34UcOOMeyK7WO5yjFuwC2yH9ICLO71ep7x0LndBjJhHJXwBAnr8PG2N0SEUk4loDk4SLM5NJMib2qTix//bRJHAAm6+0ycoZnQT3mSnJjP727iF+P6XuJt5veIsxp1uW8EZY+9AEJs8Y5YY+7YbABUXUS8kM9cmZp7TRNSwVkUhrGXDwk6Tfcje/gr46vcPRley+Gy2mlEqfkzJpxLm9fjLGGkhXFEoyzHqHcwxUUv98Ab8wT7DTVaMtQS5M0juohHGgd5S5SmBekbU4tsb5CxaCvY15hla5+NFBS/8YNxg2kj7uBBJ71ZJURKJF8Un8eeH9XOj+oRwUdNBln+AW46O8bPkaOXse0Duco/eu+UUdMk8kog70jjE/1iaqBgWqsPOUVjrl4ifi7N31pCtOvAYzZNfoHY6uJBGJFuZU1OKVjJMs3VV10D40wfzAzqlKrIzzB02ZX9QhJfaIOtAzxpO+03lsyR/grK/pHc6xKTsFe9l57Far6ZTPTcSZevcCMJExG4yJPTghiUgUKczQ5iZIRSTyevr6qTD0aj/EXCISnF8kFZFIO9A7yhippM0+E8pO1jucYzPnAlwf/gf/8J1H76gLj8+vd0QJw+dXyRrV5oUosVZJC4OwJiJvvPEGl112GcXFxSiKwpNPPhnOl4t51e79fNv0IOcM/lPvUBKOq3M3AHZTLqTl6BzNMZoyv6hdEpGICa6YAZhdEJubleWmWTAbDagq9MhqvYjpGJpgNloFNrUscRuZBYU1EXE4HCxdupT77rsvnC8TNwp8XVxr+i9net7CK1cnEZXUp5VJh61zdI7kOAQSkXJDHwODAzoHkzg67RNY3X3clfRXKjv/o3c4x8WgwALbBDnY6ZQlvBHT0D8W6j1jKFysczT6C+vA1MUXX8zFF18czpeIK+nlywCYq7TRNzpBUWaavgElENvIfgBcOfN0juQ4pGbjSSsiydFF2vB+4Hy9I0oIB3rHWGJo5Drjc7ChA5Z9VO+Qjt1zX+fJid/zC9MH6bKfrXc0CaOxe4gSTPgxYIiVJd9hFFVzRFwuFyMjI9O+EokxdxYukkhTXAy0H9A7nIRSMFEPgKk4NsukrnO+w6fcX2WTIx+nR7YIiIT6nrHY66j6boHGffMUmegcSfUDbi5w/5hfnPI6pOXqHY7uoioRufvuu8nIyAh9lZWV6R1SZBlNtJsqAHC179Q5mMQx4fbxM9dl/MxzJTlzz9A7nOOStuLDbDCtYoQ0WQERIXU9o5N7zMTqVe2U+UWtA9KZN1IaAxtUVhbGUN+ZMIqqROSOO+7AbreHvtra2vQOKeJ6U2cBoPTu0TmSxNE84OA1/3L+bPkoGSWz9Q7nuCiKQnl2KqD9fUT4HZja2j1WVz4EKjkVhl46e/t0DiZxNPRp/0dr8tJ1jiQ6RFUiYrFYsNls074SzahNmyyZOlSrcySJo6lfOyhU5cbwnByvmytTt/NF4+PUdSfWkKYeVFWlo7efSqVHuyFWh2ZSs3GnFgJg6pdjTiTYJzz82PVdHjffSY1b3nOIskREgCdPK5WaJ/p1jiRxTDSs41zDVhZnuPUO5fgpBj7V9V1uTXqM/jaZXxRu3SNOStzNGBQVNb0gpsf5g30sipz1sldRBDT2jrLCcICTDPWkpcXmsu+ZFtZEZGxsjO3bt7N9+3YAmpqa2L59O62treF82ZhmKF/NcudvuS3zx3qHkjBqGv/Gn8w/4QLvK3qHcvyMJhwZ2rCev2evzsHEv7qeMWYZOgBQAi32Y1VSkXbxM0dpC1UHRfh0tjVgU8bxYoSc2BwKnmlhTUQ2b97M8uXLWb58OQC33HILy5cv58477wzny8a0/GwbQ9iku2oEZTkaATAXLdA5khNjCJwQ0+wHmHDLyplwOtAzymO+s7it8lG49Kd6h3Niqs/hmbQP8Kp/Gfu7R/WOJu452rX5f4OWMjDF0gab4RPWPiJr1qxBVRN7V8FjVZiRDGhdDv1+FYNB0TmiOOfzUOxrByCzIjaX7gallS6Cuseppo236vs5f0GB3iHFLa2jqkJBcQXkxPiGZTXnsHlePq+ta6a6SxKRcFP69gGEKphC5ohEnXyrhYuMG7nfcDfjr96jdzhxb6RzP0n4GFOTKamIwa6qUwSHCOYo7fx3T7fO0cS32kDlYFaMtnZ/t/lF2sKAfV0y0Tnc0ke0nkWxPqQ3kyQRiTJJRgNVFgdnG3fib16ndzhxb6BxBwAthlLSkpN0juYE5c0FoEbp5JW9nbJNQJi4vD5aurr5Q9I9nNVyH/hj/31elO1npVLLQFeTVLHDyOvzU+RqBsBaFqMrrcJAEpEoZLdqpd6kgf06RxL/xju08dq+5CqdI5kBWZWopmSSFQ9WZwdbWob0jigu7esapcrXyvnGLWQc+BcYYv8wOvftr/GY5buc4t5At2x+FzZtQxO0qnm0q3lkVS7VO5yoEfv/g+KQM0sbIkgZ7wC3zGIPJ0O/luwF3/OYZjCiXP0QP6j+M21qPq/XSYOqcNjWOjS5YiYvBvcmOgRjgTZMMFvpkOGZMGrsG+NLni9yffYDGApkaCZIEpEoZMsupE8NNHPrk6pIOP0j9WN82f0FJqriZKO4mnOpmHcSPoxsbxvWO5q4tK11mDmKNsGZeBnnD84vMrSzTyashk1DoLV7TV4MN08MA0lEolBhRjL1/lLthz7pvBdO64Zz+Lf/DPIq42cr7mVlmQDsbLfj88t4/0zb1jY0mYjESUUkOL9ottLOXqmIhE1LzzAA1dLafRpJRKJQZU4qdWqJ9oMkImHj9vppGdQ2+pqVHycHhrFe5tb/idssjzHm8oauwMTM6Bt10TY4wezA0EzcJCK5c1FRyFFG6etKvD2+IuW8xrvZYvkc54w/r3coUUUSkSh0anUO9WopdjWVMWm5HDbd+97mk8qznGpppsBm0TucmeEew/DyXXxK+Q8G/NKgaoZtbxvGhoMiZVC7IVBJiHnmVHy2cu3boQNSSQuTvIkmcpRRcrJz9A4lqkgiEoUyU83sK/4gS11/4Incz+kdTtxy7X2WO5P+ymeSX0VR4qRxXGYFmJKx4KZc6ZGKyAzb1jpEsTKAy5AC1mJIydQ7pBljLNTmiVSpbbQPjescTfwZGnNRpWpDernVsmJmKklEotRFS0oBhT+vb8EvVydhoQSGvRyZcbTfg8EIudoKoDlKe6ADqJgp29uGqVXLefzCDfC5N/QOZ0YpJ32C+1JuYJ1/kSSwYdDesp90xYkHE6mFcVJJmyGSiESpj6wqI91ior53jO3tw3qHE5eCHQ4N8bLyISh/cilmQ58s/54pPr/KjsBKpOUV2ZCep29AM23epewr+wiNajENvfK5mWlDzbsA6DaVgDHGmyfOMElEopQ1OYnvZz7Fa+av4Hjnr3qHE3+8bnLdWpnUVh4/K2aA0ATKOYZ2GvvGZLx/hnQOT+Bw+zAbDcyK01UPNYG/l1REZp63W9sV254e43sThYEkIlGsLNVNpaEHb/cevUOJO+PddZjwMaKmMGd2nJVJAxWRuYZ2XF4/HUMTOgcUH5r6tSrBI8nfw/Sv62CkS+eIZt5JSS1caXiDrh7Zq2imWYYOAODJibPjzQyQRCSKpRQvBLRt3cXMatu/BYBWQxlFmak6RzPDAhWRSqUbA365up0hTf0ObDhY7tsFe58Ec/w1pTp1663cY/4tln65+Jlp2z2lvOlbhLlspd6hRB1JRKJYXvUyAIo9LXhkA7MZNdyijdeO2OJwK+7MCvjcG9w+6yn8GGTC6gxp6ncwO9jIzFYKyTZ9AwqDYKv3QlcTgw63ztHED7fXz89G1/I/nm+QtexSvcOJOpKIRLGsyiUAlCr99PQN6BxNfPnJ2Plc4fouQ0uu1zuUmWcwQNFSygu0XgWSiMyMxn4HcwzB1u5x0sjsXUwFCwBtxVWjVNJmTH3vGF6/ii3ZRFFGst7hRB1JRKKYIS2bASULgKHAFbw4cc39DjZ1etmlzGb1qWfoHU7YBLvFytDMzGgfGo+/1u7vFlxxZeigUVZczZj61nZsOJhXZIufnkUzSBKRKNdtrgDA2blb50jix0v7egA4tTqb7DSzztGESec2ztj3Xb5s/Bf1fWOoqqycORGqqtJtd04OzcRrIhLoFDtHaaehV7ryzpS0XX9jZ/L1fN3zW71DiUqSiES5PttCdvqr6J2Qf6qZsm/vDr5tepDP2jboHUr4jPaQXfsQFxs3MjzukfH+EzTi9DLu9jEnuMdMvPWeCcqdgx8DWcoYfd2y58xMSRrUdlG3ZJfoHEl0krNblNuz4BYud3+PV0xn6h1KXHB5ffjat3Kt6b+cPPCU3uGET2AOQ7WhCyM+mSdygrrtTiy4sStWMFriZ4+Zd0tKwWUtAyY7D4sTo6oqORNNAFjL4qxn0QyRRCTKlWalAMjeDzOkuX+cCr92VZtcFKdXtQAZ5WBKwYyXMqWXepknckK67BO4MPPFzF/DN7vAYtU7pLBxnftdPuG+jZfsRTg9Pr3DiXk9dicVqnbMKZole8wciiQiUS6YiHQPjYFflvCeqMa+MWoMnQAo8XpVC9rKmVxtaXKN0smBHklETkS33QmgrXgwGHWOJrwylr2ffWknY1fT2NVh1zucmNfYWEe64sSHAUteHLYLmAGSiES5ksxUHjF/lxcnPoK3S1bOnKjGfgezFC0RCW4OF7cCf79ZSie13SM6BxPbugKJSGFGis6RhJ+iKJxUngnAlpYhfYOJA33N2kKDfnMJmOJ0cvwJkkQkyuVbLRhRMSs+7G3S7fBENfaOUB1KROJo191DydUqPrOUDvZ3j8rKmRPQO+ri3qRfcnPDp6HhFb3DCS+3g6ss7/A549NslUTkhLm6tLk241bZY+ZwTHoHII7MYFDoNpeDdz8TnXv1DifmjfY2k6x48BmSMGZV6h1OeAUSrSxljKFxD32jLvJt0kzpePSPuVikNFHg6AZDnB82fR7W7v0Ga5Pg7JZLUFVVel+cgA1j+bi957Gq+hy9Q4laUhGJAfa0KgDUftlz5kSljGiz190Z1XE/1s/ci+GOdr6fcRcAtd3SF+J4DY+OUaFo/WfifkgvJRM1rQCAjPFm2mXTxOPm9Ph4criab3k/TdaZcdjFeYZIIhID3JnaBKfk4XqdI4ltfr/Ks+PzWe78LaOX3a93OOGXlAIWK3MLtRUe+yUROW7JI80YFRVfkhXSC/QOJ+yUvOD8og62tsrwzPGq6xnFr0JOmpk8q0XvcKKWJCIxwJivHRQyJ1rBL8vpjtfwhAePT2UIG5nli/QOJ2KCiYhURI6Pqqpkj2uVNG/2bEiEYYpA1afG0MmONlk5c7xae4dYqDSxIMckw1tHEOeDnfHBVlSDS03CghuGWyC7Wu+QYlLvqLbyISs1CbMpQXLwTX/kf/b/k2bDSezvuUTvaGKSw+2jzN8BRjDkx/mwTFBecKJzJxuk1ftxc7bv4BnLN7EP5gCNeocTtSQRiQEl2em86D+JFHMS58nKh+PWN+ril0n34jYVwvhKSM3WO6TwG2oip28DSw0ZPNczhs+vYjTIldmx6B91MSvQ2j0pP457z0wVmOhco3TKkN4JUPvqAG2eX4bOsUQzSURiQGlWCld5vozJp1CbWSX/aMdpuL+Hy4wbwA2Yfq13OJERKLHPNnTicvvpHnFSkhn/vTBmUt+Yi141ixalhIr8BXqHExmBpd8VSg+Dow6GHG6y4nWDyDBKtjcAk/P8xKElSH06tuVbk0kyKnj9Kj2jLr3DiVneXm3jqcGkQjCn6RxNhAROKLONXQC0DMjW7seqf9TF973XcEv+/TD3Ir3DiQxbMVz9CB9P/iU+DNT1SFXkeATnFhnyEmRI7zhJIhIDjAaFkswUDPjpaG3SO5yYZRrUlj8PpVbqG0gkBUrsBWo/qThpHZA9i45V/5iW/OemJ1BFQFFg7kUk5c1CxUCbLOE9ZqqqUuTRdjBOK1moczTRTRKRGLEmd5i9lutY8tSFIPNEjkv6qDZZbNxapXMkEZSaDWl5AFQrnbQMSiJyrAbsDkAlNz3xll8Gh/E6JBE5Zv32McrpBiCrQhKRI5FEJEYUls3GjJdk7wg4+vUOJyZlB7bidmXFeWv3dwsMz9QonVIROQ41rQ+z03I9V/T/Xu9QIqtvP1eM/p1rjC/RMSyfm2PV11qLSfHjIBlzVqne4UQ1SURixILyAtrVXO2H/jp9g4lR+a5W7ZucBBuvzZ2Ny5JLsuKhfViubI+VdbQJmzJOsiWBhmYA+vazuuW3fNj4mnRXPQ7tE2b+z3MNT6dflRi9Z06AJCIxYlFJBg1qMQDOLtlz5pj5PKT5xwBIKkywROSSn7D7Y5t4xHcOA2My2flY5TqbAVBzEq2SFmhqpnTSMSQVkWPV6Eznft+lvFP2Gb1DiXqSiMSI7DQz3eYKAIZad+scTQwyJnG6+kdWOe/Dml2sdzSRZTSF5jcMjLl1Dib6ddudvFHXF/o5OOEwqXCeXiHpI7saVTGSrjjx2Tvx+2Vu2rFoDyRvpVmyXP69SCISQzxZ2lp0b48MzRwrt9fPqMtHH1lkJ+Ckw5zA33nC48Ph8uocTXRb85NX+cSfNvJKbQ/q+BA5DAOQVjxf38AizWSGLG1id4XazuC4JLHHIqPzLeYqrZRlSOen9yKJSAxJLdaaKaWNNOgcSewZDhxEDQrYkpN0jiby0p68lnWWL1GldElV5D04PX4AXt7Xy3jXPgA61WxysnP0DEsXSt7kROduu1PnaGKIqnJj73d4wXI7s0x97/34BCeJSAzJqlzMc75VvGReI0t4j5Hp5Tv5fdI9nJtSjyEBW5wrQy2UKP3MUjrok3kiR8Xp8TPWvgeAFkpIsyTglW2gD80spTO0V5N4b+pIJ6lM4FUNZJcmyLYAJ0ASkRiSn1/E5z1f4SeeD8ss7GNkaX2DC4xbKLQk6El4ypWtTFg9Ok6vjwE1g1d8y6hNXqx3OPoIfG6qlU56RuRzc7RGggmsWkBRjk3naKJfAqb4sasoMxnQ9r5we/2Js4PsifL7SbZrzczsaQnUzGyqwAqIWYZO+mVo5qg43T72WU/jVk8aZ+Tlcp3eAelhzkX8bM5f+PVOuHFEKiJHa7R9LxlAu7GMGpNR73CinpzJYkhOmhmzSaFAHaC/bb/e4cQOeytGvwuXakLNrNA7Gn1MWYopFZGj4/T66A6cfAtsyTpHo5PUbMibjweTVESOgbcnsK9VSoIeb46RJCIxRFEUvpj6EhuSv4jlte/oHU7s6Nf2mGlWC8m1Jchmd+8WSkQ66Jex/sPyTVmi6nZ7GB3UWnQXZiTeSqugwgwtCeuVishRSwrsazWeUaNzJLFBEpEY40jXhhaCH3RxFAKdaOvVYvJtCXpCyanBjwGbMoF7pFvvaKKWy+sLfZ/jbOH2XZfyuvlmChO1IgIsHn6ZnyT9lrKBN/UOJWakjwV33ZWJqkdD5ojEGG/2LBiEtLEW8HnBKP+E76lPK5M2qMUUWxP0hGKyYM9aSMOAC+fokN7RRK3g0l2AQncLAENYE3doBiga3sYi4xs4HNl6hxIbVJV7LZ/DMnGAk6qX6B1NTJCKSIwxZpczoZoxqh4YbtE7nNig+nFiod5fQr41QSsiwL5Ln+RD7m+zy1WgdyhR690VEYB6tYT5RYm78sEc6Chb7GnD6/O/x6MT16bmQS76+Ru8caCfvwwv4te+K5hbnmBdnI+TJCIxJs+aQqNapP0gm98dnff/itOUv/Cs/5TEHZoBcgNJWL9MVj2sqRWRUl87AJ2msoRu050WaKRYrXRKD5oj+MLft1LbPcon/rQRj0/FlmxK6M/NsZBEJMbkpJtDm99JInJ0XF4fgxM+vJgoSNShGbRVVwAj4y48cmV7SE7PZEVkltKhfZM7ByWB+/YY8rWJzhVKD71DozpHE72C3ZtPUfZxgWET55b4EvpzcywkEYkxOWkWGvySiByLhl4HAFaLiczUxGvvHpQ13sxr5q/whuVmBh3SS+RQXF4tQVPwU6N0AZBXlaDNzIKsRUwoKZgUP6NdMkn+cLJStUT/U6bn+L35Z3wqe5fOEcUOSURiTE66mbf9C/mL8n6Yf7ne4US/7Q9R8o9zuNH4JAtLbAl9hWJIz6PS0EOp0s/g4IDe4USlYEWkkCFSFRdu1cj7zl6tc1Q6UxR6zOUAeHtqdQ4megUTkRqlE4A5i1boGU5MkUQkxuSlW9ikzuPbzo/gn3WB3uFEv57dZIzVk6vYWVySoXc0+krNZkjJBOCVdW/TNyrj/e8WTERq8tPZUfxRRuZciTUtVeeo9DecWolfVfAMd+odStTy+P2Y8FKh9ACQHJjkK96bJCIxJiswzu9XYUi25X5PaqCZWb1awuLSTH2DiQL9ydqVbd2erVzws9cZd3t1jii6BIdmxpMLWPrZ35F7zR90jig67FtyG/NdD/CIcrHeoUSt4XEPFUoPSYoPnykVbCV6hxQzJBGJMUlGA5mpSeRgZ/zA6zDSpXdIUc3RsRfQVj6cOStX52j057BpnR5rDJ0MjXv4xzutOkcUXYIVkeQk2R9kqqqKSlyYqe0e0TuUqOT3qwyPu0PDMsa8ObIx6TGQRCQG5aSZuSfpt5T9+yo48ILe4UQvr4uUcW3lw1mrV4eqSYlMmbLnDED70ISe4UQdV2D5bqXaAU67ztFEj/mFWh+V9qEJRpwenaOJPmNuL36V0ATn4JYK4uhIIhKDctItU5bwyiz2w2mr340RP6NqCu87bbne4USFtJL5wOQBc2RCTipTOQMNzb7e8zX4QTl0bNU5ouiQkWLip6l/5p/m77C/To4572Yf1/4fzTFKInI8JBGJQXlTE5E+2YX3cNoO7ACg21xOXgK36J6qoGYZO/zVbPdrQzRydTudy+MnnXEyfYFVRTmyaRkAisKZpt2cbNjPtq3v6B1N1BkOJCL/sFwFVz0I8y/TN6AYIxuVxKCcdDO10kvkPQ2Nu6n1l2FPl6uTIGtBFclfeIO+Pd3wYh12qYhM4/T4qA6W19MLIDnBV1pNYcqfB+0ddDfuZMzlJd0ip4+g4MKB0bQKWHiWztHEHqmIxKCctCkVkeFW8Mg4/6G8lXQaF7l/yPqFd+odSlSZW2jlpIosAEYmZNXMVE6vLzR/Rsrr02WWLwSgzN/BMztlGe9Uo07t/5EtJXEbJp6IiCQi9913H5WVlSQnJ3PKKaewcePGSLxs3MpJNzOADYfBCqgw0KB3SFGpY9gJQHGG7PfwbjazgpVxqYi8i9Pjp8YQTERm6xtMlJk60fnf2yURmWrU6aFa6eRK55PQ/Jbe4cScsCcijzzyCLfccgt33XUXW7duZenSpVx44YX09vaG+6XjVm66BVBoM5RqN8jwzMFUle4hrbV7UabMD5nmnd+x6MG5fNP0N5kj8i69o67JoRmpiEwXTEQMnbQOjuscTHQZdXo51bCPjwz9Ftb9Qu9wYk7YE5Gf/vSnXH/99Vx33XUsWLCA3/72t6SmpvKnP/0p3C8dt3LTtWWo/zReTP+aH/LmeLnOEUWh0W6eHPkIT5q/RXFG4u64e0hpuSh+D7MMnYy7fbIB3hSdwxOTQzM5UhGZJlAhKlEGGBu1o6qqzgFFj2BFBJAE9jiENRFxu91s2bKFtWvXTr6gwcDatWtZv379QY93uVyMjIxM+xIHy0nXTqx/GV3FyufL+J/He9jWOqRzVNFlvHMvqYoLG+MUZUqL7mkCB0ptd1lVlvBO0Tk8wV9959M/7+NQsEDvcKJLajZqWh6dajaZvgGZXzTFiNM7JYGdpW8wMSisiUh/fz8+n4+CgoJptxcUFNDd3X3Q4++++24yMjJCX2VlZeEML2YVZSSTZFTw+ievSN5ukE3MpnJ2acuam5USUs0yu3+a7BpAIVNxkM0oI045oQB4fH56Rpz8zXc+/kvvAVux3iFFHeXm3Vxs+B3NahE9o069w4kao1MTEamIHLOoWjVzxx13YLfbQ19tbW16hxSVkpOMLCiyYcDPSUodVxlfo7ZzWO+wooo/0F+l0yjJ7EHMqZCpvS81SqdMWA3oGXHiV8FsNJCbJsN5h5SUTL5Ve296R2TTxCDXxBilSr/2gyQixyysl4q5ubkYjUZ6enqm3d7T00NhYeFBj7dYLFgscgA4GoUZyexuV3nY/P8wKz6ualsJrNQ7rKhhHNS6P/ZYZP7MIeXOgeFWagydDDrkhALQOeykRumgymrA4B0Hc5reIUWlfJuFA71j9EpFJCTN0YJBUXEn2TCnyZ5WxyqsFRGz2cyKFSt4+eWXQ7f5/X5efvllVq9eHc6XjnuXLC7Ch5FWigBIGWlgzCUl9qBkeyMAQ6mV+gYSraYsxZT9ZjQtAw4+Y3yW+523ysqHw+mt5a7BO/hb0ve45Z87GJVVVwBkjbcAMGGrls3ujkPYB89vueUWPvnJT7Jy5UpOPvlkfv7zn+NwOLjuuuvC/dJx7fKlxRgNCiU7l0J9OzVKJ019DhaXSidI3A5SJrQlmGPplfrGEq3KV7Nnfx27eqrIH5ClmAD1fWOcZ5Bx/iNKSmbO+FYqDCYM+Hl5Xy9XLJft7l/1L+ct1//xo1PmI0fgYxf2ROQjH/kIfX193HnnnXR3d7Ns2TKef/75gyawimOjKArvW1IMffOg/hlqlE4a+8ckEQFU5wj1WWcxMtCFKV3KpIe04HK22Jfw1L/3cIH0hACgodfBZxVpZnZEGWWopmQsXielSh+NfWN6RxQV+l1GBtRqDOUn6x1KTIrIcoKbbrqJm266KRIvlXhy5wIwy9DJ+j6HzsFEh3/sc/PNrhsA+LS0XD6ssmxtWbM0p9L093aSo4xqP8gSzEMzGFFyZkHPbmYpHTTIMQeYbPEu++8cn6haNSOOQ+DKTauIyEEB4JtP7A59nyGJyGGVZ1ooVXoZHOxP+OZUbq8f87C2VYLPWioTVY9kyvyiBqmIMOHycofyANcan8dqlHl6x0MSkVgXSETyFDv9fQf3ZklE6YwD2olVEpHDq3rmo7xluZmV3m0MOtx6h6OrlgEHlXQAYMiX+SFHNCURaR5w4PcndhLb2lLPdaYX+GbS37GlynYSx0MSkVhnsdJx5g+5xn0HTcOJfUAAGHF6eNT8XXZaPsMqpZZUs1HvkKKWIbsK0E4oiT4809A3FmpIpchE1SMLXPzMMnTh9PjptCf2qqv+pl0A9BqLUExmnaOJTZKIxIG01Z9inX8x3eMqTo9P73B0daDbTpXShU2ZoJdMxt2J/X4cUbDVu2xiRkOfg2d9p/BU/udh3qV6hxPdcudAWj5OcxYAjQk+T2S8qxYAe1qVzpHELklE4kBGShJpgSv/juHEvjrpaD5AsuLBpZqYSCnh4sUHN84TAVNK7G2Jnoj0jrFDnUXb/M9A1Vl6hxPdChfD1w7wl/LvAST8yhnjgNY80ZctE5yPlyQicUAZ6+UTqRv4gOFNOhK8OdVI214A7KnlrP/WheRbZcz2sAKJSLXSRdtAYp9M6gMn05o8maT6ngINu6rz0gESfpJ8hqMJgOSieTpHErskEYkHvXu5zfkzbjI9mfAVEX+/tseMO6MGo0E6HB5RVgV+xUSq4mKsr1XvaHSjqirDve1cYtjAfGOn3uHEjOq8NEBN6JUzTo+PYl87ALmVi3WOJnZJIhIPAle25Uov3YOjOgejr7QRrbV7UuFcnSOJAcYkXLZKAMxDDfrGoqOeERfzvfv4tfleyt78qt7hxIZNf+SKVy/kG6Z/sL87cRORxo4eipRBADLLFugcTeySRCQe2IpxG1NJUny4eg/oHY1u+sdcFHu1JZhyUDg6viVX8yvv+9nlSMft9esdji6mrpgxyIqZo6MomB0dzFY66B9zJewGePuH/Cxx/p47cn6BkpqldzgxSxKReKAoOKzVABiH6nUORj91PaOs8y/kbcNKLCVL9Q4nJqSdeyv3KR+j3l+SsMN6DX1j1Bi0vYnIlQmHRyWQsM01ab2L9naO6BmNbup6xhghHWPZCr1DiWmSiMQJf2DGtnW0SedI9FPXPcqvfB/gTxU/hMJFeocTExRFoTzBW7039E5WRGSzu6MUeJ8K1R4suNmToInIgR5tKHxOgVXnSGKbJCJxwlyozdjOd7XgS9BOh/t7tLHquYXpOkcSQ1SVpRkOTjXsTdhEpHXAQbUkIscmLQ+SMzCgUql0h07IieaU9ge4y/Rnlpja9A4lpkkiEidSS+YDUK100jOSmOO13V1tZDEiVyfHwjXKj1o/ysPm/6OzKzG3CHAMdmJTJlAVA2RX6x1ObFCUaX1oDvQm3oTVCbePM11vcJ3pBaosiZmIzRRJROKEsfIMbrX8Lze6v5SwY/1n9f+Tbck3cHrDz/QOJXYk2xi35AMw3rlP52AiT1VVLHZtxZDXVg4mi84RxZB3bX6XaHvONPTYqVK05D1DJsefEElE4kVaLu3Zp9NBHp0JmIg4XF6KvVp5NK1ArmqPRagj5EDirbjqG3Wxy1PKDZ6voJx3p97hxJbi5ailJzNsyMTp8SfcBVB7834sigc3SZBRpnc4MU0SkThSkpUCQHsCdldtH5oITThMkQ6HxyTYEbLQ3cLAmEvnaCKrbWicYazssp6FacmVeocTW06+HuUzL7Ip5/0A1CfY8MxIu9bFeTC5HAyyueaJkEQkjpyi7ONm02OktL2hdygR195vp0Lp0X6QCYfHJKlAm19Uo3SyvzuxxrqDSXtpIIkXx64ssOqqfSixJjurvXUAODNqdI4k9kkiEkeWTmzgZtPjlPa+rncoETfcWa81dFOSwVqsdzixJbCte43SSW2CJSLddiefML7ABcbN4E6sE+lMKbcZMeGlPcGGZlJGtLlFpgLp4nyiJBGJI4Y8rRKQPdGicySR5+nR9pgZSikHg3ysj8mULQIOdA3pHExk9Q8N892kP/Pp9m+BJ7FOpDPib1fyze3ncqphX0JtuDnh9mF19wIyUXUmmPQOQMyctBLtP0SJtxVVVVGUxNn0LWlIm2g5YZMy6TGzFVM/57P8bg809dj1jiayBrROxM6kTJLTcnQOJgaZkjHgZ5bSwc4Eqoi0D41znefrlBsneGPJRXqHE/Pk0jGO5FRo3USLlAGGhxPrynaTu4oHvBcyXnme3qHEHkWBtXfxqG8Ne3pcCbUM0zKsldcnbLLS6rhMWcKbSKtm2obGAYX0rEKwSN+iEyWJSBxJzshjEBsAA617dY4msp4dm8V3vJ8kaflH9Q4lJlXmpGIyKEx4fPQk0AZmmQ5tSwR/zmydI4lRUxKR3lFXwmyc2DaoJV1l2TLJeSZIIhJnukzaevZEak414vQw4vQCUJIpB4bjYfKMcomtgdWGPbQOJMakTa/PT4FH6z1jlgmHxyeYiBi6UFUSpqtzasOz/DHpx1zufVHvUOKCJCJxZii1EgB/7359A4mgzt4Blin1lKW4SbPItKfj0vga9zq/xddNj9CSIHvO9I+5Q3vMpBbP1zmaGBXYrbhAGcLKON0JkojYBrZxnnEb1WriLQwIB0lE4syOiutY47qH/2R/Qu9QIma0aTNPWu7kMeXreocSu0Il9g7aBhw6BxMZ3fZxqpUuAIz5UhE5LskZkF4IaPtcddsTJBFxaAmIIU+G9GaCJCJxJq1wFs1qEe3DHr1DiRh3tzYM1Z9cqW8gsSy7Gj8GbMoEw33tekcTEd32CT7g/i4/tt0OmRV6hxO75r+PjbYLcGJOmKGZIk8rAGnFsnR3JkgiEmeKA3MkOu2JM4PdNKB1OBy1ysqH42ayMJEW2C+jv07fWCKke8RNrVpOY/4FYJQhveN26T28OPc77FfLE6IiYh8ZpUzVNrvLrlqsczTxQf73xZmSrBQ+Y3yG5QNtMFwBmfG/GVP6aCMAvmxp7X4ivNmzwNGCdaxJ71Aioitw9V6YkaxzJLGvwKa9h4kwR6S3ZS8ZisooqVizSvQOJy5IRSTOlGamcqXxTS5V38DVuVvvcCIi39UMgLlIJhyeCFNgnkS+qxVfAvQSKW95gs8Yn2GuqUfvUGJekdVIqdKbEBURR7t2XO0wlWs9eMQJk0QkzthSTLQoWpY+2r5H52giwDlCnr8fAFvZQp2DiW3BXXir6aA/AXbhXTnwFN9K+js1vka9Q4lto91c/NQKXjXfSp89/nfgHR0eZFRNYShNhoJniiQicUZRFPqStYl3wf1X4tl4lzZRtU/NoKhINrs7EcbqM7nb+Dnu8V4V/1e2qkpxYMJhskw4PDFp+WBMIknxkTzahqrGdzXtxdSLWey6n/Vzb9M7lLghiUgcclirADANHtA5kvBrcmXybc8n+KvhCmzJSXqHE9uyq9mQ/X52qLPifqzfY+/CigOfqpBXIZW0E2IwQKAzbbnazqDDrXNA4dU2qLV3L8rN1juUuCGJSBzyBiZtpo3Gf8l510gKD/ouYmvJNXqHEhcKbRYg/jtkDjbvAqCVAvKzbDpHE/uCO3/PUjrjPoltC+wyXJaVqnMk8UMSkThkKdAOCqleOzgGdI4mvGq7RwGYVygbT82EJUkdXGV8DX/nDr1DCauxwPypzqRyDAaZcHjCcrWJzjWG+G5qpg408Hv7Dfws6T7ZZ2YGSSIShwpys2lXc/FjgKFmvcMJq/Sm51ioNLGgQA4KM2GN/Ql+nPR7irte0juUsPL11gIwnCoTDmdErjY0UxPnFRF7606qlU5mKR2hnk3ixEkiEodKMpP5sOtOzrU8DKUr9A4nbFT3OLcM/R/PWL7Jwiyv3uHEBV+2tneIzRHfvUQsQ9r8KXeWtOieEVN24e0Zjt9mio5gJc1UTpJRTp8zRRqaxaGSzFQ6ycU46sPr82OK0/8wfS17yUdlWE2jsqJK73DigqlgLuyBPFer3qGE1c/z/48D/Vu5uuI0vUOJDzk11OWezzNdtrhewuvt1ippsnR3ZsXnGSrB5VstJBkVfH6VntH47QfR16jNY+gwlWNJkpx6JqQHlrKW+jpRffFbZaofVtmtVpNfWKp3KPHBZGH7qT/jF74r6Rjz6x1N2JiHtUqaP1c2SZxJkojEIYNBYYnVwY9MvyPliWv1Didsxjv2AmBPl6uTmZJbOguXmoRF8TDWG7+rrloHxwEoz5aVDzOlMNjmPV73ufL7yR5vBiC9RHrPzCRJROJUtjWVD5teJ6vlBfDE54HBNKhtzqbK1cmMSU220KIUATDaGp+deR27nuGrnt9xnmGLrHyYQYU2M6VKL2n2OO1fZG/Dojpxq0YKqyQRmUmSiMQpS2Yhw2oaCir0x+eBIWtcm1BpLZWGVDOpI0nrzOvq2qtzJOExsf9l/sf0Euda9pNqliG9mVLa8iRvWW7mVt+fmHD79A5nxo2PDrHbX8letYI5RZl6hxNXJBGJU/m2FOrUwPh37z59gwkDp9NJia8TgKLZy/QNJs68lnUV17jvYGf+5XqHEhZqn7b1wbAM6c2olMD8ojmGjrhcwrufCt7n/j7Xm39EZqpZ73DiiiQicarAZqHOH0hE+uIvETnQO8ZnPbfwU+UT5BbLipmZNJ63jHX+xbROJOsdSlgkD9cD4JGluzNKydc2TcxXhunv7dY5mpl3oEdbDTS3UDrxzjRJROJUvs0ypSJSq28wYXCg38mr/uVsLPoYisGodzhxpTAjMOkwDq9qcY1idWknSWO+zC2aURYrfcYCABztu3UOZubVddsBmF2QrnMk8UcSkThVYE3mgBq/FZGuQBtp2e9h5hXYkrnUsIHTm38FI516hzOz+rUJzn1qBrn5RToHE38GAp1qvd1xloioKjdtu4znzLezzObQO5q4I4lInMqfOjSDAj6PrvHMtMzm57nEsIGaFDkozLSijGRuNP2bS+wPQ+d2vcOZWYH5IQf8JZRmyYqZmebM1Ia7zIEVbXFjrIdM/yBzlDbKysr0jibuSCISp/JtyQyQwXznn5j4/BYwJukd0ow6s+tP/Np8L/P98bkiSE8FtmTq1BLthzirpqnDWsfYerWEUqmmzThDwXwAshzx1YNmrENbyt6iFjCrOFfnaOKPJCJxymoxkZxkYIJkekfjbKzf76PA3QaApXi+zsHEn8KMZOr82lWfrye+EpHBlV9hifMP/NL3QYoz43Myrp5Sa07nPu/l/Ml7od6hzKiBpp0AtJvKsCXH10VdNJBEJE4pikJBoNNhb7y1eR9uxYIbl5pEZvEsvaOJOzlpZpoMWiLi7Y6vXiLtQxOMkIbRWoDFJJOcZ1ph9UJ+7P0oT0wsxz4RP8PBri4tIR+RJd9hIYlIHMu3Wlil1FL9n6vg8c/qHc6McXdpZdJ6tZiiTKvO0cQfRVGYyNB2UzUN1YM/fppTtQ1prd1lfkh4pFtM5KZbAGgdGNc5mpljGdTmFnlzpAIbDpKIxLF8WzIKKjn9m6Flvd7hzBhH2y4AGpRybCnSGTMczHlVTKhmjD4XDDXrHc7M6N7Fslev5cvGf0kiEkaLs9ycYdjFUONmvUOZGapK7ngDAMZCae0eDpKIxLF865ReIvZWcMXH9tzebq0i0m2pQlEUnaOJT+U56RwITliNl868XTsoHXqHkw21MlE1jD7u/w9/M99N9r6/6x3KzPBMsNW0lP3+UtJLpCISDpKIxLECWzLDWBkxZms3BJYuxjrzgPb3sFtlfki4VOSkcpvns9xW+jeYe4ne4cyMQEJVp5ZKRSSMPDlao7jUeNn8zpzKF71f5kL3jyjKzdQ7mrgkiUgcy7cGxmpN5doNvfEx8fDp+T/ic+6bGclZrncocasiJ419agWb7FYwxMlhIvD536+WSUUkjCxF2vBF3kQTqKrO0Zw4h8vL8Lg28bYkUxLYcIiTI4w4lGCr7v2hPWfio9X7fnceL/hPJjO3QO9Q4lawjXXLwDhur1/naGZIsCLiL6Uww6JzMPErq2IRPlXBqo7CWK/e4Zywru5OFPzYkk1YZeluWEgiEseC2fsOV6F2Q5yM9XfZJ4DJREvMvEJbMtkWP180PIrroU+Az6t3SCdmfBBGuwBtaCbPKp+dcCkvyKFF1S4SgivcYln+v69hl+UzXJIeJ0NNUUgSkTgWPFHv8ZTgTy+EtDjoCLjnSc7o/gvzlRaKJBEJG0VRqMjL5HrjM1gbnobBGO+UGagGtqu5uE3p2JJltVW4ZKUm0aRofWjsLTt0juYE+f2k2utIV5wYM0v0jiZuSSISxywmI7npFraoc9h79Ub44O/1DunE7XqUayf+wimGfRRlyHhtOM0utE1ZORPj84vGB/FaMqnzl5JvtchqqzBSFIW+wOZ3rq4Y/9wMN2PyOXGpSZjzavSOJm5JIhLnSjKTAYXO4Qm9Q5kR/p7JCYdSEQmv2flWDsTL/KL57+PFS9fzBc+XQ5O4Rfg0557L1zyfZUPeh/UO5cQEhrMPqCUUZ6XrHEz8Clsi8r3vfY/TTjuN1NRUMjMzw/Uy4j0UB+aJhBKRWO6S6R5HGWoCoMVYTkaKTBwLp1kF6ZN9aOJgflHvmBsnFvJlfkjYKSXLeNS3hp3uIr1DOTGhlVallMiS77AJWyLidru56qqr+PznPx+ulxBHIThhNW//3+GeefDCN3WO6AT070dBpV+1kZxRKOX1MJtTYOVAIBFR4yERCWz+mG+Tiki4TV4AxfiGm6GVVmWydDeMwpaIfOc73+ErX/kKixcvDtdLiKNQmZsGQK/Dr60aiOVt3actv5Sr2nArzkimzVSh/TDYAF63vgEdr5Eu+PliLt79VUCVoZkIKM5IZrHSyPLef0Fv7A7rTQ4FS0UknGSOSJyrztMSkY2OQM+NnhheTjelIZUkIuGnKAppeRWMqKn4McBwq94hHZ/evTDcSs5EM6DI0EwEFGWkcIPpKW50/BoOvKB3OMdtpPIiXvSdRKOxipw0s97hxK2oSkRcLhcjIyPTvsSJqc7VJli9OZKHigKOvthtMhS4stqvllEsK2YiojQ7lYtdd/PXc96G3BhtqR+opDUElpTmydBM2BVnJrPPr1XTfF27dY7m+O2acyPXe76KJatUhoLD6JgSkdtvvx1FUY74VVt7/GW4u+++m4yMjNBXWVnZcT+X0BTYLKSajYz5LXgyq7Qbu3fpG9Tx+ujf+d+i3/Gib0VoDFqEV1FGCh3k0Tkaww3NAonIXq823yUvXRKRcMtISaLBUAmArytGjzdA6+A4AOXZsiVAOB1TV59bb72Va6+99oiPqa6uPu5g7rjjDm655ZbQzyMjI5KMnCBFUajKTWNP5whD6XMoGG6Ent0w6zy9Qzt2JgvrRgsZwEFljhwYIiGY8HXE8vLvwJDe9sAKDpmsGn6KojBknQvjYBo8AF4XmGLsfR9sYrC7E1Apk0QkrI4pEcnLyyMvLy9csWCxWLBYYuzDGgOq89LZ0zlCS1I1BRCz80R8fpW2ocAViiQiEVGckUwOdq5qvR8e9MC1/9E7pGPj94UqIrX+MgwK5KTJMSYSjFml2B2pZDAO/XVQGGMLF56/nS/WPU+38VOUZX9J72jiWtjmiLS2trJ9+3ZaW1vx+Xxs376d7du3MzY2Fq6XFIdRFVg5s0utgfLVkD9f54iOw+5/4XzsBs5Ut2A2GqSraoQUZ6bgIJkzna9B85sw2qN3SMdmoAG8E/hMqTSrheSmWzAaZKw/EgozUqlVAzt/d8fgPJFAzHX+UspkxUxYhS0RufPOO1m+fDl33XUXY2NjLF++nOXLl7N58+ZwvaQ4jJrAypkXnAvhU8/DGV/ROaLjUP8yaXsfZqmhkdLsFDmZREhRZjJOLDT7g6uuYmy83z0Gpauw5yzFj0GGZSKoODOZvYEJq/TEWCIyPggj7QDUquXMKbDqHFB8C1si8uCDD6Kq6kFfa9asCddLisMIrpxp7HfoHMkJCEyw3euvoDInTedgEkdumgWz0cC+4JVtrA3rlZwEn3mJZ5f/DtB2FRaRUZSRwt995/GDwp/CWV/TO5xjEzjetPjzUS02mawaZlG1fFeER2Wu9p+of8zFiNMDboeW8ccKnye018letZy5hXJ1EikGg0JhxuRSzJgssQPtQ9pk29IsOaFESlFmMvVqKa+75kBKpt7hHJtAIrJPrWBBkQ2DVGDDShKRBGBNTgp1kxx/4f/g+yXw5j06R3UM+uvA58ahpNKu5jFPEpGIKs5MnlIRibFExKO1GG8PTHIulbH+iAluStllj8EVV4HP+V5/BQuKbToHE/8kEUkQwQmrnWoWoMbWCSVwdVLrL0fFwIIiOTBEUnFGCrX+QCLSX6ctxYwFY73w/SL49Wo6B7VJ8pKIRE5wQvlK5wa8z94OHVt0jugYBIeC1QoWlWToHEz8k0QkQVTnafNE9vmmlNhVVceIjkHgoLDLV47ZaAglVSIyijNT6CQHhzETsqthLEZWznTvAtUPPg+tw9o+OTI0Ezm2ZBNpZiNXGNdh2vgbaHpT75COmnral/grl7DTX81CqYiEnSQiCaI6cPLeNFEAigHG+2PnhOLoB7Srk9kF6ZiM8rGNpKLMZEDhK6UPw02bILNc75COTiCB9eYvpH9Mq+JIRSRyFEWhKDOFvf7YG9ZrK72M/3V+nGFTDrPy0/UOJ+7JET1BBKsIdQM+yK7RboyVA8MHf8d9p77Gf3yrmS/DMhEX7K7aNhJjbd4Dn+/+9DmA1nY8IyVJz4gSTlFGMvvU4BLe2FlxtbvTDsC8QitJcuETdvIOJ4iKQCfStsFx1MJF2o0xtAJiZ5+PcZJloqoOghsMdgbbvMfYkF4dlQAsKLLJxmURVpSRHHvzi1reZrj2dVJxyrBMhEgikiCCY+OjLi/O7EBn1VipiAC13aMAUhHRQXGmtvohdaIb3x/Wwi+WRn8y4pnQTnzApokSAFn9oIOijBS6yGbcaAW/N7QMP6q9+n0+tudzXGJ8hwXFMlE1EiQRSRApZmNoCW9Hxkmw7BqYc5HOUR2FDb/B/8eLWDn8PACzZbw24qzJSVgtJgaxYujcCsMtMNqld1hH1rtPm6iamss7fWYAWW2lg+LA/KIWU2Az1Gjf+VtVoXsnAPv8FVIRiRBJRBJIsDtgrXkhXPFrWPwhnSM6Cq0bMLStJwc7aWYjeVZp0a2H4swUXJgZtwXmF3Xt0Deg92KywJKPoM6/jL2BappURCIvuIR3j1qp3RCoUkUtezs47XhUI/WUML9QPjORIIlIAgkmIm2DMdRgKLSev5KqvDQZ49dJUWB4pjd9nnZD53b9gjkaBQvhg7+n7bTvM+byYjYaZPWDDoKT5H/uuADPzXvh/O/qHNF7CBxv6tUScjNspJiNOgeUGCQRSSBlgUSkdXBca5vevRv69usc1RG4xmCwEYB9/nKqcuVEopfgyplm82zthmiviATs7dJWP8wpTJfVDzooyUwhJclIuy+LFncMzLcIdlRVK2R/mQiS/5kJZLIiMg5v/AR+ezqs+4XOUR1Bz25AxW7KZYCMUC8UEXnB/hs7fJXaDV3bdYvlPfl92hwRv4+9nSOAzA/Ri8GgMLtAu4A40DOqczRHIZBg7/VLIhJJkogkkGkVkaIl2o3RXGLv2ApAnXEWANV5kojopSbQmfetsUJA0SarjkZpQ7z+A/DrU+GeuewN9IOQREQ/s/O1JffGnQ/BPz4Ce5/SOaIj6NwGwE5/NeU5kohEiiQiCSSY4XcMT+AtCCQifbXaUsdoFDgobPFUAkhrdx0FE5E9fX7UyjNhzsXgHtM5qsMIfG7ImcXeruBE1RgYFohTwd4/hp5dUPc8tLytc0SHoapw1YP80XoDe9RKqYhEkCQiCSTfasFsMuDzq3T5syE1F1Rf9HY8tFjxp+Wzwak1RJJERD8VOamYDAoTHh9dV/wTPvYw5NToHdahBRIRZ94SOu3a7rvziqQRnl6WlmUC8KZD6+cStcN6igJlJ/M75/mMkxxqAinCTxKRBGIwKJQFxvpbBiegeJl2R/AKMtq876fs/uhGXvcvIc9qwZos7bn1kmQ0hErV9b1RWgkJCnyeW5PnAlol0CafHd0sLsnAaFBYN16m3dC1U5vHE4Um3D56R7XurxXZcuETKZKIJJjgypPG/jEoWqbdGK1XKEDTwDgqBqpy5KCgt7kFWlVhX9eIVsYe7dY5okPweScbUilaxWZOgay20lOK2cjcAiuNajFeYwp4HDDQoHdYB9t0P8NvP0AOdmzJJjJSJXmNFElEEkywl8KBnjEoWqrdGI1LMT1aSX1/oBnVLDmZ6G5RiTbPYn97P9wzD+6ZG9oZOWr01YLXCWYre915wOT2BkI/y8oz8WOgK0WbeB51Fz+qCq//iKLXbqVC6aFCLnwiShKRBBNMROp7x6DsZDjnW7D2OzpHdQj//gL8ZC7Whv8AyGZ3USDYmXRH9wRYAv8e0bbqKjjMWLyMjmGtxB5ceiz0sywwT2S3v0q7Ido+N6NdMNaDXzFKDxEdSCKSYEKJSN8YWAvh7K/BrPN0juoQOrfBWDf7h7WPaHBYQOhnUWDlSWO/A29hoJrWsUXHiA6h5CRY8w1YejUdgd2CSzIlEdHb8kAi8tpYGWpSKvg9+gb0boEEttdShROLLN2NMElEEkwwEekbdTHkcOsczWFMDIU6qr46qs20nysVEd3lWS3kWy2oKnSmL9JubN+kb1DvVrAQ1twGy6+hfSiQiEhFRHc1eemkmo084T6Zhk/vg0t+rHdI0wUSkWDPIqmIRJYkIgkm3WKiMpDt7+60ayf9fU/Drsd0jmyKwJwVl7UcO+kU2Cxkppp1DkrA5DyRnQRavXds1sbXo4zT46NvNDg0IycVvRkMCtV5abhJonHAqXc4BwskIlu9lQBUSCISUZKIJKCFgZPJ7o4R7aT/yMfh5SjajKp9MwDdafMBmCs7YEaN4Lbo60YLwWiZVr3S3XCrllSP9tAV6B+SkmQkS1Y/RIXqwIq9hj6HdoPfr2M0U6hqaIjxTYe2xFiGZiJLEpEEtDiUiNih+CRAgeEWGOvTN7CgQLl/r1HrAyETVaNHMBHZ1TMxueoqkDjqbv9zWlL91E10TBmWkR2bo0OwO29Kw3Pwq1Xw7xt1jihgqAkmhvCbUtjhLSPJqFCUIcN5kSSJSAIKTjrc3WmHZBvkaSd8OqLghKKq0LYRgLdcwT4QkohEi1mBfUMa+xyoiz8Eq2+a/PzoLfC5ofRk2ofGAZmoGk2Ce0W1jXihvw7aN+ocUUB2NXy1nj3nPoAXE6VZqRgNkrxGkiQiCSh4VdsyMI59wgOlK7U7omHioWcCln4UtXw1/x3Q+kBIRSR6lGenYlBg3O2jb/4n4cLvTXbo1VswESlbFVoxI0t3o0ewIvKiPdBhdaAexgd1jGiK9Dx2mxYCMlFVD5KIJKCsNHPoAL2n0w4lwUQkCioi5lS46G76PvQkfRNgUCZX+gj9mU2G0OTPpn6HztFMMdoN9lZQDFCyYtrQjIgOwb2iWp3J+LKqtRsDO2xHg4bA1gWyy3fkSSKSoILDM3s6RiYrIh1bo2YPiNpAR9XK3DSSk4w6RyOmqgycUJr6HeAahcbXwd6ub1DBakj+ArBYaZceIlEnxWwM/XsMZQV2/9Z7ONg5An+5Al75Hk19I8Bk5UZEjiQiCWpx6ZR5InnzISkN3KPa2K2e2jeDa4y6Hi0RkUZm0ac6mIgMOODxz8JfLoe9/9Y3qOB8g9JVAKGKiCzdjS7BakNLsrYiTvfh4I7N0Pgq7HyE+n7tMyMVkciTRCRBhVY/dNjBaIKP/BW+tA3y5ukXlGsU/ng+/KCc1vY2QBqZRaOywBh62+D4ZDWt7R0dIwLaAie0spPx+vx0j2jLd2WOSHQJVhu2M0e7oW2TvlXYwOfGV7JK+zwDs6QiEnEmvQMQ+gg2pmrqdzDm8pIeDW3eO7aA6oeMcrb1a8MxMlE1+pQFTu5tgxNwxmnajS3rtRVPei2V/cBvtOGZqrPpHnHi86uYjQby0i36xCMOKVhteGe8hE8XLtEmOrvHIDlDn4AClbTejCX4VbAlm8izymcm0iQRSVC56RaKMpLpsjvZ1zXCqspsvUMKjfP7S1dRtyMwNCPNzKJOqCIyNA4lZ2uNzRy92tbuubP0CSq7WvsCOhoHACjOTMYgyzCjSmVgV9umQSfc8qa+wfj9oaGh3Ya5gI8FxTbpO6MDGZpJYMH+HMHZ4rzze3j4Gv0mHrZuAGAoeykur5/kJIMspYtCwURkeNzDqNcwOTzTsk7HqCbJHjPRK5iItAyO4/frvDVAXy047ZCUynpHEQALi3WqzCQ4SUQSWHDPmeYBbWyUnQ9D7X+g5e3IB+PzhBKRfRatY+fsfKs0FopC6RZTqG162+AEVASGZ1rX6xPQGz+Gt3+lLeEF2XU3ihVnJmMyKLi9frpGnODzaqv19NivqPkt7c+yU9jVpS1FD86dE5EliUgCqwhenQwE+kGUr9b+1OPKtnM7eByQks3miUJAJqpGs2nDM3p+bvw+WPdL+O83YbQLYEpXVammRRuTcbLK2dJrh5/Mhj+co89+Re4xsNjwlp/OznY7AEtKMyMfh5BEJJFV5r6rIlJxuvZniw5Xts2B8eLK09nfoyVGMlE1epVlTVk5U3YKXPRD+MjfI39l270LXHaw2KBQ603RGNhUrUqWYUalimAldsg9uUpPjyrsmbfA15vYVXo1Lq+fnDQzNfKZ0YUkIgmsckpFRFVVKD9Vu6N/f+Q3wFt4BVz8Y1j+CfYHeojIHjPRqzRbG/ZoH5oASzqcegMULYn8qplgeb3iNDBoK60aAx1fg/1ORHSZVokNDuvpkYgAGE2sb9eWeq+qzJaJqjqRRCSBlWZN2TdkzAWp2VpnSoj8eH92NZzyWZxV59HcLxWRaBesiASHQXQTTEQqzwBgeNzNoMMNSGOqaFU1tTNvhU7Deh5n6NuNTdp+NydXRcHKwQQliUgCM5sMoZUFLaHhmeAVij4rIOp7x/CrkJWaJOv5o9hkUzNtYiiuUdj6F/jv/0YuCL9v8ko6kIg0BIZlijKSSTVLd4JoFByaaRkIDOspRhhuiexqvcevh18sxVf7PFuahwBJRPQkiUiCCw7PBKsQVJ0NhiRtIlek7H8OtvwZ7O2hPWbmFlqlTBrFQk3Nhsa1YT2/D57+Mrx9b+ROKIecHyIbl0W7ySW8DvxJ6VCyQruj4ZXIBOD3a5W0oWaax82MurxYLSbmF8mKGb1IIpLgpl2dAMy+AG5rhvffF7kgNv4env4S1D4je8zEiJKsFJTAsN6gww0pmZO7OEfqhDJQD0bzYeaHSJvuaFWalYLJoOD0+Om0T0DNudod9S9HJoC+fTAxCEmpvDFWCsCKyixpFaAjqV0muFCnw+AS3qTkyAbgcYb6h1B5BrV7pKNqLLCYjBRYk+kecdI2NEFOukU7obRv1E4oJ30i/EEs/hDMuxTGB0M3SUUk+pmMBmblp1PbPcrezhFK518GigHmXBCZABpf1/4sP5V3WrTjjQzL6EsqIgnuoF4iU7kPcdtMa10PnnFIL4T8Bezv1rbilh4i0a8sO7jnTKCaFtyvqPG1yG1klpQCGSWhH4NLd6tl47KoFuxguqdzBAoXwZrboHh5ZF68/iUA1Jpz2dQcmKgaDVtcJDBJRBJcsLtqS39grB/A3gG/Owt+tjD8J5TAQYFZaxme8NAz4gJgToGcSKJdqJdIcOVM8UlgyQDnsNagLpwO8bn0+vyhIUZZuhvdFpVoFc89nfbIvrBnIjQRvzX7dAYcbiwmA4tLpbW7niQRSXBl2akoCoy6vKFlj6QXwGAzTAxB57bwBhAcF551HvsDE1VLMlOwJieF93XFCSt998oZowmqz9K+bwjzeP9//xd+czrseTJ0U/vQBG6fH4vJIO3do9y0igho1dc9T8JbPwvvCzevA68TbCWsG84BYHl5JhaTMbyvK45IEpEEl5xkpMimzQsJdViddkIJ48RDe7s2cUwxQPWaUCMz6R8SG4IrZ6b1Eqk5D1DA3hbeF69/CXp2T7upsV+bH1KVmya77ka5+UXa//Euu5OBMRc4+uDRT8LL/w+cI+F7YVsRrPoMLP84G4PDMlU54Xs9cVQkERGHnidSExjvDw6dhEP3Lq2HQMlKSM1mX9fk0l0R/YJ7hjT1T/ncLLoSvlYPl/8yfC881KJ1/1WMUL0mdHNwfkiNzA+JetbkpFBjsz2dI5BVCdk1oPqg6fXwvXDBQrj0Hnxn38G6hgFA5odEA0lExOSeM1NPKLPP1/5s2xi+du9zL9ZOWpf9AoANjdqBYWlZZnheT8yo2YEl1u1DE4y5vNqNyTZIyw3vC+9/Vvuz/FRt2XBAQ2iiqswPiQULioPzRAIVkNmBVTP7nwv7a7/TOEDfqIuMlCRZMRMFJBERzM7XTih7AxUJADJKoWgZoE4e+MMhNRsKFtA6ME5TvwOTQeG0GimVxoLsNHOo++2BntGDH+CZCM8L1z6j/TnvfdNulqW7sWVhIBHZHZywOu9S7c/9z4HPO/Mv2PiaNkfE7+Pf2zsBuGRxIWaTnAb1Jv8CgiWBGeM724en3zE/cKAPHvhn0rtWPTy9UzswnFSRJRNVY0hwPk9wojEAjgF48H1wz9xpe3rMiPHBye0H5l0y7S5pZhZbFgUmrO4NVkTKV0NKttZsLBx7Xb38XXjwEjxb/sJzu7sAuGxp8cy/jjhmkogIFhZnYFCgd9RFz8iUE8e8y2DBFbDsYzP/ok9+Hv54ATS9yYjTw/1vNgLw0VVlM/9aImyCOyTXTk1EUrJgoAGc9pkf7697HlQ/FCzW5hUEjDo99I1qS7+lIhIbghWRpn4Ho06PNkl+7sXanbX/mdkXG+mEji2AwgbjKkacXvKtFk6RiapRQRIRQYrZGDqhvNM02aWS/Hnw4T/Dwitm9gU9Tq382vYOGM3c88J+hsY9VOelcblcocSUYD+IHVOraQbDZJl9779n9gXz5sGSj8CSq6bdHJyomme1SEUtRuSkWyjO0FbsBSeqh4bbhmd41dW+p7U/S1fxfIvWL+nChYXS1j1KSCIiADhvfj4ATwXGTsOq7nlwjYCtlJ6Mxfz9nVYA/t/7F2EyykcyliwrywK0CYdur3/yjoUf0P7c9/TMDs+UnAQf/D2c/uVpNweX7kojs9gSbCS2rVXbAZeac+GmzXD1P2b2hXb+EwB14Qd4bb82+f6ceXkz+xriuMlRXwBwxTKtTfZr+3unD8+AVmZ/7Qfa2P9M2PWo9ufiD/GPje14/SorK7I4fVaYV1uIGVeZk0pmahJur599XVP6P5SvBluplnDWPR/2OKS1e2xaWaGtWNncEkhEkpIhd/bMvshAA3RsBsVAe8nFdAxPYDYaOLVahmWihSQiAtCWYq6qzMLrV/nTuqbpdz56Lbx2N+x5/MRfaGIIDvxX+37Jh3m5tgeAq08uP/HnFhGnKArLAsutt7cNT95hMGib0kHoavSEvfN76NoJwa0IpmgIrJipkfkhMWVlpVZR29w8OLnFRJDTDl73ib/Irse0P6vXsHXQDGhLh1PNsudrtJBERIR89qwaAP65qW16mX3JR7Q/dz5y4i+y5wnwuSF/IXbbnFAPgTNnSzUkVh0yEYHJz82B/554NW2wEZ77mrYH0ljvQXc3Sg+RmLSwOIOUJCND457JfiIAz34dfjwb6magp0jnVu3PxR8OfUaXSa+iqCKJiAg5d14++VYLQ+MeXqmdcrBffBUYTNC+SbsiPV6qCpv+qH2/7GNsahpEVbWTR36gzbyIPYdNRAoWwLKPw+X3gvkEE4TND2h/1pwL1oJpd/n9aqi7q3RVjS1mk4E1c7W5Gv/Z2TXljlTwuWDzn078Ra5+GD75H5h/GTskEYlKkoiIEKNB4QPLtbki/9raPnmHtQDmX6Z9v/mPJ/Yia27XOiguvya00mJlRdaJPafQVfCg3tTvYHj8XaX0K+7Tln8nnUCi6XHCtr9p3598/UF3dwxP4PL6MRsNlAZ2BBax431LtJVyT27rwOUN9BdacR2gaE3I+g+c2AsoClSdiWpOC/W7CS4dFtFBEhExzZUrSgF4tbZX24wqaFXgBLDzn9rY7fFQFC2hueZRSMkKTW5cUCQHhViWmWoO7RtyUFVkJux9UmtylVE22QZ8imAjs4qcVFmOGYPOm59PoS2Z7hEnD65r1m7MqoA5F2nfH29VxDkC7skNGXtGXDjcPowGJbS/logOYUtEmpub+fSnP01VVRUpKSnU1NRw11134XbPwOQjETZzCqwsLsnA61d5dnf35B0Vp0H+AvCMTw6vnKBg74AFgQ6LInYddngGtIrGO7+Dfx1czXhPfj+8HdhAb8W1YDh4u/bdHVpiHOyFI2JLcpKRL52nrZT50Qv7eW1/YFh41We0P7f+Veuoe6xe/yH8dF4okQluAVCenSpt3aNM2P41amtr8fv9/O53v2PPnj387Gc/47e//S3f+MY3wvWSYoZcuqQIgBemJiKKovVuMKdr3x+rF++EV++GiWEAhsfddAxre5HMK5ITSKw7YiLi6IMXvgm7/qnt9XEsav8DPbvBYoNVnz7kQ4KbJcrmZbHr6pPL+OBJJfj8Kjf9Yxv9Yy5tPlDBYnCPwoZfH9sTjvVqF0xOO2RoK/JkZVX0ClsictFFF/HAAw9wwQUXUF1dzeWXX85Xv/pVHn98BpaAirC6aGEhAOsbB7BPeCbvWPQh+PJOOOMrx/aEw22w/tfw+g+gdy8wWQ0pzUrBJp0wY96KiuAyzCE8Pv/0OzPLYPnHte9f/8GxPbHXCam5cMrntNbx7+L2+tncrPWgkL4QsUtRFH7wwSUsLLYx5vLyj3datSXga27THrDt7+DzHPlJpnr7XvBOQMkKmHUeMHV3ZpnQHG0iWp+y2+1kZx/+qsXlcjEyMjLtS0ReZW4aVblp+PwqG6e2fDeaIO04DvYv3gl+D1SeqQ3xgMwPiTMLimxkp5kZc3nZ1jp88APOvAUMSdD0BtQew27OSz4MN+88qJNq0GNb2pnw+Mi3WpidLyeYWGY2GfjsWdUAPLyxVesrMvdSuPBu+Pw6MB7lBctAg9ZzBuDs20MV3GBFRLrvRp+IJSL19fX88pe/5HOf+9xhH3P33XeTkZER+iorkw3Q9BK8ulzfcJj+D01vwIt3vfcTHXhRa4SmGODC74Vu3htIROZLIhIXDAaFMwKdcUNj/FNllsPqL2jfP/tVcI0e/JjDMaeB5eDhO/uEh5+9VAfA59fUYJCJqjHvwoWFWEwGOu1ODvSOaVWR1V+A1KMcdlNV+M9XtKW/NefC7PNDdwV7zdRIwhp1jjkRuf3221EU5YhftbW1036no6ODiy66iKuuuorrrz/8hLU77rgDu90e+mprm+GNj8RRW12jJSLB8fdphtvgL1fAup9Pdi08lLFeePpm7ftTvwBFS0N37ZNEJO4E9yt6bnf3wV0yQbs6zayAkQ547vZDdkgFtAmqT30Rdj9++McAP3+pjr5RF9W5aXzsFOnMGw+Sk4yhuT5v1PVNv1NVtYmnR1q1t/EP2o7PpmS49J5QNWTC7QvNSZOKSPQ55kTk1ltvZd++fUf8qq6uDj2+s7OTc845h9NOO43f//73R3xui8WCzWab9iX0cWq1djDY1z1ycG+IzLLJUvmTX4C2jQc/gWcCHroaRtohuwbW3DF5l8/PgR6tTCrr+ePH2vkFJCcZaOp3sKvjECcLc6rW3EwxwO5/aSX0Q3npLtj6F3jiBhioP+RD7OMeHt6oXajcdflCLKaDV9OI2HTWbK3B2UHV2Bfv1Kodj157+Pkiqg9Q4Nz/hezJ81Cw4V1mahLZaeYwRC1OxDE328/LyyMv7+h2Lezo6OCcc85hxYoVPPDAAxgMsmQqVuRbk6nJS6Ohz8GGxkEuWlQ4/QHnfgv6amH/s/DXD8Llv4CFH5xcUTPWC0NNkJyp9Q2xTJZDG/rGcPv8WC0mSrNSIveXEmGVZjFx/oJCnt7RyUMbW1lSmnnwg6rXwGW/gIJFkDtr+n2uUW24L9g07/33HXYDtP/s6mTC42NugZWzZHuAuLIqUBHZ0jqE369ODrkt+iBsuh8aXoF/fBgu/xVklGgVtOC55dTPaxsuTqm+wvT5IcrxrPoTYRW2zKCjo4M1a9ZQXl7OT37yE/r6+uju7qa7u/u9f1lEhSMOzxiM8ME/aBNQ3aPw2Kfg50ug8XXt/qwKuPoRrb1yTs20Xw0Oy8wrsspBIc78z6kVADyxrePgSlrQSZ+AkpMmf37th/CHc+GeeZNJyAXfgyVXHfZ13jrQD8D7lhTJZyjOLCy2kZxkYHjcQ2P/2OQdxcvhw3+BpFQtGfnFUvjd2fCzBdC1Y8rjlh3UYmB3p1ahm1soFdhoFLZE5MUXX6S+vp6XX36Z0tJSioqKQl8iNqyq1K5Mth2uW6YlHT7+uDb2b04HeyuM90/eX7YKKlYf9Gt7O2V+SLxaVZnFvEIrTo+ff24+ijle7nGtR0THFnCPQc5s+Pi/4LSbDvsrPr/K+kByfNosqYbEmySjgaWBalpwaXbI7PPhMy9DxenaSryu7TDa9Z7dV3e1a4nI0lJpnhiNwrYP8rXXXsu1114brqcXEbC8TOvbsLfTjtPjIznpEOPwJjOcc4d24ujYop1I3sNeWbobtxRF4drTKrn98V08vKkttKPzYZksWjI72gUZpVC4ZLLMfhj1vWMMj3tIMxvlxBKnVlZm8U7TIJtbhvjoye+aiFywAK57Vptj1FcLyRlQfNKhnwhtU8RgInLI4UKhO5m0IQ6rLDuF3HQzHp/Kns732F/GYtXG/zNKjvgwVVXZ3aElIotK5CQSjy5dUoTJoNDY56BlwHHkBxuMULoC5r9PK6kfxTyyvV3aZ3FBsQ2TUQ5h8WhlRWCeSMvQ4R+UUwPzLoXKM7SJ0Iexp3OEUZcXi8nA7AJZuhuN5H+xOCxFUUIl0mDycKLahyawT3hIMipyUIhT1uSkUKfV1/b3vcejj11waE8qavHrpHLt89PU79DavZ+Ax7dpO4mvnV9AkiSuUUn+VcQRBedxBCeYnqg9gZPInAKrLLmMY2fN0VbWTevMO0OC2wPIHKP4lZGaxJzAhcoRqyJHYJ/w8I93WrV28cCVK45crRX6CdscEREfZj4R0crqi2TH3bi2ODDsNlOfmyBVVSfnGEkPmri2oiKbup4xtrQMceHCQlxeH39+u5nHtrRjMRn5zvsXhion7/bv7R1868ndjDq9AJw3L581c/IjGb44BpKIiCOaH9gZd3/PKD6/ivEE22gHt2xfVCInkXgWTGCbBhyMu72kmmfmUNM76mLQ4cagaFU1Eb9WVmTx0MZW3mkcYHjczXUPbpq2j9H1f97MW7edS4p5srLq9Pi44/FdPLGtA9B22v3QijKuO71StgCIYjI0I46oIieNlCQjTo8/1J3wROwODM0slImqcS3PaiHPakFVobb7GPaVeQ/BakhNXvqhV3GJuHHarBxMBoUd7XaWffdFtrUOY0s28a1L55OZmsSAwx1KOIJ+/VoDT2zrwKDAzWtn88LNZ/H5NTXyWYlykoiIIzIaFOYFqiJ7T7DM3jPipG/UhUGB+dJYKO4tmOFhPZAeNImkKCOFL6yZXP6dZ7Xw6A2n8Zkzq7npHK0r7yNTetXYxz088FYTAD/98DJuXjtHVlXFCPlXEu9ppuaJBCcuzi20TSunivgU/NwEk4eZEBzak/khieEr58/h/k+s5O4PLualW85mbqF2UXT5smIMCuxoG6Z1YByA+99qZNTlZV6hlcuXFusZtjhGkoiI9zRTicjbDVrX1dMCreNFfAvOL5qpiojfr/JOIJldVXnoSYoiviiKwtoFBVx9cjkZKUmh2/OtyaEtKJ7e2cnwuJsH1jUD2pCMzAeJLTJZVbyn4A65u9rtqKp6THt7vF3fT8+ok4sXFfFmYH+Q02dJIpIIgp+b2u7R6ZuXHae63lEGHW5SkowsLsmcgQhFLLt8aTHr6gd4ekcn424vYy4v84tsXLCg8L1/WUQVSUTEe1pYbMNsMjDgcNPU76A67+gakf36tXp+9Px+AL7yiLYpldVi4pQqSUQSQWVOGhaTgXG3j5bBcapy007o+V6p7QW09t9mkxRzE91FC4v41pO7qe0eDU2IlmpIbJL/zeI9WUxGlk3ZhMrnV3lsSzs/e7GOEafnkL8z6HDzy5frD7r9oyeXkWaR/DcRmIwG5gXG9I9nnoiqqtO+f2yz1iHzsiUy/i+0pmcfXlkW+nlBkY0LFhToGJE4XnJGEEdlVVUWG5sHea2ul10ddv66oQWA1+r6eOyG1Qe1Tn50cxsTHh+LSzK49+rl3PdqPSaDwhfWzNIjfKGT+UU2drTb2dc1wqVLjm7nbVVV+f6z+/jjW02srMjmY6eU83ZDP439DlLNRi45yucR8e/rF87jQO8YFpOB71y+8JiGjUX0kEREHJVLFhdx36sNPLure9rtO9qGeW5390Gz1INl9KtWllKVm8ZPrloasVhF9AiubjmWCavP7e7mD29qyzA3Ng+ysXmyTfw3L51PulTUREBGahL//NxqvcMQJ0j+R4ujsrA4g0UlttDmd9edXklmipmfvVTHg+uapiUiI05PaH8Iaauc2IK9RHa0Dx/1hNV/BnpDXLyokBSzkdquUeYUpHPJ4iIuWCgTEYWIN5KIiKN270eX8/1n95FkNHDbRfMYcXr4xct1bG3V1vKX52hbca870I/Xr1Kdmxa6TSSmJaWZpJqN9I+52dc9wqDDzau1fSwvz+R9S4oOKqUPj7t5K7C66qsXzqXmKCdGCyFilyQi4qhV56Vz/ydXhX5OTjJyWk0ub9X38/TOTm4MdDsMbv2+Zq5UQxKd2WRgdXUOL9f2cum9b03esQ46hie44eyaaY/f0jKE169Sk5cmSYgQCUJWzYgTcvkybUjmn5vb8PtVfH6V1+q0+SFr5ubpGZqIEhcumj6cEuwv8tP/1tE2OD7tvh3tWufUpWWZEYlNCKE/SUTECXnfkiKsySZaBsZ5ra6X9Q0D9Iy4sCWbOLkqW+/wRBT40EmlXH9mFUUZyfzqY8v5zxfP4PRZObh9fn75yoFpj93VPgzA0sBycSFE/JNERJyQVLOJj67S1vL/9MU6/ry+GdAqJbLjpQAwGBS+eekC1t9xHu9bUoyiKNx6wVwA/rW1g+bArs6qqrIzUBFZUiq7MwuRKCQRESfshrNrSLeY2N0xwot7ezAo8D+nVuodlohiJ5Vncc7cPHx+ld+81gBoc0YGHG5MBkV21xUigUgiIk5YTrqF731gUejn68+qDu2SKcThfCEwufnfOzqwT3jYFaiGzC20SjVNiAQiq2bEjHj/shLKslNRgGUy0VAchZUVWcwtsLK/Z5THt7bTM+ICtCW/QojEIRURMWNOKs9ieXmWtFkWR0VRFD5+ajkAf3+nldf2a6utlksiK0RCkURECKGbK5aXkGo2Ut87Rm33KGaTgQule6oQCUUSESGEbqzJSXz9wrmhny9dXERGapKOEQkhIk3miAghdPXJ0ypJT07C7fVz2VLZWVeIRCOJiBBCV4qi8KEVpXqHIYTQiQzNCCGEEEI3kogIIYQQQjeSiAghhBBCN5KICCGEEEI3kogIIYQQQjeSiAghhBBCN5KICCGEEEI3kogIIYQQQjeSiAghhBBCN5KICCGEEEI3kogIIYQQQjeSiAghhBBCN5KICCGEEEI3Ub37rqqqAIyMjOgciRBCCCGOVvC8HTyPH0lUJyKjo6MAlJWV6RyJEEIIIY7V6OgoGRkZR3yMoh5NuqITv99PZ2cnVqsVRVFm9LlHRkYoKyujra0Nm802o88db+S9OnryXh0beb+OnrxXR0/eq6MXrvdKVVVGR0cpLi7GYDjyLJCorogYDAZKS0vD+ho2m00+qEdJ3qujJ+/VsZH36+jJe3X05L06euF4r96rEhIkk1WFEEIIoRtJRIQQQgihm4RNRCwWC3fddRcWi0XvUKKevFdHT96rYyPv19GT9+royXt19KLhvYrqyapCCCGEiG8JWxERQgghhP4kERFCCCGEbiQREUIIIYRuJBERQgghhG4SMhG57777qKysJDk5mVNOOYWNGzfqHVLEvfHGG1x22WUUFxejKApPPvnktPtVVeXOO++kqKiIlJQU1q5dy4EDB6Y9ZnBwkGuuuQabzUZmZiaf/vSnGRsbi+DfIjLuvvtuVq1ahdVqJT8/nyuuuIL9+/dPe4zT6eTGG28kJyeH9PR0rrzySnp6eqY9prW1lUsvvZTU1FTy8/P52te+htfrjeRfJSJ+85vfsGTJklCDpNWrV/Pcc8+F7pf36tB+8IMfoCgKN998c+g2ea8mffvb30ZRlGlf8+bNC90v79V0HR0dfPzjHycnJ4eUlBQWL17M5s2bQ/dH1TFeTTAPP/ywajab1T/96U/qnj171Ouvv17NzMxUe3p69A4top599ln1m9/8pvr444+rgPrEE09Mu/8HP/iBmpGRoT755JPqjh071Msvv1ytqqpSJyYmQo+56KKL1KVLl6obNmxQ33zzTXXWrFnq1VdfHeG/SfhdeOGF6gMPPKDu3r1b3b59u3rJJZeo5eXl6tjYWOgxN9xwg1pWVqa+/PLL6ubNm9VTTz1VPe2000L3e71eddGiReratWvVbdu2qc8++6yam5ur3nHHHXr8lcLqqaeeUp955hm1rq5O3b9/v/qNb3xDTUpKUnfv3q2qqrxXh7Jx40a1srJSXbJkifrlL385dLu8V5PuuusudeHChWpXV1foq6+vL3S/vFeTBgcH1YqKCvXaa69V33nnHbWxsVF94YUX1Pr6+tBjoukYn3CJyMknn6zeeOONoZ99Pp9aXFys3n333TpGpa93JyJ+v18tLCxUf/zjH4duGx4eVi0Wi/rQQw+pqqqqe/fuVQF106ZNocc899xzqqIoakdHR8Ri10Nvb68KqK+//rqqqtp7k5SUpD766KOhx+zbt08F1PXr16uqqiV+BoNB7e7uDj3mN7/5jWqz2VSXyxXZv4AOsrKy1Pvvv1/eq0MYHR1VZ8+erb744ovq2WefHUpE5L2a7q677lKXLl16yPvkvZrutttuU88444zD3h9tx/iEGppxu91s2bKFtWvXhm4zGAysXbuW9evX6xhZdGlqaqK7u3va+5SRkcEpp5wSep/Wr19PZmYmK1euDD1m7dq1GAwG3nnnnYjHHEl2ux2A7OxsALZs2YLH45n2fs2bN4/y8vJp79fixYspKCgIPebCCy9kZGSEPXv2RDD6yPL5fDz88MM4HA5Wr14t79Uh3HjjjVx66aXT3hOQz9WhHDhwgOLiYqqrq7nmmmtobW0F5L16t6eeeoqVK1dy1VVX8f/bu7uQpvo4DuBf6XSWIrZiuo3CIWQvIsWaNIZ0tQi8iq4kuhh1EVpSgTfedFneBdWFURcZFEgEEnVhidOBQUa24SSwt/VykY0Ka1H0dr5dhHs86iPPRXXOo98PDMb5/xm/fTn782M7/7OqqiqEw2GcP3++OO62NX5JNSJv3rzBjx8/bCciAPj9fkxOTjpUlftMZ7FQTpOTk6iqqrKNG4aB1atXL+osLcvC0aNH0djYiPr6egC/sjBNE16v1zZ3dl7z5Tk9tthks1mUl5fD4/GgpaUFvb29qKurU1az9PT04P79++js7JwzpqzsotEouru70dfXh66uLuRyOWzfvh2FQkFZzfL06VN0dXWhtrYWN2/eRGtrKw4fPoyLFy8CcN8a7+p/3xVxm0OHDmF8fBzDw8NOl+JqGzZsQCaTwfv373H16lUkEgmkUimny3KVly9f4siRI+jv78eKFSucLsf1mpqais83b96MaDSKUCiEK1euoLS01MHK3MeyLDQ0NODEiRMAgHA4jPHxcZw9exaJRMLh6uZaUt+I+Hw+LFu2bM6V1K9fv0YgEHCoKveZzmKhnAKBAPL5vG38+/fvePfu3aLNsq2tDTdu3MDg4CDWrl1bPB4IBPD161dMTU3Z5s/Oa748p8cWG9M0sW7dOkQiEXR2dmLLli04deqUspphdHQU+XweW7duhWEYMAwDqVQKp0+fhmEY8Pv9ymoBXq8X69evx+PHj3VezRIMBlFXV2c7tmnTpuJPWW5b45dUI2KaJiKRCAYGBorHLMvCwMAAYrGYg5W5S01NDQKBgC2nDx8+YGRkpJhTLBbD1NQURkdHi3OSySQsy0I0Gv3rNf9JJNHW1obe3l4kk0nU1NTYxiORCJYvX27La2JiAi9evLDllc1mbR/s/v5+VFRUzFkwFiPLsvDlyxdlNUM8Hkc2m0Umkyk+GhoasHfv3uJzZfXvPn78iCdPniAYDOq8mqWxsXHOLQYePnyIUCgEwIVr/G+99PV/oKenhx6Ph93d3Xzw4AEPHDhAr9dru5J6KSgUCkyn00yn0wTAkydPMp1O8/nz5yR/be3yer28du0ax8bGuGvXrnm3doXDYY6MjHB4eJi1tbWLcvtua2srV65cyaGhIdvWwU+fPhXntLS0sLq6mslkkvfu3WMsFmMsFiuOT28d3LlzJzOZDPv6+lhZWbkotw52dHQwlUoxl8txbGyMHR0dLCkp4a1bt0gqq4XM3DVDKquZ2tvbOTQ0xFwux9u3b3PHjh30+XzM5/MkldVMd+/epWEYPH78OB89esTLly+zrKyMly5dKs5x0xq/5BoRkjxz5gyrq6tpmia3bdvGO3fuOF3SXzc4OEgAcx6JRILkr+1dx44do9/vp8fjYTwe58TEhO013r59yz179rC8vJwVFRXct28fC4WCA+/mz5ovJwC8cOFCcc7nz5958OBBrlq1imVlZdy9ezdfvXple51nz56xqamJpaWl9Pl8bG9v57dv3/7yu/nz9u/fz1AoRNM0WVlZyXg8XmxCSGW1kNmNiLL6R3NzM4PBIE3T5Jo1a9jc3Gy7L4aysrt+/Trr6+vp8Xi4ceNGnjt3zjbupjW+hCR/73csIiIiIv/NkrpGRERERNxFjYiIiIg4Ro2IiIiIOEaNiIiIiDhGjYiIiIg4Ro2IiIiIOEaNiIiIiDhGjYiIiIg4Ro2IiIiIOEaNiIiIiDhGjYiIiIg4Ro2IiIiIOOYn6ciSc0iyHlkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z[2])\n",
    "plt.plot(b[2],\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 600, 600)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=23\n",
    "\n",
    "plt.plot(z[n])\n",
    "plt.plot(b[n],\"--\")\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(2):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(series_aux[n][i])\n",
    "    plt.subplot(2,2,i+3)\n",
    "    plt.imshow(prior_aux[n][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 600, 600)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 600, 600])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 600)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assdis=association_discrepancy(y[1],y[2]).cpu().detach().numpy()\n",
    "assdis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    return (x-x.min())/(x.max()-x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd08f287e90>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assdis=association_discrepancy(y[1],y[2]).cpu().detach().numpy()\n",
    "plt.plot(minmax(assdis[1]))\n",
    "plt.plot(minmax(z[n]))\n",
    "plt.plot(minmax(b[n]),\"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer entrenamiento, segunda parte\n",
    "Ahora en lugar de la reconstrucción de la misma señal, va a ser la reconstruccion de la señal flipeada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model import AnomalyTransformer\n",
    "import gc\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinne(lenght=100,amp=1,sf=0.1,f=2,phase=0):\n",
    "    x = torch.arange(0,lenght*sf, sf)\n",
    "    return amp*torch.sin(x*sf*2*torch.pi/f+phase)\n",
    "\n",
    "\n",
    "class DataFlip(Dataset):\n",
    "    #esta es la clase de los datos que seran secuencias de senos de freq aleatoria \n",
    "    def __init__(self,lenght,num_samples,amp_random=True,freq_random=True,phase_random=True,sf=0.1):\n",
    "        super().__init__()\n",
    "        self.amp_random=amp_random\n",
    "        self.freq_random=freq_random\n",
    "        self.phase_random=phase_random\n",
    "        self.num_samples=num_samples\n",
    "        self.sf=0.1\n",
    "        self.lenght=lenght\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        amp=float(np.random.randint(1,300,1)*0.01)\n",
    "        phase=np.random.randint(0,100,1)*0.02\n",
    "        f=np.random.randint(1,200,1)*0.01\n",
    "        y=sinne(lenght=self.lenght,amp=amp,sf=0.1,f=f,phase=phase)\n",
    "        y=y.unsqueeze(-1)\n",
    "        return y, y.flip(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=600\n",
    "dataflip=DataFlip(win_size,4000)\n",
    "\n",
    "dataloader=DataLoader(dataflip,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnomalyTransformer(\n",
       "  (embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (inner_attention): AnomalyAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (sigma_projection): Linear(in_features=32, out_features=2, bias=True)\n",
       "          (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo=AnomalyTransformer.AnomalyTransformer(win_size, 1, 1, d_model=32, n_heads=2, e_layers=2, d_ff=32,\n",
    "                          dropout=0.0, activation='gelu', output_attention=True)\n",
    "modelo.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [1/125], Loss_min: 1.3865, Loss_max: 1.3865\n",
      "tensor(2.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [2/125], Loss_min: 2.0922, Loss_max: 2.0922\n",
      "tensor(1.5530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [3/125], Loss_min: 1.5530, Loss_max: 1.5530\n",
      "tensor(1.7077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [4/125], Loss_min: 1.7077, Loss_max: 1.7077\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [5/125], Loss_min: 1.3634, Loss_max: 1.3634\n",
      "tensor(1.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [6/125], Loss_min: 1.5311, Loss_max: 1.5311\n",
      "tensor(1.4956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [7/125], Loss_min: 1.4956, Loss_max: 1.4956\n",
      "tensor(1.7724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [8/125], Loss_min: 1.7724, Loss_max: 1.7724\n",
      "tensor(1.1767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [9/125], Loss_min: 1.1767, Loss_max: 1.1767\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [10/125], Loss_min: 0.9677, Loss_max: 0.9677\n",
      "tensor(1.5189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [11/125], Loss_min: 1.5189, Loss_max: 1.5189\n",
      "tensor(1.4749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.2956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [12/125], Loss_min: 1.4749, Loss_max: 1.4749\n",
      "tensor(2.2714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.2714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [13/125], Loss_min: 2.2714, Loss_max: 2.2714\n",
      "tensor(1.3592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [14/125], Loss_min: 1.3592, Loss_max: 1.3592\n",
      "tensor(1.4405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [15/125], Loss_min: 1.4405, Loss_max: 1.4405\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [16/125], Loss_min: 1.6105, Loss_max: 1.6105\n",
      "tensor(1.3151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [17/125], Loss_min: 1.3151, Loss_max: 1.3151\n",
      "tensor(1.7274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [18/125], Loss_min: 1.7274, Loss_max: 1.7274\n",
      "tensor(1.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [19/125], Loss_min: 1.9712, Loss_max: 1.9712\n",
      "tensor(1.2514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [20/125], Loss_min: 1.2514, Loss_max: 1.2514\n",
      "tensor(1.5273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [21/125], Loss_min: 1.5273, Loss_max: 1.5273\n",
      "tensor(1.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [22/125], Loss_min: 1.7615, Loss_max: 1.7615\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [23/125], Loss_min: 1.5990, Loss_max: 1.5990\n",
      "tensor(1.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [24/125], Loss_min: 1.9682, Loss_max: 1.9682\n",
      "tensor(1.2703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [25/125], Loss_min: 1.2703, Loss_max: 1.2703\n",
      "tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [26/125], Loss_min: 0.9822, Loss_max: 0.9822\n",
      "tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [27/125], Loss_min: 1.4507, Loss_max: 1.4507\n",
      "tensor(1.2721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [28/125], Loss_min: 1.2721, Loss_max: 1.2721\n",
      "tensor(1.6501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [29/125], Loss_min: 1.6501, Loss_max: 1.6501\n",
      "tensor(1.3760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [30/125], Loss_min: 1.3760, Loss_max: 1.3760\n",
      "tensor(1.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [31/125], Loss_min: 1.6994, Loss_max: 1.6994\n",
      "tensor(1.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [32/125], Loss_min: 1.0024, Loss_max: 1.0024\n",
      "tensor(1.4207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [33/125], Loss_min: 1.4207, Loss_max: 1.4207\n",
      "tensor(1.6489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [34/125], Loss_min: 1.6489, Loss_max: 1.6489\n",
      "tensor(1.2534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [35/125], Loss_min: 1.2534, Loss_max: 1.2534\n",
      "tensor(1.3767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [36/125], Loss_min: 1.3767, Loss_max: 1.3767\n",
      "tensor(1.6926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [37/125], Loss_min: 1.6926, Loss_max: 1.6926\n",
      "tensor(1.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [38/125], Loss_min: 1.8845, Loss_max: 1.8845\n",
      "tensor(1.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [39/125], Loss_min: 1.7916, Loss_max: 1.7916\n",
      "tensor(1.5887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [40/125], Loss_min: 1.5887, Loss_max: 1.5887\n",
      "tensor(1.4600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [41/125], Loss_min: 1.4600, Loss_max: 1.4600\n",
      "tensor(1.5764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [42/125], Loss_min: 1.5764, Loss_max: 1.5764\n",
      "tensor(1.6296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [43/125], Loss_min: 1.6296, Loss_max: 1.6296\n",
      "tensor(1.3926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [44/125], Loss_min: 1.3926, Loss_max: 1.3926\n",
      "tensor(1.4087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [45/125], Loss_min: 1.4087, Loss_max: 1.4087\n",
      "tensor(1.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [46/125], Loss_min: 1.0424, Loss_max: 1.0424\n",
      "tensor(1.9822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [47/125], Loss_min: 1.9822, Loss_max: 1.9822\n",
      "tensor(1.4868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [48/125], Loss_min: 1.4868, Loss_max: 1.4868\n",
      "tensor(1.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [49/125], Loss_min: 1.7350, Loss_max: 1.7350\n",
      "tensor(1.4377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [50/125], Loss_min: 1.4377, Loss_max: 1.4377\n",
      "tensor(1.4979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [51/125], Loss_min: 1.4979, Loss_max: 1.4979\n",
      "tensor(1.7182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [52/125], Loss_min: 1.7182, Loss_max: 1.7182\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [53/125], Loss_min: 1.6397, Loss_max: 1.6397\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [54/125], Loss_min: 1.1394, Loss_max: 1.1394\n",
      "tensor(1.7335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [55/125], Loss_min: 1.7335, Loss_max: 1.7335\n",
      "tensor(1.2900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [56/125], Loss_min: 1.2900, Loss_max: 1.2900\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [57/125], Loss_min: 1.1268, Loss_max: 1.1268\n",
      "tensor(1.3385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [58/125], Loss_min: 1.3385, Loss_max: 1.3385\n",
      "tensor(1.3136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [59/125], Loss_min: 1.3136, Loss_max: 1.3136\n",
      "tensor(1.3069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [60/125], Loss_min: 1.3069, Loss_max: 1.3069\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [61/125], Loss_min: 1.3433, Loss_max: 1.3433\n",
      "tensor(1.4441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [62/125], Loss_min: 1.4441, Loss_max: 1.4441\n",
      "tensor(1.4037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [63/125], Loss_min: 1.4037, Loss_max: 1.4037\n",
      "tensor(1.2930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [64/125], Loss_min: 1.2930, Loss_max: 1.2930\n",
      "tensor(1.3746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [65/125], Loss_min: 1.3746, Loss_max: 1.3746\n",
      "tensor(1.5234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [66/125], Loss_min: 1.5234, Loss_max: 1.5234\n",
      "tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [67/125], Loss_min: 0.9973, Loss_max: 0.9973\n",
      "tensor(1.2888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [68/125], Loss_min: 1.2888, Loss_max: 1.2888\n",
      "tensor(1.5477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [69/125], Loss_min: 1.5477, Loss_max: 1.5477\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [70/125], Loss_min: 1.6055, Loss_max: 1.6055\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [71/125], Loss_min: 1.6189, Loss_max: 1.6189\n",
      "tensor(1.3080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [72/125], Loss_min: 1.3080, Loss_max: 1.3080\n",
      "tensor(1.8319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [73/125], Loss_min: 1.8319, Loss_max: 1.8319\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [74/125], Loss_min: 1.6151, Loss_max: 1.6151\n",
      "tensor(1.2204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [75/125], Loss_min: 1.2204, Loss_max: 1.2204\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [76/125], Loss_min: 1.1214, Loss_max: 1.1214\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [77/125], Loss_min: 1.1481, Loss_max: 1.1481\n",
      "tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [78/125], Loss_min: 1.4402, Loss_max: 1.4402\n",
      "tensor(1.3679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [79/125], Loss_min: 1.3679, Loss_max: 1.3679\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [80/125], Loss_min: 1.1779, Loss_max: 1.1779\n",
      "tensor(1.2687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [81/125], Loss_min: 1.2687, Loss_max: 1.2687\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [82/125], Loss_min: 1.1313, Loss_max: 1.1313\n",
      "tensor(1.4316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [83/125], Loss_min: 1.4316, Loss_max: 1.4316\n",
      "tensor(1.3995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [84/125], Loss_min: 1.3995, Loss_max: 1.3995\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [85/125], Loss_min: 0.9373, Loss_max: 0.9373\n",
      "tensor(1.4171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [86/125], Loss_min: 1.4171, Loss_max: 1.4171\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [87/125], Loss_min: 1.6236, Loss_max: 1.6236\n",
      "tensor(1.3593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [88/125], Loss_min: 1.3593, Loss_max: 1.3593\n",
      "tensor(1.4858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [89/125], Loss_min: 1.4858, Loss_max: 1.4858\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [90/125], Loss_min: 1.6170, Loss_max: 1.6170\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [91/125], Loss_min: 1.6269, Loss_max: 1.6269\n",
      "tensor(1.6279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [92/125], Loss_min: 1.6279, Loss_max: 1.6279\n",
      "tensor(1.5252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [93/125], Loss_min: 1.5252, Loss_max: 1.5252\n",
      "tensor(1.2431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [94/125], Loss_min: 1.2431, Loss_max: 1.2431\n",
      "tensor(1.4101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [95/125], Loss_min: 1.4101, Loss_max: 1.4101\n",
      "tensor(1.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [96/125], Loss_min: 1.3112, Loss_max: 1.3112\n",
      "tensor(1.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [97/125], Loss_min: 1.6230, Loss_max: 1.6230\n",
      "tensor(0.8961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [98/125], Loss_min: 0.8961, Loss_max: 0.8961\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [99/125], Loss_min: 1.1635, Loss_max: 1.1635\n",
      "tensor(1.4924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [100/125], Loss_min: 1.4924, Loss_max: 1.4924\n",
      "tensor(1.4251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [101/125], Loss_min: 1.4251, Loss_max: 1.4251\n",
      "tensor(1.2051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [102/125], Loss_min: 1.2051, Loss_max: 1.2051\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [103/125], Loss_min: 1.1130, Loss_max: 1.1130\n",
      "tensor(1.3451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [104/125], Loss_min: 1.3451, Loss_max: 1.3451\n",
      "tensor(1.3313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [105/125], Loss_min: 1.3313, Loss_max: 1.3313\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [106/125], Loss_min: 1.6102, Loss_max: 1.6102\n",
      "tensor(1.2339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [107/125], Loss_min: 1.2339, Loss_max: 1.2339\n",
      "tensor(1.5998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [108/125], Loss_min: 1.5998, Loss_max: 1.5998\n",
      "tensor(1.5232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [109/125], Loss_min: 1.5232, Loss_max: 1.5232\n",
      "tensor(1.3839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [110/125], Loss_min: 1.3839, Loss_max: 1.3839\n",
      "tensor(1.3572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [111/125], Loss_min: 1.3572, Loss_max: 1.3572\n",
      "tensor(1.2007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [112/125], Loss_min: 1.2007, Loss_max: 1.2007\n",
      "tensor(1.5961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [113/125], Loss_min: 1.5961, Loss_max: 1.5961\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [114/125], Loss_min: 1.0176, Loss_max: 1.0176\n",
      "tensor(1.4202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [115/125], Loss_min: 1.4202, Loss_max: 1.4202\n",
      "tensor(1.3297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [116/125], Loss_min: 1.3297, Loss_max: 1.3297\n",
      "tensor(1.3383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [117/125], Loss_min: 1.3383, Loss_max: 1.3383\n",
      "tensor(1.2227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [118/125], Loss_min: 1.2227, Loss_max: 1.2227\n",
      "tensor(1.2931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [119/125], Loss_min: 1.2931, Loss_max: 1.2931\n",
      "tensor(1.4909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [120/125], Loss_min: 1.4909, Loss_max: 1.4909\n",
      "tensor(1.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [121/125], Loss_min: 1.0734, Loss_max: 1.0734\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [122/125], Loss_min: 1.0791, Loss_max: 1.0791\n",
      "tensor(1.2144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [123/125], Loss_min: 1.2144, Loss_max: 1.2144\n",
      "tensor(1.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [124/125], Loss_min: 1.1619, Loss_max: 1.1619\n",
      "tensor(1.8254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [1/10], Step [125/125], Loss_min: 1.8254, Loss_max: 1.8254\n",
      "Epoch: 1\n",
      "tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [1/125], Loss_min: 0.9278, Loss_max: 0.9278\n",
      "tensor(1.4769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [2/125], Loss_min: 1.4769, Loss_max: 1.4769\n",
      "tensor(1.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [3/125], Loss_min: 1.0581, Loss_max: 1.0581\n",
      "tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [4/125], Loss_min: 1.0766, Loss_max: 1.0766\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [5/125], Loss_min: 1.3433, Loss_max: 1.3433\n",
      "tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [6/125], Loss_min: 0.8749, Loss_max: 0.8749\n",
      "tensor(1.2064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [7/125], Loss_min: 1.2064, Loss_max: 1.2064\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [8/125], Loss_min: 1.2499, Loss_max: 1.2499\n",
      "tensor(1.4082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [9/125], Loss_min: 1.4082, Loss_max: 1.4082\n",
      "tensor(1.4506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [10/125], Loss_min: 1.4506, Loss_max: 1.4506\n",
      "tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [11/125], Loss_min: 0.8896, Loss_max: 0.8896\n",
      "tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [12/125], Loss_min: 1.1062, Loss_max: 1.1062\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [13/125], Loss_min: 1.1600, Loss_max: 1.1600\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [14/125], Loss_min: 1.2905, Loss_max: 1.2905\n",
      "tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [15/125], Loss_min: 1.4402, Loss_max: 1.4402\n",
      "tensor(1.5320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [16/125], Loss_min: 1.5320, Loss_max: 1.5320\n",
      "tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [17/125], Loss_min: 1.0933, Loss_max: 1.0933\n",
      "tensor(0.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [18/125], Loss_min: 0.9789, Loss_max: 0.9789\n",
      "tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [19/125], Loss_min: 0.8332, Loss_max: 0.8332\n",
      "tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [20/125], Loss_min: 1.0121, Loss_max: 1.0121\n",
      "tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [21/125], Loss_min: 0.7330, Loss_max: 0.7330\n",
      "tensor(1.1692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [22/125], Loss_min: 1.1692, Loss_max: 1.1692\n",
      "tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [23/125], Loss_min: 0.9752, Loss_max: 0.9752\n",
      "tensor(1.3670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [24/125], Loss_min: 1.3670, Loss_max: 1.3670\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [25/125], Loss_min: 1.3352, Loss_max: 1.3352\n",
      "tensor(1.2362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [26/125], Loss_min: 1.2362, Loss_max: 1.2362\n",
      "tensor(1.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [27/125], Loss_min: 1.0218, Loss_max: 1.0218\n",
      "tensor(1.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [28/125], Loss_min: 1.0822, Loss_max: 1.0822\n",
      "tensor(1.3518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [29/125], Loss_min: 1.3518, Loss_max: 1.3518\n",
      "tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [30/125], Loss_min: 1.0309, Loss_max: 1.0309\n",
      "tensor(1.4708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [31/125], Loss_min: 1.4708, Loss_max: 1.4708\n",
      "tensor(1.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [32/125], Loss_min: 1.1565, Loss_max: 1.1565\n",
      "tensor(1.2696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [33/125], Loss_min: 1.2696, Loss_max: 1.2696\n",
      "tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [34/125], Loss_min: 1.2765, Loss_max: 1.2765\n",
      "tensor(1.5037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [35/125], Loss_min: 1.5037, Loss_max: 1.5037\n",
      "tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [36/125], Loss_min: 0.8404, Loss_max: 0.8404\n",
      "tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [37/125], Loss_min: 0.9973, Loss_max: 0.9973\n",
      "tensor(1.3420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [38/125], Loss_min: 1.3420, Loss_max: 1.3420\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [39/125], Loss_min: 1.6028, Loss_max: 1.6028\n",
      "tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [40/125], Loss_min: 0.8458, Loss_max: 0.8458\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [41/125], Loss_min: 0.9031, Loss_max: 0.9031\n",
      "tensor(1.2244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [42/125], Loss_min: 1.2244, Loss_max: 1.2244\n",
      "tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [43/125], Loss_min: 0.8978, Loss_max: 0.8978\n",
      "tensor(1.3003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [44/125], Loss_min: 1.3003, Loss_max: 1.3003\n",
      "tensor(1.0673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [45/125], Loss_min: 1.0673, Loss_max: 1.0673\n",
      "tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [46/125], Loss_min: 0.8722, Loss_max: 0.8722\n",
      "tensor(1.2717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [47/125], Loss_min: 1.2717, Loss_max: 1.2717\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [48/125], Loss_min: 1.0842, Loss_max: 1.0842\n",
      "tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [49/125], Loss_min: 0.6566, Loss_max: 0.6566\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [50/125], Loss_min: 1.1082, Loss_max: 1.1082\n",
      "tensor(1.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [51/125], Loss_min: 1.0803, Loss_max: 1.0803\n",
      "tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [52/125], Loss_min: 1.2090, Loss_max: 1.2090\n",
      "tensor(1.1576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [53/125], Loss_min: 1.1576, Loss_max: 1.1576\n",
      "tensor(1.2215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [54/125], Loss_min: 1.2215, Loss_max: 1.2215\n",
      "tensor(1.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [55/125], Loss_min: 1.0323, Loss_max: 1.0323\n",
      "tensor(1.1105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [56/125], Loss_min: 1.1105, Loss_max: 1.1105\n",
      "tensor(1.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [57/125], Loss_min: 1.0760, Loss_max: 1.0760\n",
      "tensor(1.3858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [58/125], Loss_min: 1.3858, Loss_max: 1.3858\n",
      "tensor(1.1798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [59/125], Loss_min: 1.1798, Loss_max: 1.1798\n",
      "tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [60/125], Loss_min: 0.8604, Loss_max: 0.8604\n",
      "tensor(1.5361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [61/125], Loss_min: 1.5361, Loss_max: 1.5361\n",
      "tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [62/125], Loss_min: 1.0834, Loss_max: 1.0834\n",
      "tensor(1.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [63/125], Loss_min: 1.7677, Loss_max: 1.7677\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [64/125], Loss_min: 1.6130, Loss_max: 1.6130\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [65/125], Loss_min: 1.0409, Loss_max: 1.0409\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [66/125], Loss_min: 0.9677, Loss_max: 0.9677\n",
      "tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [67/125], Loss_min: 1.2575, Loss_max: 1.2575\n",
      "tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [68/125], Loss_min: 1.0453, Loss_max: 1.0453\n",
      "tensor(0.9145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [69/125], Loss_min: 0.9145, Loss_max: 0.9145\n",
      "tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [70/125], Loss_min: 0.7336, Loss_max: 0.7336\n",
      "tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [71/125], Loss_min: 0.8747, Loss_max: 0.8747\n",
      "tensor(1.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [72/125], Loss_min: 1.0302, Loss_max: 1.0302\n",
      "tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [73/125], Loss_min: 0.8442, Loss_max: 0.8442\n",
      "tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [74/125], Loss_min: 0.7020, Loss_max: 0.7020\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [75/125], Loss_min: 1.1566, Loss_max: 1.1566\n",
      "tensor(1.2074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [76/125], Loss_min: 1.2074, Loss_max: 1.2074\n",
      "tensor(1.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [77/125], Loss_min: 1.1710, Loss_max: 1.1710\n",
      "tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [78/125], Loss_min: 0.8625, Loss_max: 0.8625\n",
      "tensor(1.4360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [79/125], Loss_min: 1.4360, Loss_max: 1.4360\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [80/125], Loss_min: 1.1097, Loss_max: 1.1097\n",
      "tensor(1.3152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [81/125], Loss_min: 1.3152, Loss_max: 1.3152\n",
      "tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [82/125], Loss_min: 0.7092, Loss_max: 0.7092\n",
      "tensor(1.4411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [83/125], Loss_min: 1.4411, Loss_max: 1.4411\n",
      "tensor(1.2328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [84/125], Loss_min: 1.2328, Loss_max: 1.2328\n",
      "tensor(0.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [85/125], Loss_min: 0.9793, Loss_max: 0.9793\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [86/125], Loss_min: 1.4645, Loss_max: 1.4645\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [87/125], Loss_min: 1.1635, Loss_max: 1.1635\n",
      "tensor(1.4629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [88/125], Loss_min: 1.4629, Loss_max: 1.4629\n",
      "tensor(1.3429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [89/125], Loss_min: 1.3429, Loss_max: 1.3429\n",
      "tensor(1.3416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [90/125], Loss_min: 1.3416, Loss_max: 1.3416\n",
      "tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [91/125], Loss_min: 0.9335, Loss_max: 0.9335\n",
      "tensor(1.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [92/125], Loss_min: 1.0493, Loss_max: 1.0493\n",
      "tensor(1.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [93/125], Loss_min: 1.0071, Loss_max: 1.0071\n",
      "tensor(1.6228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [94/125], Loss_min: 1.6228, Loss_max: 1.6228\n",
      "tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [95/125], Loss_min: 0.8391, Loss_max: 0.8391\n",
      "tensor(0.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [96/125], Loss_min: 0.9816, Loss_max: 0.9816\n",
      "tensor(1.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [97/125], Loss_min: 1.0035, Loss_max: 1.0035\n",
      "tensor(1.3726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [98/125], Loss_min: 1.3726, Loss_max: 1.3726\n",
      "tensor(1.4530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [99/125], Loss_min: 1.4530, Loss_max: 1.4530\n",
      "tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [100/125], Loss_min: 1.1601, Loss_max: 1.1601\n",
      "tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [101/125], Loss_min: 0.9230, Loss_max: 0.9230\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [102/125], Loss_min: 0.7425, Loss_max: 0.7425\n",
      "tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [103/125], Loss_min: 0.9551, Loss_max: 0.9551\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [104/125], Loss_min: 1.1232, Loss_max: 1.1232\n",
      "tensor(1.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [105/125], Loss_min: 1.0157, Loss_max: 1.0157\n",
      "tensor(1.2190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [106/125], Loss_min: 1.2190, Loss_max: 1.2190\n",
      "tensor(1.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [107/125], Loss_min: 1.2066, Loss_max: 1.2066\n",
      "tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [108/125], Loss_min: 1.0002, Loss_max: 1.0002\n",
      "tensor(1.2594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [109/125], Loss_min: 1.2594, Loss_max: 1.2594\n",
      "tensor(1.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [110/125], Loss_min: 1.1615, Loss_max: 1.1615\n",
      "tensor(1.4599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [111/125], Loss_min: 1.4599, Loss_max: 1.4599\n",
      "tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [112/125], Loss_min: 0.9042, Loss_max: 0.9042\n",
      "tensor(1.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [113/125], Loss_min: 1.0410, Loss_max: 1.0410\n",
      "tensor(0.8792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [114/125], Loss_min: 0.8792, Loss_max: 0.8792\n",
      "tensor(0.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [115/125], Loss_min: 0.8913, Loss_max: 0.8913\n",
      "tensor(1.4085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [116/125], Loss_min: 1.4085, Loss_max: 1.4085\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [117/125], Loss_min: 1.1207, Loss_max: 1.1207\n",
      "tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [118/125], Loss_min: 1.0851, Loss_max: 1.0851\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [119/125], Loss_min: 1.0684, Loss_max: 1.0684\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [120/125], Loss_min: 1.1379, Loss_max: 1.1379\n",
      "tensor(1.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [121/125], Loss_min: 1.0257, Loss_max: 1.0257\n",
      "tensor(1.2969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [122/125], Loss_min: 1.2969, Loss_max: 1.2969\n",
      "tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [123/125], Loss_min: 0.6342, Loss_max: 0.6342\n",
      "tensor(1.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [124/125], Loss_min: 1.0967, Loss_max: 1.0967\n",
      "tensor(1.5214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [2/10], Step [125/125], Loss_min: 1.5214, Loss_max: 1.5214\n",
      "Epoch: 2\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [1/125], Loss_min: 1.1094, Loss_max: 1.1094\n",
      "tensor(1.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [2/125], Loss_min: 1.0458, Loss_max: 1.0458\n",
      "tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [3/125], Loss_min: 1.0274, Loss_max: 1.0274\n",
      "tensor(1.1502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [4/125], Loss_min: 1.1502, Loss_max: 1.1502\n",
      "tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [5/125], Loss_min: 1.2575, Loss_max: 1.2575\n",
      "tensor(1.3419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [6/125], Loss_min: 1.3419, Loss_max: 1.3419\n",
      "tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [7/125], Loss_min: 0.7767, Loss_max: 0.7767\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [8/125], Loss_min: 0.9812, Loss_max: 0.9812\n",
      "tensor(0.9804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [9/125], Loss_min: 0.9804, Loss_max: 0.9804\n",
      "tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [10/125], Loss_min: 0.9165, Loss_max: 0.9165\n",
      "tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [11/125], Loss_min: 1.3599, Loss_max: 1.3599\n",
      "tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [12/125], Loss_min: 0.8903, Loss_max: 0.8903\n",
      "tensor(1.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [13/125], Loss_min: 1.0234, Loss_max: 1.0234\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [14/125], Loss_min: 1.6009, Loss_max: 1.6009\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [15/125], Loss_min: 0.9494, Loss_max: 0.9494\n",
      "tensor(1.2816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [16/125], Loss_min: 1.2816, Loss_max: 1.2816\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [17/125], Loss_min: 1.1234, Loss_max: 1.1234\n",
      "tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [18/125], Loss_min: 1.1935, Loss_max: 1.1935\n",
      "tensor(0.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [19/125], Loss_min: 0.9983, Loss_max: 0.9983\n",
      "tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [20/125], Loss_min: 0.9104, Loss_max: 0.9104\n",
      "tensor(1.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [21/125], Loss_min: 1.0083, Loss_max: 1.0083\n",
      "tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [22/125], Loss_min: 0.7761, Loss_max: 0.7761\n",
      "tensor(1.1819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [23/125], Loss_min: 1.1819, Loss_max: 1.1819\n",
      "tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [24/125], Loss_min: 0.9712, Loss_max: 0.9712\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [25/125], Loss_min: 1.0074, Loss_max: 1.0074\n",
      "tensor(1.2164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [26/125], Loss_min: 1.2164, Loss_max: 1.2164\n",
      "tensor(0.9168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [27/125], Loss_min: 0.9168, Loss_max: 0.9168\n",
      "tensor(1.2226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [28/125], Loss_min: 1.2226, Loss_max: 1.2226\n",
      "tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [29/125], Loss_min: 0.9079, Loss_max: 0.9079\n",
      "tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [30/125], Loss_min: 0.8782, Loss_max: 0.8782\n",
      "tensor(1.4894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [31/125], Loss_min: 1.4894, Loss_max: 1.4894\n",
      "tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [32/125], Loss_min: 0.9000, Loss_max: 0.9000\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [33/125], Loss_min: 0.7425, Loss_max: 0.7425\n",
      "tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [34/125], Loss_min: 0.8011, Loss_max: 0.8011\n",
      "tensor(0.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [35/125], Loss_min: 0.9302, Loss_max: 0.9302\n",
      "tensor(1.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [36/125], Loss_min: 1.0859, Loss_max: 1.0859\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [37/125], Loss_min: 0.7958, Loss_max: 0.7958\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [38/125], Loss_min: 1.1455, Loss_max: 1.1455\n",
      "tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [39/125], Loss_min: 0.6202, Loss_max: 0.6202\n",
      "tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [40/125], Loss_min: 0.8903, Loss_max: 0.8903\n",
      "tensor(1.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [41/125], Loss_min: 1.2140, Loss_max: 1.2140\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [42/125], Loss_min: 1.1198, Loss_max: 1.1198\n",
      "tensor(1.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [43/125], Loss_min: 1.0223, Loss_max: 1.0223\n",
      "tensor(1.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [44/125], Loss_min: 1.2457, Loss_max: 1.2457\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [45/125], Loss_min: 0.7968, Loss_max: 0.7968\n",
      "tensor(1.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [46/125], Loss_min: 1.0052, Loss_max: 1.0052\n",
      "tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [47/125], Loss_min: 0.8144, Loss_max: 0.8144\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [48/125], Loss_min: 1.1388, Loss_max: 1.1388\n",
      "tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [49/125], Loss_min: 0.8787, Loss_max: 0.8787\n",
      "tensor(1.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [50/125], Loss_min: 1.0597, Loss_max: 1.0597\n",
      "tensor(1.2348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [51/125], Loss_min: 1.2348, Loss_max: 1.2348\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [52/125], Loss_min: 0.8171, Loss_max: 0.8171\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [53/125], Loss_min: 1.0944, Loss_max: 1.0944\n",
      "tensor(1.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [54/125], Loss_min: 1.1096, Loss_max: 1.1096\n",
      "tensor(1.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [55/125], Loss_min: 1.0845, Loss_max: 1.0845\n",
      "tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [56/125], Loss_min: 1.0933, Loss_max: 1.0933\n",
      "tensor(1.3060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [57/125], Loss_min: 1.3060, Loss_max: 1.3060\n",
      "tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [58/125], Loss_min: 0.7520, Loss_max: 0.7520\n",
      "tensor(1.2898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [59/125], Loss_min: 1.2898, Loss_max: 1.2898\n",
      "tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [60/125], Loss_min: 0.8389, Loss_max: 0.8389\n",
      "tensor(0.9790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [61/125], Loss_min: 0.9790, Loss_max: 0.9790\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [62/125], Loss_min: 0.9151, Loss_max: 0.9151\n",
      "tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [63/125], Loss_min: 0.7653, Loss_max: 0.7653\n",
      "tensor(0.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [64/125], Loss_min: 0.9733, Loss_max: 0.9733\n",
      "tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [65/125], Loss_min: 0.7342, Loss_max: 0.7342\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [66/125], Loss_min: 0.8650, Loss_max: 0.8650\n",
      "tensor(1.2954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [67/125], Loss_min: 1.2954, Loss_max: 1.2954\n",
      "tensor(1.5095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [68/125], Loss_min: 1.5095, Loss_max: 1.5095\n",
      "tensor(1.1815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [69/125], Loss_min: 1.1815, Loss_max: 1.1815\n",
      "tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [70/125], Loss_min: 1.1140, Loss_max: 1.1140\n",
      "tensor(1.3543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [71/125], Loss_min: 1.3543, Loss_max: 1.3543\n",
      "tensor(1.2030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [72/125], Loss_min: 1.2030, Loss_max: 1.2030\n",
      "tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [73/125], Loss_min: 0.8975, Loss_max: 0.8975\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [74/125], Loss_min: 1.0176, Loss_max: 1.0176\n",
      "tensor(1.2464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [75/125], Loss_min: 1.2464, Loss_max: 1.2464\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [76/125], Loss_min: 1.1150, Loss_max: 1.1150\n",
      "tensor(1.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [77/125], Loss_min: 1.0164, Loss_max: 1.0164\n",
      "tensor(0.9505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [78/125], Loss_min: 0.9505, Loss_max: 0.9505\n",
      "tensor(1.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [79/125], Loss_min: 1.0174, Loss_max: 1.0174\n",
      "tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [80/125], Loss_min: 0.7647, Loss_max: 0.7647\n",
      "tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [81/125], Loss_min: 0.8430, Loss_max: 0.8430\n",
      "tensor(1.2316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [82/125], Loss_min: 1.2316, Loss_max: 1.2316\n",
      "tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [83/125], Loss_min: 0.9476, Loss_max: 0.9476\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [84/125], Loss_min: 1.0714, Loss_max: 1.0714\n",
      "tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [85/125], Loss_min: 0.5777, Loss_max: 0.5777\n",
      "tensor(1.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [86/125], Loss_min: 1.0225, Loss_max: 1.0225\n",
      "tensor(1.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [87/125], Loss_min: 1.0611, Loss_max: 1.0611\n",
      "tensor(1.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [88/125], Loss_min: 1.0457, Loss_max: 1.0457\n",
      "tensor(0.9038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [89/125], Loss_min: 0.9038, Loss_max: 0.9038\n",
      "tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [90/125], Loss_min: 0.8970, Loss_max: 0.8970\n",
      "tensor(1.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [91/125], Loss_min: 1.6706, Loss_max: 1.6706\n",
      "tensor(1.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [92/125], Loss_min: 1.0416, Loss_max: 1.0416\n",
      "tensor(1.4265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [93/125], Loss_min: 1.4265, Loss_max: 1.4265\n",
      "tensor(0.9697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [94/125], Loss_min: 0.9697, Loss_max: 0.9697\n",
      "tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [95/125], Loss_min: 0.6406, Loss_max: 0.6406\n",
      "tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [96/125], Loss_min: 0.9058, Loss_max: 0.9058\n",
      "tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [97/125], Loss_min: 0.9783, Loss_max: 0.9783\n",
      "tensor(0.9173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [98/125], Loss_min: 0.9173, Loss_max: 0.9173\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [99/125], Loss_min: 1.1533, Loss_max: 1.1533\n",
      "tensor(1.5020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [100/125], Loss_min: 1.5020, Loss_max: 1.5020\n",
      "tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [101/125], Loss_min: 0.9005, Loss_max: 0.9005\n",
      "tensor(1.2670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [102/125], Loss_min: 1.2670, Loss_max: 1.2670\n",
      "tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [103/125], Loss_min: 1.0428, Loss_max: 1.0428\n",
      "tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [104/125], Loss_min: 1.3865, Loss_max: 1.3865\n",
      "tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [105/125], Loss_min: 1.0635, Loss_max: 1.0635\n",
      "tensor(1.4579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [106/125], Loss_min: 1.4579, Loss_max: 1.4579\n",
      "tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [107/125], Loss_min: 0.6599, Loss_max: 0.6599\n",
      "tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [108/125], Loss_min: 0.8670, Loss_max: 0.8670\n",
      "tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [109/125], Loss_min: 0.9612, Loss_max: 0.9612\n",
      "tensor(1.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [110/125], Loss_min: 1.3886, Loss_max: 1.3886\n",
      "tensor(1.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [111/125], Loss_min: 1.0100, Loss_max: 1.0100\n",
      "tensor(1.6473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [112/125], Loss_min: 1.6473, Loss_max: 1.6473\n",
      "tensor(0.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [113/125], Loss_min: 0.9179, Loss_max: 0.9179\n",
      "tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [114/125], Loss_min: 0.7468, Loss_max: 0.7468\n",
      "tensor(1.2344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [115/125], Loss_min: 1.2344, Loss_max: 1.2344\n",
      "tensor(1.3262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [116/125], Loss_min: 1.3262, Loss_max: 1.3262\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [117/125], Loss_min: 1.1291, Loss_max: 1.1291\n",
      "tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [118/125], Loss_min: 1.1671, Loss_max: 1.1671\n",
      "tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [119/125], Loss_min: 0.9861, Loss_max: 0.9861\n",
      "tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [120/125], Loss_min: 0.8260, Loss_max: 0.8260\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [121/125], Loss_min: 1.1045, Loss_max: 1.1045\n",
      "tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [122/125], Loss_min: 0.7745, Loss_max: 0.7745\n",
      "tensor(1.4654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [123/125], Loss_min: 1.4654, Loss_max: 1.4654\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [124/125], Loss_min: 0.7219, Loss_max: 0.7219\n",
      "tensor(1.2557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [3/10], Step [125/125], Loss_min: 1.2557, Loss_max: 1.2557\n",
      "Epoch: 3\n",
      "tensor(1.1932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [1/125], Loss_min: 1.1932, Loss_max: 1.1932\n",
      "tensor(1.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [2/125], Loss_min: 1.2109, Loss_max: 1.2109\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [3/125], Loss_min: 1.1512, Loss_max: 1.1512\n",
      "tensor(1.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [4/125], Loss_min: 1.1596, Loss_max: 1.1596\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [5/125], Loss_min: 1.0074, Loss_max: 1.0074\n",
      "tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [6/125], Loss_min: 1.1708, Loss_max: 1.1708\n",
      "tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [7/125], Loss_min: 0.8786, Loss_max: 0.8786\n",
      "tensor(1.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [8/125], Loss_min: 1.2624, Loss_max: 1.2624\n",
      "tensor(0.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [9/125], Loss_min: 0.8810, Loss_max: 0.8810\n",
      "tensor(1.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [10/125], Loss_min: 1.0290, Loss_max: 1.0290\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [11/125], Loss_min: 1.1149, Loss_max: 1.1149\n",
      "tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [12/125], Loss_min: 1.0383, Loss_max: 1.0383\n",
      "tensor(1.4948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [13/125], Loss_min: 1.4948, Loss_max: 1.4948\n",
      "tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [14/125], Loss_min: 0.9755, Loss_max: 0.9755\n",
      "tensor(1.1771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [15/125], Loss_min: 1.1771, Loss_max: 1.1771\n",
      "tensor(1.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [16/125], Loss_min: 1.0612, Loss_max: 1.0612\n",
      "tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [17/125], Loss_min: 0.9961, Loss_max: 0.9961\n",
      "tensor(1.3349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [18/125], Loss_min: 1.3349, Loss_max: 1.3349\n",
      "tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [19/125], Loss_min: 1.0135, Loss_max: 1.0135\n",
      "tensor(1.2568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [20/125], Loss_min: 1.2568, Loss_max: 1.2568\n",
      "tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [21/125], Loss_min: 1.1945, Loss_max: 1.1945\n",
      "tensor(1.2336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [22/125], Loss_min: 1.2336, Loss_max: 1.2336\n",
      "tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [23/125], Loss_min: 0.8797, Loss_max: 0.8797\n",
      "tensor(0.4180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [24/125], Loss_min: 0.4180, Loss_max: 0.4180\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [25/125], Loss_min: 1.1495, Loss_max: 1.1495\n",
      "tensor(1.3198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [26/125], Loss_min: 1.3198, Loss_max: 1.3198\n",
      "tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [27/125], Loss_min: 1.0956, Loss_max: 1.0956\n",
      "tensor(1.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [28/125], Loss_min: 1.0300, Loss_max: 1.0300\n",
      "tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [29/125], Loss_min: 1.3599, Loss_max: 1.3599\n",
      "tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [30/125], Loss_min: 0.8267, Loss_max: 0.8267\n",
      "tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [31/125], Loss_min: 0.8849, Loss_max: 0.8849\n",
      "tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [32/125], Loss_min: 0.7003, Loss_max: 0.7003\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [33/125], Loss_min: 0.6917, Loss_max: 0.6917\n",
      "tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [34/125], Loss_min: 1.3991, Loss_max: 1.3991\n",
      "tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [35/125], Loss_min: 0.7175, Loss_max: 0.7175\n",
      "tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [36/125], Loss_min: 0.7538, Loss_max: 0.7538\n",
      "tensor(1.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [37/125], Loss_min: 1.0477, Loss_max: 1.0477\n",
      "tensor(0.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [38/125], Loss_min: 0.9948, Loss_max: 0.9948\n",
      "tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [39/125], Loss_min: 0.9134, Loss_max: 0.9134\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [40/125], Loss_min: 1.1074, Loss_max: 1.1074\n",
      "tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [41/125], Loss_min: 0.6275, Loss_max: 0.6275\n",
      "tensor(1.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [42/125], Loss_min: 1.0138, Loss_max: 1.0138\n",
      "tensor(1.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [43/125], Loss_min: 1.2304, Loss_max: 1.2304\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [44/125], Loss_min: 1.1385, Loss_max: 1.1385\n",
      "tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [45/125], Loss_min: 0.7886, Loss_max: 0.7886\n",
      "tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [46/125], Loss_min: 0.9411, Loss_max: 0.9411\n",
      "tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [47/125], Loss_min: 0.8394, Loss_max: 0.8394\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [48/125], Loss_min: 1.2617, Loss_max: 1.2617\n",
      "tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [49/125], Loss_min: 0.7368, Loss_max: 0.7368\n",
      "tensor(1.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [50/125], Loss_min: 1.1050, Loss_max: 1.1050\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [51/125], Loss_min: 0.8547, Loss_max: 0.8547\n",
      "tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [52/125], Loss_min: 0.6580, Loss_max: 0.6580\n",
      "tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [53/125], Loss_min: 0.9218, Loss_max: 0.9218\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [54/125], Loss_min: 1.1037, Loss_max: 1.1037\n",
      "tensor(1.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [55/125], Loss_min: 1.0645, Loss_max: 1.0645\n",
      "tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [56/125], Loss_min: 0.5419, Loss_max: 0.5419\n",
      "tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [57/125], Loss_min: 0.8958, Loss_max: 0.8958\n",
      "tensor(1.1696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [58/125], Loss_min: 1.1696, Loss_max: 1.1696\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [59/125], Loss_min: 1.1792, Loss_max: 1.1792\n",
      "tensor(0.5373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [60/125], Loss_min: 0.5373, Loss_max: 0.5373\n",
      "tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [61/125], Loss_min: 0.7172, Loss_max: 0.7172\n",
      "tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [62/125], Loss_min: 0.6956, Loss_max: 0.6956\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [63/125], Loss_min: 0.7590, Loss_max: 0.7590\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [64/125], Loss_min: 1.1120, Loss_max: 1.1120\n",
      "tensor(1.7145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [65/125], Loss_min: 1.7145, Loss_max: 1.7145\n",
      "tensor(0.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [66/125], Loss_min: 0.9652, Loss_max: 0.9652\n",
      "tensor(1.2403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [67/125], Loss_min: 1.2403, Loss_max: 1.2403\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [68/125], Loss_min: 1.1199, Loss_max: 1.1199\n",
      "tensor(1.4122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [69/125], Loss_min: 1.4122, Loss_max: 1.4122\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [70/125], Loss_min: 1.0842, Loss_max: 1.0842\n",
      "tensor(0.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [71/125], Loss_min: 0.8235, Loss_max: 0.8235\n",
      "tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [72/125], Loss_min: 0.9475, Loss_max: 0.9475\n",
      "tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [73/125], Loss_min: 0.7801, Loss_max: 0.7801\n",
      "tensor(1.1949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [74/125], Loss_min: 1.1949, Loss_max: 1.1949\n",
      "tensor(1.3224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [75/125], Loss_min: 1.3224, Loss_max: 1.3224\n",
      "tensor(1.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [76/125], Loss_min: 1.0855, Loss_max: 1.0855\n",
      "tensor(0.9287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [77/125], Loss_min: 0.9287, Loss_max: 0.9287\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [78/125], Loss_min: 0.7048, Loss_max: 0.7048\n",
      "tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [79/125], Loss_min: 0.7382, Loss_max: 0.7382\n",
      "tensor(1.2490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [80/125], Loss_min: 1.2490, Loss_max: 1.2490\n",
      "tensor(1.1941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [81/125], Loss_min: 1.1941, Loss_max: 1.1941\n",
      "tensor(1.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [82/125], Loss_min: 1.0659, Loss_max: 1.0659\n",
      "tensor(1.0736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [83/125], Loss_min: 1.0736, Loss_max: 1.0736\n",
      "tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [84/125], Loss_min: 0.8799, Loss_max: 0.8799\n",
      "tensor(0.9064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [85/125], Loss_min: 0.9064, Loss_max: 0.9064\n",
      "tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [86/125], Loss_min: 0.6088, Loss_max: 0.6088\n",
      "tensor(1.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [87/125], Loss_min: 1.0219, Loss_max: 1.0219\n",
      "tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [88/125], Loss_min: 0.8060, Loss_max: 0.8060\n",
      "tensor(1.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [89/125], Loss_min: 1.0589, Loss_max: 1.0589\n",
      "tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [90/125], Loss_min: 0.7893, Loss_max: 0.7893\n",
      "tensor(1.3596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [91/125], Loss_min: 1.3596, Loss_max: 1.3596\n",
      "tensor(1.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [92/125], Loss_min: 1.0319, Loss_max: 1.0319\n",
      "tensor(0.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [93/125], Loss_min: 0.9735, Loss_max: 0.9735\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [94/125], Loss_min: 0.9151, Loss_max: 0.9151\n",
      "tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [95/125], Loss_min: 0.8418, Loss_max: 0.8418\n",
      "tensor(1.1577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [96/125], Loss_min: 1.1577, Loss_max: 1.1577\n",
      "tensor(0.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [97/125], Loss_min: 0.9527, Loss_max: 0.9527\n",
      "tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [98/125], Loss_min: 0.6775, Loss_max: 0.6775\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [99/125], Loss_min: 0.7969, Loss_max: 0.7969\n",
      "tensor(1.2231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [100/125], Loss_min: 1.2231, Loss_max: 1.2231\n",
      "tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [101/125], Loss_min: 0.8299, Loss_max: 0.8299\n",
      "tensor(1.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [102/125], Loss_min: 1.0072, Loss_max: 1.0072\n",
      "tensor(1.2044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [103/125], Loss_min: 1.2044, Loss_max: 1.2044\n",
      "tensor(1.2067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [104/125], Loss_min: 1.2067, Loss_max: 1.2067\n",
      "tensor(1.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [105/125], Loss_min: 1.0764, Loss_max: 1.0764\n",
      "tensor(1.3204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [106/125], Loss_min: 1.3204, Loss_max: 1.3204\n",
      "tensor(1.2535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [107/125], Loss_min: 1.2535, Loss_max: 1.2535\n",
      "tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [108/125], Loss_min: 0.9321, Loss_max: 0.9321\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [109/125], Loss_min: 1.1350, Loss_max: 1.1350\n",
      "tensor(1.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [110/125], Loss_min: 1.0396, Loss_max: 1.0396\n",
      "tensor(1.0787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [111/125], Loss_min: 1.0787, Loss_max: 1.0787\n",
      "tensor(1.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [112/125], Loss_min: 1.0463, Loss_max: 1.0463\n",
      "tensor(0.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [113/125], Loss_min: 0.9268, Loss_max: 0.9268\n",
      "tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [114/125], Loss_min: 1.0155, Loss_max: 1.0155\n",
      "tensor(0.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [115/125], Loss_min: 0.9975, Loss_max: 0.9975\n",
      "tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [116/125], Loss_min: 1.0691, Loss_max: 1.0691\n",
      "tensor(1.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [117/125], Loss_min: 1.0252, Loss_max: 1.0252\n",
      "tensor(1.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [118/125], Loss_min: 1.0243, Loss_max: 1.0243\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [119/125], Loss_min: 1.0528, Loss_max: 1.0528\n",
      "tensor(1.3573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [120/125], Loss_min: 1.3573, Loss_max: 1.3573\n",
      "tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [121/125], Loss_min: 0.9964, Loss_max: 0.9964\n",
      "tensor(1.2901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [122/125], Loss_min: 1.2901, Loss_max: 1.2901\n",
      "tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [123/125], Loss_min: 0.9228, Loss_max: 0.9228\n",
      "tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [124/125], Loss_min: 0.7588, Loss_max: 0.7588\n",
      "tensor(1.2211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [4/10], Step [125/125], Loss_min: 1.2211, Loss_max: 1.2211\n",
      "Epoch: 4\n",
      "tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [1/125], Loss_min: 0.8584, Loss_max: 0.8584\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [2/125], Loss_min: 1.1369, Loss_max: 1.1369\n",
      "tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [3/125], Loss_min: 1.0350, Loss_max: 1.0350\n",
      "tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [4/125], Loss_min: 0.7909, Loss_max: 0.7909\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [5/125], Loss_min: 0.8000, Loss_max: 0.8000\n",
      "tensor(1.4442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [6/125], Loss_min: 1.4442, Loss_max: 1.4442\n",
      "tensor(1.2570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [7/125], Loss_min: 1.2570, Loss_max: 1.2570\n",
      "tensor(1.5517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [8/125], Loss_min: 1.5517, Loss_max: 1.5517\n",
      "tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [9/125], Loss_min: 0.8340, Loss_max: 0.8340\n",
      "tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [10/125], Loss_min: 0.9413, Loss_max: 0.9413\n",
      "tensor(1.4499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [11/125], Loss_min: 1.4499, Loss_max: 1.4499\n",
      "tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [12/125], Loss_min: 1.0299, Loss_max: 1.0299\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [13/125], Loss_min: 0.9677, Loss_max: 0.9677\n",
      "tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [14/125], Loss_min: 0.8535, Loss_max: 0.8535\n",
      "tensor(1.1593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [15/125], Loss_min: 1.1593, Loss_max: 1.1593\n",
      "tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [16/125], Loss_min: 0.8997, Loss_max: 0.8997\n",
      "tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [17/125], Loss_min: 0.6528, Loss_max: 0.6528\n",
      "tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [18/125], Loss_min: 0.8345, Loss_max: 0.8345\n",
      "tensor(1.2405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [19/125], Loss_min: 1.2405, Loss_max: 1.2405\n",
      "tensor(1.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [20/125], Loss_min: 1.0364, Loss_max: 1.0364\n",
      "tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [21/125], Loss_min: 0.8126, Loss_max: 0.8126\n",
      "tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [22/125], Loss_min: 1.2421, Loss_max: 1.2421\n",
      "tensor(1.2835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [23/125], Loss_min: 1.2835, Loss_max: 1.2835\n",
      "tensor(1.2289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [24/125], Loss_min: 1.2289, Loss_max: 1.2289\n",
      "tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [25/125], Loss_min: 0.7705, Loss_max: 0.7705\n",
      "tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [26/125], Loss_min: 0.8209, Loss_max: 0.8209\n",
      "tensor(1.4552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [27/125], Loss_min: 1.4552, Loss_max: 1.4552\n",
      "tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [28/125], Loss_min: 1.0927, Loss_max: 1.0927\n",
      "tensor(0.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [29/125], Loss_min: 0.9879, Loss_max: 0.9879\n",
      "tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [30/125], Loss_min: 0.7064, Loss_max: 0.7064\n",
      "tensor(1.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [31/125], Loss_min: 1.0825, Loss_max: 1.0825\n",
      "tensor(1.2556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [32/125], Loss_min: 1.2556, Loss_max: 1.2556\n",
      "tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [33/125], Loss_min: 0.6126, Loss_max: 0.6126\n",
      "tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [34/125], Loss_min: 0.9300, Loss_max: 0.9300\n",
      "tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [35/125], Loss_min: 0.8133, Loss_max: 0.8133\n",
      "tensor(1.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [36/125], Loss_min: 1.2523, Loss_max: 1.2523\n",
      "tensor(1.1964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [37/125], Loss_min: 1.1964, Loss_max: 1.1964\n",
      "tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [38/125], Loss_min: 0.9192, Loss_max: 0.9192\n",
      "tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [39/125], Loss_min: 0.8695, Loss_max: 0.8695\n",
      "tensor(0.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [40/125], Loss_min: 0.9874, Loss_max: 0.9874\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [41/125], Loss_min: 1.0528, Loss_max: 1.0528\n",
      "tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [42/125], Loss_min: 0.7471, Loss_max: 0.7471\n",
      "tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [43/125], Loss_min: 0.5869, Loss_max: 0.5869\n",
      "tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [44/125], Loss_min: 1.0059, Loss_max: 1.0059\n",
      "tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [45/125], Loss_min: 1.0428, Loss_max: 1.0428\n",
      "tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [46/125], Loss_min: 0.8644, Loss_max: 0.8644\n",
      "tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [47/125], Loss_min: 0.9592, Loss_max: 0.9592\n",
      "tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [48/125], Loss_min: 0.8338, Loss_max: 0.8338\n",
      "tensor(1.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [49/125], Loss_min: 1.0660, Loss_max: 1.0660\n",
      "tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [50/125], Loss_min: 0.8952, Loss_max: 0.8952\n",
      "tensor(1.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [51/125], Loss_min: 1.0935, Loss_max: 1.0935\n",
      "tensor(1.1916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [52/125], Loss_min: 1.1916, Loss_max: 1.1916\n",
      "tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [53/125], Loss_min: 0.7557, Loss_max: 0.7557\n",
      "tensor(0.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [54/125], Loss_min: 0.9813, Loss_max: 0.9813\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [55/125], Loss_min: 0.9629, Loss_max: 0.9629\n",
      "tensor(0.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [56/125], Loss_min: 0.9853, Loss_max: 0.9853\n",
      "tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [57/125], Loss_min: 0.8652, Loss_max: 0.8652\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [58/125], Loss_min: 1.1228, Loss_max: 1.1228\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [59/125], Loss_min: 0.9997, Loss_max: 0.9997\n",
      "tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [60/125], Loss_min: 0.7376, Loss_max: 0.7376\n",
      "tensor(1.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [61/125], Loss_min: 1.0546, Loss_max: 1.0546\n",
      "tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [62/125], Loss_min: 0.5799, Loss_max: 0.5799\n",
      "tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [63/125], Loss_min: 0.6255, Loss_max: 0.6255\n",
      "tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [64/125], Loss_min: 0.8955, Loss_max: 0.8955\n",
      "tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [65/125], Loss_min: 0.6967, Loss_max: 0.6967\n",
      "tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [66/125], Loss_min: 0.7874, Loss_max: 0.7874\n",
      "tensor(0.8733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [67/125], Loss_min: 0.8733, Loss_max: 0.8733\n",
      "tensor(1.1990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [68/125], Loss_min: 1.1990, Loss_max: 1.1990\n",
      "tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [69/125], Loss_min: 0.8320, Loss_max: 0.8320\n",
      "tensor(1.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [70/125], Loss_min: 1.0518, Loss_max: 1.0518\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [71/125], Loss_min: 0.9995, Loss_max: 0.9995\n",
      "tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [72/125], Loss_min: 1.0066, Loss_max: 1.0066\n",
      "tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [73/125], Loss_min: 0.9308, Loss_max: 0.9308\n",
      "tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [74/125], Loss_min: 1.0308, Loss_max: 1.0308\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [75/125], Loss_min: 0.6794, Loss_max: 0.6794\n",
      "tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [76/125], Loss_min: 0.7944, Loss_max: 0.7944\n",
      "tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [77/125], Loss_min: 1.0337, Loss_max: 1.0337\n",
      "tensor(1.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [78/125], Loss_min: 1.1920, Loss_max: 1.1920\n",
      "tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [79/125], Loss_min: 0.6228, Loss_max: 0.6228\n",
      "tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [80/125], Loss_min: 0.8634, Loss_max: 0.8634\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [81/125], Loss_min: 0.9580, Loss_max: 0.9580\n",
      "tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [82/125], Loss_min: 0.7598, Loss_max: 0.7598\n",
      "tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [83/125], Loss_min: 0.5310, Loss_max: 0.5310\n",
      "tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [84/125], Loss_min: 1.0121, Loss_max: 1.0121\n",
      "tensor(0.4730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [85/125], Loss_min: 0.4730, Loss_max: 0.4730\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [86/125], Loss_min: 1.1295, Loss_max: 1.1295\n",
      "tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [87/125], Loss_min: 0.9124, Loss_max: 0.9124\n",
      "tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [88/125], Loss_min: 0.7182, Loss_max: 0.7182\n",
      "tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [89/125], Loss_min: 0.6647, Loss_max: 0.6647\n",
      "tensor(1.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [90/125], Loss_min: 1.2114, Loss_max: 1.2114\n",
      "tensor(0.4018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [91/125], Loss_min: 0.4018, Loss_max: 0.4018\n",
      "tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [92/125], Loss_min: 0.9006, Loss_max: 0.9006\n",
      "tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [93/125], Loss_min: 0.8579, Loss_max: 0.8579\n",
      "tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [94/125], Loss_min: 0.8804, Loss_max: 0.8804\n",
      "tensor(1.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [95/125], Loss_min: 1.0351, Loss_max: 1.0351\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [96/125], Loss_min: 1.1043, Loss_max: 1.1043\n",
      "tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [97/125], Loss_min: 0.6991, Loss_max: 0.6991\n",
      "tensor(1.2320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [98/125], Loss_min: 1.2320, Loss_max: 1.2320\n",
      "tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [99/125], Loss_min: 0.9301, Loss_max: 0.9301\n",
      "tensor(0.9524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [100/125], Loss_min: 0.9524, Loss_max: 0.9524\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [101/125], Loss_min: 0.8180, Loss_max: 0.8180\n",
      "tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [102/125], Loss_min: 0.7726, Loss_max: 0.7726\n",
      "tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [103/125], Loss_min: 0.6697, Loss_max: 0.6697\n",
      "tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [104/125], Loss_min: 0.7019, Loss_max: 0.7019\n",
      "tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [105/125], Loss_min: 0.6938, Loss_max: 0.6938\n",
      "tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [106/125], Loss_min: 0.9625, Loss_max: 0.9625\n",
      "tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [107/125], Loss_min: 0.8845, Loss_max: 0.8845\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [108/125], Loss_min: 1.1097, Loss_max: 1.1097\n",
      "tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [109/125], Loss_min: 0.9700, Loss_max: 0.9700\n",
      "tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [110/125], Loss_min: 0.5954, Loss_max: 0.5954\n",
      "tensor(0.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [111/125], Loss_min: 0.9920, Loss_max: 0.9920\n",
      "tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [112/125], Loss_min: 0.7245, Loss_max: 0.7245\n",
      "tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [113/125], Loss_min: 0.7492, Loss_max: 0.7492\n",
      "tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [114/125], Loss_min: 0.8214, Loss_max: 0.8214\n",
      "tensor(1.1851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [115/125], Loss_min: 1.1851, Loss_max: 1.1851\n",
      "tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [116/125], Loss_min: 0.9559, Loss_max: 0.9559\n",
      "tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [117/125], Loss_min: 0.7151, Loss_max: 0.7151\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [118/125], Loss_min: 0.8013, Loss_max: 0.8013\n",
      "tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [119/125], Loss_min: 0.7520, Loss_max: 0.7520\n",
      "tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [120/125], Loss_min: 0.7764, Loss_max: 0.7764\n",
      "tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [121/125], Loss_min: 0.7656, Loss_max: 0.7656\n",
      "tensor(1.1842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [122/125], Loss_min: 1.1842, Loss_max: 1.1842\n",
      "tensor(1.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [123/125], Loss_min: 1.0543, Loss_max: 1.0543\n",
      "tensor(0.4744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [124/125], Loss_min: 0.4744, Loss_max: 0.4744\n",
      "tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [5/10], Step [125/125], Loss_min: 0.7695, Loss_max: 0.7695\n",
      "Epoch: 5\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [1/125], Loss_min: 1.1463, Loss_max: 1.1463\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [2/125], Loss_min: 0.8905, Loss_max: 0.8905\n",
      "tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [3/125], Loss_min: 0.5883, Loss_max: 0.5883\n",
      "tensor(1.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [4/125], Loss_min: 1.0012, Loss_max: 1.0012\n",
      "tensor(0.9520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [5/125], Loss_min: 0.9520, Loss_max: 0.9520\n",
      "tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [6/125], Loss_min: 0.5741, Loss_max: 0.5741\n",
      "tensor(0.4176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [7/125], Loss_min: 0.4176, Loss_max: 0.4176\n",
      "tensor(0.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [8/125], Loss_min: 0.9564, Loss_max: 0.9564\n",
      "tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [9/125], Loss_min: 0.8144, Loss_max: 0.8144\n",
      "tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [10/125], Loss_min: 0.6420, Loss_max: 0.6420\n",
      "tensor(0.4604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [11/125], Loss_min: 0.4604, Loss_max: 0.4604\n",
      "tensor(1.3688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [12/125], Loss_min: 1.3688, Loss_max: 1.3688\n",
      "tensor(0.5148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [13/125], Loss_min: 0.5148, Loss_max: 0.5148\n",
      "tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [14/125], Loss_min: 0.6338, Loss_max: 0.6338\n",
      "tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [15/125], Loss_min: 1.0971, Loss_max: 1.0971\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [16/125], Loss_min: 1.3634, Loss_max: 1.3634\n",
      "tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [17/125], Loss_min: 0.7097, Loss_max: 0.7097\n",
      "tensor(0.4481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [18/125], Loss_min: 0.4481, Loss_max: 0.4481\n",
      "tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [19/125], Loss_min: 0.9160, Loss_max: 0.9160\n",
      "tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [20/125], Loss_min: 0.6985, Loss_max: 0.6985\n",
      "tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [21/125], Loss_min: 0.7154, Loss_max: 0.7154\n",
      "tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [22/125], Loss_min: 0.8476, Loss_max: 0.8476\n",
      "tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [23/125], Loss_min: 0.8478, Loss_max: 0.8478\n",
      "tensor(0.9513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [24/125], Loss_min: 0.9513, Loss_max: 0.9513\n",
      "tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [25/125], Loss_min: 0.6110, Loss_max: 0.6110\n",
      "tensor(0.6237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [26/125], Loss_min: 0.6237, Loss_max: 0.6237\n",
      "tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [27/125], Loss_min: 0.7367, Loss_max: 0.7367\n",
      "tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [28/125], Loss_min: 0.8998, Loss_max: 0.8998\n",
      "tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [29/125], Loss_min: 0.7032, Loss_max: 0.7032\n",
      "tensor(0.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [30/125], Loss_min: 0.9008, Loss_max: 0.9008\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [31/125], Loss_min: 0.6918, Loss_max: 0.6918\n",
      "tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [32/125], Loss_min: 1.0254, Loss_max: 1.0254\n",
      "tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [33/125], Loss_min: 0.9137, Loss_max: 0.9137\n",
      "tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [34/125], Loss_min: 0.7372, Loss_max: 0.7372\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [35/125], Loss_min: 1.0842, Loss_max: 1.0842\n",
      "tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [36/125], Loss_min: 0.7484, Loss_max: 0.7484\n",
      "tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [37/125], Loss_min: 0.7350, Loss_max: 0.7350\n",
      "tensor(0.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [38/125], Loss_min: 0.9803, Loss_max: 0.9803\n",
      "tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [39/125], Loss_min: 0.8870, Loss_max: 0.8870\n",
      "tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [40/125], Loss_min: 0.6991, Loss_max: 0.6991\n",
      "tensor(1.2158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [41/125], Loss_min: 1.2158, Loss_max: 1.2158\n",
      "tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [42/125], Loss_min: 0.8154, Loss_max: 0.8154\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [43/125], Loss_min: 0.8180, Loss_max: 0.8180\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [44/125], Loss_min: 0.7590, Loss_max: 0.7590\n",
      "tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [45/125], Loss_min: 1.0273, Loss_max: 1.0273\n",
      "tensor(0.9952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [46/125], Loss_min: 0.9952, Loss_max: 0.9952\n",
      "tensor(1.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [47/125], Loss_min: 1.0847, Loss_max: 1.0847\n",
      "tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [48/125], Loss_min: 0.5612, Loss_max: 0.5612\n",
      "tensor(0.5575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [49/125], Loss_min: 0.5575, Loss_max: 0.5575\n",
      "tensor(1.3028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [50/125], Loss_min: 1.3028, Loss_max: 1.3028\n",
      "tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [51/125], Loss_min: 0.8558, Loss_max: 0.8558\n",
      "tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [52/125], Loss_min: 0.8178, Loss_max: 0.8178\n",
      "tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [53/125], Loss_min: 1.0495, Loss_max: 1.0495\n",
      "tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [54/125], Loss_min: 0.4379, Loss_max: 0.4379\n",
      "tensor(0.5136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [55/125], Loss_min: 0.5136, Loss_max: 0.5136\n",
      "tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [56/125], Loss_min: 0.7832, Loss_max: 0.7832\n",
      "tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [57/125], Loss_min: 0.7916, Loss_max: 0.7916\n",
      "tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [58/125], Loss_min: 0.8478, Loss_max: 0.8478\n",
      "tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [59/125], Loss_min: 0.7719, Loss_max: 0.7719\n",
      "tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [60/125], Loss_min: 0.6363, Loss_max: 0.6363\n",
      "tensor(1.3539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [61/125], Loss_min: 1.3539, Loss_max: 1.3539\n",
      "tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [62/125], Loss_min: 0.8503, Loss_max: 0.8503\n",
      "tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [63/125], Loss_min: 0.8371, Loss_max: 0.8371\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [64/125], Loss_min: 0.6705, Loss_max: 0.6705\n",
      "tensor(0.5048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [65/125], Loss_min: 0.5048, Loss_max: 0.5048\n",
      "tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [66/125], Loss_min: 0.8756, Loss_max: 0.8756\n",
      "tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [67/125], Loss_min: 0.8649, Loss_max: 0.8649\n",
      "tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [68/125], Loss_min: 0.8581, Loss_max: 0.8581\n",
      "tensor(1.2311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [69/125], Loss_min: 1.2311, Loss_max: 1.2311\n",
      "tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [70/125], Loss_min: 0.7535, Loss_max: 0.7535\n",
      "tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [71/125], Loss_min: 0.8104, Loss_max: 0.8104\n",
      "tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [72/125], Loss_min: 0.7169, Loss_max: 0.7169\n",
      "tensor(0.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [73/125], Loss_min: 0.9763, Loss_max: 0.9763\n",
      "tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [74/125], Loss_min: 0.6004, Loss_max: 0.6004\n",
      "tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [75/125], Loss_min: 0.7942, Loss_max: 0.7942\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [76/125], Loss_min: 0.6876, Loss_max: 0.6876\n",
      "tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [77/125], Loss_min: 0.8761, Loss_max: 0.8761\n",
      "tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [78/125], Loss_min: 0.7877, Loss_max: 0.7877\n",
      "tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [79/125], Loss_min: 0.7666, Loss_max: 0.7666\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [80/125], Loss_min: 0.7320, Loss_max: 0.7320\n",
      "tensor(1.2145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [81/125], Loss_min: 1.2145, Loss_max: 1.2145\n",
      "tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [82/125], Loss_min: 0.6756, Loss_max: 0.6756\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [83/125], Loss_min: 0.7301, Loss_max: 0.7301\n",
      "tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [84/125], Loss_min: 0.5772, Loss_max: 0.5772\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [85/125], Loss_min: 1.1495, Loss_max: 1.1495\n",
      "tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [86/125], Loss_min: 0.7891, Loss_max: 0.7891\n",
      "tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [87/125], Loss_min: 1.0875, Loss_max: 1.0875\n",
      "tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [88/125], Loss_min: 1.2793, Loss_max: 1.2793\n",
      "tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [89/125], Loss_min: 0.9009, Loss_max: 0.9009\n",
      "tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [90/125], Loss_min: 0.8092, Loss_max: 0.8092\n",
      "tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [91/125], Loss_min: 1.0093, Loss_max: 1.0093\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [92/125], Loss_min: 0.9373, Loss_max: 0.9373\n",
      "tensor(0.6054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [93/125], Loss_min: 0.6054, Loss_max: 0.6054\n",
      "tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [94/125], Loss_min: 0.9081, Loss_max: 0.9081\n",
      "tensor(1.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [95/125], Loss_min: 1.1004, Loss_max: 1.1004\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [96/125], Loss_min: 0.7713, Loss_max: 0.7713\n",
      "tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [97/125], Loss_min: 1.1671, Loss_max: 1.1671\n",
      "tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [98/125], Loss_min: 0.7625, Loss_max: 0.7625\n",
      "tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [99/125], Loss_min: 0.7569, Loss_max: 0.7569\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [100/125], Loss_min: 0.8048, Loss_max: 0.8048\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [101/125], Loss_min: 1.0776, Loss_max: 1.0776\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [102/125], Loss_min: 0.6899, Loss_max: 0.6899\n",
      "tensor(0.9400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [103/125], Loss_min: 0.9400, Loss_max: 0.9400\n",
      "tensor(1.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [104/125], Loss_min: 1.0583, Loss_max: 1.0583\n",
      "tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [105/125], Loss_min: 1.2765, Loss_max: 1.2765\n",
      "tensor(0.4797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [106/125], Loss_min: 0.4797, Loss_max: 0.4797\n",
      "tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [107/125], Loss_min: 0.6587, Loss_max: 0.6587\n",
      "tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [108/125], Loss_min: 0.6496, Loss_max: 0.6496\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [109/125], Loss_min: 0.5220, Loss_max: 0.5220\n",
      "tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [110/125], Loss_min: 0.8407, Loss_max: 0.8407\n",
      "tensor(0.5468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [111/125], Loss_min: 0.5468, Loss_max: 0.5468\n",
      "tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [112/125], Loss_min: 0.6608, Loss_max: 0.6608\n",
      "tensor(1.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [113/125], Loss_min: 1.0217, Loss_max: 1.0217\n",
      "tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [114/125], Loss_min: 0.5985, Loss_max: 0.5985\n",
      "tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [115/125], Loss_min: 0.7850, Loss_max: 0.7850\n",
      "tensor(1.3561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [116/125], Loss_min: 1.3561, Loss_max: 1.3561\n",
      "tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [117/125], Loss_min: 0.8578, Loss_max: 0.8578\n",
      "tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [118/125], Loss_min: 0.8652, Loss_max: 0.8652\n",
      "tensor(0.5242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [119/125], Loss_min: 0.5242, Loss_max: 0.5242\n",
      "tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [120/125], Loss_min: 0.7128, Loss_max: 0.7128\n",
      "tensor(0.9798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [121/125], Loss_min: 0.9798, Loss_max: 0.9798\n",
      "tensor(0.5746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [122/125], Loss_min: 0.5746, Loss_max: 0.5746\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [123/125], Loss_min: 0.5193, Loss_max: 0.5193\n",
      "tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [124/125], Loss_min: 1.0274, Loss_max: 1.0274\n",
      "tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [6/10], Step [125/125], Loss_min: 0.8967, Loss_max: 0.8967\n",
      "Epoch: 6\n",
      "tensor(0.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [1/125], Loss_min: 0.9600, Loss_max: 0.9600\n",
      "tensor(0.4143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [2/125], Loss_min: 0.4143, Loss_max: 0.4143\n",
      "tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [3/125], Loss_min: 1.0405, Loss_max: 1.0405\n",
      "tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [4/125], Loss_min: 0.8249, Loss_max: 0.8249\n",
      "tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [5/125], Loss_min: 0.7231, Loss_max: 0.7231\n",
      "tensor(1.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [6/125], Loss_min: 1.0107, Loss_max: 1.0107\n",
      "tensor(0.5563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [7/125], Loss_min: 0.5563, Loss_max: 0.5563\n",
      "tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [8/125], Loss_min: 0.5975, Loss_max: 0.5975\n",
      "tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [9/125], Loss_min: 1.0523, Loss_max: 1.0523\n",
      "tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [10/125], Loss_min: 0.8497, Loss_max: 0.8497\n",
      "tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [11/125], Loss_min: 0.7732, Loss_max: 0.7732\n",
      "tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [12/125], Loss_min: 0.7798, Loss_max: 0.7798\n",
      "tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [13/125], Loss_min: 0.8641, Loss_max: 0.8641\n",
      "tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [14/125], Loss_min: 0.7611, Loss_max: 0.7611\n",
      "tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [15/125], Loss_min: 0.7170, Loss_max: 0.7170\n",
      "tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [16/125], Loss_min: 0.8076, Loss_max: 0.8076\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [17/125], Loss_min: 0.4999, Loss_max: 0.4999\n",
      "tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [18/125], Loss_min: 0.6595, Loss_max: 0.6595\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [19/125], Loss_min: 0.5108, Loss_max: 0.5108\n",
      "tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [20/125], Loss_min: 0.8500, Loss_max: 0.8500\n",
      "tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [21/125], Loss_min: 0.5994, Loss_max: 0.5994\n",
      "tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [22/125], Loss_min: 0.7482, Loss_max: 0.7482\n",
      "tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [23/125], Loss_min: 0.7293, Loss_max: 0.7293\n",
      "tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [24/125], Loss_min: 0.8177, Loss_max: 0.8177\n",
      "tensor(0.4624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [25/125], Loss_min: 0.4624, Loss_max: 0.4624\n",
      "tensor(0.9087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [26/125], Loss_min: 0.9087, Loss_max: 0.9087\n",
      "tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [27/125], Loss_min: 0.7525, Loss_max: 0.7525\n",
      "tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [28/125], Loss_min: 0.6371, Loss_max: 0.6371\n",
      "tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [29/125], Loss_min: 0.9013, Loss_max: 0.9013\n",
      "tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [30/125], Loss_min: 0.7123, Loss_max: 0.7123\n",
      "tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [31/125], Loss_min: 0.6527, Loss_max: 0.6527\n",
      "tensor(0.5103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [32/125], Loss_min: 0.5103, Loss_max: 0.5103\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [33/125], Loss_min: 0.4976, Loss_max: 0.4976\n",
      "tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [34/125], Loss_min: 0.5416, Loss_max: 0.5416\n",
      "tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [35/125], Loss_min: 0.6112, Loss_max: 0.6112\n",
      "tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [36/125], Loss_min: 0.6236, Loss_max: 0.6236\n",
      "tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [37/125], Loss_min: 0.6168, Loss_max: 0.6168\n",
      "tensor(0.4589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [38/125], Loss_min: 0.4589, Loss_max: 0.4589\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [39/125], Loss_min: 0.6705, Loss_max: 0.6705\n",
      "tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [40/125], Loss_min: 0.8317, Loss_max: 0.8317\n",
      "tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [41/125], Loss_min: 0.5969, Loss_max: 0.5969\n",
      "tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [42/125], Loss_min: 0.6283, Loss_max: 0.6283\n",
      "tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [43/125], Loss_min: 0.6168, Loss_max: 0.6168\n",
      "tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [44/125], Loss_min: 0.8936, Loss_max: 0.8936\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [45/125], Loss_min: 0.8356, Loss_max: 0.8356\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [46/125], Loss_min: 0.5194, Loss_max: 0.5194\n",
      "tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [47/125], Loss_min: 0.4947, Loss_max: 0.4947\n",
      "tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [48/125], Loss_min: 0.7221, Loss_max: 0.7221\n",
      "tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [49/125], Loss_min: 0.7452, Loss_max: 0.7452\n",
      "tensor(1.2571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [50/125], Loss_min: 1.2571, Loss_max: 1.2571\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [51/125], Loss_min: 0.3077, Loss_max: 0.3077\n",
      "tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [52/125], Loss_min: 0.6460, Loss_max: 0.6460\n",
      "tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [53/125], Loss_min: 0.8534, Loss_max: 0.8534\n",
      "tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [54/125], Loss_min: 0.5669, Loss_max: 0.5669\n",
      "tensor(1.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [55/125], Loss_min: 1.0390, Loss_max: 1.0390\n",
      "tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [56/125], Loss_min: 0.7407, Loss_max: 0.7407\n",
      "tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [57/125], Loss_min: 0.7101, Loss_max: 0.7101\n",
      "tensor(1.2454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [58/125], Loss_min: 1.2454, Loss_max: 1.2454\n",
      "tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [59/125], Loss_min: 0.6005, Loss_max: 0.6005\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [60/125], Loss_min: 0.5127, Loss_max: 0.5127\n",
      "tensor(0.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [61/125], Loss_min: 0.9819, Loss_max: 0.9819\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [62/125], Loss_min: 0.5315, Loss_max: 0.5315\n",
      "tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [63/125], Loss_min: 0.6120, Loss_max: 0.6120\n",
      "tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [64/125], Loss_min: 0.7254, Loss_max: 0.7254\n",
      "tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [65/125], Loss_min: 0.6358, Loss_max: 0.6358\n",
      "tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [66/125], Loss_min: 0.4532, Loss_max: 0.4532\n",
      "tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [67/125], Loss_min: 0.6147, Loss_max: 0.6147\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [68/125], Loss_min: 0.3724, Loss_max: 0.3724\n",
      "tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [69/125], Loss_min: 0.5744, Loss_max: 0.5744\n",
      "tensor(0.4544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [70/125], Loss_min: 0.4544, Loss_max: 0.4544\n",
      "tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [71/125], Loss_min: 0.8497, Loss_max: 0.8497\n",
      "tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [72/125], Loss_min: 0.7854, Loss_max: 0.7854\n",
      "tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [73/125], Loss_min: 0.7345, Loss_max: 0.7345\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [74/125], Loss_min: 0.5013, Loss_max: 0.5013\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [75/125], Loss_min: 0.3982, Loss_max: 0.3982\n",
      "tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [76/125], Loss_min: 0.4490, Loss_max: 0.4490\n",
      "tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [77/125], Loss_min: 0.6092, Loss_max: 0.6092\n",
      "tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [78/125], Loss_min: 0.5667, Loss_max: 0.5667\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [79/125], Loss_min: 0.4172, Loss_max: 0.4172\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [80/125], Loss_min: 0.7219, Loss_max: 0.7219\n",
      "tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [81/125], Loss_min: 0.5364, Loss_max: 0.5364\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [82/125], Loss_min: 0.6788, Loss_max: 0.6788\n",
      "tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [83/125], Loss_min: 0.7273, Loss_max: 0.7273\n",
      "tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [84/125], Loss_min: 0.6050, Loss_max: 0.6050\n",
      "tensor(0.3747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [85/125], Loss_min: 0.3747, Loss_max: 0.3747\n",
      "tensor(0.4386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [86/125], Loss_min: 0.4386, Loss_max: 0.4386\n",
      "tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [87/125], Loss_min: 0.5185, Loss_max: 0.5185\n",
      "tensor(0.4685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [88/125], Loss_min: 0.4685, Loss_max: 0.4685\n",
      "tensor(0.3621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [89/125], Loss_min: 0.3621, Loss_max: 0.3621\n",
      "tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [90/125], Loss_min: 0.5057, Loss_max: 0.5057\n",
      "tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [91/125], Loss_min: 0.6450, Loss_max: 0.6450\n",
      "tensor(0.4278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [92/125], Loss_min: 0.4278, Loss_max: 0.4278\n",
      "tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [93/125], Loss_min: 0.8167, Loss_max: 0.8167\n",
      "tensor(0.3597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [94/125], Loss_min: 0.3597, Loss_max: 0.3597\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [95/125], Loss_min: 0.4923, Loss_max: 0.4923\n",
      "tensor(0.5222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [96/125], Loss_min: 0.5222, Loss_max: 0.5222\n",
      "tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [97/125], Loss_min: 0.6280, Loss_max: 0.6280\n",
      "tensor(1.2810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [98/125], Loss_min: 1.2810, Loss_max: 1.2810\n",
      "tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [99/125], Loss_min: 0.6973, Loss_max: 0.6973\n",
      "tensor(0.5781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [100/125], Loss_min: 0.5781, Loss_max: 0.5781\n",
      "tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [101/125], Loss_min: 0.5587, Loss_max: 0.5587\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [102/125], Loss_min: 0.4405, Loss_max: 0.4405\n",
      "tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [103/125], Loss_min: 0.5750, Loss_max: 0.5750\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [104/125], Loss_min: 0.7320, Loss_max: 0.7320\n",
      "tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [105/125], Loss_min: 0.7635, Loss_max: 0.7635\n",
      "tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [106/125], Loss_min: 0.7479, Loss_max: 0.7479\n",
      "tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [107/125], Loss_min: 0.6678, Loss_max: 0.6678\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [108/125], Loss_min: 0.6831, Loss_max: 0.6831\n",
      "tensor(0.4399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [109/125], Loss_min: 0.4399, Loss_max: 0.4399\n",
      "tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [110/125], Loss_min: 0.5636, Loss_max: 0.5636\n",
      "tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [111/125], Loss_min: 0.6747, Loss_max: 0.6747\n",
      "tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [112/125], Loss_min: 0.5754, Loss_max: 0.5754\n",
      "tensor(0.4869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [113/125], Loss_min: 0.4869, Loss_max: 0.4869\n",
      "tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [114/125], Loss_min: 0.5739, Loss_max: 0.5739\n",
      "tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [115/125], Loss_min: 0.6714, Loss_max: 0.6714\n",
      "tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [116/125], Loss_min: 0.6125, Loss_max: 0.6125\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [117/125], Loss_min: 0.4755, Loss_max: 0.4755\n",
      "tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [118/125], Loss_min: 0.5665, Loss_max: 0.5665\n",
      "tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [119/125], Loss_min: 0.6241, Loss_max: 0.6241\n",
      "tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [120/125], Loss_min: 0.4914, Loss_max: 0.4914\n",
      "tensor(0.3725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [121/125], Loss_min: 0.3725, Loss_max: 0.3725\n",
      "tensor(0.4439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [122/125], Loss_min: 0.4439, Loss_max: 0.4439\n",
      "tensor(0.5135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [123/125], Loss_min: 0.5135, Loss_max: 0.5135\n",
      "tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [124/125], Loss_min: 0.5814, Loss_max: 0.5814\n",
      "tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [7/10], Step [125/125], Loss_min: 0.4623, Loss_max: 0.4623\n",
      "Epoch: 7\n",
      "tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [1/125], Loss_min: 0.3979, Loss_max: 0.3979\n",
      "tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [2/125], Loss_min: 0.8370, Loss_max: 0.8370\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [3/125], Loss_min: 0.7140, Loss_max: 0.7140\n",
      "tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [4/125], Loss_min: 0.6173, Loss_max: 0.6173\n",
      "tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [5/125], Loss_min: 0.5787, Loss_max: 0.5787\n",
      "tensor(0.5332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [6/125], Loss_min: 0.5332, Loss_max: 0.5332\n",
      "tensor(0.3928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [7/125], Loss_min: 0.3928, Loss_max: 0.3928\n",
      "tensor(0.3142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [8/125], Loss_min: 0.3142, Loss_max: 0.3142\n",
      "tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [9/125], Loss_min: 0.8519, Loss_max: 0.8519\n",
      "tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [10/125], Loss_min: 0.6226, Loss_max: 0.6226\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [11/125], Loss_min: 0.3650, Loss_max: 0.3650\n",
      "tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [12/125], Loss_min: 0.5417, Loss_max: 0.5417\n",
      "tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [13/125], Loss_min: 0.5311, Loss_max: 0.5311\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [14/125], Loss_min: 0.4993, Loss_max: 0.4993\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [15/125], Loss_min: 0.2687, Loss_max: 0.2687\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [16/125], Loss_min: 0.5204, Loss_max: 0.5204\n",
      "tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [17/125], Loss_min: 0.5322, Loss_max: 0.5322\n",
      "tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [18/125], Loss_min: 0.5574, Loss_max: 0.5574\n",
      "tensor(0.5433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [19/125], Loss_min: 0.5433, Loss_max: 0.5433\n",
      "tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [20/125], Loss_min: 0.5678, Loss_max: 0.5678\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [21/125], Loss_min: 0.5109, Loss_max: 0.5109\n",
      "tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [22/125], Loss_min: 0.6718, Loss_max: 0.6718\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [23/125], Loss_min: 0.5127, Loss_max: 0.5127\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [24/125], Loss_min: 0.3631, Loss_max: 0.3631\n",
      "tensor(0.4132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [25/125], Loss_min: 0.4132, Loss_max: 0.4132\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [26/125], Loss_min: 0.7088, Loss_max: 0.7088\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [27/125], Loss_min: 0.6874, Loss_max: 0.6874\n",
      "tensor(0.5259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [28/125], Loss_min: 0.5259, Loss_max: 0.5259\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [29/125], Loss_min: 0.5009, Loss_max: 0.5009\n",
      "tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [30/125], Loss_min: 0.8352, Loss_max: 0.8352\n",
      "tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [31/125], Loss_min: 0.8075, Loss_max: 0.8075\n",
      "tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [32/125], Loss_min: 0.7257, Loss_max: 0.7257\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [33/125], Loss_min: 0.3551, Loss_max: 0.3551\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [34/125], Loss_min: 0.3720, Loss_max: 0.3720\n",
      "tensor(0.5262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [35/125], Loss_min: 0.5262, Loss_max: 0.5262\n",
      "tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [36/125], Loss_min: 0.5619, Loss_max: 0.5619\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [37/125], Loss_min: 0.3349, Loss_max: 0.3349\n",
      "tensor(0.5327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [38/125], Loss_min: 0.5327, Loss_max: 0.5327\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [39/125], Loss_min: 0.5144, Loss_max: 0.5144\n",
      "tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [40/125], Loss_min: 0.6120, Loss_max: 0.6120\n",
      "tensor(0.4744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [41/125], Loss_min: 0.4744, Loss_max: 0.4744\n",
      "tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [42/125], Loss_min: 0.6611, Loss_max: 0.6611\n",
      "tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [43/125], Loss_min: 0.5741, Loss_max: 0.5741\n",
      "tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [44/125], Loss_min: 0.6387, Loss_max: 0.6387\n",
      "tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [45/125], Loss_min: 0.4940, Loss_max: 0.4940\n",
      "tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [46/125], Loss_min: 0.5463, Loss_max: 0.5463\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [47/125], Loss_min: 0.4492, Loss_max: 0.4492\n",
      "tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [48/125], Loss_min: 0.5386, Loss_max: 0.5386\n",
      "tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [49/125], Loss_min: 0.5322, Loss_max: 0.5322\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [50/125], Loss_min: 0.4125, Loss_max: 0.4125\n",
      "tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [51/125], Loss_min: 0.5851, Loss_max: 0.5851\n",
      "tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [52/125], Loss_min: 0.4441, Loss_max: 0.4441\n",
      "tensor(0.5120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [53/125], Loss_min: 0.5120, Loss_max: 0.5120\n",
      "tensor(0.3002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [54/125], Loss_min: 0.3002, Loss_max: 0.3002\n",
      "tensor(0.3715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [55/125], Loss_min: 0.3715, Loss_max: 0.3715\n",
      "tensor(0.4268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [56/125], Loss_min: 0.4268, Loss_max: 0.4268\n",
      "tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [57/125], Loss_min: 0.6020, Loss_max: 0.6020\n",
      "tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [58/125], Loss_min: 0.5233, Loss_max: 0.5233\n",
      "tensor(0.4691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [59/125], Loss_min: 0.4691, Loss_max: 0.4691\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [60/125], Loss_min: 0.3878, Loss_max: 0.3878\n",
      "tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [61/125], Loss_min: 0.8783, Loss_max: 0.8783\n",
      "tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [62/125], Loss_min: 0.7282, Loss_max: 0.7282\n",
      "tensor(0.3520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [63/125], Loss_min: 0.3520, Loss_max: 0.3520\n",
      "tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [64/125], Loss_min: 0.8117, Loss_max: 0.8117\n",
      "tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [65/125], Loss_min: 0.7691, Loss_max: 0.7691\n",
      "tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [66/125], Loss_min: 0.5697, Loss_max: 0.5697\n",
      "tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [67/125], Loss_min: 0.5255, Loss_max: 0.5255\n",
      "tensor(0.4563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [68/125], Loss_min: 0.4563, Loss_max: 0.4563\n",
      "tensor(0.4230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [69/125], Loss_min: 0.4230, Loss_max: 0.4230\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [70/125], Loss_min: 0.3176, Loss_max: 0.3176\n",
      "tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [71/125], Loss_min: 0.8826, Loss_max: 0.8826\n",
      "tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [72/125], Loss_min: 0.6565, Loss_max: 0.6565\n",
      "tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [73/125], Loss_min: 0.5984, Loss_max: 0.5984\n",
      "tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [74/125], Loss_min: 0.6037, Loss_max: 0.6037\n",
      "tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [75/125], Loss_min: 0.5907, Loss_max: 0.5907\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [76/125], Loss_min: 0.3559, Loss_max: 0.3559\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [77/125], Loss_min: 0.3669, Loss_max: 0.3669\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [78/125], Loss_min: 0.4321, Loss_max: 0.4321\n",
      "tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [79/125], Loss_min: 0.4644, Loss_max: 0.4644\n",
      "tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [80/125], Loss_min: 0.6046, Loss_max: 0.6046\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [81/125], Loss_min: 0.5315, Loss_max: 0.5315\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [82/125], Loss_min: 0.3398, Loss_max: 0.3398\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [83/125], Loss_min: 0.3514, Loss_max: 0.3514\n",
      "tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [84/125], Loss_min: 0.5707, Loss_max: 0.5707\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [85/125], Loss_min: 0.3428, Loss_max: 0.3428\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [86/125], Loss_min: 0.4107, Loss_max: 0.4107\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [87/125], Loss_min: 0.3724, Loss_max: 0.3724\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [88/125], Loss_min: 0.4842, Loss_max: 0.4842\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [89/125], Loss_min: 0.4530, Loss_max: 0.4530\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [90/125], Loss_min: 0.4294, Loss_max: 0.4294\n",
      "tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [91/125], Loss_min: 0.4644, Loss_max: 0.4644\n",
      "tensor(0.4601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [92/125], Loss_min: 0.4601, Loss_max: 0.4601\n",
      "tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [93/125], Loss_min: 0.6333, Loss_max: 0.6333\n",
      "tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [94/125], Loss_min: 0.5379, Loss_max: 0.5379\n",
      "tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [95/125], Loss_min: 0.4943, Loss_max: 0.4943\n",
      "tensor(0.4653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [96/125], Loss_min: 0.4653, Loss_max: 0.4653\n",
      "tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [97/125], Loss_min: 0.4361, Loss_max: 0.4361\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [98/125], Loss_min: 0.5042, Loss_max: 0.5042\n",
      "tensor(0.4241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [99/125], Loss_min: 0.4241, Loss_max: 0.4241\n",
      "tensor(0.5198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [100/125], Loss_min: 0.5198, Loss_max: 0.5198\n",
      "tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [101/125], Loss_min: 0.8099, Loss_max: 0.8099\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [102/125], Loss_min: 0.4994, Loss_max: 0.4994\n",
      "tensor(0.3922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [103/125], Loss_min: 0.3922, Loss_max: 0.3922\n",
      "tensor(0.4206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [104/125], Loss_min: 0.4206, Loss_max: 0.4206\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [105/125], Loss_min: 0.4026, Loss_max: 0.4026\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [106/125], Loss_min: 0.5880, Loss_max: 0.5880\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [107/125], Loss_min: 0.4994, Loss_max: 0.4994\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [108/125], Loss_min: 0.4767, Loss_max: 0.4767\n",
      "tensor(0.3862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [109/125], Loss_min: 0.3862, Loss_max: 0.3862\n",
      "tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [110/125], Loss_min: 0.5600, Loss_max: 0.5600\n",
      "tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [111/125], Loss_min: 0.9065, Loss_max: 0.9065\n",
      "tensor(0.4370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [112/125], Loss_min: 0.4370, Loss_max: 0.4370\n",
      "tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [113/125], Loss_min: 0.5611, Loss_max: 0.5611\n",
      "tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [114/125], Loss_min: 0.5476, Loss_max: 0.5476\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [115/125], Loss_min: 0.3598, Loss_max: 0.3598\n",
      "tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [116/125], Loss_min: 0.5031, Loss_max: 0.5031\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [117/125], Loss_min: 0.4027, Loss_max: 0.4027\n",
      "tensor(0.3296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [118/125], Loss_min: 0.3296, Loss_max: 0.3296\n",
      "tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [119/125], Loss_min: 0.5822, Loss_max: 0.5822\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [120/125], Loss_min: 0.3160, Loss_max: 0.3160\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [121/125], Loss_min: 0.3707, Loss_max: 0.3707\n",
      "tensor(0.4161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [122/125], Loss_min: 0.4161, Loss_max: 0.4161\n",
      "tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [123/125], Loss_min: 0.5841, Loss_max: 0.5841\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [124/125], Loss_min: 0.3681, Loss_max: 0.3681\n",
      "tensor(0.3234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [8/10], Step [125/125], Loss_min: 0.3234, Loss_max: 0.3234\n",
      "Epoch: 8\n",
      "tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [1/125], Loss_min: 0.6532, Loss_max: 0.6532\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [2/125], Loss_min: 0.5194, Loss_max: 0.5194\n",
      "tensor(0.5156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [3/125], Loss_min: 0.5156, Loss_max: 0.5156\n",
      "tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [4/125], Loss_min: 0.5499, Loss_max: 0.5499\n",
      "tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [5/125], Loss_min: 0.5347, Loss_max: 0.5347\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [6/125], Loss_min: 0.3174, Loss_max: 0.3174\n",
      "tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [7/125], Loss_min: 0.5381, Loss_max: 0.5381\n",
      "tensor(0.4636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [8/125], Loss_min: 0.4636, Loss_max: 0.4636\n",
      "tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [9/125], Loss_min: 0.3617, Loss_max: 0.3617\n",
      "tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [10/125], Loss_min: 0.5846, Loss_max: 0.5846\n",
      "tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [11/125], Loss_min: 0.5090, Loss_max: 0.5090\n",
      "tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [12/125], Loss_min: 0.4683, Loss_max: 0.4683\n",
      "tensor(0.5439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [13/125], Loss_min: 0.5439, Loss_max: 0.5439\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [14/125], Loss_min: 0.3918, Loss_max: 0.3918\n",
      "tensor(0.2953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [15/125], Loss_min: 0.2953, Loss_max: 0.2953\n",
      "tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [16/125], Loss_min: 0.5788, Loss_max: 0.5788\n",
      "tensor(0.3283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [17/125], Loss_min: 0.3283, Loss_max: 0.3283\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [18/125], Loss_min: 0.4688, Loss_max: 0.4688\n",
      "tensor(0.4860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [19/125], Loss_min: 0.4860, Loss_max: 0.4860\n",
      "tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [20/125], Loss_min: 0.4892, Loss_max: 0.4892\n",
      "tensor(0.5183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [21/125], Loss_min: 0.5183, Loss_max: 0.5183\n",
      "tensor(0.4612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [22/125], Loss_min: 0.4612, Loss_max: 0.4612\n",
      "tensor(0.4488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [23/125], Loss_min: 0.4488, Loss_max: 0.4488\n",
      "tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [24/125], Loss_min: 0.4748, Loss_max: 0.4748\n",
      "tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [25/125], Loss_min: 0.7020, Loss_max: 0.7020\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [26/125], Loss_min: 0.2734, Loss_max: 0.2734\n",
      "tensor(0.3926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [27/125], Loss_min: 0.3926, Loss_max: 0.3926\n",
      "tensor(0.3534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [28/125], Loss_min: 0.3534, Loss_max: 0.3534\n",
      "tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [29/125], Loss_min: 0.4960, Loss_max: 0.4960\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [30/125], Loss_min: 0.2899, Loss_max: 0.2899\n",
      "tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [31/125], Loss_min: 0.4240, Loss_max: 0.4240\n",
      "tensor(0.5548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [32/125], Loss_min: 0.5548, Loss_max: 0.5548\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [33/125], Loss_min: 0.3896, Loss_max: 0.3896\n",
      "tensor(0.4444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [34/125], Loss_min: 0.4444, Loss_max: 0.4444\n",
      "tensor(0.4249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [35/125], Loss_min: 0.4249, Loss_max: 0.4249\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [36/125], Loss_min: 0.3242, Loss_max: 0.3242\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [37/125], Loss_min: 0.3950, Loss_max: 0.3950\n",
      "tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [38/125], Loss_min: 0.4833, Loss_max: 0.4833\n",
      "tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [39/125], Loss_min: 0.7361, Loss_max: 0.7361\n",
      "tensor(0.4823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [40/125], Loss_min: 0.4823, Loss_max: 0.4823\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [41/125], Loss_min: 0.3331, Loss_max: 0.3331\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [42/125], Loss_min: 0.3331, Loss_max: 0.3331\n",
      "tensor(0.3543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [43/125], Loss_min: 0.3543, Loss_max: 0.3543\n",
      "tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [44/125], Loss_min: 0.3619, Loss_max: 0.3619\n",
      "tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [45/125], Loss_min: 0.4352, Loss_max: 0.4352\n",
      "tensor(0.4637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [46/125], Loss_min: 0.4637, Loss_max: 0.4637\n",
      "tensor(0.4284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [47/125], Loss_min: 0.4284, Loss_max: 0.4284\n",
      "tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [48/125], Loss_min: 0.5309, Loss_max: 0.5309\n",
      "tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [49/125], Loss_min: 0.3342, Loss_max: 0.3342\n",
      "tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [50/125], Loss_min: 0.5910, Loss_max: 0.5910\n",
      "tensor(0.4293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [51/125], Loss_min: 0.4293, Loss_max: 0.4293\n",
      "tensor(0.3652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [52/125], Loss_min: 0.3652, Loss_max: 0.3652\n",
      "tensor(0.4292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [53/125], Loss_min: 0.4292, Loss_max: 0.4292\n",
      "tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [54/125], Loss_min: 0.6337, Loss_max: 0.6337\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [55/125], Loss_min: 0.4731, Loss_max: 0.4731\n",
      "tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [56/125], Loss_min: 0.5844, Loss_max: 0.5844\n",
      "tensor(0.3121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [57/125], Loss_min: 0.3121, Loss_max: 0.3121\n",
      "tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [58/125], Loss_min: 0.4948, Loss_max: 0.4948\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [59/125], Loss_min: 0.4761, Loss_max: 0.4761\n",
      "tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [60/125], Loss_min: 0.5884, Loss_max: 0.5884\n",
      "tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [61/125], Loss_min: 0.6625, Loss_max: 0.6625\n",
      "tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [62/125], Loss_min: 0.5356, Loss_max: 0.5356\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [63/125], Loss_min: 0.3367, Loss_max: 0.3367\n",
      "tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [64/125], Loss_min: 0.8655, Loss_max: 0.8655\n",
      "tensor(0.4949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [65/125], Loss_min: 0.4949, Loss_max: 0.4949\n",
      "tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [66/125], Loss_min: 0.4446, Loss_max: 0.4446\n",
      "tensor(0.4245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [67/125], Loss_min: 0.4245, Loss_max: 0.4245\n",
      "tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [68/125], Loss_min: 0.6108, Loss_max: 0.6108\n",
      "tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [69/125], Loss_min: 0.2410, Loss_max: 0.2410\n",
      "tensor(0.4486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [70/125], Loss_min: 0.4486, Loss_max: 0.4486\n",
      "tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [71/125], Loss_min: 0.4199, Loss_max: 0.4199\n",
      "tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [72/125], Loss_min: 0.6258, Loss_max: 0.6258\n",
      "tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [73/125], Loss_min: 0.5358, Loss_max: 0.5358\n",
      "tensor(0.4732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [74/125], Loss_min: 0.4732, Loss_max: 0.4732\n",
      "tensor(0.3668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [75/125], Loss_min: 0.3668, Loss_max: 0.3668\n",
      "tensor(0.3408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [76/125], Loss_min: 0.3408, Loss_max: 0.3408\n",
      "tensor(0.3429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [77/125], Loss_min: 0.3429, Loss_max: 0.3429\n",
      "tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [78/125], Loss_min: 0.5263, Loss_max: 0.5263\n",
      "tensor(0.4062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [79/125], Loss_min: 0.4062, Loss_max: 0.4062\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [80/125], Loss_min: 0.3340, Loss_max: 0.3340\n",
      "tensor(0.4738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [81/125], Loss_min: 0.4738, Loss_max: 0.4738\n",
      "tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [82/125], Loss_min: 0.7698, Loss_max: 0.7698\n",
      "tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [83/125], Loss_min: 0.3914, Loss_max: 0.3914\n",
      "tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [84/125], Loss_min: 0.4422, Loss_max: 0.4422\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [85/125], Loss_min: 0.4290, Loss_max: 0.4290\n",
      "tensor(0.4615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [86/125], Loss_min: 0.4615, Loss_max: 0.4615\n",
      "tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [87/125], Loss_min: 0.5875, Loss_max: 0.5875\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [88/125], Loss_min: 0.3950, Loss_max: 0.3950\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [89/125], Loss_min: 0.3708, Loss_max: 0.3708\n",
      "tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [90/125], Loss_min: 0.5233, Loss_max: 0.5233\n",
      "tensor(0.4735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [91/125], Loss_min: 0.4735, Loss_max: 0.4735\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [92/125], Loss_min: 0.4410, Loss_max: 0.4410\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [93/125], Loss_min: 0.3159, Loss_max: 0.3159\n",
      "tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [94/125], Loss_min: 0.5819, Loss_max: 0.5819\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [95/125], Loss_min: 0.3721, Loss_max: 0.3721\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [96/125], Loss_min: 0.4290, Loss_max: 0.4290\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [97/125], Loss_min: 0.3176, Loss_max: 0.3176\n",
      "tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [98/125], Loss_min: 0.6487, Loss_max: 0.6487\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [99/125], Loss_min: 0.3437, Loss_max: 0.3437\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [100/125], Loss_min: 0.3847, Loss_max: 0.3847\n",
      "tensor(0.5441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [101/125], Loss_min: 0.5441, Loss_max: 0.5441\n",
      "tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [102/125], Loss_min: 0.5604, Loss_max: 0.5604\n",
      "tensor(0.3613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [103/125], Loss_min: 0.3613, Loss_max: 0.3613\n",
      "tensor(0.4067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [104/125], Loss_min: 0.4067, Loss_max: 0.4067\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [105/125], Loss_min: 0.5220, Loss_max: 0.5220\n",
      "tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [106/125], Loss_min: 0.4849, Loss_max: 0.4849\n",
      "tensor(0.4419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [107/125], Loss_min: 0.4419, Loss_max: 0.4419\n",
      "tensor(0.3683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [108/125], Loss_min: 0.3683, Loss_max: 0.3683\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [109/125], Loss_min: 0.4250, Loss_max: 0.4250\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [110/125], Loss_min: 0.6369, Loss_max: 0.6369\n",
      "tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [111/125], Loss_min: 0.4333, Loss_max: 0.4333\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [112/125], Loss_min: 0.3737, Loss_max: 0.3737\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [113/125], Loss_min: 0.5033, Loss_max: 0.5033\n",
      "tensor(0.3718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [114/125], Loss_min: 0.3718, Loss_max: 0.3718\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [115/125], Loss_min: 0.3938, Loss_max: 0.3938\n",
      "tensor(0.4521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [116/125], Loss_min: 0.4521, Loss_max: 0.4521\n",
      "tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [117/125], Loss_min: 0.3090, Loss_max: 0.3090\n",
      "tensor(0.4168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [118/125], Loss_min: 0.4168, Loss_max: 0.4168\n",
      "tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [119/125], Loss_min: 0.4866, Loss_max: 0.4866\n",
      "tensor(0.4666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [120/125], Loss_min: 0.4666, Loss_max: 0.4666\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [121/125], Loss_min: 0.3573, Loss_max: 0.3573\n",
      "tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [122/125], Loss_min: 0.3330, Loss_max: 0.3330\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [123/125], Loss_min: 0.3582, Loss_max: 0.3582\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [124/125], Loss_min: 0.3228, Loss_max: 0.3228\n",
      "tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [9/10], Step [125/125], Loss_min: 0.4821, Loss_max: 0.4821\n",
      "Epoch: 9\n",
      "tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [1/125], Loss_min: 0.3521, Loss_max: 0.3521\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [2/125], Loss_min: 0.5026, Loss_max: 0.5026\n",
      "tensor(0.4155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [3/125], Loss_min: 0.4155, Loss_max: 0.4155\n",
      "tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [4/125], Loss_min: 0.7449, Loss_max: 0.7449\n",
      "tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [5/125], Loss_min: 0.5481, Loss_max: 0.5481\n",
      "tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [6/125], Loss_min: 0.6091, Loss_max: 0.6091\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [7/125], Loss_min: 0.3206, Loss_max: 0.3206\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [8/125], Loss_min: 0.2179, Loss_max: 0.2179\n",
      "tensor(0.4077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [9/125], Loss_min: 0.4077, Loss_max: 0.4077\n",
      "tensor(0.2636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [10/125], Loss_min: 0.2636, Loss_max: 0.2636\n",
      "tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [11/125], Loss_min: 0.4099, Loss_max: 0.4099\n",
      "tensor(0.3448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [12/125], Loss_min: 0.3448, Loss_max: 0.3448\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [13/125], Loss_min: 0.2688, Loss_max: 0.2688\n",
      "tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [14/125], Loss_min: 0.4959, Loss_max: 0.4959\n",
      "tensor(0.3015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [15/125], Loss_min: 0.3015, Loss_max: 0.3015\n",
      "tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [16/125], Loss_min: 0.6145, Loss_max: 0.6145\n",
      "tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [17/125], Loss_min: 0.3980, Loss_max: 0.3980\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [18/125], Loss_min: 0.3886, Loss_max: 0.3886\n",
      "tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [19/125], Loss_min: 0.5644, Loss_max: 0.5644\n",
      "tensor(0.3685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [20/125], Loss_min: 0.3685, Loss_max: 0.3685\n",
      "tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [21/125], Loss_min: 0.8250, Loss_max: 0.8250\n",
      "tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [22/125], Loss_min: 0.6244, Loss_max: 0.6244\n",
      "tensor(0.3731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [23/125], Loss_min: 0.3731, Loss_max: 0.3731\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [24/125], Loss_min: 0.4566, Loss_max: 0.4566\n",
      "tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [25/125], Loss_min: 0.6987, Loss_max: 0.6987\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [26/125], Loss_min: 0.4327, Loss_max: 0.4327\n",
      "tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [27/125], Loss_min: 0.7211, Loss_max: 0.7211\n",
      "tensor(0.3296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [28/125], Loss_min: 0.3296, Loss_max: 0.3296\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [29/125], Loss_min: 0.3148, Loss_max: 0.3148\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [30/125], Loss_min: 0.3160, Loss_max: 0.3160\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [31/125], Loss_min: 0.3612, Loss_max: 0.3612\n",
      "tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [32/125], Loss_min: 0.3515, Loss_max: 0.3515\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [33/125], Loss_min: 0.3423, Loss_max: 0.3423\n",
      "tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [34/125], Loss_min: 0.5086, Loss_max: 0.5086\n",
      "tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [35/125], Loss_min: 0.5257, Loss_max: 0.5257\n",
      "tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [36/125], Loss_min: 0.4631, Loss_max: 0.4631\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [37/125], Loss_min: 0.3716, Loss_max: 0.3716\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [38/125], Loss_min: 0.3997, Loss_max: 0.3997\n",
      "tensor(0.3605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [39/125], Loss_min: 0.3605, Loss_max: 0.3605\n",
      "tensor(0.4806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [40/125], Loss_min: 0.4806, Loss_max: 0.4806\n",
      "tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [41/125], Loss_min: 0.5502, Loss_max: 0.5502\n",
      "tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [42/125], Loss_min: 0.6742, Loss_max: 0.6742\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [43/125], Loss_min: 0.3763, Loss_max: 0.3763\n",
      "tensor(0.4088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [44/125], Loss_min: 0.4088, Loss_max: 0.4088\n",
      "tensor(0.4542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [45/125], Loss_min: 0.4542, Loss_max: 0.4542\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [46/125], Loss_min: 0.3819, Loss_max: 0.3819\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [47/125], Loss_min: 0.3537, Loss_max: 0.3537\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [48/125], Loss_min: 0.3734, Loss_max: 0.3734\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [49/125], Loss_min: 0.3721, Loss_max: 0.3721\n",
      "tensor(0.1976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [50/125], Loss_min: 0.1976, Loss_max: 0.1976\n",
      "tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [51/125], Loss_min: 0.6674, Loss_max: 0.6674\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [52/125], Loss_min: 0.3654, Loss_max: 0.3654\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [53/125], Loss_min: 0.3202, Loss_max: 0.3202\n",
      "tensor(0.4357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [54/125], Loss_min: 0.4357, Loss_max: 0.4357\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [55/125], Loss_min: 0.3737, Loss_max: 0.3737\n",
      "tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [56/125], Loss_min: 0.5684, Loss_max: 0.5684\n",
      "tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [57/125], Loss_min: 0.4387, Loss_max: 0.4387\n",
      "tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [58/125], Loss_min: 0.6180, Loss_max: 0.6180\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [59/125], Loss_min: 0.3844, Loss_max: 0.3844\n",
      "tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [60/125], Loss_min: 0.7506, Loss_max: 0.7506\n",
      "tensor(0.4218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [61/125], Loss_min: 0.4218, Loss_max: 0.4218\n",
      "tensor(0.3854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [62/125], Loss_min: 0.3854, Loss_max: 0.3854\n",
      "tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [63/125], Loss_min: 0.4194, Loss_max: 0.4194\n",
      "tensor(0.3664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [64/125], Loss_min: 0.3664, Loss_max: 0.3664\n",
      "tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [65/125], Loss_min: 0.3840, Loss_max: 0.3840\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [66/125], Loss_min: 0.4153, Loss_max: 0.4153\n",
      "tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [67/125], Loss_min: 0.4592, Loss_max: 0.4592\n",
      "tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [68/125], Loss_min: 0.4099, Loss_max: 0.4099\n",
      "tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [69/125], Loss_min: 0.4251, Loss_max: 0.4251\n",
      "tensor(0.5229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [70/125], Loss_min: 0.5229, Loss_max: 0.5229\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [71/125], Loss_min: 0.2795, Loss_max: 0.2795\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [72/125], Loss_min: 0.5713, Loss_max: 0.5713\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [73/125], Loss_min: 0.4965, Loss_max: 0.4965\n",
      "tensor(0.3301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [74/125], Loss_min: 0.3301, Loss_max: 0.3301\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [75/125], Loss_min: 0.4761, Loss_max: 0.4761\n",
      "tensor(0.4299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [76/125], Loss_min: 0.4299, Loss_max: 0.4299\n",
      "tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [77/125], Loss_min: 0.6306, Loss_max: 0.6306\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [78/125], Loss_min: 0.4505, Loss_max: 0.4505\n",
      "tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [79/125], Loss_min: 0.4144, Loss_max: 0.4144\n",
      "tensor(0.3247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [80/125], Loss_min: 0.3247, Loss_max: 0.3247\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [81/125], Loss_min: 0.3508, Loss_max: 0.3508\n",
      "tensor(0.3880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [82/125], Loss_min: 0.3880, Loss_max: 0.3880\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [83/125], Loss_min: 0.2624, Loss_max: 0.2624\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [84/125], Loss_min: 0.4842, Loss_max: 0.4842\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [85/125], Loss_min: 0.3540, Loss_max: 0.3540\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [86/125], Loss_min: 0.2938, Loss_max: 0.2938\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [87/125], Loss_min: 0.3690, Loss_max: 0.3690\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [88/125], Loss_min: 0.2409, Loss_max: 0.2409\n",
      "tensor(0.4536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [89/125], Loss_min: 0.4536, Loss_max: 0.4536\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [90/125], Loss_min: 0.3460, Loss_max: 0.3460\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [91/125], Loss_min: 0.3199, Loss_max: 0.3199\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [92/125], Loss_min: 0.3997, Loss_max: 0.3997\n",
      "tensor(0.5279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [93/125], Loss_min: 0.5279, Loss_max: 0.5279\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [94/125], Loss_min: 0.5880, Loss_max: 0.5880\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [95/125], Loss_min: 0.2610, Loss_max: 0.2610\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [96/125], Loss_min: 0.2941, Loss_max: 0.2941\n",
      "tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [97/125], Loss_min: 0.5485, Loss_max: 0.5485\n",
      "tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [98/125], Loss_min: 0.6181, Loss_max: 0.6181\n",
      "tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [99/125], Loss_min: 0.6174, Loss_max: 0.6174\n",
      "tensor(0.4534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [100/125], Loss_min: 0.4534, Loss_max: 0.4534\n",
      "tensor(0.3260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [101/125], Loss_min: 0.3260, Loss_max: 0.3260\n",
      "tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [102/125], Loss_min: 0.8194, Loss_max: 0.8194\n",
      "tensor(0.4610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [103/125], Loss_min: 0.4610, Loss_max: 0.4610\n",
      "tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [104/125], Loss_min: 0.5854, Loss_max: 0.5854\n",
      "tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [105/125], Loss_min: 0.4762, Loss_max: 0.4762\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [106/125], Loss_min: 0.5271, Loss_max: 0.5271\n",
      "tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [107/125], Loss_min: 0.6457, Loss_max: 0.6457\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [108/125], Loss_min: 0.4391, Loss_max: 0.4391\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [109/125], Loss_min: 0.5598, Loss_max: 0.5598\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [110/125], Loss_min: 0.3770, Loss_max: 0.3770\n",
      "tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [111/125], Loss_min: 0.5070, Loss_max: 0.5070\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [112/125], Loss_min: 0.7860, Loss_max: 0.7860\n",
      "tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [113/125], Loss_min: 0.5557, Loss_max: 0.5557\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [114/125], Loss_min: 0.3611, Loss_max: 0.3611\n",
      "tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [115/125], Loss_min: 0.3070, Loss_max: 0.3070\n",
      "tensor(0.4133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [116/125], Loss_min: 0.4133, Loss_max: 0.4133\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [117/125], Loss_min: 0.3996, Loss_max: 0.3996\n",
      "tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [118/125], Loss_min: 0.4683, Loss_max: 0.4683\n",
      "tensor(0.4483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [119/125], Loss_min: 0.4483, Loss_max: 0.4483\n",
      "tensor(0.3722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [120/125], Loss_min: 0.3722, Loss_max: 0.3722\n",
      "tensor(0.3783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [121/125], Loss_min: 0.3783, Loss_max: 0.3783\n",
      "tensor(0.4658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [122/125], Loss_min: 0.4658, Loss_max: 0.4658\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [123/125], Loss_min: 0.4737, Loss_max: 0.4737\n",
      "tensor(0.5251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [124/125], Loss_min: 0.5251, Loss_max: 0.5251\n",
      "tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Epoch [10/10], Step [125/125], Loss_min: 0.5925, Loss_max: 0.5925\n",
      "Entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "modelo.train()\n",
    "lambda_=0\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        # Forward\n",
    "        inputs=inputs.float().to(\"cuda:0\")\n",
    "        labels=labels.float().to(\"cuda:0\")\n",
    "        outputs, series, prior, _ = modelo(inputs)\n",
    "        prior=[j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600) for j in prior]\n",
    "        loss_min = min_loss(outputs,prior,series, labels,lambda_)\n",
    "        loss_max = max_loss(outputs,prior,series, labels,lambda_)\n",
    "\n",
    "        # Backward y optimización\n",
    "        loss_min.backward(retain_graph=True)\n",
    "        loss_max.backward()\n",
    "        #clip_gradients(modelo, max_norm=1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        del inputs \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        #warmup_and_decay_learning_rate(optimizer, epoch, 1e-2,15 , num_epochs)\n",
    "        # Printear resultados\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss_min: {loss_min.item():.4f}, Loss_max: {loss_max.item():.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo.cuda()\n",
    "a_x,a_label=next(iter(dataloader))\n",
    "a_x_cuda=a_x.float().to(\"cuda:0\")\n",
    "modelo.eval()\n",
    "output,series_aux,prior_aux,_=modelo(a_x_cuda)\n",
    "\n",
    "\n",
    "output=output.squeeze().cpu().detach().numpy()\n",
    "series_aux=series_aux[0].squeeze().cpu().detach().numpy()\n",
    "prior_aux=prior_aux[0].squeeze().cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe04de1dcd0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a_label[31])\n",
    "plt.plot(output[31],\"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer entrenamiento tercera parte (con lr schedule, pero sin clipping)\n",
    "\n",
    "Es exactamente lo mismo que antes, con el vector invertido, pero con lr schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model import AnomalyTransformer\n",
    "import gc\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinne(lenght=100,amp=1,sf=0.1,f=2,phase=0):\n",
    "    x = torch.arange(0,lenght*sf, sf)\n",
    "    return amp*torch.sin(x*sf*2*torch.pi/f+phase)\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    #esta es la clase de los datos que seran secuencias de senos de freq aleatoria \n",
    "    def __init__(self,lenght,num_samples,amp_random=True,freq_random=True,phase_random=True,sf=0.1):\n",
    "        super().__init__()\n",
    "        self.amp_random=amp_random\n",
    "        self.freq_random=freq_random\n",
    "        self.phase_random=phase_random\n",
    "        self.num_samples=num_samples\n",
    "        self.sf=0.1\n",
    "        self.lenght=lenght\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        amp=float(np.random.randint(1,300,1)*0.01)\n",
    "        phase=np.random.randint(0,100,1)*0.02\n",
    "        f=np.random.randint(1,200,1)*0.01\n",
    "        y=sinne(lenght=self.lenght,amp=amp,sf=0.1,f=f,phase=phase)\n",
    "        y=y.unsqueeze(-1)\n",
    "        return y\n",
    "\n",
    "\n",
    "def warmup_and_decay_learning_rate(optimizer, epoch, init_lr, warmup_epochs, total_epochs):\n",
    "    if epoch <= warmup_epochs:\n",
    "        lr = init_lr * (epoch / warmup_epochs)\n",
    "        print('Warmup: Updating learning rate to {}'.format(lr))\n",
    "    else:\n",
    "        decay_epochs = total_epochs - warmup_epochs\n",
    "        decay_rate = 1e-7+(epoch - warmup_epochs) / decay_epochs\n",
    "        lr = init_lr * (1 - decay_rate)\n",
    "        print('Decay: Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def clip_gradients(model, max_norm, norm_type=2):\n",
    "    \"\"\"\n",
    "    Clip gradients of the model parameters.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        max_norm (float): The maximum allowed norm for the gradients.\n",
    "        norm_type (float): The type of the norm calculation (default: 2 for L2 norm).\n",
    "    \"\"\"\n",
    "    # Recupera todos los gradientes de los parámetros del modelo\n",
    "    gradients = [param.grad for param in model.parameters() if param.grad is not None]\n",
    "\n",
    "    # Calcula la norma total de los gradientes\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(grad, norm_type) for grad in gradients]), norm_type)\n",
    "\n",
    "    # Calcula el factor de escalado para recortar los gradientes\n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    if clip_coef < 1:\n",
    "        # Aplica el factor de escalado a los gradientes\n",
    "        for grad in gradients:\n",
    "            grad.mul_(clip_coef)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def layer_association_discrepancy( Pl, Sl):\n",
    "#     #Pl y Sl viene con dimension B,Head,Height,Width\n",
    "#     B,Head,Height,_ = Pl.shape\n",
    "#     result=torch.zeros(B,Head,Height)\n",
    "#     for batch_size in range(B):\n",
    "#         for head_size in range(Head):\n",
    "#             rowwise_kl = lambda row: (F.kl_div(Pl[batch_size,head_size,row, :], Sl[batch_size,head_size,row, :]) + F.kl_div(Sl[batch_size,head_size,row, :], Pl[batch_size,head_size,row, :]))\n",
    "#             ad_vector = torch.concat([rowwise_kl(row).unsqueeze(0) for row in range(Height)])\n",
    "#             result[batch_size,head_size,:]=ad_vector\n",
    "#     return result\n",
    "\n",
    "def my_kl_loss(p, q):\n",
    "    res = p * (torch.log(p + 0.0001) - torch.log(q + 0.0001))\n",
    "    return torch.mean(torch.sum(res, dim=-1), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# def layer_association_discrepancy(Pl, Sl):\n",
    "#     # Pl y Sl vienen con dimension B, Head, Height, Width\n",
    "#     B, Head, Height, _ = Pl.shape\n",
    "\n",
    "#     # Calcular el KL Divergence entre Pl y Sl a lo largo del último eje (Width)\n",
    "#     kl1 = F.kl_div(Pl, Sl, reduction='none').mean(dim=-1)\n",
    "#     kl2 = F.kl_div(Sl, Pl, reduction='none').mean(dim=-1)\n",
    "\n",
    "#     # Sumar los KL Divergence calculados\n",
    "#     ad_vector = kl1 + kl2\n",
    "\n",
    "#     return ad_vector\n",
    "\n",
    "def layer_association_discrepancy(Pl, Sl):\n",
    "    # Pl y Sl vienen con dimension B, Head, Height, Width\n",
    "    B, Head, Height, _ = Pl.shape\n",
    "\n",
    "    # Calcular el KL Divergence entre Pl y Sl a lo largo del último eje (Width)\n",
    "    kl1 = my_kl_loss(Pl.view(B, Head, Height, -1), Sl.view(B, Head, Height, -1))\n",
    "    kl2 = my_kl_loss(Sl.view(B, Head, Height, -1), Pl.view(B, Head, Height, -1))\n",
    "\n",
    "    # Sumar los KL Divergence calculados\n",
    "    ad_vector = kl1 + kl2\n",
    "\n",
    "    return ad_vector\n",
    "\n",
    "\n",
    "\n",
    "def association_discrepancy( P_list, S_list):\n",
    "\n",
    "    return torch.stack([layer_association_discrepancy(j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600),i) for i, j in zip(S_list,P_list)]).mean(axis=[0])\n",
    "\n",
    "# (1 / len(P_list)) * sum(\n",
    "#         [\n",
    "#             torch.mean(layer_association_discrepancy(P, S),axis=0)#hacemos la media sobre todas las cabezas\n",
    "#             for P, S in zip(P_list, S_list)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "def loss_function( x_hat, P_list, S_list, lambda_, x):\n",
    "    frob_norm = ((x_hat - x)**2).mean()   #usamo MSE  #torch.linalg.matrix_norm(x_hat - x, ord=\"fro\").mean() #norm L2 \n",
    "    diss_norm=torch.mean(association_discrepancy(P_list, S_list))#torch.linalg.norm(, ord=1) # le añado esto para que se normaliza acros muestras \n",
    "    print(frob_norm,diss_norm)\n",
    "    return frob_norm - (lambda_* diss_norm) #hacemos la suma de todos los valores absolutos y dividimos todo por el batchsize\n",
    "    \n",
    "\n",
    "def min_loss(output,P_layers,S_layers, x,lambda_):\n",
    "    P_list = P_layers\n",
    "    S_list = [S.detach() for S in S_layers]\n",
    "    lambda_ = -lambda_\n",
    "    return loss_function(output, P_list, S_list, lambda_, x)\n",
    "\n",
    "def max_loss(output,P_layers,S_layers,x,lambda_):\n",
    "    P_list = [P.detach() for P in P_layers]\n",
    "    S_list = S_layers\n",
    "    lambda_ = lambda_\n",
    "    return loss_function(output, P_list, S_list, lambda_, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=600\n",
    "data=Data(win_size,4000)\n",
    "\n",
    "dataloader=DataLoader(data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnomalyTransformer(\n",
       "  (embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (inner_attention): AnomalyAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (key_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (value_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (sigma_projection): Linear(in_features=32, out_features=2, bias=True)\n",
       "          (out_projection): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo=AnomalyTransformer.AnomalyTransformer(win_size, 1, 1, d_model=32, n_heads=2, e_layers=2, d_ff=32,\n",
    "                          dropout=0.0, activation='gelu', output_attention=True)\n",
    "modelo.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "tensor(1.6430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [1/125], Loss_min: 10.5373, Loss_max: -7.2514\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [2/125], Loss_min: 11.0423, Loss_max: -7.2161\n",
      "tensor(1.3403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [3/125], Loss_min: 10.3564, Loss_max: -7.6757\n",
      "tensor(1.3345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [4/125], Loss_min: 10.3169, Loss_max: -7.6478\n",
      "tensor(1.4668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [5/125], Loss_min: 10.5039, Loss_max: -7.5703\n",
      "tensor(1.1823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [6/125], Loss_min: 10.1147, Loss_max: -7.7501\n",
      "tensor(1.8188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [7/125], Loss_min: 10.9472, Loss_max: -7.3097\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [8/125], Loss_min: 10.8659, Loss_max: -7.4876\n",
      "tensor(1.5490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [9/125], Loss_min: 10.5679, Loss_max: -7.4699\n",
      "tensor(1.4334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [10/125], Loss_min: 10.3568, Loss_max: -7.4900\n",
      "tensor(1.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [11/125], Loss_min: 10.0610, Loss_max: -7.7304\n",
      "tensor(1.3682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [12/125], Loss_min: 10.3599, Loss_max: -7.6236\n",
      "tensor(1.2916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [13/125], Loss_min: 10.3111, Loss_max: -7.7279\n",
      "tensor(1.4388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [14/125], Loss_min: 10.5147, Loss_max: -7.6372\n",
      "tensor(1.2690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [15/125], Loss_min: 10.2303, Loss_max: -7.6923\n",
      "tensor(1.4827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [16/125], Loss_min: 10.4815, Loss_max: -7.5161\n",
      "tensor(1.1508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [17/125], Loss_min: 9.9901, Loss_max: -7.6885\n",
      "tensor(1.3456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [18/125], Loss_min: 10.2683, Loss_max: -7.5772\n",
      "tensor(1.4215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [19/125], Loss_min: 10.4220, Loss_max: -7.5789\n",
      "tensor(1.4910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [20/125], Loss_min: 10.4812, Loss_max: -7.4992\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [21/125], Loss_min: 10.0446, Loss_max: -7.7631\n",
      "tensor(1.3826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [22/125], Loss_min: 10.4025, Loss_max: -7.6374\n",
      "tensor(1.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [23/125], Loss_min: 10.7617, Loss_max: -7.4576\n",
      "tensor(1.4127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [24/125], Loss_min: 10.4677, Loss_max: -7.6424\n",
      "tensor(1.3315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [25/125], Loss_min: 10.2962, Loss_max: -7.6333\n",
      "tensor(1.4098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [26/125], Loss_min: 10.4394, Loss_max: -7.6199\n",
      "tensor(1.4915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [27/125], Loss_min: 10.5508, Loss_max: -7.5679\n",
      "tensor(1.2280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [28/125], Loss_min: 10.1681, Loss_max: -7.7121\n",
      "tensor(1.5743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [29/125], Loss_min: 10.6669, Loss_max: -7.5183\n",
      "tensor(1.3312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [30/125], Loss_min: 10.2901, Loss_max: -7.6277\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [31/125], Loss_min: 9.7926, Loss_max: -7.8715\n",
      "tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [32/125], Loss_min: 9.6453, Loss_max: -7.9019\n",
      "tensor(2.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [33/125], Loss_min: 11.3717, Loss_max: -7.1429\n",
      "tensor(1.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [34/125], Loss_min: 10.2262, Loss_max: -7.7153\n",
      "tensor(1.1853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [35/125], Loss_min: 10.1008, Loss_max: -7.7302\n",
      "tensor(1.2484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [36/125], Loss_min: 10.1722, Loss_max: -7.6754\n",
      "tensor(1.5601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [37/125], Loss_min: 10.5685, Loss_max: -7.4484\n",
      "tensor(1.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [38/125], Loss_min: 10.7966, Loss_max: -7.3250\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [39/125], Loss_min: 10.7127, Loss_max: -7.5172\n",
      "tensor(1.4427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [40/125], Loss_min: 10.5293, Loss_max: -7.6438\n",
      "tensor(1.3558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [41/125], Loss_min: 10.3097, Loss_max: -7.5980\n",
      "tensor(1.2401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [42/125], Loss_min: 10.1769, Loss_max: -7.6967\n",
      "tensor(1.3824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [43/125], Loss_min: 10.3541, Loss_max: -7.5893\n",
      "tensor(1.3170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [44/125], Loss_min: 10.2906, Loss_max: -7.6565\n",
      "tensor(1.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [45/125], Loss_min: 10.8988, Loss_max: -7.4264\n",
      "tensor(1.5206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [46/125], Loss_min: 10.5024, Loss_max: -7.4612\n",
      "tensor(1.4828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [47/125], Loss_min: 10.5482, Loss_max: -7.5825\n",
      "tensor(1.5748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [48/125], Loss_min: 10.6580, Loss_max: -7.5083\n",
      "tensor(1.1100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [49/125], Loss_min: 9.9880, Loss_max: -7.7680\n",
      "tensor(1.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [50/125], Loss_min: 9.9781, Loss_max: -7.8197\n",
      "tensor(1.5893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [51/125], Loss_min: 10.6814, Loss_max: -7.5028\n",
      "tensor(1.6784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [52/125], Loss_min: 10.8143, Loss_max: -7.4575\n",
      "tensor(1.4517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [53/125], Loss_min: 10.4943, Loss_max: -7.5908\n",
      "tensor(1.3414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [54/125], Loss_min: 10.3677, Loss_max: -7.6849\n",
      "tensor(1.4746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [55/125], Loss_min: 10.4901, Loss_max: -7.5409\n",
      "tensor(1.8464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [56/125], Loss_min: 10.8568, Loss_max: -7.1640\n",
      "tensor(1.3265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [57/125], Loss_min: 10.2777, Loss_max: -7.6247\n",
      "tensor(1.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [58/125], Loss_min: 9.9351, Loss_max: -7.7863\n",
      "tensor(1.4636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [59/125], Loss_min: 10.4270, Loss_max: -7.4998\n",
      "tensor(1.3169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [60/125], Loss_min: 10.3180, Loss_max: -7.6842\n",
      "tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [61/125], Loss_min: 10.2156, Loss_max: -7.7155\n",
      "tensor(1.6644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [62/125], Loss_min: 10.8423, Loss_max: -7.5134\n",
      "tensor(1.3633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [63/125], Loss_min: 10.3806, Loss_max: -7.6540\n",
      "tensor(1.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [64/125], Loss_min: 10.2639, Loss_max: -7.6287\n",
      "tensor(1.4524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [65/125], Loss_min: 10.4214, Loss_max: -7.5165\n",
      "tensor(1.6357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [66/125], Loss_min: 10.6635, Loss_max: -7.3922\n",
      "tensor(1.3512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [67/125], Loss_min: 10.3863, Loss_max: -7.6838\n",
      "tensor(1.4940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [68/125], Loss_min: 10.5810, Loss_max: -7.5930\n",
      "tensor(1.1514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [69/125], Loss_min: 10.0540, Loss_max: -7.7512\n",
      "tensor(1.3652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [70/125], Loss_min: 10.3499, Loss_max: -7.6194\n",
      "tensor(1.4663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [71/125], Loss_min: 10.5520, Loss_max: -7.6193\n",
      "tensor(1.6186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [72/125], Loss_min: 10.6960, Loss_max: -7.4588\n",
      "tensor(1.3692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [73/125], Loss_min: 10.3622, Loss_max: -7.6237\n",
      "tensor(2.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [74/125], Loss_min: 11.3203, Loss_max: -7.0277\n",
      "tensor(1.6787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [75/125], Loss_min: 10.8168, Loss_max: -7.4595\n",
      "tensor(1.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [76/125], Loss_min: 9.9835, Loss_max: -7.8611\n",
      "tensor(1.2998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [77/125], Loss_min: 10.2687, Loss_max: -7.6690\n",
      "tensor(1.4384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [78/125], Loss_min: 10.4901, Loss_max: -7.6133\n",
      "tensor(1.3034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [79/125], Loss_min: 10.2872, Loss_max: -7.6804\n",
      "tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [80/125], Loss_min: 10.4793, Loss_max: -7.6810\n",
      "tensor(1.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [81/125], Loss_min: 10.5327, Loss_max: -7.5594\n",
      "tensor(1.5161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [82/125], Loss_min: 10.5729, Loss_max: -7.5407\n",
      "tensor(1.4371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [83/125], Loss_min: 10.4041, Loss_max: -7.5299\n",
      "tensor(1.3973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [84/125], Loss_min: 10.3959, Loss_max: -7.6012\n",
      "tensor(1.6351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [85/125], Loss_min: 10.6513, Loss_max: -7.3811\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [86/125], Loss_min: 10.7183, Loss_max: -7.5073\n",
      "tensor(1.5042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [87/125], Loss_min: 10.5812, Loss_max: -7.5728\n",
      "tensor(1.3789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [88/125], Loss_min: 10.3638, Loss_max: -7.6059\n",
      "tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [89/125], Loss_min: 10.0738, Loss_max: -7.7322\n",
      "tensor(1.5547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [90/125], Loss_min: 10.6571, Loss_max: -7.5478\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [91/125], Loss_min: 10.0271, Loss_max: -7.7224\n",
      "tensor(1.2935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [92/125], Loss_min: 10.2346, Loss_max: -7.6476\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [93/125], Loss_min: 10.0283, Loss_max: -7.7803\n",
      "tensor(1.2039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [94/125], Loss_min: 10.1937, Loss_max: -7.7859\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [95/125], Loss_min: 10.2203, Loss_max: -7.6968\n",
      "tensor(1.5053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [96/125], Loss_min: 10.5726, Loss_max: -7.5619\n",
      "tensor(1.2975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [97/125], Loss_min: 10.3026, Loss_max: -7.7076\n",
      "tensor(1.3618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [98/125], Loss_min: 10.3584, Loss_max: -7.6348\n",
      "tensor(1.5325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [99/125], Loss_min: 10.5362, Loss_max: -7.4712\n",
      "tensor(1.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [100/125], Loss_min: 10.5631, Loss_max: -7.5899\n",
      "tensor(2.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [101/125], Loss_min: 11.2093, Loss_max: -7.1262\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [102/125], Loss_min: 10.1223, Loss_max: -7.7639\n",
      "tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [103/125], Loss_min: 10.2135, Loss_max: -7.7219\n",
      "tensor(1.6472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [104/125], Loss_min: 10.8254, Loss_max: -7.5309\n",
      "tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [105/125], Loss_min: 10.2792, Loss_max: -7.6110\n",
      "tensor(1.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [106/125], Loss_min: 10.8571, Loss_max: -7.2823\n",
      "tensor(1.4990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [107/125], Loss_min: 10.5873, Loss_max: -7.5893\n",
      "tensor(1.3848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [108/125], Loss_min: 10.3593, Loss_max: -7.5896\n",
      "tensor(1.4740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [109/125], Loss_min: 10.5197, Loss_max: -7.5716\n",
      "tensor(1.6663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [110/125], Loss_min: 10.8099, Loss_max: -7.4773\n",
      "tensor(1.4004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [111/125], Loss_min: 10.3513, Loss_max: -7.5506\n",
      "tensor(1.5700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [112/125], Loss_min: 10.6549, Loss_max: -7.5150\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [113/125], Loss_min: 10.7776, Loss_max: -7.5282\n",
      "tensor(1.5972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [114/125], Loss_min: 10.6138, Loss_max: -7.4193\n",
      "tensor(1.3318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [115/125], Loss_min: 10.3008, Loss_max: -7.6373\n",
      "tensor(1.3377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [116/125], Loss_min: 10.3185, Loss_max: -7.6430\n",
      "tensor(1.2056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [117/125], Loss_min: 10.1766, Loss_max: -7.7655\n",
      "tensor(1.6908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [118/125], Loss_min: 10.9163, Loss_max: -7.5348\n",
      "tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [119/125], Loss_min: 10.3525, Loss_max: -7.6824\n",
      "tensor(1.4996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [120/125], Loss_min: 10.6075, Loss_max: -7.6083\n",
      "tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [121/125], Loss_min: 10.3256, Loss_max: -7.6912\n",
      "tensor(1.8261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [122/125], Loss_min: 11.0356, Loss_max: -7.3833\n",
      "tensor(1.5073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [123/125], Loss_min: 10.6170, Loss_max: -7.6023\n",
      "tensor(1.2736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [124/125], Loss_min: 10.2916, Loss_max: -7.7444\n",
      "tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/15], Step [125/125], Loss_min: 10.2365, Loss_max: -7.6021\n",
      "Epoch: 1\n",
      "tensor(1.2917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [1/125], Loss_min: 10.2597, Loss_max: -7.6762\n",
      "tensor(1.5277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [2/125], Loss_min: 10.4965, Loss_max: -7.4411\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [3/125], Loss_min: 9.9992, Loss_max: -8.2897\n",
      "tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [4/125], Loss_min: 9.8894, Loss_max: -8.7049\n",
      "tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [5/125], Loss_min: 9.8869, Loss_max: -8.8406\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [6/125], Loss_min: 10.0784, Loss_max: -8.7165\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [7/125], Loss_min: 10.5163, Loss_max: -9.1482\n",
      "tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [8/125], Loss_min: 10.8782, Loss_max: -9.3078\n",
      "tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [9/125], Loss_min: 11.0208, Loss_max: -9.3954\n",
      "tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.9656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [10/125], Loss_min: 10.8736, Loss_max: -9.0577\n",
      "tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [11/125], Loss_min: 11.0690, Loss_max: -9.7288\n",
      "tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.1837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [12/125], Loss_min: 10.8172, Loss_max: -9.5503\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [13/125], Loss_min: 11.0029, Loss_max: -10.0025\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [14/125], Loss_min: 10.9717, Loss_max: -10.2548\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.5998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [15/125], Loss_min: 10.9865, Loss_max: -10.2131\n",
      "tensor(0.3985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [16/125], Loss_min: 10.6644, Loss_max: -9.8674\n",
      "tensor(0.4909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [17/125], Loss_min: 11.5073, Loss_max: -10.5255\n",
      "tensor(0.3647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [18/125], Loss_min: 10.7221, Loss_max: -9.9928\n",
      "tensor(0.4722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [19/125], Loss_min: 11.1483, Loss_max: -10.2038\n",
      "tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [20/125], Loss_min: 11.5407, Loss_max: -10.4984\n",
      "tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [21/125], Loss_min: 11.1875, Loss_max: -10.2426\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.4523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [22/125], Loss_min: 10.7886, Loss_max: -10.1161\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [23/125], Loss_min: 11.3853, Loss_max: -10.4721\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [24/125], Loss_min: 11.5159, Loss_max: -10.8356\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [25/125], Loss_min: 10.9566, Loss_max: -10.2632\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [26/125], Loss_min: 11.0813, Loss_max: -10.5008\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [27/125], Loss_min: 11.0135, Loss_max: -10.4220\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [28/125], Loss_min: 11.5559, Loss_max: -10.8157\n",
      "tensor(0.3454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [29/125], Loss_min: 11.0788, Loss_max: -10.3879\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [30/125], Loss_min: 11.0861, Loss_max: -10.4971\n",
      "tensor(0.2621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [31/125], Loss_min: 11.1892, Loss_max: -10.6650\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [32/125], Loss_min: 11.5186, Loss_max: -10.9273\n",
      "tensor(0.2922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [33/125], Loss_min: 11.2431, Loss_max: -10.6587\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [34/125], Loss_min: 10.6075, Loss_max: -10.1668\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [35/125], Loss_min: 11.3421, Loss_max: -10.5409\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [36/125], Loss_min: 11.6354, Loss_max: -10.6898\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.0369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [37/125], Loss_min: 11.4255, Loss_max: -10.6483\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.7710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [38/125], Loss_min: 11.0388, Loss_max: -10.5032\n",
      "tensor(0.2275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [39/125], Loss_min: 11.3848, Loss_max: -10.9297\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.2917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [40/125], Loss_min: 11.5374, Loss_max: -11.0460\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [41/125], Loss_min: 11.6917, Loss_max: -11.1843\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [42/125], Loss_min: 11.3262, Loss_max: -10.9603\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [43/125], Loss_min: 11.9283, Loss_max: -11.2274\n",
      "tensor(0.2352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [44/125], Loss_min: 11.9928, Loss_max: -11.5224\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [45/125], Loss_min: 11.8688, Loss_max: -11.1523\n",
      "tensor(0.1652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(10.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [46/125], Loss_min: 11.1550, Loss_max: -10.8246\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [47/125], Loss_min: 11.7269, Loss_max: -11.3022\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [48/125], Loss_min: 11.6513, Loss_max: -11.2151\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [49/125], Loss_min: 11.4857, Loss_max: -11.1765\n",
      "tensor(0.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [50/125], Loss_min: 11.5527, Loss_max: -11.2548\n",
      "tensor(0.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [51/125], Loss_min: 11.7530, Loss_max: -11.3726\n",
      "tensor(0.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [52/125], Loss_min: 11.8913, Loss_max: -11.5330\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.4021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [53/125], Loss_min: 11.5635, Loss_max: -11.2407\n",
      "tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [54/125], Loss_min: 11.9269, Loss_max: -11.5118\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [55/125], Loss_min: 11.9604, Loss_max: -11.6971\n",
      "tensor(0.1909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [56/125], Loss_min: 12.2674, Loss_max: -11.8856\n",
      "tensor(0.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [57/125], Loss_min: 12.0847, Loss_max: -11.7099\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.0609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [58/125], Loss_min: 12.1862, Loss_max: -11.9356\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [59/125], Loss_min: 12.3924, Loss_max: -11.9048\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [60/125], Loss_min: 12.0224, Loss_max: -11.7741\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [61/125], Loss_min: 12.0954, Loss_max: -11.8853\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [62/125], Loss_min: 12.2366, Loss_max: -12.0563\n",
      "tensor(0.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [63/125], Loss_min: 12.0825, Loss_max: -11.8761\n",
      "tensor(0.1503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(11.9969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [64/125], Loss_min: 12.1471, Loss_max: -11.8466\n",
      "tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [65/125], Loss_min: 12.6134, Loss_max: -12.3842\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [66/125], Loss_min: 12.5595, Loss_max: -12.2973\n",
      "tensor(0.1832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [67/125], Loss_min: 12.3677, Loss_max: -12.0014\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.3395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [68/125], Loss_min: 12.4920, Loss_max: -12.1870\n",
      "tensor(0.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [69/125], Loss_min: 12.5485, Loss_max: -12.4021\n",
      "tensor(0.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.4951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [70/125], Loss_min: 12.5767, Loss_max: -12.4135\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [71/125], Loss_min: 12.8187, Loss_max: -12.6484\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [72/125], Loss_min: 12.9325, Loss_max: -12.6662\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.6602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.6602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [73/125], Loss_min: 12.7617, Loss_max: -12.5587\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [74/125], Loss_min: 12.9811, Loss_max: -12.8099\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [75/125], Loss_min: 13.1314, Loss_max: -12.8814\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.0169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [76/125], Loss_min: 13.0965, Loss_max: -12.9372\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [77/125], Loss_min: 13.2052, Loss_max: -13.0526\n",
      "tensor(0.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [78/125], Loss_min: 13.2935, Loss_max: -13.1417\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [79/125], Loss_min: 13.3028, Loss_max: -13.1371\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [80/125], Loss_min: 13.2651, Loss_max: -13.1240\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [81/125], Loss_min: 13.4578, Loss_max: -13.3116\n",
      "tensor(0.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.4643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [82/125], Loss_min: 13.5454, Loss_max: -13.3831\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.5143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [83/125], Loss_min: 13.5882, Loss_max: -13.4405\n",
      "tensor(0.2901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [84/125], Loss_min: 13.9902, Loss_max: -13.4100\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [85/125], Loss_min: 13.7341, Loss_max: -13.5626\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [86/125], Loss_min: 13.7957, Loss_max: -13.5614\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [87/125], Loss_min: 13.7091, Loss_max: -13.5719\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [88/125], Loss_min: 14.3330, Loss_max: -13.7053\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [89/125], Loss_min: 14.0414, Loss_max: -13.9042\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.6773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [90/125], Loss_min: 13.7450, Loss_max: -13.6095\n",
      "tensor(0.1960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [91/125], Loss_min: 14.3250, Loss_max: -13.9330\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [92/125], Loss_min: 14.0985, Loss_max: -13.9000\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [93/125], Loss_min: 13.9092, Loss_max: -13.7349\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.1930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [94/125], Loss_min: 14.2629, Loss_max: -14.1231\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(13.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [95/125], Loss_min: 14.0042, Loss_max: -13.8126\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [96/125], Loss_min: 14.4622, Loss_max: -14.2365\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.0636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [97/125], Loss_min: 14.1454, Loss_max: -13.9818\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [98/125], Loss_min: 14.4481, Loss_max: -14.2829\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [99/125], Loss_min: 14.6216, Loss_max: -14.4612\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [100/125], Loss_min: 14.7580, Loss_max: -14.6175\n",
      "tensor(0.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [101/125], Loss_min: 14.6031, Loss_max: -14.2709\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [102/125], Loss_min: 14.6847, Loss_max: -14.4887\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [103/125], Loss_min: 14.6745, Loss_max: -14.3999\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [104/125], Loss_min: 15.0494, Loss_max: -14.2225\n",
      "tensor(0.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [105/125], Loss_min: 14.8308, Loss_max: -14.6697\n",
      "tensor(0.0561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [106/125], Loss_min: 14.6050, Loss_max: -14.4928\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [107/125], Loss_min: 14.6248, Loss_max: -14.5139\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [108/125], Loss_min: 14.7930, Loss_max: -14.6047\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [109/125], Loss_min: 14.7372, Loss_max: -14.5966\n",
      "tensor(0.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [110/125], Loss_min: 14.7758, Loss_max: -14.6290\n",
      "tensor(0.1344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.5519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [111/125], Loss_min: 14.6863, Loss_max: -14.4176\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [112/125], Loss_min: 14.8309, Loss_max: -14.7170\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [113/125], Loss_min: 15.0958, Loss_max: -14.9414\n",
      "tensor(0.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [114/125], Loss_min: 14.9010, Loss_max: -14.6683\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [115/125], Loss_min: 14.9184, Loss_max: -14.8008\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [116/125], Loss_min: 14.8208, Loss_max: -14.7195\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [117/125], Loss_min: 14.8449, Loss_max: -14.7210\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [118/125], Loss_min: 14.8686, Loss_max: -14.7529\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [119/125], Loss_min: 15.0438, Loss_max: -14.9253\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [120/125], Loss_min: 15.0561, Loss_max: -14.7419\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [121/125], Loss_min: 14.9106, Loss_max: -14.7437\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [122/125], Loss_min: 15.0383, Loss_max: -14.9468\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [123/125], Loss_min: 14.9799, Loss_max: -14.9016\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [124/125], Loss_min: 15.1022, Loss_max: -15.0063\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.0016666666666666666\n",
      "Epoch [2/15], Step [125/125], Loss_min: 14.6554, Loss_max: -14.5573\n",
      "Epoch: 2\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [1/125], Loss_min: 14.8160, Loss_max: -14.6894\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [2/125], Loss_min: 14.7047, Loss_max: -14.6184\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [3/125], Loss_min: 14.9567, Loss_max: -14.8577\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [4/125], Loss_min: 15.0767, Loss_max: -14.9937\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [5/125], Loss_min: 15.1476, Loss_max: -15.0466\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [6/125], Loss_min: 14.9757, Loss_max: -14.8940\n",
      "tensor(0.2838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [7/125], Loss_min: 15.3113, Loss_max: -14.7438\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [8/125], Loss_min: 15.1100, Loss_max: -14.9999\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [9/125], Loss_min: 14.9675, Loss_max: -14.8496\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [10/125], Loss_min: 15.3345, Loss_max: -15.2165\n",
      "tensor(0.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [11/125], Loss_min: 15.3316, Loss_max: -15.2253\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [12/125], Loss_min: 15.1735, Loss_max: -15.0341\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [13/125], Loss_min: 15.0941, Loss_max: -14.9701\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [14/125], Loss_min: 14.9740, Loss_max: -14.8654\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [15/125], Loss_min: 15.2970, Loss_max: -15.1986\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [16/125], Loss_min: 15.1426, Loss_max: -15.0596\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [17/125], Loss_min: 15.0742, Loss_max: -15.0008\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [18/125], Loss_min: 15.2059, Loss_max: -15.0594\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [19/125], Loss_min: 15.2502, Loss_max: -15.1253\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [20/125], Loss_min: 15.3748, Loss_max: -15.3037\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.6939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [21/125], Loss_min: 14.7612, Loss_max: -14.6265\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [22/125], Loss_min: 15.1723, Loss_max: -15.0640\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [23/125], Loss_min: 15.2026, Loss_max: -15.1277\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(14.8579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [24/125], Loss_min: 14.9098, Loss_max: -14.8060\n",
      "tensor(0.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [25/125], Loss_min: 15.1852, Loss_max: -15.0112\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [26/125], Loss_min: 15.3167, Loss_max: -15.2168\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [27/125], Loss_min: 15.4198, Loss_max: -15.3092\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [28/125], Loss_min: 15.2658, Loss_max: -15.1698\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [29/125], Loss_min: 15.1964, Loss_max: -15.1252\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [30/125], Loss_min: 15.1376, Loss_max: -15.0502\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [31/125], Loss_min: 15.3853, Loss_max: -15.1851\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [32/125], Loss_min: 15.2713, Loss_max: -15.1426\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [33/125], Loss_min: 15.1027, Loss_max: -14.9628\n",
      "tensor(0.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [34/125], Loss_min: 15.2773, Loss_max: -15.1382\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [35/125], Loss_min: 15.1989, Loss_max: -15.0660\n",
      "tensor(0.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [36/125], Loss_min: 15.3794, Loss_max: -15.0394\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [37/125], Loss_min: 15.1045, Loss_max: -15.0331\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [38/125], Loss_min: 15.3543, Loss_max: -15.2567\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [39/125], Loss_min: 15.5692, Loss_max: -15.4615\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [40/125], Loss_min: 15.6512, Loss_max: -15.5333\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [41/125], Loss_min: 15.6766, Loss_max: -15.5544\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [42/125], Loss_min: 15.2501, Loss_max: -15.1544\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [43/125], Loss_min: 15.7400, Loss_max: -15.6643\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [44/125], Loss_min: 15.3749, Loss_max: -15.3187\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [45/125], Loss_min: 15.2034, Loss_max: -15.1247\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [46/125], Loss_min: 15.4070, Loss_max: -15.3568\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [47/125], Loss_min: 15.4346, Loss_max: -15.3669\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [48/125], Loss_min: 15.3834, Loss_max: -15.3149\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [49/125], Loss_min: 15.7593, Loss_max: -15.6692\n",
      "tensor(0.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [50/125], Loss_min: 15.2424, Loss_max: -15.0584\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [51/125], Loss_min: 15.3295, Loss_max: -15.2489\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [52/125], Loss_min: 15.6165, Loss_max: -15.5399\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [53/125], Loss_min: 15.2746, Loss_max: -15.2201\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [54/125], Loss_min: 15.4877, Loss_max: -15.3930\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [55/125], Loss_min: 15.1811, Loss_max: -15.1189\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [56/125], Loss_min: 15.5984, Loss_max: -15.5401\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [57/125], Loss_min: 15.3377, Loss_max: -15.2922\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [58/125], Loss_min: 15.5765, Loss_max: -15.5234\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [59/125], Loss_min: 15.4906, Loss_max: -15.4371\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [60/125], Loss_min: 15.4150, Loss_max: -15.3652\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [61/125], Loss_min: 15.7133, Loss_max: -15.6554\n",
      "tensor(0.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [62/125], Loss_min: 15.4610, Loss_max: -15.3135\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [63/125], Loss_min: 15.5878, Loss_max: -15.4542\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [64/125], Loss_min: 15.3517, Loss_max: -15.2880\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [65/125], Loss_min: 15.6799, Loss_max: -15.6001\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [66/125], Loss_min: 15.2182, Loss_max: -15.1731\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [67/125], Loss_min: 15.2144, Loss_max: -15.1687\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [68/125], Loss_min: 15.5133, Loss_max: -15.4633\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [69/125], Loss_min: 15.6199, Loss_max: -15.5521\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [70/125], Loss_min: 15.5411, Loss_max: -15.4790\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [71/125], Loss_min: 15.4417, Loss_max: -15.3896\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [72/125], Loss_min: 15.2054, Loss_max: -15.1566\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [73/125], Loss_min: 15.6788, Loss_max: -15.6331\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [74/125], Loss_min: 15.4401, Loss_max: -15.3902\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [75/125], Loss_min: 15.5504, Loss_max: -15.4423\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [76/125], Loss_min: 15.4076, Loss_max: -15.3509\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [77/125], Loss_min: 15.4680, Loss_max: -15.4251\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.1929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [78/125], Loss_min: 15.2237, Loss_max: -15.1622\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [79/125], Loss_min: 15.2943, Loss_max: -15.2487\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [80/125], Loss_min: 15.6558, Loss_max: -15.6073\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [81/125], Loss_min: 15.6342, Loss_max: -15.5817\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [82/125], Loss_min: 15.3910, Loss_max: -15.3287\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [83/125], Loss_min: 15.6006, Loss_max: -15.5566\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [84/125], Loss_min: 15.7049, Loss_max: -15.5627\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [85/125], Loss_min: 15.6536, Loss_max: -15.6004\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [86/125], Loss_min: 15.4391, Loss_max: -15.3932\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [87/125], Loss_min: 15.6248, Loss_max: -15.5785\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [88/125], Loss_min: 15.5627, Loss_max: -15.5243\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [89/125], Loss_min: 15.5576, Loss_max: -15.5166\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [90/125], Loss_min: 15.2514, Loss_max: -15.2047\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [91/125], Loss_min: 15.6487, Loss_max: -15.6098\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [92/125], Loss_min: 15.6830, Loss_max: -15.6323\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [93/125], Loss_min: 15.4836, Loss_max: -15.4417\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [94/125], Loss_min: 15.4535, Loss_max: -15.4116\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [95/125], Loss_min: 15.4394, Loss_max: -15.3965\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [96/125], Loss_min: 15.6626, Loss_max: -15.6198\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [97/125], Loss_min: 15.4226, Loss_max: -15.3794\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [98/125], Loss_min: 15.4839, Loss_max: -15.4369\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [99/125], Loss_min: 15.5965, Loss_max: -15.4970\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [100/125], Loss_min: 15.5799, Loss_max: -15.5302\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [101/125], Loss_min: 15.4011, Loss_max: -15.3698\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [102/125], Loss_min: 15.4265, Loss_max: -15.3804\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [103/125], Loss_min: 15.6021, Loss_max: -15.5675\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [104/125], Loss_min: 15.5845, Loss_max: -15.5463\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [105/125], Loss_min: 15.6227, Loss_max: -15.5823\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [106/125], Loss_min: 15.6298, Loss_max: -15.5865\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.2171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [107/125], Loss_min: 15.2370, Loss_max: -15.1973\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [108/125], Loss_min: 15.8183, Loss_max: -15.7758\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [109/125], Loss_min: 15.5824, Loss_max: -15.5437\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [110/125], Loss_min: 15.6400, Loss_max: -15.5942\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [111/125], Loss_min: 15.6038, Loss_max: -15.5576\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [112/125], Loss_min: 15.7680, Loss_max: -15.7258\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [113/125], Loss_min: 15.7797, Loss_max: -15.7382\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [114/125], Loss_min: 15.6037, Loss_max: -15.5121\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [115/125], Loss_min: 15.6802, Loss_max: -15.6382\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [116/125], Loss_min: 15.5940, Loss_max: -15.5360\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [117/125], Loss_min: 15.8593, Loss_max: -15.8042\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [118/125], Loss_min: 15.7601, Loss_max: -15.7144\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [119/125], Loss_min: 15.6417, Loss_max: -15.6009\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [120/125], Loss_min: 15.4982, Loss_max: -15.4578\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [121/125], Loss_min: 15.6577, Loss_max: -15.5637\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [122/125], Loss_min: 15.7236, Loss_max: -15.6875\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [123/125], Loss_min: 15.6534, Loss_max: -15.6087\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [124/125], Loss_min: 15.6888, Loss_max: -15.6486\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [3/15], Step [125/125], Loss_min: 15.4985, Loss_max: -15.4670\n",
      "Epoch: 3\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [1/125], Loss_min: 15.6188, Loss_max: -15.5813\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [2/125], Loss_min: 15.7208, Loss_max: -15.6884\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [3/125], Loss_min: 15.7136, Loss_max: -15.6718\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [4/125], Loss_min: 15.6636, Loss_max: -15.6282\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [5/125], Loss_min: 15.6663, Loss_max: -15.6361\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [6/125], Loss_min: 15.6133, Loss_max: -15.5772\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [7/125], Loss_min: 15.8366, Loss_max: -15.7879\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [8/125], Loss_min: 15.6839, Loss_max: -15.6514\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [9/125], Loss_min: 15.8296, Loss_max: -15.7594\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [10/125], Loss_min: 15.7826, Loss_max: -15.7569\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [11/125], Loss_min: 15.7223, Loss_max: -15.6791\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [12/125], Loss_min: 15.7882, Loss_max: -15.7570\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [13/125], Loss_min: 15.7000, Loss_max: -15.6678\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [14/125], Loss_min: 15.8359, Loss_max: -15.7904\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [15/125], Loss_min: 15.7853, Loss_max: -15.7543\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [16/125], Loss_min: 15.7452, Loss_max: -15.6729\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [17/125], Loss_min: 15.7532, Loss_max: -15.7163\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [18/125], Loss_min: 15.7284, Loss_max: -15.7019\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [19/125], Loss_min: 15.7257, Loss_max: -15.6567\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [20/125], Loss_min: 15.7531, Loss_max: -15.7157\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [21/125], Loss_min: 15.8011, Loss_max: -15.7689\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [22/125], Loss_min: 15.6019, Loss_max: -15.5626\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [23/125], Loss_min: 15.8534, Loss_max: -15.8204\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [24/125], Loss_min: 15.7255, Loss_max: -15.6966\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [25/125], Loss_min: 15.8877, Loss_max: -15.8352\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [26/125], Loss_min: 15.7314, Loss_max: -15.7028\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [27/125], Loss_min: 15.7233, Loss_max: -15.6832\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [28/125], Loss_min: 15.8621, Loss_max: -15.8179\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [29/125], Loss_min: 15.8187, Loss_max: -15.7875\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [30/125], Loss_min: 15.8173, Loss_max: -15.7620\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.5168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [31/125], Loss_min: 15.5337, Loss_max: -15.5000\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [32/125], Loss_min: 15.8790, Loss_max: -15.8385\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [33/125], Loss_min: 15.7563, Loss_max: -15.6630\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [34/125], Loss_min: 15.8212, Loss_max: -15.7879\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [35/125], Loss_min: 15.7614, Loss_max: -15.7101\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [36/125], Loss_min: 15.8356, Loss_max: -15.7767\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [37/125], Loss_min: 15.8216, Loss_max: -15.7917\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [38/125], Loss_min: 15.6917, Loss_max: -15.6620\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [39/125], Loss_min: 15.9062, Loss_max: -15.8736\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [40/125], Loss_min: 15.7184, Loss_max: -15.6849\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [41/125], Loss_min: 15.8167, Loss_max: -15.7748\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [42/125], Loss_min: 15.8447, Loss_max: -15.7932\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [43/125], Loss_min: 15.7722, Loss_max: -15.7307\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [44/125], Loss_min: 15.8592, Loss_max: -15.8268\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [45/125], Loss_min: 15.7218, Loss_max: -15.6692\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [46/125], Loss_min: 15.9376, Loss_max: -15.9046\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [47/125], Loss_min: 15.8850, Loss_max: -15.8434\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [48/125], Loss_min: 15.7952, Loss_max: -15.7699\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [49/125], Loss_min: 15.7637, Loss_max: -15.7384\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [50/125], Loss_min: 15.9531, Loss_max: -15.9188\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [51/125], Loss_min: 15.9141, Loss_max: -15.8658\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [52/125], Loss_min: 15.8671, Loss_max: -15.8347\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [53/125], Loss_min: 15.7217, Loss_max: -15.6944\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [54/125], Loss_min: 15.7778, Loss_max: -15.7498\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [55/125], Loss_min: 15.8248, Loss_max: -15.7946\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [56/125], Loss_min: 15.7617, Loss_max: -15.7337\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [57/125], Loss_min: 15.9506, Loss_max: -15.9145\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [58/125], Loss_min: 15.8585, Loss_max: -15.8323\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [59/125], Loss_min: 15.9054, Loss_max: -15.8640\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [60/125], Loss_min: 15.8413, Loss_max: -15.8178\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [61/125], Loss_min: 15.8442, Loss_max: -15.7995\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [62/125], Loss_min: 15.7851, Loss_max: -15.7631\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [63/125], Loss_min: 16.0053, Loss_max: -15.9672\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [64/125], Loss_min: 15.9217, Loss_max: -15.8973\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [65/125], Loss_min: 15.7110, Loss_max: -15.6467\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [66/125], Loss_min: 15.8702, Loss_max: -15.8435\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [67/125], Loss_min: 15.8604, Loss_max: -15.8167\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [68/125], Loss_min: 15.9114, Loss_max: -15.8804\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [69/125], Loss_min: 15.9016, Loss_max: -15.8569\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [70/125], Loss_min: 15.8318, Loss_max: -15.8139\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [71/125], Loss_min: 15.8271, Loss_max: -15.8073\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [72/125], Loss_min: 15.9594, Loss_max: -15.9326\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [73/125], Loss_min: 15.9540, Loss_max: -15.9316\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [74/125], Loss_min: 15.8771, Loss_max: -15.8469\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [75/125], Loss_min: 15.9626, Loss_max: -15.9363\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [76/125], Loss_min: 15.7758, Loss_max: -15.7202\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [77/125], Loss_min: 15.8967, Loss_max: -15.8709\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [78/125], Loss_min: 15.9158, Loss_max: -15.8910\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [79/125], Loss_min: 15.9435, Loss_max: -15.9191\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [80/125], Loss_min: 15.8420, Loss_max: -15.8173\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [81/125], Loss_min: 15.8846, Loss_max: -15.8586\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [82/125], Loss_min: 15.9104, Loss_max: -15.8817\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [83/125], Loss_min: 15.9652, Loss_max: -15.9042\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [84/125], Loss_min: 15.9280, Loss_max: -15.9059\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [85/125], Loss_min: 15.8323, Loss_max: -15.8035\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [86/125], Loss_min: 15.8162, Loss_max: -15.7962\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [87/125], Loss_min: 15.7916, Loss_max: -15.7667\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [88/125], Loss_min: 15.9630, Loss_max: -15.9303\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [89/125], Loss_min: 15.8173, Loss_max: -15.7881\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [90/125], Loss_min: 15.8598, Loss_max: -15.8319\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [91/125], Loss_min: 15.9358, Loss_max: -15.9142\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [92/125], Loss_min: 16.0118, Loss_max: -15.9827\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [93/125], Loss_min: 15.9319, Loss_max: -15.9075\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [94/125], Loss_min: 15.8289, Loss_max: -15.8099\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [95/125], Loss_min: 15.9388, Loss_max: -15.9188\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [96/125], Loss_min: 15.9025, Loss_max: -15.8781\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [97/125], Loss_min: 15.9124, Loss_max: -15.8959\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [98/125], Loss_min: 15.9235, Loss_max: -15.9037\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [99/125], Loss_min: 15.8324, Loss_max: -15.8163\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [100/125], Loss_min: 15.9239, Loss_max: -15.9050\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [101/125], Loss_min: 15.9280, Loss_max: -15.9057\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [102/125], Loss_min: 15.8363, Loss_max: -15.8208\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [103/125], Loss_min: 15.8661, Loss_max: -15.8395\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [104/125], Loss_min: 15.9307, Loss_max: -15.9136\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [105/125], Loss_min: 15.8831, Loss_max: -15.8603\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [106/125], Loss_min: 15.9796, Loss_max: -15.9559\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [107/125], Loss_min: 15.9002, Loss_max: -15.8823\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [108/125], Loss_min: 15.9017, Loss_max: -15.8655\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [109/125], Loss_min: 15.8713, Loss_max: -15.8506\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [110/125], Loss_min: 15.9104, Loss_max: -15.8844\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [111/125], Loss_min: 15.9384, Loss_max: -15.9228\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [112/125], Loss_min: 15.8519, Loss_max: -15.8340\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [113/125], Loss_min: 15.9171, Loss_max: -15.9010\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [114/125], Loss_min: 15.8650, Loss_max: -15.8461\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [115/125], Loss_min: 15.9507, Loss_max: -15.9336\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [116/125], Loss_min: 15.8819, Loss_max: -15.8690\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [117/125], Loss_min: 16.0025, Loss_max: -15.9778\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [118/125], Loss_min: 15.9603, Loss_max: -15.9328\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [119/125], Loss_min: 15.9521, Loss_max: -15.9281\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [120/125], Loss_min: 15.9613, Loss_max: -15.9425\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [121/125], Loss_min: 15.8905, Loss_max: -15.8709\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [122/125], Loss_min: 15.8800, Loss_max: -15.8656\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [123/125], Loss_min: 15.9529, Loss_max: -15.9358\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [124/125], Loss_min: 15.9739, Loss_max: -15.9313\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.005\n",
      "Epoch [4/15], Step [125/125], Loss_min: 15.9323, Loss_max: -15.9169\n",
      "Epoch: 4\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [1/125], Loss_min: 15.8073, Loss_max: -15.7893\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [2/125], Loss_min: 15.9184, Loss_max: -15.9014\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [3/125], Loss_min: 15.9658, Loss_max: -15.9397\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [4/125], Loss_min: 15.8611, Loss_max: -15.8436\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [5/125], Loss_min: 15.9403, Loss_max: -15.9267\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [6/125], Loss_min: 15.9816, Loss_max: -15.9674\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [7/125], Loss_min: 16.0130, Loss_max: -15.9959\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [8/125], Loss_min: 15.8902, Loss_max: -15.8757\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [9/125], Loss_min: 15.9517, Loss_max: -15.9325\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [10/125], Loss_min: 15.9367, Loss_max: -15.9136\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [11/125], Loss_min: 15.9218, Loss_max: -15.9092\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [12/125], Loss_min: 15.9678, Loss_max: -15.9531\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [13/125], Loss_min: 16.0205, Loss_max: -16.0016\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [14/125], Loss_min: 15.9241, Loss_max: -15.9097\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [15/125], Loss_min: 15.9849, Loss_max: -15.9683\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [16/125], Loss_min: 15.8891, Loss_max: -15.8699\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [17/125], Loss_min: 15.9706, Loss_max: -15.8795\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [18/125], Loss_min: 15.9818, Loss_max: -15.9537\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [19/125], Loss_min: 15.9828, Loss_max: -15.9658\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [20/125], Loss_min: 16.0076, Loss_max: -15.9858\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [21/125], Loss_min: 16.0168, Loss_max: -15.9988\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [22/125], Loss_min: 15.9849, Loss_max: -15.9702\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [23/125], Loss_min: 15.9805, Loss_max: -15.9618\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [24/125], Loss_min: 16.0078, Loss_max: -15.9869\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [25/125], Loss_min: 15.9563, Loss_max: -15.9386\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [26/125], Loss_min: 15.9619, Loss_max: -15.9375\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [27/125], Loss_min: 15.9621, Loss_max: -15.9438\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [28/125], Loss_min: 15.9904, Loss_max: -15.9678\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [29/125], Loss_min: 15.9411, Loss_max: -15.9199\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [30/125], Loss_min: 15.9540, Loss_max: -15.9395\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [31/125], Loss_min: 15.9613, Loss_max: -15.9459\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [32/125], Loss_min: 15.9879, Loss_max: -15.9713\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [33/125], Loss_min: 15.9475, Loss_max: -15.9320\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [34/125], Loss_min: 16.0366, Loss_max: -16.0209\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [35/125], Loss_min: 15.9998, Loss_max: -15.9867\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [36/125], Loss_min: 15.9914, Loss_max: -15.9739\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [37/125], Loss_min: 16.0071, Loss_max: -15.9947\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [38/125], Loss_min: 15.9761, Loss_max: -15.9588\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [39/125], Loss_min: 15.9407, Loss_max: -15.9274\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [40/125], Loss_min: 15.9154, Loss_max: -15.9015\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [41/125], Loss_min: 16.0181, Loss_max: -16.0037\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [42/125], Loss_min: 15.9623, Loss_max: -15.9500\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [43/125], Loss_min: 15.9911, Loss_max: -15.9744\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [44/125], Loss_min: 15.9578, Loss_max: -15.9369\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [45/125], Loss_min: 15.9655, Loss_max: -15.9464\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [46/125], Loss_min: 16.0749, Loss_max: -16.0282\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [47/125], Loss_min: 15.9844, Loss_max: -15.9162\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [48/125], Loss_min: 15.9507, Loss_max: -15.9138\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [49/125], Loss_min: 15.9709, Loss_max: -15.9377\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [50/125], Loss_min: 15.9904, Loss_max: -15.9481\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [51/125], Loss_min: 16.0123, Loss_max: -15.9931\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [52/125], Loss_min: 15.9475, Loss_max: -15.9020\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [53/125], Loss_min: 16.0446, Loss_max: -16.0211\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [54/125], Loss_min: 16.0173, Loss_max: -15.9933\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [55/125], Loss_min: 16.0093, Loss_max: -15.9892\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [56/125], Loss_min: 15.9973, Loss_max: -15.9730\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [57/125], Loss_min: 16.0045, Loss_max: -15.9852\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [58/125], Loss_min: 16.0152, Loss_max: -15.9778\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [59/125], Loss_min: 16.0230, Loss_max: -15.9967\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [60/125], Loss_min: 15.9964, Loss_max: -15.9566\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [61/125], Loss_min: 16.0282, Loss_max: -16.0060\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [62/125], Loss_min: 16.0363, Loss_max: -15.9908\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [63/125], Loss_min: 15.9680, Loss_max: -15.9239\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [64/125], Loss_min: 16.0097, Loss_max: -15.9866\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [65/125], Loss_min: 16.0092, Loss_max: -15.9630\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [66/125], Loss_min: 15.9899, Loss_max: -15.9659\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [67/125], Loss_min: 16.0055, Loss_max: -15.9642\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [68/125], Loss_min: 16.0199, Loss_max: -15.9915\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [69/125], Loss_min: 16.0257, Loss_max: -15.9937\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [70/125], Loss_min: 16.0462, Loss_max: -16.0125\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [71/125], Loss_min: 15.9789, Loss_max: -15.9599\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [72/125], Loss_min: 16.0460, Loss_max: -16.0122\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [73/125], Loss_min: 16.0014, Loss_max: -15.9797\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [74/125], Loss_min: 16.0307, Loss_max: -16.0051\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [75/125], Loss_min: 16.0081, Loss_max: -15.9909\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [76/125], Loss_min: 15.9915, Loss_max: -15.9689\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [77/125], Loss_min: 16.0210, Loss_max: -15.9994\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [78/125], Loss_min: 16.0427, Loss_max: -16.0229\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [79/125], Loss_min: 16.0111, Loss_max: -15.9900\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [80/125], Loss_min: 16.0754, Loss_max: -16.0546\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [81/125], Loss_min: 16.0130, Loss_max: -15.9877\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [82/125], Loss_min: 16.0417, Loss_max: -15.9678\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [83/125], Loss_min: 16.0414, Loss_max: -16.0097\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [84/125], Loss_min: 16.0319, Loss_max: -15.9931\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [85/125], Loss_min: 15.9975, Loss_max: -15.9739\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [86/125], Loss_min: 16.0640, Loss_max: -16.0313\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [87/125], Loss_min: 16.0550, Loss_max: -16.0261\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [88/125], Loss_min: 15.9955, Loss_max: -15.9706\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [89/125], Loss_min: 16.0745, Loss_max: -16.0463\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [90/125], Loss_min: 16.0048, Loss_max: -15.9736\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [91/125], Loss_min: 16.0499, Loss_max: -16.0237\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [92/125], Loss_min: 16.0514, Loss_max: -16.0047\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [93/125], Loss_min: 16.0315, Loss_max: -16.0152\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [94/125], Loss_min: 16.0196, Loss_max: -15.9786\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [95/125], Loss_min: 16.0396, Loss_max: -16.0205\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [96/125], Loss_min: 15.9960, Loss_max: -15.9398\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [97/125], Loss_min: 16.0789, Loss_max: -16.0490\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [98/125], Loss_min: 16.0643, Loss_max: -16.0298\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [99/125], Loss_min: 16.0771, Loss_max: -16.0316\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [100/125], Loss_min: 16.0309, Loss_max: -15.9868\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [101/125], Loss_min: 16.0471, Loss_max: -16.0210\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [102/125], Loss_min: 16.0468, Loss_max: -16.0202\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [103/125], Loss_min: 16.0622, Loss_max: -16.0438\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [104/125], Loss_min: 16.0120, Loss_max: -15.9783\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [105/125], Loss_min: 16.0706, Loss_max: -16.0494\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [106/125], Loss_min: 16.0587, Loss_max: -16.0383\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [107/125], Loss_min: 16.0297, Loss_max: -16.0090\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [108/125], Loss_min: 16.0480, Loss_max: -16.0294\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [109/125], Loss_min: 16.0135, Loss_max: -15.9943\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [110/125], Loss_min: 16.0885, Loss_max: -16.0704\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [111/125], Loss_min: 16.0378, Loss_max: -16.0209\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [112/125], Loss_min: 16.0411, Loss_max: -16.0279\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [113/125], Loss_min: 16.0278, Loss_max: -16.0073\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [114/125], Loss_min: 16.0295, Loss_max: -16.0117\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [115/125], Loss_min: 16.0361, Loss_max: -16.0157\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [116/125], Loss_min: 16.0234, Loss_max: -16.0050\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [117/125], Loss_min: 16.0797, Loss_max: -16.0658\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [118/125], Loss_min: 16.0496, Loss_max: -16.0268\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [119/125], Loss_min: 16.0159, Loss_max: -15.9609\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [120/125], Loss_min: 16.0276, Loss_max: -16.0175\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [121/125], Loss_min: 16.0763, Loss_max: -16.0607\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [122/125], Loss_min: 16.0186, Loss_max: -16.0053\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [123/125], Loss_min: 16.0221, Loss_max: -15.9931\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [124/125], Loss_min: 16.0737, Loss_max: -16.0466\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [5/15], Step [125/125], Loss_min: 16.0457, Loss_max: -16.0296\n",
      "Epoch: 5\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [1/125], Loss_min: 16.0308, Loss_max: -16.0064\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [2/125], Loss_min: 16.0588, Loss_max: -16.0446\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [3/125], Loss_min: 16.0851, Loss_max: -16.0543\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [4/125], Loss_min: 16.0723, Loss_max: -16.0600\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [5/125], Loss_min: 16.0845, Loss_max: -16.0352\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [6/125], Loss_min: 16.0459, Loss_max: -16.0280\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [7/125], Loss_min: 16.0509, Loss_max: -16.0243\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [8/125], Loss_min: 16.0277, Loss_max: -16.0019\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [9/125], Loss_min: 16.0698, Loss_max: -16.0541\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [10/125], Loss_min: 16.0880, Loss_max: -16.0515\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [11/125], Loss_min: 16.0733, Loss_max: -16.0210\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [12/125], Loss_min: 16.0822, Loss_max: -16.0468\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [13/125], Loss_min: 16.0881, Loss_max: -16.0719\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [14/125], Loss_min: 16.0363, Loss_max: -16.0188\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [15/125], Loss_min: 16.0746, Loss_max: -16.0518\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [16/125], Loss_min: 16.0419, Loss_max: -16.0261\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [17/125], Loss_min: 16.0550, Loss_max: -16.0395\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [18/125], Loss_min: 16.0976, Loss_max: -16.0605\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [19/125], Loss_min: 16.1077, Loss_max: -16.0594\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [20/125], Loss_min: 16.1036, Loss_max: -16.0768\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [21/125], Loss_min: 16.0360, Loss_max: -16.0169\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [22/125], Loss_min: 16.0911, Loss_max: -16.0654\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [23/125], Loss_min: 16.0938, Loss_max: -16.0708\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [24/125], Loss_min: 16.0610, Loss_max: -16.0439\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [25/125], Loss_min: 16.0340, Loss_max: -16.0125\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [26/125], Loss_min: 16.0500, Loss_max: -16.0234\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [27/125], Loss_min: 16.0834, Loss_max: -16.0657\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [28/125], Loss_min: 16.0592, Loss_max: -16.0408\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [29/125], Loss_min: 16.0333, Loss_max: -16.0153\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [30/125], Loss_min: 16.0425, Loss_max: -16.0216\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [31/125], Loss_min: 16.0741, Loss_max: -16.0600\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [32/125], Loss_min: 16.0778, Loss_max: -16.0619\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [33/125], Loss_min: 16.1098, Loss_max: -16.0913\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [34/125], Loss_min: 16.0567, Loss_max: -16.0349\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [35/125], Loss_min: 16.0481, Loss_max: -16.0359\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [36/125], Loss_min: 16.0951, Loss_max: -16.0750\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [37/125], Loss_min: 16.0620, Loss_max: -16.0492\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [38/125], Loss_min: 16.0868, Loss_max: -16.0701\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [39/125], Loss_min: 16.0680, Loss_max: -16.0512\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [40/125], Loss_min: 16.0888, Loss_max: -16.0764\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [41/125], Loss_min: 16.0730, Loss_max: -16.0525\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [42/125], Loss_min: 16.0352, Loss_max: -16.0203\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [43/125], Loss_min: 16.0597, Loss_max: -16.0453\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [44/125], Loss_min: 16.0709, Loss_max: -16.0477\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [45/125], Loss_min: 16.0677, Loss_max: -16.0551\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [46/125], Loss_min: 16.0839, Loss_max: -16.0727\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [47/125], Loss_min: 16.0559, Loss_max: -16.0460\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [48/125], Loss_min: 16.0898, Loss_max: -16.0144\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [49/125], Loss_min: 16.0328, Loss_max: -16.0118\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [50/125], Loss_min: 16.0696, Loss_max: -16.0461\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [51/125], Loss_min: 16.0240, Loss_max: -15.9675\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [52/125], Loss_min: 16.0961, Loss_max: -16.0559\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [53/125], Loss_min: 16.0788, Loss_max: -16.0410\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [54/125], Loss_min: 16.0869, Loss_max: -16.0622\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [55/125], Loss_min: 16.0584, Loss_max: -16.0241\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [56/125], Loss_min: 16.0962, Loss_max: -16.0680\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [57/125], Loss_min: 16.0878, Loss_max: -16.0324\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [58/125], Loss_min: 16.0400, Loss_max: -16.0023\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [59/125], Loss_min: 16.1064, Loss_max: -16.0539\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [60/125], Loss_min: 16.1424, Loss_max: -16.0685\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [61/125], Loss_min: 16.1332, Loss_max: -16.0157\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [62/125], Loss_min: 16.1105, Loss_max: -16.0595\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [63/125], Loss_min: 16.1106, Loss_max: -16.0282\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [64/125], Loss_min: 16.0875, Loss_max: -16.0673\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [65/125], Loss_min: 16.0984, Loss_max: -16.0094\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [66/125], Loss_min: 16.0949, Loss_max: -16.0473\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [67/125], Loss_min: 16.0778, Loss_max: -16.0302\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [68/125], Loss_min: 16.0690, Loss_max: -16.0013\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [69/125], Loss_min: 16.0753, Loss_max: -16.0550\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [70/125], Loss_min: 16.0886, Loss_max: -16.0335\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [71/125], Loss_min: 16.0812, Loss_max: -16.0559\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [72/125], Loss_min: 16.1104, Loss_max: -16.0392\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [73/125], Loss_min: 16.0643, Loss_max: -16.0392\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [74/125], Loss_min: 16.1014, Loss_max: -16.0276\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [75/125], Loss_min: 16.0548, Loss_max: -16.0295\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [76/125], Loss_min: 16.1130, Loss_max: -16.0676\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [77/125], Loss_min: 16.0934, Loss_max: -16.0486\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [78/125], Loss_min: 16.0746, Loss_max: -16.0306\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [79/125], Loss_min: 16.1151, Loss_max: -16.0084\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [80/125], Loss_min: 16.0901, Loss_max: -16.0512\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [81/125], Loss_min: 16.1664, Loss_max: -15.9934\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [82/125], Loss_min: 16.0663, Loss_max: -16.0298\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [83/125], Loss_min: 16.1808, Loss_max: -15.9804\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [84/125], Loss_min: 16.1143, Loss_max: -16.0715\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [85/125], Loss_min: 16.1167, Loss_max: -16.0371\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [86/125], Loss_min: 16.1035, Loss_max: -16.0683\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [87/125], Loss_min: 16.1244, Loss_max: -16.0815\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [88/125], Loss_min: 16.1049, Loss_max: -16.0188\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [89/125], Loss_min: 16.0876, Loss_max: -16.0538\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [90/125], Loss_min: 16.0866, Loss_max: -16.0522\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [91/125], Loss_min: 16.1246, Loss_max: -16.0675\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [92/125], Loss_min: 16.0853, Loss_max: -16.0624\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [93/125], Loss_min: 16.0800, Loss_max: -16.0525\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [94/125], Loss_min: 16.1204, Loss_max: -16.0904\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [95/125], Loss_min: 16.0895, Loss_max: -16.0662\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [96/125], Loss_min: 16.1055, Loss_max: -16.0793\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [97/125], Loss_min: 16.1108, Loss_max: -16.0823\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [98/125], Loss_min: 16.0264, Loss_max: -16.0061\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [99/125], Loss_min: 16.0832, Loss_max: -16.0530\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [100/125], Loss_min: 16.0856, Loss_max: -16.0628\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [101/125], Loss_min: 16.1062, Loss_max: -16.0701\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [102/125], Loss_min: 16.0915, Loss_max: -16.0644\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [103/125], Loss_min: 16.1400, Loss_max: -16.0562\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [104/125], Loss_min: 16.0978, Loss_max: -16.0782\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [105/125], Loss_min: 16.0999, Loss_max: -16.0819\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [106/125], Loss_min: 16.0991, Loss_max: -16.0852\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [107/125], Loss_min: 16.0820, Loss_max: -16.0581\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [108/125], Loss_min: 16.1006, Loss_max: -16.0874\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [109/125], Loss_min: 16.0765, Loss_max: -16.0585\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [110/125], Loss_min: 16.0895, Loss_max: -16.0718\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [111/125], Loss_min: 16.0993, Loss_max: -16.0872\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [112/125], Loss_min: 16.1155, Loss_max: -16.0924\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [113/125], Loss_min: 16.0809, Loss_max: -16.0621\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [114/125], Loss_min: 16.1186, Loss_max: -16.1017\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [115/125], Loss_min: 16.1204, Loss_max: -16.0969\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [116/125], Loss_min: 16.0947, Loss_max: -16.0796\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [117/125], Loss_min: 16.1150, Loss_max: -16.0981\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [118/125], Loss_min: 16.0882, Loss_max: -16.0520\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [119/125], Loss_min: 16.1182, Loss_max: -16.0994\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [120/125], Loss_min: 16.0495, Loss_max: -16.0308\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [121/125], Loss_min: 16.1178, Loss_max: -16.0958\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [122/125], Loss_min: 16.1178, Loss_max: -16.0902\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [123/125], Loss_min: 16.0726, Loss_max: -16.0463\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [124/125], Loss_min: 16.0727, Loss_max: -16.0505\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.008333333333333333\n",
      "Epoch [6/15], Step [125/125], Loss_min: 16.1126, Loss_max: -16.0735\n",
      "Epoch: 6\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [1/125], Loss_min: 16.0891, Loss_max: -16.0575\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [2/125], Loss_min: 16.1241, Loss_max: -16.0780\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [3/125], Loss_min: 16.1085, Loss_max: -16.0611\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [4/125], Loss_min: 16.1288, Loss_max: -16.1072\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [5/125], Loss_min: 16.1111, Loss_max: -16.0661\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [6/125], Loss_min: 16.1484, Loss_max: -16.1208\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [7/125], Loss_min: 16.1322, Loss_max: -16.0646\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [8/125], Loss_min: 16.0920, Loss_max: -16.0608\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [9/125], Loss_min: 16.1288, Loss_max: -16.1109\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [10/125], Loss_min: 16.1079, Loss_max: -16.0864\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [11/125], Loss_min: 16.0861, Loss_max: -16.0749\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [12/125], Loss_min: 16.0844, Loss_max: -16.0670\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [13/125], Loss_min: 16.1000, Loss_max: -16.0750\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [14/125], Loss_min: 16.1195, Loss_max: -16.0933\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [15/125], Loss_min: 16.1002, Loss_max: -16.0839\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [16/125], Loss_min: 16.1129, Loss_max: -16.0973\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [17/125], Loss_min: 16.1009, Loss_max: -16.0769\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [18/125], Loss_min: 16.0752, Loss_max: -16.0643\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [19/125], Loss_min: 16.1060, Loss_max: -16.0910\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [20/125], Loss_min: 16.0772, Loss_max: -16.0657\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [21/125], Loss_min: 16.1050, Loss_max: -16.0871\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [22/125], Loss_min: 16.0860, Loss_max: -16.0637\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [23/125], Loss_min: 16.1276, Loss_max: -16.1146\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [24/125], Loss_min: 16.1300, Loss_max: -16.1115\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [25/125], Loss_min: 16.1007, Loss_max: -16.0832\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [26/125], Loss_min: 16.1113, Loss_max: -16.0965\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [27/125], Loss_min: 16.1122, Loss_max: -16.0951\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [28/125], Loss_min: 16.0951, Loss_max: -16.0822\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [29/125], Loss_min: 16.1075, Loss_max: -16.0750\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [30/125], Loss_min: 16.0741, Loss_max: -16.0621\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [31/125], Loss_min: 16.0999, Loss_max: -16.0844\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [32/125], Loss_min: 16.1181, Loss_max: -16.1017\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [33/125], Loss_min: 16.1024, Loss_max: -16.0833\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [34/125], Loss_min: 16.0985, Loss_max: -16.0864\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [35/125], Loss_min: 16.0981, Loss_max: -16.0856\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [36/125], Loss_min: 16.0857, Loss_max: -16.0698\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [37/125], Loss_min: 16.1037, Loss_max: -16.0905\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [38/125], Loss_min: 16.1088, Loss_max: -16.0927\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [39/125], Loss_min: 16.1281, Loss_max: -16.1118\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [40/125], Loss_min: 16.0993, Loss_max: -16.0865\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [41/125], Loss_min: 16.0951, Loss_max: -16.0823\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [42/125], Loss_min: 16.1314, Loss_max: -16.1146\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [43/125], Loss_min: 16.1050, Loss_max: -16.0937\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [44/125], Loss_min: 16.0899, Loss_max: -16.0764\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [45/125], Loss_min: 16.1067, Loss_max: -16.0919\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [46/125], Loss_min: 16.0882, Loss_max: -16.0766\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [47/125], Loss_min: 16.1072, Loss_max: -16.0937\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [48/125], Loss_min: 16.1050, Loss_max: -16.0505\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [49/125], Loss_min: 16.0991, Loss_max: -16.0827\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [50/125], Loss_min: 16.0959, Loss_max: -16.0752\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [51/125], Loss_min: 16.0670, Loss_max: -16.0539\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [52/125], Loss_min: 16.1423, Loss_max: -16.1104\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [53/125], Loss_min: 16.1234, Loss_max: -16.1086\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [54/125], Loss_min: 16.1191, Loss_max: -16.0924\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [55/125], Loss_min: 16.1098, Loss_max: -16.0879\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [56/125], Loss_min: 16.1409, Loss_max: -16.1186\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [57/125], Loss_min: 16.0947, Loss_max: -16.0600\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [58/125], Loss_min: 16.1298, Loss_max: -16.1070\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [59/125], Loss_min: 16.1062, Loss_max: -16.0981\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [60/125], Loss_min: 16.1321, Loss_max: -16.1074\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [61/125], Loss_min: 16.1421, Loss_max: -16.1285\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [62/125], Loss_min: 16.0989, Loss_max: -16.0743\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [63/125], Loss_min: 16.1085, Loss_max: -16.0950\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [64/125], Loss_min: 16.1111, Loss_max: -16.0890\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [65/125], Loss_min: 16.1170, Loss_max: -16.1037\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [66/125], Loss_min: 16.1426, Loss_max: -16.1242\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [67/125], Loss_min: 16.0762, Loss_max: -16.0627\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [68/125], Loss_min: 16.1171, Loss_max: -16.0947\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [69/125], Loss_min: 16.1338, Loss_max: -16.1234\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [70/125], Loss_min: 16.1325, Loss_max: -16.1170\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [71/125], Loss_min: 16.1062, Loss_max: -16.0983\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [72/125], Loss_min: 16.1272, Loss_max: -16.1158\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [73/125], Loss_min: 16.1135, Loss_max: -16.1018\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [74/125], Loss_min: 16.0971, Loss_max: -16.0866\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [75/125], Loss_min: 16.1191, Loss_max: -16.1113\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [76/125], Loss_min: 16.1148, Loss_max: -16.1029\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [77/125], Loss_min: 16.1189, Loss_max: -16.0980\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [78/125], Loss_min: 16.1135, Loss_max: -16.1027\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [79/125], Loss_min: 16.1133, Loss_max: -16.0937\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [80/125], Loss_min: 16.1374, Loss_max: -16.1243\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [81/125], Loss_min: 16.0765, Loss_max: -16.0610\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [82/125], Loss_min: 16.1164, Loss_max: -16.1027\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [83/125], Loss_min: 16.1205, Loss_max: -16.1109\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [84/125], Loss_min: 16.1395, Loss_max: -16.1284\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [85/125], Loss_min: 16.1221, Loss_max: -16.1108\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [86/125], Loss_min: 16.1053, Loss_max: -16.0947\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [87/125], Loss_min: 16.0922, Loss_max: -16.0785\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [88/125], Loss_min: 16.1130, Loss_max: -16.0950\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [89/125], Loss_min: 16.1103, Loss_max: -16.0882\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [90/125], Loss_min: 16.1153, Loss_max: -16.0878\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [91/125], Loss_min: 16.1153, Loss_max: -16.0851\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(15.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [92/125], Loss_min: 16.0107, Loss_max: -15.9661\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [93/125], Loss_min: 16.1576, Loss_max: -16.0923\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [94/125], Loss_min: 16.1322, Loss_max: -16.0869\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [95/125], Loss_min: 16.1149, Loss_max: -16.0733\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [96/125], Loss_min: 16.1334, Loss_max: -16.1077\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [97/125], Loss_min: 16.1027, Loss_max: -16.0775\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [98/125], Loss_min: 16.1429, Loss_max: -16.0799\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [99/125], Loss_min: 16.1299, Loss_max: -16.0802\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [100/125], Loss_min: 16.1362, Loss_max: -16.1111\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [101/125], Loss_min: 16.1413, Loss_max: -16.1093\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [102/125], Loss_min: 16.1137, Loss_max: -16.0780\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [103/125], Loss_min: 16.1315, Loss_max: -16.1117\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [104/125], Loss_min: 16.1220, Loss_max: -16.0737\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [105/125], Loss_min: 16.1593, Loss_max: -16.0873\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [106/125], Loss_min: 16.1508, Loss_max: -16.0745\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [107/125], Loss_min: 16.1164, Loss_max: -16.0876\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [108/125], Loss_min: 16.1210, Loss_max: -16.0854\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [109/125], Loss_min: 16.1626, Loss_max: -16.0918\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [110/125], Loss_min: 16.1354, Loss_max: -16.1017\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [111/125], Loss_min: 16.1122, Loss_max: -16.0865\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [112/125], Loss_min: 16.1282, Loss_max: -16.1022\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [113/125], Loss_min: 16.1175, Loss_max: -16.0953\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [114/125], Loss_min: 16.1420, Loss_max: -16.1049\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [115/125], Loss_min: 16.1338, Loss_max: -16.1214\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [116/125], Loss_min: 16.1414, Loss_max: -16.0879\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [117/125], Loss_min: 16.1162, Loss_max: -16.1035\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [118/125], Loss_min: 16.1151, Loss_max: -16.0910\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [119/125], Loss_min: 16.1407, Loss_max: -16.1052\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [120/125], Loss_min: 16.1571, Loss_max: -16.1261\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [121/125], Loss_min: 16.1424, Loss_max: -16.1129\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [122/125], Loss_min: 16.1417, Loss_max: -16.0756\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [123/125], Loss_min: 16.1334, Loss_max: -16.1146\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [124/125], Loss_min: 16.1441, Loss_max: -16.1235\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [7/15], Step [125/125], Loss_min: 16.1105, Loss_max: -16.0973\n",
      "Epoch: 7\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [1/125], Loss_min: 16.1186, Loss_max: -16.1041\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [2/125], Loss_min: 16.1140, Loss_max: -16.0940\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [3/125], Loss_min: 16.1173, Loss_max: -16.1026\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [4/125], Loss_min: 16.1141, Loss_max: -16.0941\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [5/125], Loss_min: 16.1327, Loss_max: -16.1014\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [6/125], Loss_min: 16.1367, Loss_max: -16.1173\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [7/125], Loss_min: 16.1297, Loss_max: -16.1119\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [8/125], Loss_min: 16.1429, Loss_max: -16.1207\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [9/125], Loss_min: 16.1355, Loss_max: -16.1142\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [10/125], Loss_min: 16.1367, Loss_max: -16.1264\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [11/125], Loss_min: 16.1497, Loss_max: -16.1145\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [12/125], Loss_min: 16.1285, Loss_max: -16.1141\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [13/125], Loss_min: 16.1246, Loss_max: -16.1072\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [14/125], Loss_min: 16.1157, Loss_max: -16.1038\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [15/125], Loss_min: 16.1555, Loss_max: -16.1244\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [16/125], Loss_min: 16.0963, Loss_max: -16.0763\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [17/125], Loss_min: 16.1355, Loss_max: -16.1186\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [18/125], Loss_min: 16.1307, Loss_max: -16.1132\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [19/125], Loss_min: 16.1316, Loss_max: -16.1159\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [20/125], Loss_min: 16.1325, Loss_max: -16.1154\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [21/125], Loss_min: 16.1324, Loss_max: -16.1163\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [22/125], Loss_min: 16.1292, Loss_max: -16.1125\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [23/125], Loss_min: 16.1506, Loss_max: -16.1262\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [24/125], Loss_min: 16.1528, Loss_max: -16.1262\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [25/125], Loss_min: 16.1356, Loss_max: -16.1250\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [26/125], Loss_min: 16.1222, Loss_max: -16.1100\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [27/125], Loss_min: 16.1419, Loss_max: -16.0989\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [28/125], Loss_min: 16.1409, Loss_max: -16.1281\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [29/125], Loss_min: 16.1407, Loss_max: -16.1183\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [30/125], Loss_min: 16.1338, Loss_max: -16.1256\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [31/125], Loss_min: 16.1213, Loss_max: -16.0915\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [32/125], Loss_min: 16.1318, Loss_max: -16.1204\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [33/125], Loss_min: 16.1498, Loss_max: -16.1326\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [34/125], Loss_min: 16.1343, Loss_max: -16.1237\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [35/125], Loss_min: 16.1299, Loss_max: -16.1097\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [36/125], Loss_min: 16.1464, Loss_max: -16.1282\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [37/125], Loss_min: 16.1409, Loss_max: -16.1279\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [38/125], Loss_min: 16.1392, Loss_max: -16.1214\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [39/125], Loss_min: 16.1179, Loss_max: -16.1065\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [40/125], Loss_min: 16.1358, Loss_max: -16.1183\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [41/125], Loss_min: 16.1418, Loss_max: -16.1258\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [42/125], Loss_min: 16.1153, Loss_max: -16.1060\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [43/125], Loss_min: 16.1546, Loss_max: -16.1363\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [44/125], Loss_min: 16.1157, Loss_max: -16.1044\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [45/125], Loss_min: 16.1261, Loss_max: -16.1063\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [46/125], Loss_min: 16.1293, Loss_max: -16.1138\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.0954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [47/125], Loss_min: 16.1041, Loss_max: -16.0868\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [48/125], Loss_min: 16.1115, Loss_max: -16.0910\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [49/125], Loss_min: 16.1217, Loss_max: -16.1107\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [50/125], Loss_min: 16.1425, Loss_max: -16.1281\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [51/125], Loss_min: 16.1368, Loss_max: -16.1291\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [52/125], Loss_min: 16.1271, Loss_max: -16.1109\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [53/125], Loss_min: 16.1242, Loss_max: -16.1166\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [54/125], Loss_min: 16.1152, Loss_max: -16.1033\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [55/125], Loss_min: 16.1378, Loss_max: -16.1255\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [56/125], Loss_min: 16.1264, Loss_max: -16.1190\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [57/125], Loss_min: 16.1398, Loss_max: -16.1269\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [58/125], Loss_min: 16.1426, Loss_max: -16.1352\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [59/125], Loss_min: 16.1251, Loss_max: -16.1186\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [60/125], Loss_min: 16.1225, Loss_max: -16.1121\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [61/125], Loss_min: 16.1362, Loss_max: -16.1234\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [62/125], Loss_min: 16.1253, Loss_max: -16.1137\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [63/125], Loss_min: 16.1447, Loss_max: -16.1367\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [64/125], Loss_min: 16.1474, Loss_max: -16.1399\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [65/125], Loss_min: 16.1282, Loss_max: -16.1207\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [66/125], Loss_min: 16.1459, Loss_max: -16.1292\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [67/125], Loss_min: 16.1293, Loss_max: -16.1211\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [68/125], Loss_min: 16.1363, Loss_max: -16.1278\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [69/125], Loss_min: 16.1336, Loss_max: -16.1192\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [70/125], Loss_min: 16.1284, Loss_max: -16.1184\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [71/125], Loss_min: 16.1107, Loss_max: -16.0962\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [72/125], Loss_min: 16.1262, Loss_max: -16.1063\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [73/125], Loss_min: 16.1300, Loss_max: -16.1166\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [74/125], Loss_min: 16.1443, Loss_max: -16.1345\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [75/125], Loss_min: 16.1485, Loss_max: -16.1298\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [76/125], Loss_min: 16.1499, Loss_max: -16.1142\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [77/125], Loss_min: 16.1509, Loss_max: -16.1260\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [78/125], Loss_min: 16.1338, Loss_max: -16.1094\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [79/125], Loss_min: 16.1419, Loss_max: -16.1282\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [80/125], Loss_min: 16.1408, Loss_max: -16.1093\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [81/125], Loss_min: 16.1377, Loss_max: -16.1234\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [82/125], Loss_min: 16.1215, Loss_max: -16.1077\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [83/125], Loss_min: 16.1220, Loss_max: -16.1079\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [84/125], Loss_min: 16.1456, Loss_max: -16.1231\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [85/125], Loss_min: 16.1428, Loss_max: -16.1302\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [86/125], Loss_min: 16.1182, Loss_max: -16.1068\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [87/125], Loss_min: 16.1118, Loss_max: -16.1044\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [88/125], Loss_min: 16.1520, Loss_max: -16.1437\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [89/125], Loss_min: 16.1483, Loss_max: -16.1358\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [90/125], Loss_min: 16.1137, Loss_max: -16.0903\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [91/125], Loss_min: 16.1138, Loss_max: -16.1061\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [92/125], Loss_min: 16.1305, Loss_max: -16.1209\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [93/125], Loss_min: 16.1203, Loss_max: -16.1078\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [94/125], Loss_min: 16.1406, Loss_max: -16.1287\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [95/125], Loss_min: 16.1557, Loss_max: -16.1429\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [96/125], Loss_min: 16.1336, Loss_max: -16.1175\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [97/125], Loss_min: 16.1345, Loss_max: -16.1211\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [98/125], Loss_min: 16.1161, Loss_max: -16.1027\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [99/125], Loss_min: 16.1311, Loss_max: -16.1199\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [100/125], Loss_min: 16.1137, Loss_max: -16.0974\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [101/125], Loss_min: 16.1212, Loss_max: -16.1097\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [102/125], Loss_min: 16.1278, Loss_max: -16.1150\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [103/125], Loss_min: 16.1543, Loss_max: -16.1376\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [104/125], Loss_min: 16.1328, Loss_max: -16.1171\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [105/125], Loss_min: 16.1376, Loss_max: -16.1201\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [106/125], Loss_min: 16.1491, Loss_max: -16.1017\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [107/125], Loss_min: 16.1178, Loss_max: -16.1013\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [108/125], Loss_min: 16.1285, Loss_max: -16.1200\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [109/125], Loss_min: 16.1352, Loss_max: -16.1187\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [110/125], Loss_min: 16.1152, Loss_max: -16.1061\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [111/125], Loss_min: 16.1372, Loss_max: -16.1288\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [112/125], Loss_min: 16.1504, Loss_max: -16.1413\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [113/125], Loss_min: 16.1100, Loss_max: -16.0992\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [114/125], Loss_min: 16.1429, Loss_max: -16.1328\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [115/125], Loss_min: 16.1303, Loss_max: -16.1246\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [116/125], Loss_min: 16.1434, Loss_max: -16.1365\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [117/125], Loss_min: 16.1481, Loss_max: -16.1254\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [118/125], Loss_min: 16.1229, Loss_max: -16.1106\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [119/125], Loss_min: 16.1365, Loss_max: -16.1228\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [120/125], Loss_min: 16.1269, Loss_max: -16.0889\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [121/125], Loss_min: 16.1395, Loss_max: -16.1308\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [122/125], Loss_min: 16.1390, Loss_max: -16.1328\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [123/125], Loss_min: 16.1335, Loss_max: -16.1245\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [124/125], Loss_min: 16.1174, Loss_max: -16.1111\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [8/15], Step [125/125], Loss_min: 16.1257, Loss_max: -16.1192\n",
      "Epoch: 8\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [1/125], Loss_min: 16.1214, Loss_max: -16.1109\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [2/125], Loss_min: 16.1346, Loss_max: -16.1213\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [3/125], Loss_min: 16.1379, Loss_max: -16.1324\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [4/125], Loss_min: 16.1446, Loss_max: -16.1373\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [5/125], Loss_min: 16.1621, Loss_max: -16.1436\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [6/125], Loss_min: 16.1359, Loss_max: -16.1202\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [7/125], Loss_min: 16.1421, Loss_max: -16.1334\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [8/125], Loss_min: 16.1064, Loss_max: -16.0964\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [9/125], Loss_min: 16.1156, Loss_max: -16.1081\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [10/125], Loss_min: 16.1174, Loss_max: -16.1083\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [11/125], Loss_min: 16.1360, Loss_max: -16.1270\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [12/125], Loss_min: 16.1474, Loss_max: -16.1376\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [13/125], Loss_min: 16.1338, Loss_max: -16.1199\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [14/125], Loss_min: 16.1520, Loss_max: -16.1439\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [15/125], Loss_min: 16.1408, Loss_max: -16.1274\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [16/125], Loss_min: 16.1268, Loss_max: -16.1199\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [17/125], Loss_min: 16.1317, Loss_max: -16.1241\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [18/125], Loss_min: 16.1339, Loss_max: -16.1166\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [19/125], Loss_min: 16.1313, Loss_max: -16.1237\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [20/125], Loss_min: 16.1141, Loss_max: -16.1081\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [21/125], Loss_min: 16.1387, Loss_max: -16.1332\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [22/125], Loss_min: 16.1261, Loss_max: -16.1192\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [23/125], Loss_min: 16.1446, Loss_max: -16.1403\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [24/125], Loss_min: 16.1149, Loss_max: -16.1086\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [25/125], Loss_min: 16.1406, Loss_max: -16.1318\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [26/125], Loss_min: 16.1490, Loss_max: -16.1440\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [27/125], Loss_min: 16.1363, Loss_max: -16.1291\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [28/125], Loss_min: 16.1515, Loss_max: -16.1369\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [29/125], Loss_min: 16.1531, Loss_max: -16.1470\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [30/125], Loss_min: 16.1382, Loss_max: -16.1306\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [31/125], Loss_min: 16.1271, Loss_max: -16.1139\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [32/125], Loss_min: 16.1466, Loss_max: -16.1337\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [33/125], Loss_min: 16.1343, Loss_max: -16.1290\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [34/125], Loss_min: 16.1265, Loss_max: -16.1180\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [35/125], Loss_min: 16.1372, Loss_max: -16.1314\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [36/125], Loss_min: 16.1391, Loss_max: -16.1344\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [37/125], Loss_min: 16.1427, Loss_max: -16.1330\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [38/125], Loss_min: 16.1478, Loss_max: -16.1415\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [39/125], Loss_min: 16.1448, Loss_max: -16.1352\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [40/125], Loss_min: 16.1261, Loss_max: -16.1205\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [41/125], Loss_min: 16.1434, Loss_max: -16.1374\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [42/125], Loss_min: 16.1779, Loss_max: -16.1171\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [43/125], Loss_min: 16.1535, Loss_max: -16.1304\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [44/125], Loss_min: 16.1266, Loss_max: -16.1175\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [45/125], Loss_min: 16.1509, Loss_max: -16.1391\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [46/125], Loss_min: 16.1497, Loss_max: -16.1387\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [47/125], Loss_min: 16.1536, Loss_max: -16.1428\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [48/125], Loss_min: 16.1365, Loss_max: -16.1230\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [49/125], Loss_min: 16.1357, Loss_max: -16.1265\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [50/125], Loss_min: 16.1511, Loss_max: -16.1341\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [51/125], Loss_min: 16.1494, Loss_max: -16.1406\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [52/125], Loss_min: 16.1326, Loss_max: -16.1159\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [53/125], Loss_min: 16.1345, Loss_max: -16.1257\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [54/125], Loss_min: 16.1435, Loss_max: -16.1336\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [55/125], Loss_min: 16.1472, Loss_max: -16.1377\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [56/125], Loss_min: 16.1467, Loss_max: -16.1361\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [57/125], Loss_min: 16.1391, Loss_max: -16.1309\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [58/125], Loss_min: 16.1442, Loss_max: -16.1391\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [59/125], Loss_min: 16.1461, Loss_max: -16.1190\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [60/125], Loss_min: 16.1316, Loss_max: -16.1223\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [61/125], Loss_min: 16.1562, Loss_max: -16.1448\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [62/125], Loss_min: 16.1379, Loss_max: -16.1280\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [63/125], Loss_min: 16.1471, Loss_max: -16.1418\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [64/125], Loss_min: 16.1455, Loss_max: -16.1331\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [65/125], Loss_min: 16.1594, Loss_max: -16.1526\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [66/125], Loss_min: 16.1440, Loss_max: -16.1376\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [67/125], Loss_min: 16.1378, Loss_max: -16.1297\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [68/125], Loss_min: 16.1484, Loss_max: -16.1415\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [69/125], Loss_min: 16.1343, Loss_max: -16.1276\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [70/125], Loss_min: 16.1526, Loss_max: -16.1468\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [71/125], Loss_min: 16.1437, Loss_max: -16.1392\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [72/125], Loss_min: 16.1362, Loss_max: -16.1307\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [73/125], Loss_min: 16.1430, Loss_max: -16.1337\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [74/125], Loss_min: 16.1500, Loss_max: -16.1386\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [75/125], Loss_min: 16.1476, Loss_max: -16.1315\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [76/125], Loss_min: 16.1588, Loss_max: -16.1394\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [77/125], Loss_min: 16.1583, Loss_max: -16.1514\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [78/125], Loss_min: 16.1438, Loss_max: -16.1370\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [79/125], Loss_min: 16.1345, Loss_max: -16.1249\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [80/125], Loss_min: 16.1465, Loss_max: -16.1325\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [81/125], Loss_min: 16.1634, Loss_max: -16.1518\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [82/125], Loss_min: 16.1501, Loss_max: -16.1353\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [83/125], Loss_min: 16.1417, Loss_max: -16.1315\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [84/125], Loss_min: 16.1486, Loss_max: -16.1408\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [85/125], Loss_min: 16.1362, Loss_max: -16.1268\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [86/125], Loss_min: 16.1409, Loss_max: -16.1350\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [87/125], Loss_min: 16.1370, Loss_max: -16.1307\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [88/125], Loss_min: 16.1374, Loss_max: -16.1317\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [89/125], Loss_min: 16.1618, Loss_max: -16.1182\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [90/125], Loss_min: 16.1386, Loss_max: -16.1334\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [91/125], Loss_min: 16.1381, Loss_max: -16.1315\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [92/125], Loss_min: 16.1454, Loss_max: -16.1378\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [93/125], Loss_min: 16.1437, Loss_max: -16.1346\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [94/125], Loss_min: 16.1625, Loss_max: -16.1502\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [95/125], Loss_min: 16.1424, Loss_max: -16.1362\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [96/125], Loss_min: 16.1491, Loss_max: -16.1442\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [97/125], Loss_min: 16.1376, Loss_max: -16.1328\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [98/125], Loss_min: 16.1429, Loss_max: -16.1348\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [99/125], Loss_min: 16.1375, Loss_max: -16.1308\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [100/125], Loss_min: 16.1661, Loss_max: -16.1589\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [101/125], Loss_min: 16.1504, Loss_max: -16.1435\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [102/125], Loss_min: 16.1464, Loss_max: -16.1385\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [103/125], Loss_min: 16.1370, Loss_max: -16.1312\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [104/125], Loss_min: 16.1516, Loss_max: -16.1411\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [105/125], Loss_min: 16.1620, Loss_max: -16.1335\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [106/125], Loss_min: 16.1372, Loss_max: -16.1300\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [107/125], Loss_min: 16.1315, Loss_max: -16.1259\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [108/125], Loss_min: 16.1583, Loss_max: -16.1469\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [109/125], Loss_min: 16.1559, Loss_max: -16.1508\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [110/125], Loss_min: 16.1462, Loss_max: -16.1408\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [111/125], Loss_min: 16.1481, Loss_max: -16.1395\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [112/125], Loss_min: 16.1400, Loss_max: -16.1232\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [113/125], Loss_min: 16.1415, Loss_max: -16.1353\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [114/125], Loss_min: 16.1470, Loss_max: -16.1382\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [115/125], Loss_min: 16.1353, Loss_max: -16.1283\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [116/125], Loss_min: 16.1359, Loss_max: -16.1182\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [117/125], Loss_min: 16.1528, Loss_max: -16.1474\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [118/125], Loss_min: 16.1402, Loss_max: -16.1350\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [119/125], Loss_min: 16.1581, Loss_max: -16.1502\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [120/125], Loss_min: 16.1495, Loss_max: -16.1454\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [121/125], Loss_min: 16.1275, Loss_max: -16.1229\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [122/125], Loss_min: 16.1334, Loss_max: -16.1272\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [123/125], Loss_min: 16.1427, Loss_max: -16.1373\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [124/125], Loss_min: 16.1464, Loss_max: -16.1407\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [9/15], Step [125/125], Loss_min: 16.1260, Loss_max: -16.1229\n",
      "Epoch: 9\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [1/125], Loss_min: 16.1470, Loss_max: -16.1394\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [2/125], Loss_min: 16.1537, Loss_max: -16.1462\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [3/125], Loss_min: 16.1372, Loss_max: -16.1308\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [4/125], Loss_min: 16.1476, Loss_max: -16.1349\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [5/125], Loss_min: 16.1300, Loss_max: -16.1250\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [6/125], Loss_min: 16.1479, Loss_max: -16.1365\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [7/125], Loss_min: 16.1614, Loss_max: -16.1488\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [8/125], Loss_min: 16.1349, Loss_max: -16.1309\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [9/125], Loss_min: 16.1431, Loss_max: -16.1372\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [10/125], Loss_min: 16.1449, Loss_max: -16.1407\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [11/125], Loss_min: 16.1510, Loss_max: -16.1457\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [12/125], Loss_min: 16.1520, Loss_max: -16.1483\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [13/125], Loss_min: 16.1346, Loss_max: -16.1277\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [14/125], Loss_min: 16.1369, Loss_max: -16.1297\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [15/125], Loss_min: 16.1502, Loss_max: -16.1443\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [16/125], Loss_min: 16.1336, Loss_max: -16.1284\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [17/125], Loss_min: 16.1436, Loss_max: -16.1392\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [18/125], Loss_min: 16.1461, Loss_max: -16.1389\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [19/125], Loss_min: 16.1332, Loss_max: -16.1297\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [20/125], Loss_min: 16.1431, Loss_max: -16.1378\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [21/125], Loss_min: 16.1558, Loss_max: -16.1497\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [22/125], Loss_min: 16.1485, Loss_max: -16.1429\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [23/125], Loss_min: 16.1403, Loss_max: -16.1343\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [24/125], Loss_min: 16.1563, Loss_max: -16.1450\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [25/125], Loss_min: 16.1531, Loss_max: -16.1426\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [26/125], Loss_min: 16.1432, Loss_max: -16.1376\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [27/125], Loss_min: 16.1618, Loss_max: -16.1327\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [28/125], Loss_min: 16.1456, Loss_max: -16.1331\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [29/125], Loss_min: 16.1548, Loss_max: -16.1458\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [30/125], Loss_min: 16.1401, Loss_max: -16.1224\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [31/125], Loss_min: 16.1272, Loss_max: -16.1200\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [32/125], Loss_min: 16.1557, Loss_max: -16.1366\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [33/125], Loss_min: 16.1453, Loss_max: -16.1374\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [34/125], Loss_min: 16.1560, Loss_max: -16.1398\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [35/125], Loss_min: 16.1569, Loss_max: -16.1458\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [36/125], Loss_min: 16.1520, Loss_max: -16.1453\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [37/125], Loss_min: 16.1462, Loss_max: -16.1405\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [38/125], Loss_min: 16.1377, Loss_max: -16.1300\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [39/125], Loss_min: 16.1524, Loss_max: -16.1453\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [40/125], Loss_min: 16.1488, Loss_max: -16.1414\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [41/125], Loss_min: 16.1487, Loss_max: -16.1394\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [42/125], Loss_min: 16.1616, Loss_max: -16.1528\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [43/125], Loss_min: 16.1362, Loss_max: -16.1298\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [44/125], Loss_min: 16.1448, Loss_max: -16.1380\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [45/125], Loss_min: 16.1532, Loss_max: -16.1443\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [46/125], Loss_min: 16.1285, Loss_max: -16.1183\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [47/125], Loss_min: 16.1534, Loss_max: -16.1420\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [48/125], Loss_min: 16.1757, Loss_max: -16.1564\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [49/125], Loss_min: 16.1431, Loss_max: -16.1327\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [50/125], Loss_min: 16.1447, Loss_max: -16.1364\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [51/125], Loss_min: 16.1521, Loss_max: -16.1274\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [52/125], Loss_min: 16.1398, Loss_max: -16.1275\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [53/125], Loss_min: 16.1445, Loss_max: -16.1330\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [54/125], Loss_min: 16.1677, Loss_max: -16.1573\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [55/125], Loss_min: 16.1583, Loss_max: -16.1475\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [56/125], Loss_min: 16.1572, Loss_max: -16.1406\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [57/125], Loss_min: 16.1529, Loss_max: -16.1370\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [58/125], Loss_min: 16.1481, Loss_max: -16.1367\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [59/125], Loss_min: 16.1543, Loss_max: -16.1375\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [60/125], Loss_min: 16.1398, Loss_max: -16.1283\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [61/125], Loss_min: 16.1682, Loss_max: -16.1567\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [62/125], Loss_min: 16.1470, Loss_max: -16.1312\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [63/125], Loss_min: 16.1633, Loss_max: -16.1448\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [64/125], Loss_min: 16.1617, Loss_max: -16.1439\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [65/125], Loss_min: 16.1475, Loss_max: -16.1347\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [66/125], Loss_min: 16.1254, Loss_max: -16.1094\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [67/125], Loss_min: 16.1724, Loss_max: -16.1565\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [68/125], Loss_min: 16.1278, Loss_max: -16.1208\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [69/125], Loss_min: 16.1392, Loss_max: -16.1325\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [70/125], Loss_min: 16.1574, Loss_max: -16.1474\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [71/125], Loss_min: 16.1401, Loss_max: -16.1315\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [72/125], Loss_min: 16.1272, Loss_max: -16.1104\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [73/125], Loss_min: 16.1138, Loss_max: -16.0977\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [74/125], Loss_min: 16.1224, Loss_max: -16.1111\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [75/125], Loss_min: 16.1288, Loss_max: -16.1170\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [76/125], Loss_min: 16.1375, Loss_max: -16.1282\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [77/125], Loss_min: 16.1476, Loss_max: -16.1342\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [78/125], Loss_min: 16.1518, Loss_max: -16.1405\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [79/125], Loss_min: 16.1391, Loss_max: -16.1025\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [80/125], Loss_min: 16.1571, Loss_max: -16.1455\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [81/125], Loss_min: 16.1614, Loss_max: -16.1432\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [82/125], Loss_min: 16.1395, Loss_max: -16.1289\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [83/125], Loss_min: 16.1474, Loss_max: -16.1215\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [84/125], Loss_min: 16.1454, Loss_max: -16.1311\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [85/125], Loss_min: 16.1675, Loss_max: -16.1400\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [86/125], Loss_min: 16.1289, Loss_max: -16.1209\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [87/125], Loss_min: 16.1528, Loss_max: -16.1381\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [88/125], Loss_min: 16.1584, Loss_max: -16.1397\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [89/125], Loss_min: 16.1465, Loss_max: -16.1108\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [90/125], Loss_min: 16.1674, Loss_max: -16.1584\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [91/125], Loss_min: 16.1462, Loss_max: -16.1328\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [92/125], Loss_min: 16.1491, Loss_max: -16.1349\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [93/125], Loss_min: 16.1354, Loss_max: -16.1282\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [94/125], Loss_min: 16.1614, Loss_max: -16.1494\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [95/125], Loss_min: 16.1468, Loss_max: -16.1345\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [96/125], Loss_min: 16.1385, Loss_max: -16.1276\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [97/125], Loss_min: 16.1398, Loss_max: -16.1335\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [98/125], Loss_min: 16.1564, Loss_max: -16.1502\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [99/125], Loss_min: 16.1588, Loss_max: -16.1531\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [100/125], Loss_min: 16.1381, Loss_max: -16.1341\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [101/125], Loss_min: 16.1387, Loss_max: -16.1343\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [102/125], Loss_min: 16.1405, Loss_max: -16.1351\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [103/125], Loss_min: 16.1422, Loss_max: -16.1374\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [104/125], Loss_min: 16.1265, Loss_max: -16.1108\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [105/125], Loss_min: 16.1591, Loss_max: -16.1536\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [106/125], Loss_min: 16.1568, Loss_max: -16.1467\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [107/125], Loss_min: 16.1333, Loss_max: -16.1257\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [108/125], Loss_min: 16.1567, Loss_max: -16.1523\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [109/125], Loss_min: 16.1462, Loss_max: -16.1372\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [110/125], Loss_min: 16.1738, Loss_max: -16.1346\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [111/125], Loss_min: 16.1419, Loss_max: -16.1358\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [112/125], Loss_min: 16.1500, Loss_max: -16.1448\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [113/125], Loss_min: 16.1479, Loss_max: -16.1405\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [114/125], Loss_min: 16.1525, Loss_max: -16.1474\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [115/125], Loss_min: 16.1613, Loss_max: -16.1513\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [116/125], Loss_min: 16.1403, Loss_max: -16.1353\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [117/125], Loss_min: 16.1381, Loss_max: -16.1338\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [118/125], Loss_min: 16.1823, Loss_max: -16.1261\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [119/125], Loss_min: 16.1512, Loss_max: -16.1347\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [120/125], Loss_min: 16.1269, Loss_max: -16.1218\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [121/125], Loss_min: 16.1480, Loss_max: -16.1401\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [122/125], Loss_min: 16.1258, Loss_max: -16.1214\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [123/125], Loss_min: 16.1294, Loss_max: -16.1226\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [124/125], Loss_min: 16.1567, Loss_max: -16.1517\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [10/15], Step [125/125], Loss_min: 16.1469, Loss_max: -16.1418\n",
      "Epoch: 10\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [1/125], Loss_min: 16.1538, Loss_max: -16.1444\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [2/125], Loss_min: 16.1574, Loss_max: -16.1504\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [3/125], Loss_min: 16.1515, Loss_max: -16.1454\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [4/125], Loss_min: 16.1477, Loss_max: -16.1423\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [5/125], Loss_min: 16.1615, Loss_max: -16.1470\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [6/125], Loss_min: 16.1468, Loss_max: -16.1398\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [7/125], Loss_min: 16.1316, Loss_max: -16.1266\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [8/125], Loss_min: 16.1495, Loss_max: -16.1401\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [9/125], Loss_min: 16.1664, Loss_max: -16.1543\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [10/125], Loss_min: 16.1419, Loss_max: -16.1293\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [11/125], Loss_min: 16.1297, Loss_max: -16.1269\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [12/125], Loss_min: 16.1504, Loss_max: -16.1396\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [13/125], Loss_min: 16.1516, Loss_max: -16.1451\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [14/125], Loss_min: 16.1470, Loss_max: -16.1380\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [15/125], Loss_min: 16.1430, Loss_max: -16.1313\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [16/125], Loss_min: 16.1499, Loss_max: -16.1471\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [17/125], Loss_min: 16.1470, Loss_max: -16.1380\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [18/125], Loss_min: 16.1563, Loss_max: -16.1494\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [19/125], Loss_min: 16.1419, Loss_max: -16.1379\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [20/125], Loss_min: 16.1620, Loss_max: -16.1550\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [21/125], Loss_min: 16.1583, Loss_max: -16.1527\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [22/125], Loss_min: 16.1320, Loss_max: -16.1255\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [23/125], Loss_min: 16.1463, Loss_max: -16.1419\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [24/125], Loss_min: 16.1525, Loss_max: -16.1479\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [25/125], Loss_min: 16.1447, Loss_max: -16.1405\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [26/125], Loss_min: 16.1421, Loss_max: -16.1355\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [27/125], Loss_min: 16.1318, Loss_max: -16.1273\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [28/125], Loss_min: 16.1374, Loss_max: -16.1314\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [29/125], Loss_min: 16.1684, Loss_max: -16.1630\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [30/125], Loss_min: 16.1514, Loss_max: -16.1425\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [31/125], Loss_min: 16.1478, Loss_max: -16.1423\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [32/125], Loss_min: 16.1245, Loss_max: -16.1224\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [33/125], Loss_min: 16.1477, Loss_max: -16.1410\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [34/125], Loss_min: 16.1464, Loss_max: -16.1413\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [35/125], Loss_min: 16.1543, Loss_max: -16.1426\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [36/125], Loss_min: 16.1630, Loss_max: -16.1480\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [37/125], Loss_min: 16.1504, Loss_max: -16.1457\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [38/125], Loss_min: 16.1660, Loss_max: -16.1531\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [39/125], Loss_min: 16.1479, Loss_max: -16.1410\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [40/125], Loss_min: 16.1599, Loss_max: -16.1441\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [41/125], Loss_min: 16.1519, Loss_max: -16.1469\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [42/125], Loss_min: 16.1479, Loss_max: -16.1387\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [43/125], Loss_min: 16.1616, Loss_max: -16.1553\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [44/125], Loss_min: 16.1573, Loss_max: -16.1375\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [45/125], Loss_min: 16.1402, Loss_max: -16.1316\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [46/125], Loss_min: 16.1628, Loss_max: -16.1525\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [47/125], Loss_min: 16.1593, Loss_max: -16.1542\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [48/125], Loss_min: 16.1555, Loss_max: -16.1434\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [49/125], Loss_min: 16.1531, Loss_max: -16.1461\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [50/125], Loss_min: 16.1465, Loss_max: -16.1412\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [51/125], Loss_min: 16.1530, Loss_max: -16.1484\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [52/125], Loss_min: 16.1247, Loss_max: -16.1156\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [53/125], Loss_min: 16.1112, Loss_max: -16.1065\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [54/125], Loss_min: 16.1548, Loss_max: -16.1443\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [55/125], Loss_min: 16.1475, Loss_max: -16.1431\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [56/125], Loss_min: 16.1550, Loss_max: -16.1474\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [57/125], Loss_min: 16.1511, Loss_max: -16.1475\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [58/125], Loss_min: 16.1376, Loss_max: -16.1295\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [59/125], Loss_min: 16.1558, Loss_max: -16.1502\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [60/125], Loss_min: 16.1464, Loss_max: -16.1374\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [61/125], Loss_min: 16.1629, Loss_max: -16.1452\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [62/125], Loss_min: 16.1660, Loss_max: -16.1544\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [63/125], Loss_min: 16.1540, Loss_max: -16.1456\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [64/125], Loss_min: 16.1592, Loss_max: -16.1457\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [65/125], Loss_min: 16.1339, Loss_max: -16.1259\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [66/125], Loss_min: 16.1498, Loss_max: -16.1355\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [67/125], Loss_min: 16.1558, Loss_max: -16.1470\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [68/125], Loss_min: 16.1548, Loss_max: -16.1483\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [69/125], Loss_min: 16.1556, Loss_max: -16.1421\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [70/125], Loss_min: 16.1489, Loss_max: -16.1439\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [71/125], Loss_min: 16.1457, Loss_max: -16.1375\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [72/125], Loss_min: 16.1390, Loss_max: -16.1318\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [73/125], Loss_min: 16.1584, Loss_max: -16.1499\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [74/125], Loss_min: 16.1509, Loss_max: -16.1456\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [75/125], Loss_min: 16.1583, Loss_max: -16.1512\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [76/125], Loss_min: 16.1530, Loss_max: -16.1479\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [77/125], Loss_min: 16.1510, Loss_max: -16.1422\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [78/125], Loss_min: 16.1327, Loss_max: -16.1274\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [79/125], Loss_min: 16.1467, Loss_max: -16.1395\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [80/125], Loss_min: 16.1531, Loss_max: -16.1458\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [81/125], Loss_min: 16.1514, Loss_max: -16.1439\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [82/125], Loss_min: 16.1775, Loss_max: -16.1687\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [83/125], Loss_min: 16.1382, Loss_max: -16.1349\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [84/125], Loss_min: 16.1554, Loss_max: -16.1490\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [85/125], Loss_min: 16.1367, Loss_max: -16.1329\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [86/125], Loss_min: 16.1539, Loss_max: -16.1499\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [87/125], Loss_min: 16.1379, Loss_max: -16.1338\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [88/125], Loss_min: 16.1429, Loss_max: -16.1385\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [89/125], Loss_min: 16.1362, Loss_max: -16.1327\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [90/125], Loss_min: 16.1422, Loss_max: -16.1366\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [91/125], Loss_min: 16.1460, Loss_max: -16.1336\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [92/125], Loss_min: 16.1304, Loss_max: -16.1241\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [93/125], Loss_min: 16.1548, Loss_max: -16.1505\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [94/125], Loss_min: 16.1574, Loss_max: -16.1485\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [95/125], Loss_min: 16.1361, Loss_max: -16.1306\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [96/125], Loss_min: 16.1446, Loss_max: -16.1388\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [97/125], Loss_min: 16.1448, Loss_max: -16.1400\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [98/125], Loss_min: 16.1121, Loss_max: -16.1049\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [99/125], Loss_min: 16.1447, Loss_max: -16.1373\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [100/125], Loss_min: 16.1414, Loss_max: -16.1356\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [101/125], Loss_min: 16.1303, Loss_max: -16.1216\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [102/125], Loss_min: 16.1331, Loss_max: -16.1278\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [103/125], Loss_min: 16.1536, Loss_max: -16.1409\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [104/125], Loss_min: 16.1527, Loss_max: -16.1469\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [105/125], Loss_min: 16.1570, Loss_max: -16.1483\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [106/125], Loss_min: 16.1552, Loss_max: -16.1477\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [107/125], Loss_min: 16.1252, Loss_max: -16.1184\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [108/125], Loss_min: 16.1455, Loss_max: -16.1415\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [109/125], Loss_min: 16.1350, Loss_max: -16.1302\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [110/125], Loss_min: 16.1564, Loss_max: -16.1517\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [111/125], Loss_min: 16.1665, Loss_max: -16.1589\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [112/125], Loss_min: 16.1510, Loss_max: -16.1440\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [113/125], Loss_min: 16.1636, Loss_max: -16.1586\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [114/125], Loss_min: 16.1509, Loss_max: -16.1442\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [115/125], Loss_min: 16.1455, Loss_max: -16.1426\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [116/125], Loss_min: 16.1540, Loss_max: -16.1486\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [117/125], Loss_min: 16.1490, Loss_max: -16.1446\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [118/125], Loss_min: 16.1591, Loss_max: -16.1524\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [119/125], Loss_min: 16.1633, Loss_max: -16.1579\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [120/125], Loss_min: 16.1406, Loss_max: -16.1371\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [121/125], Loss_min: 16.1576, Loss_max: -16.1539\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [122/125], Loss_min: 16.1684, Loss_max: -16.1629\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [123/125], Loss_min: 16.1445, Loss_max: -16.1360\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [124/125], Loss_min: 16.1518, Loss_max: -16.1462\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [11/15], Step [125/125], Loss_min: 16.1579, Loss_max: -16.1528\n",
      "Epoch: 11\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [1/125], Loss_min: 16.1519, Loss_max: -16.1455\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [2/125], Loss_min: 16.1436, Loss_max: -16.1369\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [3/125], Loss_min: 16.1510, Loss_max: -16.1476\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [4/125], Loss_min: 16.1578, Loss_max: -16.1544\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [5/125], Loss_min: 16.1645, Loss_max: -16.1602\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [6/125], Loss_min: 16.1406, Loss_max: -16.1366\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [7/125], Loss_min: 16.1583, Loss_max: -16.1535\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [8/125], Loss_min: 16.1526, Loss_max: -16.1484\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [9/125], Loss_min: 16.1484, Loss_max: -16.1442\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [10/125], Loss_min: 16.1506, Loss_max: -16.1466\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [11/125], Loss_min: 16.1576, Loss_max: -16.1501\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [12/125], Loss_min: 16.1467, Loss_max: -16.1425\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [13/125], Loss_min: 16.1545, Loss_max: -16.1508\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [14/125], Loss_min: 16.1579, Loss_max: -16.1535\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [15/125], Loss_min: 16.1460, Loss_max: -16.1413\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [16/125], Loss_min: 16.1429, Loss_max: -16.1397\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [17/125], Loss_min: 16.1319, Loss_max: -16.1283\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [18/125], Loss_min: 16.1371, Loss_max: -16.1325\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [19/125], Loss_min: 16.1443, Loss_max: -16.1400\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [20/125], Loss_min: 16.1551, Loss_max: -16.1494\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [21/125], Loss_min: 16.1447, Loss_max: -16.1393\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [22/125], Loss_min: 16.1560, Loss_max: -16.1507\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [23/125], Loss_min: 16.1502, Loss_max: -16.1455\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [24/125], Loss_min: 16.1553, Loss_max: -16.1513\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [25/125], Loss_min: 16.1378, Loss_max: -16.1337\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [26/125], Loss_min: 16.1674, Loss_max: -16.1633\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [27/125], Loss_min: 16.1528, Loss_max: -16.1489\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [28/125], Loss_min: 16.1405, Loss_max: -16.1343\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [29/125], Loss_min: 16.1608, Loss_max: -16.1573\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [30/125], Loss_min: 16.1572, Loss_max: -16.1535\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [31/125], Loss_min: 16.1660, Loss_max: -16.1627\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [32/125], Loss_min: 16.1597, Loss_max: -16.1562\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [33/125], Loss_min: 16.1531, Loss_max: -16.1480\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [34/125], Loss_min: 16.1507, Loss_max: -16.1464\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [35/125], Loss_min: 16.1457, Loss_max: -16.1420\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [36/125], Loss_min: 16.1575, Loss_max: -16.1539\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [37/125], Loss_min: 16.1614, Loss_max: -16.1578\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [38/125], Loss_min: 16.1505, Loss_max: -16.1462\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [39/125], Loss_min: 16.1514, Loss_max: -16.1466\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [40/125], Loss_min: 16.1499, Loss_max: -16.1447\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [41/125], Loss_min: 16.1416, Loss_max: -16.1378\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [42/125], Loss_min: 16.1699, Loss_max: -16.1354\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [43/125], Loss_min: 16.1532, Loss_max: -16.1461\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [44/125], Loss_min: 16.1635, Loss_max: -16.1578\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [45/125], Loss_min: 16.1568, Loss_max: -16.1523\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [46/125], Loss_min: 16.1485, Loss_max: -16.1432\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [47/125], Loss_min: 16.1644, Loss_max: -16.1605\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [48/125], Loss_min: 16.1544, Loss_max: -16.1497\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [49/125], Loss_min: 16.1527, Loss_max: -16.1487\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [50/125], Loss_min: 16.1463, Loss_max: -16.1418\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [51/125], Loss_min: 16.1657, Loss_max: -16.1613\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [52/125], Loss_min: 16.1515, Loss_max: -16.1475\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [53/125], Loss_min: 16.1643, Loss_max: -16.1607\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [54/125], Loss_min: 16.1485, Loss_max: -16.1443\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [55/125], Loss_min: 16.1670, Loss_max: -16.1618\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [56/125], Loss_min: 16.1602, Loss_max: -16.1558\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [57/125], Loss_min: 16.1493, Loss_max: -16.1451\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [58/125], Loss_min: 16.1511, Loss_max: -16.1466\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [59/125], Loss_min: 16.1511, Loss_max: -16.1481\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [60/125], Loss_min: 16.1546, Loss_max: -16.1506\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [61/125], Loss_min: 16.1538, Loss_max: -16.1487\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [62/125], Loss_min: 16.1448, Loss_max: -16.1415\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [63/125], Loss_min: 16.1682, Loss_max: -16.1648\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [64/125], Loss_min: 16.1654, Loss_max: -16.1615\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [65/125], Loss_min: 16.1562, Loss_max: -16.1527\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [66/125], Loss_min: 16.1526, Loss_max: -16.1481\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [67/125], Loss_min: 16.1523, Loss_max: -16.1483\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [68/125], Loss_min: 16.1589, Loss_max: -16.1547\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [69/125], Loss_min: 16.1730, Loss_max: -16.1698\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [70/125], Loss_min: 16.1613, Loss_max: -16.1580\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [71/125], Loss_min: 16.1490, Loss_max: -16.1463\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [72/125], Loss_min: 16.1567, Loss_max: -16.1532\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [73/125], Loss_min: 16.1472, Loss_max: -16.1437\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [74/125], Loss_min: 16.1531, Loss_max: -16.1502\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [75/125], Loss_min: 16.1410, Loss_max: -16.1384\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [76/125], Loss_min: 16.1595, Loss_max: -16.1362\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [77/125], Loss_min: 16.1398, Loss_max: -16.1371\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [78/125], Loss_min: 16.1520, Loss_max: -16.1494\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [79/125], Loss_min: 16.1567, Loss_max: -16.1521\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [80/125], Loss_min: 16.1524, Loss_max: -16.1487\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [81/125], Loss_min: 16.1645, Loss_max: -16.1584\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [82/125], Loss_min: 16.1467, Loss_max: -16.1418\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [83/125], Loss_min: 16.1524, Loss_max: -16.1484\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [84/125], Loss_min: 16.1620, Loss_max: -16.1419\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [85/125], Loss_min: 16.1463, Loss_max: -16.1375\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [86/125], Loss_min: 16.1532, Loss_max: -16.1494\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [87/125], Loss_min: 16.1467, Loss_max: -16.1401\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [88/125], Loss_min: 16.1489, Loss_max: -16.1449\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [89/125], Loss_min: 16.1525, Loss_max: -16.1492\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [90/125], Loss_min: 16.1631, Loss_max: -16.1592\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [91/125], Loss_min: 16.1436, Loss_max: -16.1410\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [92/125], Loss_min: 16.1513, Loss_max: -16.1482\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [93/125], Loss_min: 16.1604, Loss_max: -16.1572\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [94/125], Loss_min: 16.1553, Loss_max: -16.1516\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [95/125], Loss_min: 16.1405, Loss_max: -16.1376\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [96/125], Loss_min: 16.1460, Loss_max: -16.1429\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [97/125], Loss_min: 16.1510, Loss_max: -16.1488\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [98/125], Loss_min: 16.1562, Loss_max: -16.1524\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [99/125], Loss_min: 16.1473, Loss_max: -16.1446\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [100/125], Loss_min: 16.1584, Loss_max: -16.1555\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [101/125], Loss_min: 16.1629, Loss_max: -16.1591\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [102/125], Loss_min: 16.1472, Loss_max: -16.1439\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [103/125], Loss_min: 16.1532, Loss_max: -16.1507\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [104/125], Loss_min: 16.1647, Loss_max: -16.1613\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [105/125], Loss_min: 16.1573, Loss_max: -16.1547\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [106/125], Loss_min: 16.1517, Loss_max: -16.1493\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [107/125], Loss_min: 16.1444, Loss_max: -16.1414\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [108/125], Loss_min: 16.1549, Loss_max: -16.1520\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [109/125], Loss_min: 16.1569, Loss_max: -16.1522\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [110/125], Loss_min: 16.1484, Loss_max: -16.1450\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [111/125], Loss_min: 16.1686, Loss_max: -16.1652\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [112/125], Loss_min: 16.1514, Loss_max: -16.1476\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [113/125], Loss_min: 16.1671, Loss_max: -16.1643\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [114/125], Loss_min: 16.1630, Loss_max: -16.1594\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [115/125], Loss_min: 16.1473, Loss_max: -16.1450\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [116/125], Loss_min: 16.1601, Loss_max: -16.1544\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [117/125], Loss_min: 16.1577, Loss_max: -16.1553\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [118/125], Loss_min: 16.1674, Loss_max: -16.1636\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [119/125], Loss_min: 16.1340, Loss_max: -16.1315\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [120/125], Loss_min: 16.1453, Loss_max: -16.1426\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [121/125], Loss_min: 16.1608, Loss_max: -16.1557\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [122/125], Loss_min: 16.1639, Loss_max: -16.1609\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [123/125], Loss_min: 16.1478, Loss_max: -16.1439\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [124/125], Loss_min: 16.1541, Loss_max: -16.1511\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [12/15], Step [125/125], Loss_min: 16.1611, Loss_max: -16.1575\n",
      "Epoch: 12\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [1/125], Loss_min: 16.1651, Loss_max: -16.1617\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [2/125], Loss_min: 16.1643, Loss_max: -16.1596\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [3/125], Loss_min: 16.1409, Loss_max: -16.1383\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [4/125], Loss_min: 16.1766, Loss_max: -16.1478\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [5/125], Loss_min: 16.1555, Loss_max: -16.1525\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [6/125], Loss_min: 16.1482, Loss_max: -16.1453\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [7/125], Loss_min: 16.1363, Loss_max: -16.1318\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [8/125], Loss_min: 16.1421, Loss_max: -16.1383\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [9/125], Loss_min: 16.1610, Loss_max: -16.1580\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [10/125], Loss_min: 16.1609, Loss_max: -16.1567\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [11/125], Loss_min: 16.1480, Loss_max: -16.1449\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [12/125], Loss_min: 16.1646, Loss_max: -16.1545\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [13/125], Loss_min: 16.1365, Loss_max: -16.1287\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [14/125], Loss_min: 16.1293, Loss_max: -16.1256\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [15/125], Loss_min: 16.1493, Loss_max: -16.1458\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [16/125], Loss_min: 16.1489, Loss_max: -16.1462\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [17/125], Loss_min: 16.1640, Loss_max: -16.1564\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [18/125], Loss_min: 16.1611, Loss_max: -16.1574\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [19/125], Loss_min: 16.1596, Loss_max: -16.1553\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [20/125], Loss_min: 16.1353, Loss_max: -16.1313\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [21/125], Loss_min: 16.1333, Loss_max: -16.1304\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [22/125], Loss_min: 16.1360, Loss_max: -16.1331\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [23/125], Loss_min: 16.1574, Loss_max: -16.1527\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [24/125], Loss_min: 16.1623, Loss_max: -16.1591\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [25/125], Loss_min: 16.1672, Loss_max: -16.1635\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [26/125], Loss_min: 16.1385, Loss_max: -16.1355\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [27/125], Loss_min: 16.1670, Loss_max: -16.1634\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [28/125], Loss_min: 16.1491, Loss_max: -16.1455\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [29/125], Loss_min: 16.1551, Loss_max: -16.1516\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [30/125], Loss_min: 16.1399, Loss_max: -16.1371\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [31/125], Loss_min: 16.1597, Loss_max: -16.1545\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [32/125], Loss_min: 16.1488, Loss_max: -16.1448\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [33/125], Loss_min: 16.1520, Loss_max: -16.1484\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [34/125], Loss_min: 16.1586, Loss_max: -16.1542\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [35/125], Loss_min: 16.1582, Loss_max: -16.1543\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [36/125], Loss_min: 16.1514, Loss_max: -16.1482\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [37/125], Loss_min: 16.1532, Loss_max: -16.1488\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [38/125], Loss_min: 16.1514, Loss_max: -16.1484\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [39/125], Loss_min: 16.1659, Loss_max: -16.1627\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [40/125], Loss_min: 16.1416, Loss_max: -16.1392\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [41/125], Loss_min: 16.1600, Loss_max: -16.1562\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [42/125], Loss_min: 16.1495, Loss_max: -16.1458\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [43/125], Loss_min: 16.1522, Loss_max: -16.1491\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [44/125], Loss_min: 16.1534, Loss_max: -16.1503\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [45/125], Loss_min: 16.1523, Loss_max: -16.1493\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [46/125], Loss_min: 16.1549, Loss_max: -16.1509\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [47/125], Loss_min: 16.1366, Loss_max: -16.1334\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [48/125], Loss_min: 16.1386, Loss_max: -16.1357\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [49/125], Loss_min: 16.1545, Loss_max: -16.1488\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [50/125], Loss_min: 16.1604, Loss_max: -16.1569\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [51/125], Loss_min: 16.1030, Loss_max: -16.0998\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [52/125], Loss_min: 16.1303, Loss_max: -16.1259\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [53/125], Loss_min: 16.1456, Loss_max: -16.1409\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [54/125], Loss_min: 16.1501, Loss_max: -16.1461\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [55/125], Loss_min: 16.1561, Loss_max: -16.1508\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [56/125], Loss_min: 16.1517, Loss_max: -16.1461\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [57/125], Loss_min: 16.1484, Loss_max: -16.1424\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [58/125], Loss_min: 16.1288, Loss_max: -16.1229\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [59/125], Loss_min: 16.1365, Loss_max: -16.1324\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [60/125], Loss_min: 16.1313, Loss_max: -16.1248\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [61/125], Loss_min: 16.1539, Loss_max: -16.1482\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [62/125], Loss_min: 16.1450, Loss_max: -16.1373\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [63/125], Loss_min: 16.1436, Loss_max: -16.1376\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [64/125], Loss_min: 16.1525, Loss_max: -16.1467\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [65/125], Loss_min: 16.1468, Loss_max: -16.1375\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [66/125], Loss_min: 16.1339, Loss_max: -16.1286\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [67/125], Loss_min: 16.1396, Loss_max: -16.1300\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [68/125], Loss_min: 16.1356, Loss_max: -16.1287\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [69/125], Loss_min: 16.1521, Loss_max: -16.1458\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [70/125], Loss_min: 16.1465, Loss_max: -16.1402\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [71/125], Loss_min: 16.1103, Loss_max: -16.1051\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [72/125], Loss_min: 16.1648, Loss_max: -16.1583\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [73/125], Loss_min: 16.1169, Loss_max: -16.1100\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [74/125], Loss_min: 16.1346, Loss_max: -16.1243\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [75/125], Loss_min: 16.1387, Loss_max: -16.1276\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [76/125], Loss_min: 16.1315, Loss_max: -16.1234\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [77/125], Loss_min: 16.1533, Loss_max: -16.1415\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [78/125], Loss_min: 16.1403, Loss_max: -16.1192\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [79/125], Loss_min: 16.1436, Loss_max: -16.1333\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [80/125], Loss_min: 16.1363, Loss_max: -16.1285\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [81/125], Loss_min: 16.1324, Loss_max: -16.1261\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [82/125], Loss_min: 16.1684, Loss_max: -16.1436\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [83/125], Loss_min: 16.1527, Loss_max: -16.1459\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [84/125], Loss_min: 16.1311, Loss_max: -16.1229\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [85/125], Loss_min: 16.1665, Loss_max: -16.1589\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [86/125], Loss_min: 16.1344, Loss_max: -16.1277\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [87/125], Loss_min: 16.1504, Loss_max: -16.1423\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [88/125], Loss_min: 16.1440, Loss_max: -16.1340\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [89/125], Loss_min: 16.1532, Loss_max: -16.1460\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [90/125], Loss_min: 16.1706, Loss_max: -16.1554\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [91/125], Loss_min: 16.1469, Loss_max: -16.1386\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [92/125], Loss_min: 16.1386, Loss_max: -16.1288\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [93/125], Loss_min: 16.1679, Loss_max: -16.1618\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [94/125], Loss_min: 16.1481, Loss_max: -16.1343\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [95/125], Loss_min: 16.1532, Loss_max: -16.1341\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [96/125], Loss_min: 16.1650, Loss_max: -16.1499\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [97/125], Loss_min: 16.1485, Loss_max: -16.1339\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [98/125], Loss_min: 16.1398, Loss_max: -16.1316\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [99/125], Loss_min: 16.1618, Loss_max: -16.1470\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [100/125], Loss_min: 16.1502, Loss_max: -16.1392\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [101/125], Loss_min: 16.1554, Loss_max: -16.1414\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [102/125], Loss_min: 16.1552, Loss_max: -16.1361\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [103/125], Loss_min: 16.1526, Loss_max: -16.1316\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [104/125], Loss_min: 16.1524, Loss_max: -16.1379\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [105/125], Loss_min: 16.1604, Loss_max: -16.1502\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [106/125], Loss_min: 16.1553, Loss_max: -16.1462\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [107/125], Loss_min: 16.1476, Loss_max: -16.1421\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [108/125], Loss_min: 16.1603, Loss_max: -16.1519\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [109/125], Loss_min: 16.1572, Loss_max: -16.1461\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [110/125], Loss_min: 16.1572, Loss_max: -16.1485\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [111/125], Loss_min: 16.1511, Loss_max: -16.1436\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [112/125], Loss_min: 16.1552, Loss_max: -16.1490\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [113/125], Loss_min: 16.1513, Loss_max: -16.1466\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [114/125], Loss_min: 16.1562, Loss_max: -16.1476\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [115/125], Loss_min: 16.1606, Loss_max: -16.1541\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [116/125], Loss_min: 16.1623, Loss_max: -16.1565\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [117/125], Loss_min: 16.1592, Loss_max: -16.1508\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [118/125], Loss_min: 16.1678, Loss_max: -16.1598\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [119/125], Loss_min: 16.1648, Loss_max: -16.1585\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [120/125], Loss_min: 16.1581, Loss_max: -16.1445\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [121/125], Loss_min: 16.1453, Loss_max: -16.1361\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [122/125], Loss_min: 16.1594, Loss_max: -16.1522\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [123/125], Loss_min: 16.1583, Loss_max: -16.1515\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [124/125], Loss_min: 16.1680, Loss_max: -16.1562\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [13/15], Step [125/125], Loss_min: 16.1563, Loss_max: -16.1489\n",
      "Epoch: 13\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [1/125], Loss_min: 16.1485, Loss_max: -16.1447\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [2/125], Loss_min: 16.1556, Loss_max: -16.1482\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [3/125], Loss_min: 16.1488, Loss_max: -16.1454\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [4/125], Loss_min: 16.1599, Loss_max: -16.1512\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [5/125], Loss_min: 16.1554, Loss_max: -16.1508\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [6/125], Loss_min: 16.1546, Loss_max: -16.1514\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [7/125], Loss_min: 16.1513, Loss_max: -16.1463\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [8/125], Loss_min: 16.1603, Loss_max: -16.1552\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [9/125], Loss_min: 16.1521, Loss_max: -16.1484\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [10/125], Loss_min: 16.1391, Loss_max: -16.1339\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [11/125], Loss_min: 16.1513, Loss_max: -16.1475\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [12/125], Loss_min: 16.1476, Loss_max: -16.1431\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [13/125], Loss_min: 16.1605, Loss_max: -16.1542\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [14/125], Loss_min: 16.1377, Loss_max: -16.1341\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [15/125], Loss_min: 16.1514, Loss_max: -16.1473\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [16/125], Loss_min: 16.1394, Loss_max: -16.1347\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [17/125], Loss_min: 16.1409, Loss_max: -16.1361\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [18/125], Loss_min: 16.1345, Loss_max: -16.1311\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [19/125], Loss_min: 16.1541, Loss_max: -16.1494\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [20/125], Loss_min: 16.1414, Loss_max: -16.1372\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [21/125], Loss_min: 16.1492, Loss_max: -16.1444\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [22/125], Loss_min: 16.1540, Loss_max: -16.1502\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [23/125], Loss_min: 16.1180, Loss_max: -16.1152\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [24/125], Loss_min: 16.1674, Loss_max: -16.1614\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [25/125], Loss_min: 16.1563, Loss_max: -16.1516\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [26/125], Loss_min: 16.1633, Loss_max: -16.1578\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [27/125], Loss_min: 16.1476, Loss_max: -16.1443\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [28/125], Loss_min: 16.1500, Loss_max: -16.1462\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [29/125], Loss_min: 16.1625, Loss_max: -16.1578\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [30/125], Loss_min: 16.1549, Loss_max: -16.1511\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [31/125], Loss_min: 16.1614, Loss_max: -16.1538\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [32/125], Loss_min: 16.1588, Loss_max: -16.1539\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [33/125], Loss_min: 16.1686, Loss_max: -16.1642\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [34/125], Loss_min: 16.1688, Loss_max: -16.1622\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [35/125], Loss_min: 16.1585, Loss_max: -16.1540\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [36/125], Loss_min: 16.1639, Loss_max: -16.1593\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [37/125], Loss_min: 16.1572, Loss_max: -16.1515\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [38/125], Loss_min: 16.1557, Loss_max: -16.1511\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [39/125], Loss_min: 16.1598, Loss_max: -16.1516\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [40/125], Loss_min: 16.1396, Loss_max: -16.1347\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [41/125], Loss_min: 16.1600, Loss_max: -16.1535\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [42/125], Loss_min: 16.1587, Loss_max: -16.1535\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [43/125], Loss_min: 16.1421, Loss_max: -16.1371\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [44/125], Loss_min: 16.1707, Loss_max: -16.1638\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [45/125], Loss_min: 16.1522, Loss_max: -16.1434\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [46/125], Loss_min: 16.1527, Loss_max: -16.1474\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [47/125], Loss_min: 16.1608, Loss_max: -16.1514\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [48/125], Loss_min: 16.1570, Loss_max: -16.1527\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [49/125], Loss_min: 16.1644, Loss_max: -16.1566\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [50/125], Loss_min: 16.1581, Loss_max: -16.1538\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [51/125], Loss_min: 16.1481, Loss_max: -16.1419\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [52/125], Loss_min: 16.1570, Loss_max: -16.1530\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [53/125], Loss_min: 16.1375, Loss_max: -16.1345\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [54/125], Loss_min: 16.1662, Loss_max: -16.1560\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [55/125], Loss_min: 16.1522, Loss_max: -16.1477\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [56/125], Loss_min: 16.1635, Loss_max: -16.1546\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [57/125], Loss_min: 16.1421, Loss_max: -16.1396\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [58/125], Loss_min: 16.1528, Loss_max: -16.1497\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [59/125], Loss_min: 16.1466, Loss_max: -16.1418\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [60/125], Loss_min: 16.1607, Loss_max: -16.1573\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [61/125], Loss_min: 16.1637, Loss_max: -16.1527\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [62/125], Loss_min: 16.1722, Loss_max: -16.1541\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [63/125], Loss_min: 16.1668, Loss_max: -16.1619\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [64/125], Loss_min: 16.1698, Loss_max: -16.1646\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [65/125], Loss_min: 16.1583, Loss_max: -16.1521\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [66/125], Loss_min: 16.1637, Loss_max: -16.1579\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [67/125], Loss_min: 16.1526, Loss_max: -16.1472\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [68/125], Loss_min: 16.1639, Loss_max: -16.1576\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [69/125], Loss_min: 16.1565, Loss_max: -16.1504\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [70/125], Loss_min: 16.1615, Loss_max: -16.1571\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [71/125], Loss_min: 16.1640, Loss_max: -16.1573\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [72/125], Loss_min: 16.1475, Loss_max: -16.1445\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [73/125], Loss_min: 16.1726, Loss_max: -16.1676\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [74/125], Loss_min: 16.1495, Loss_max: -16.1462\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [75/125], Loss_min: 16.1551, Loss_max: -16.1513\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [76/125], Loss_min: 16.1737, Loss_max: -16.1680\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [77/125], Loss_min: 16.1514, Loss_max: -16.1473\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [78/125], Loss_min: 16.1608, Loss_max: -16.1566\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [79/125], Loss_min: 16.1608, Loss_max: -16.1487\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [80/125], Loss_min: 16.1698, Loss_max: -16.1459\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [81/125], Loss_min: 16.1544, Loss_max: -16.1503\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [82/125], Loss_min: 16.1632, Loss_max: -16.1544\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [83/125], Loss_min: 16.1698, Loss_max: -16.1652\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [84/125], Loss_min: 16.1569, Loss_max: -16.1521\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [85/125], Loss_min: 16.1523, Loss_max: -16.1489\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [86/125], Loss_min: 16.1603, Loss_max: -16.1574\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [87/125], Loss_min: 16.1512, Loss_max: -16.1453\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [88/125], Loss_min: 16.1597, Loss_max: -16.1562\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [89/125], Loss_min: 16.1765, Loss_max: -16.1716\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [90/125], Loss_min: 16.1580, Loss_max: -16.1540\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [91/125], Loss_min: 16.1618, Loss_max: -16.1563\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [92/125], Loss_min: 16.1645, Loss_max: -16.1582\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [93/125], Loss_min: 16.1680, Loss_max: -16.1610\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [94/125], Loss_min: 16.1572, Loss_max: -16.1514\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [95/125], Loss_min: 16.1661, Loss_max: -16.1617\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [96/125], Loss_min: 16.1700, Loss_max: -16.1618\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [97/125], Loss_min: 16.1691, Loss_max: -16.1661\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [98/125], Loss_min: 16.1566, Loss_max: -16.1505\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [99/125], Loss_min: 16.1596, Loss_max: -16.1529\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [100/125], Loss_min: 16.1626, Loss_max: -16.1538\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [101/125], Loss_min: 16.1542, Loss_max: -16.1486\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [102/125], Loss_min: 16.1565, Loss_max: -16.1455\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [103/125], Loss_min: 16.1617, Loss_max: -16.1523\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [104/125], Loss_min: 16.1577, Loss_max: -16.1520\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [105/125], Loss_min: 16.1521, Loss_max: -16.1487\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [106/125], Loss_min: 16.1637, Loss_max: -16.1563\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [107/125], Loss_min: 16.1595, Loss_max: -16.1559\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [108/125], Loss_min: 16.1577, Loss_max: -16.1526\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [109/125], Loss_min: 16.1517, Loss_max: -16.1461\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [110/125], Loss_min: 16.1596, Loss_max: -16.1548\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [111/125], Loss_min: 16.1633, Loss_max: -16.1596\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [112/125], Loss_min: 16.1679, Loss_max: -16.1633\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [113/125], Loss_min: 16.1635, Loss_max: -16.1586\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [114/125], Loss_min: 16.1734, Loss_max: -16.1673\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [115/125], Loss_min: 16.1512, Loss_max: -16.1477\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [116/125], Loss_min: 16.1636, Loss_max: -16.1586\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [117/125], Loss_min: 16.1609, Loss_max: -16.1568\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [118/125], Loss_min: 16.1590, Loss_max: -16.1548\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [119/125], Loss_min: 16.1686, Loss_max: -16.1647\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [120/125], Loss_min: 16.1621, Loss_max: -16.1577\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [121/125], Loss_min: 16.1603, Loss_max: -16.1571\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [122/125], Loss_min: 16.1728, Loss_max: -16.1683\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [123/125], Loss_min: 16.1558, Loss_max: -16.1519\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [124/125], Loss_min: 16.1706, Loss_max: -16.1676\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [14/15], Step [125/125], Loss_min: 16.1695, Loss_max: -16.1663\n",
      "Epoch: 14\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [1/125], Loss_min: 16.1505, Loss_max: -16.1470\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [2/125], Loss_min: 16.1645, Loss_max: -16.1585\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [3/125], Loss_min: 16.1685, Loss_max: -16.1646\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [4/125], Loss_min: 16.1502, Loss_max: -16.1438\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [5/125], Loss_min: 16.1638, Loss_max: -16.1561\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [6/125], Loss_min: 16.1640, Loss_max: -16.1598\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [7/125], Loss_min: 16.1671, Loss_max: -16.1633\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [8/125], Loss_min: 16.1568, Loss_max: -16.1534\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [9/125], Loss_min: 16.1493, Loss_max: -16.1467\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [10/125], Loss_min: 16.1488, Loss_max: -16.1457\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [11/125], Loss_min: 16.1683, Loss_max: -16.1631\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [12/125], Loss_min: 16.1694, Loss_max: -16.1659\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [13/125], Loss_min: 16.1667, Loss_max: -16.1639\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [14/125], Loss_min: 16.1586, Loss_max: -16.1541\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [15/125], Loss_min: 16.1693, Loss_max: -16.1628\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [16/125], Loss_min: 16.1566, Loss_max: -16.1527\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [17/125], Loss_min: 16.1529, Loss_max: -16.1497\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [18/125], Loss_min: 16.1672, Loss_max: -16.1549\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [19/125], Loss_min: 16.1464, Loss_max: -16.1219\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [20/125], Loss_min: 16.1708, Loss_max: -16.1669\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [21/125], Loss_min: 16.1603, Loss_max: -16.1569\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [22/125], Loss_min: 16.1519, Loss_max: -16.1483\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [23/125], Loss_min: 16.1694, Loss_max: -16.1661\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [24/125], Loss_min: 16.1780, Loss_max: -16.1740\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [25/125], Loss_min: 16.1667, Loss_max: -16.1629\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [26/125], Loss_min: 16.1677, Loss_max: -16.1629\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [27/125], Loss_min: 16.1707, Loss_max: -16.1631\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [28/125], Loss_min: 16.1728, Loss_max: -16.1692\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [29/125], Loss_min: 16.1758, Loss_max: -16.1656\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [30/125], Loss_min: 16.1677, Loss_max: -16.1640\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [31/125], Loss_min: 16.1695, Loss_max: -16.1665\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [32/125], Loss_min: 16.1655, Loss_max: -16.1624\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [33/125], Loss_min: 16.1619, Loss_max: -16.1580\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [34/125], Loss_min: 16.1460, Loss_max: -16.1436\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [35/125], Loss_min: 16.1605, Loss_max: -16.1561\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [36/125], Loss_min: 16.1692, Loss_max: -16.1654\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [37/125], Loss_min: 16.1717, Loss_max: -16.1681\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [38/125], Loss_min: 16.1681, Loss_max: -16.1645\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [39/125], Loss_min: 16.1578, Loss_max: -16.1553\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [40/125], Loss_min: 16.1671, Loss_max: -16.1638\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [41/125], Loss_min: 16.1727, Loss_max: -16.1692\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [42/125], Loss_min: 16.1529, Loss_max: -16.1497\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [43/125], Loss_min: 16.1679, Loss_max: -16.1650\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [44/125], Loss_min: 16.1708, Loss_max: -16.1677\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [45/125], Loss_min: 16.1609, Loss_max: -16.1576\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [46/125], Loss_min: 16.1685, Loss_max: -16.1660\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [47/125], Loss_min: 16.1645, Loss_max: -16.1600\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [48/125], Loss_min: 16.1610, Loss_max: -16.1586\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [49/125], Loss_min: 16.1711, Loss_max: -16.1620\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [50/125], Loss_min: 16.1618, Loss_max: -16.1573\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [51/125], Loss_min: 16.1685, Loss_max: -16.1651\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [52/125], Loss_min: 16.1618, Loss_max: -16.1573\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [53/125], Loss_min: 16.1573, Loss_max: -16.1544\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [54/125], Loss_min: 16.1689, Loss_max: -16.1659\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [55/125], Loss_min: 16.1711, Loss_max: -16.1674\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [56/125], Loss_min: 16.1570, Loss_max: -16.1539\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [57/125], Loss_min: 16.1544, Loss_max: -16.1511\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [58/125], Loss_min: 16.1542, Loss_max: -16.1452\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [59/125], Loss_min: 16.1647, Loss_max: -16.1617\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [60/125], Loss_min: 16.1764, Loss_max: -16.1528\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [61/125], Loss_min: 16.1769, Loss_max: -16.1724\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [62/125], Loss_min: 16.1573, Loss_max: -16.1520\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [63/125], Loss_min: 16.1616, Loss_max: -16.1488\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [64/125], Loss_min: 16.1552, Loss_max: -16.1524\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [65/125], Loss_min: 16.1645, Loss_max: -16.1597\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [66/125], Loss_min: 16.1614, Loss_max: -16.1576\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [67/125], Loss_min: 16.1664, Loss_max: -16.1435\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [68/125], Loss_min: 16.1723, Loss_max: -16.1684\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [69/125], Loss_min: 16.1640, Loss_max: -16.1597\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [70/125], Loss_min: 16.1659, Loss_max: -16.1502\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [71/125], Loss_min: 16.1663, Loss_max: -16.1620\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [72/125], Loss_min: 16.1708, Loss_max: -16.1673\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [73/125], Loss_min: 16.1694, Loss_max: -16.1562\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [74/125], Loss_min: 16.1585, Loss_max: -16.1542\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [75/125], Loss_min: 16.1510, Loss_max: -16.1478\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [76/125], Loss_min: 16.1467, Loss_max: -16.1435\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [77/125], Loss_min: 16.1590, Loss_max: -16.1548\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [78/125], Loss_min: 16.1561, Loss_max: -16.1525\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [79/125], Loss_min: 16.1399, Loss_max: -16.1359\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [80/125], Loss_min: 16.1662, Loss_max: -16.1614\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [81/125], Loss_min: 16.1700, Loss_max: -16.1664\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [82/125], Loss_min: 16.1533, Loss_max: -16.1491\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [83/125], Loss_min: 16.1546, Loss_max: -16.1515\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [84/125], Loss_min: 16.1598, Loss_max: -16.1570\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [85/125], Loss_min: 16.1674, Loss_max: -16.1649\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [86/125], Loss_min: 16.1537, Loss_max: -16.1506\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [87/125], Loss_min: 16.1732, Loss_max: -16.1697\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [88/125], Loss_min: 16.1365, Loss_max: -16.1320\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [89/125], Loss_min: 16.1713, Loss_max: -16.1683\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [90/125], Loss_min: 16.1669, Loss_max: -16.1639\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [91/125], Loss_min: 16.1693, Loss_max: -16.1661\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [92/125], Loss_min: 16.1686, Loss_max: -16.1642\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [93/125], Loss_min: 16.1754, Loss_max: -16.1724\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [94/125], Loss_min: 16.1534, Loss_max: -16.1511\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [95/125], Loss_min: 16.1745, Loss_max: -16.1700\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [96/125], Loss_min: 16.1767, Loss_max: -16.1741\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [97/125], Loss_min: 16.1767, Loss_max: -16.1742\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [98/125], Loss_min: 16.1671, Loss_max: -16.1642\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [99/125], Loss_min: 16.1663, Loss_max: -16.1638\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [100/125], Loss_min: 16.1636, Loss_max: -16.1614\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [101/125], Loss_min: 16.1677, Loss_max: -16.1646\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [102/125], Loss_min: 16.1660, Loss_max: -16.1627\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [103/125], Loss_min: 16.1641, Loss_max: -16.1607\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [104/125], Loss_min: 16.1684, Loss_max: -16.1651\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [105/125], Loss_min: 16.1644, Loss_max: -16.1613\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [106/125], Loss_min: 16.1639, Loss_max: -16.1615\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [107/125], Loss_min: 16.1650, Loss_max: -16.1603\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [108/125], Loss_min: 16.1663, Loss_max: -16.1635\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [109/125], Loss_min: 16.1627, Loss_max: -16.1595\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [110/125], Loss_min: 16.1733, Loss_max: -16.1687\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [111/125], Loss_min: 16.1666, Loss_max: -16.1637\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [112/125], Loss_min: 16.1692, Loss_max: -16.1661\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [113/125], Loss_min: 16.1599, Loss_max: -16.1568\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [114/125], Loss_min: 16.1704, Loss_max: -16.1673\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [115/125], Loss_min: 16.1724, Loss_max: -16.1693\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [116/125], Loss_min: 16.1585, Loss_max: -16.1551\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [117/125], Loss_min: 16.1443, Loss_max: -16.1407\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [118/125], Loss_min: 16.1634, Loss_max: -16.1606\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [119/125], Loss_min: 16.1739, Loss_max: -16.1713\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [120/125], Loss_min: 16.1543, Loss_max: -16.1509\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [121/125], Loss_min: 16.1554, Loss_max: -16.1508\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [122/125], Loss_min: 16.1617, Loss_max: -16.1580\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [123/125], Loss_min: 16.1625, Loss_max: -16.1593\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [124/125], Loss_min: 16.1678, Loss_max: -16.1644\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(16.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [15/15], Step [125/125], Loss_min: 16.1692, Loss_max: -16.1654\n",
      "Entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "modelo.train()\n",
    "lambda_=1\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i, (inputs) in enumerate(dataloader):\n",
    "        # Forward\n",
    "        inputs=inputs.float().to(\"cuda:0\")\n",
    "        outputs, series, prior, _ = modelo(inputs)\n",
    "        prior=[j/torch.unsqueeze(torch.sum(j, dim=-1), dim=-1).repeat(1, 1, 1, 600) for j in prior]\n",
    "        loss_min = min_loss(outputs,prior,series, inputs,lambda_)\n",
    "        loss_max = max_loss(outputs,prior,series, inputs,lambda_)\n",
    "\n",
    "        # Backward y optimización\n",
    "        loss_min.backward(retain_graph=True)\n",
    "        loss_max.backward()\n",
    "        #clip_gradients(modelo, max_norm=1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        del inputs \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        warmup_and_decay_learning_rate(optimizer, epoch, 1e-2,6 , num_epochs)\n",
    "        # Printear resultados\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss_min: {loss_min.item():.4f}, Loss_max: {loss_max.item():.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo.cuda()\n",
    "a_x=next(iter(dataloader))\n",
    "a_x_cuda=a_x.float().to(\"cuda:0\")\n",
    "modelo.eval()\n",
    "output,series_aux,prior_aux,_=modelo(a_x_cuda)\n",
    "\n",
    "\n",
    "output=output.squeeze().cpu().detach().numpy()\n",
    "series_aux=series_aux[0].squeeze().cpu().detach().numpy()\n",
    "prior_aux=prior_aux[0].squeeze().cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f64fef650>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=11\n",
    "plt.plot(a_x[n])\n",
    "plt.plot(output[n],\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
