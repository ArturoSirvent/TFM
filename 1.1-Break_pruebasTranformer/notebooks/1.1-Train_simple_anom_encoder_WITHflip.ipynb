{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear unos datos MUYYY sencillitos, y vamos a entrenar el modelo en RECONSTRUIRLOS solo. No vamos a pretender que haga nada m√°s.   \n",
    "Luego le meteremos lo de al AssDis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model import AnomalyTransformer\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los datos sinteticos\n",
    "\n",
    "Voy a hacer un generador que nos de una secuencia regular, con puntos de anomalia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinne(lenght=100,amp=1,sf=0.1,f=2,phase=0):\n",
    "    x = torch.arange(0,lenght*sf, sf)\n",
    "    return amp*torch.sin(x*sf*2*torch.pi/f+phase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd2dc93d8d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y=sinne(380,sf=0.1,f=1,phase=4)\n",
    "plt.plot(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora el generador de datos. Le decimos que nos devuelva un batch de datos y nos lo da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    #esta es la clase de los datos que seran secuencias de senos de freq aleatoria \n",
    "    def __init__(self,lenght,num_samples,amp_random=True,freq_random=True,phase_random=True,sf=0.1):\n",
    "        super().__init__()\n",
    "        self.amp_random=amp_random\n",
    "        self.freq_random=freq_random\n",
    "        self.phase_random=phase_random\n",
    "        self.num_samples=num_samples\n",
    "        self.sf=0.1\n",
    "        self.lenght=lenght\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        amp=float(np.random.randint(1,300,1)*0.01)\n",
    "        phase=np.random.randint(0,100,1)*0.02\n",
    "        f=np.random.randint(1,200,1)*0.01\n",
    "        y=sinne(lenght=self.lenght,amp=amp,sf=0.1,f=f,phase=phase)\n",
    "        y=y.unsqueeze(-1)\n",
    "        return y, y.flip(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=600\n",
    "data=Data(win_size,4000)\n",
    "\n",
    "dataloader=DataLoader(data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd2dc81d890>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a[1])\n",
    "plt.plot(a.flip(1)[1])\n",
    "plt.plot(b[1],\"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es todo lo personalizable que querria, pero bien, ahora creamos la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=AnomalyTransformer.AnomalyTransformer(win_size, 1, 1, d_model=32, n_heads=4, e_layers=1, d_ff=32,\n",
    "                          dropout=0.4, activation='gelu', output_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 6853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6853"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def warmup_and_decay_learning_rate(optimizer, epoch, init_lr, warmup_epochs, total_epochs):\n",
    "    if epoch <= warmup_epochs:\n",
    "        lr = init_lr * (epoch / warmup_epochs)\n",
    "        print('Warmup: Updating learning rate to {}'.format(lr))\n",
    "    else:\n",
    "        decay_epochs = total_epochs - warmup_epochs\n",
    "        decay_rate = 1e-7+(epoch - warmup_epochs) / decay_epochs\n",
    "        lr = init_lr * (1 - decay_rate)\n",
    "        print('Decay: Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \n",
    "    total=sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total}\")\n",
    "    return total\n",
    "count_parameters(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [1/125], Loss: 1.6742\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [2/125], Loss: 1.3609\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [3/125], Loss: 1.8953\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [4/125], Loss: 1.9769\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [5/125], Loss: 1.9735\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [6/125], Loss: 2.4365\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [7/125], Loss: 1.6243\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [8/125], Loss: 2.1733\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [9/125], Loss: 1.7370\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [10/125], Loss: 1.8141\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [11/125], Loss: 1.7929\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [12/125], Loss: 1.8113\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [13/125], Loss: 2.0169\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [14/125], Loss: 1.9623\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [15/125], Loss: 1.9681\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [16/125], Loss: 1.3897\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [17/125], Loss: 2.0748\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [18/125], Loss: 1.8004\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [19/125], Loss: 2.5673\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [20/125], Loss: 1.9947\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [21/125], Loss: 1.7885\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [22/125], Loss: 2.0670\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [23/125], Loss: 1.9296\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [24/125], Loss: 2.1219\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [25/125], Loss: 1.4410\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [26/125], Loss: 1.5209\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [27/125], Loss: 1.8286\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [28/125], Loss: 1.8876\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [29/125], Loss: 2.1380\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [30/125], Loss: 1.8926\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [31/125], Loss: 1.4628\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [32/125], Loss: 2.2781\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [33/125], Loss: 2.0024\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [34/125], Loss: 2.2091\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [35/125], Loss: 1.6543\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [36/125], Loss: 2.2921\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [37/125], Loss: 1.4332\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [38/125], Loss: 2.0973\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [39/125], Loss: 2.1782\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [40/125], Loss: 2.2711\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [41/125], Loss: 2.0992\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [42/125], Loss: 2.2316\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [43/125], Loss: 2.0982\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [44/125], Loss: 2.0247\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [45/125], Loss: 2.0836\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [46/125], Loss: 1.9910\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [47/125], Loss: 1.3468\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [48/125], Loss: 1.8559\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [49/125], Loss: 1.6335\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [50/125], Loss: 1.8408\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [51/125], Loss: 1.8324\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [52/125], Loss: 2.1123\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [53/125], Loss: 2.0110\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [54/125], Loss: 1.6088\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [55/125], Loss: 1.8914\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [56/125], Loss: 1.6407\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [57/125], Loss: 2.3380\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [58/125], Loss: 1.9798\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [59/125], Loss: 1.9318\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [60/125], Loss: 2.2686\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [61/125], Loss: 1.5814\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [62/125], Loss: 1.6341\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [63/125], Loss: 1.7923\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [64/125], Loss: 1.7372\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [65/125], Loss: 2.0770\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [66/125], Loss: 2.5617\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [67/125], Loss: 1.9935\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [68/125], Loss: 1.8693\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [69/125], Loss: 1.5192\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [70/125], Loss: 2.0952\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [71/125], Loss: 2.1319\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [72/125], Loss: 2.1328\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [73/125], Loss: 1.9012\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [74/125], Loss: 1.5687\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [75/125], Loss: 1.9476\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [76/125], Loss: 1.6743\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [77/125], Loss: 1.9155\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [78/125], Loss: 1.6921\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [79/125], Loss: 1.9532\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [80/125], Loss: 2.1578\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [81/125], Loss: 1.4340\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [82/125], Loss: 1.8686\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [83/125], Loss: 1.7118\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [84/125], Loss: 1.9741\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [85/125], Loss: 1.6542\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [86/125], Loss: 2.5048\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [87/125], Loss: 1.9984\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [88/125], Loss: 1.1632\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [89/125], Loss: 2.2842\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [90/125], Loss: 1.7902\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [91/125], Loss: 1.9339\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [92/125], Loss: 1.8851\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [93/125], Loss: 1.9495\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [94/125], Loss: 1.6304\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [95/125], Loss: 1.8726\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [96/125], Loss: 1.7660\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [97/125], Loss: 1.6495\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [98/125], Loss: 2.3507\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [99/125], Loss: 1.9616\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [100/125], Loss: 2.0247\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [101/125], Loss: 1.8289\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [102/125], Loss: 2.0261\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [103/125], Loss: 2.2824\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [104/125], Loss: 1.5801\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [105/125], Loss: 1.9785\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [106/125], Loss: 1.3521\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [107/125], Loss: 2.0713\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [108/125], Loss: 1.9631\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [109/125], Loss: 1.2313\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [110/125], Loss: 1.7256\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [111/125], Loss: 1.9591\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [112/125], Loss: 2.2945\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [113/125], Loss: 1.8808\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [114/125], Loss: 1.5831\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [115/125], Loss: 1.6152\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [116/125], Loss: 1.7100\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [117/125], Loss: 1.7829\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [118/125], Loss: 1.7885\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [119/125], Loss: 1.6596\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [120/125], Loss: 1.7500\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [121/125], Loss: 1.4262\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [122/125], Loss: 1.3649\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [123/125], Loss: 2.0028\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [124/125], Loss: 1.7671\n",
      "Warmup: Updating learning rate to 0.0\n",
      "Epoch [1/60], Step [125/125], Loss: 2.1048\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [1/125], Loss: 1.5133\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [2/125], Loss: 2.3573\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [3/125], Loss: 1.8793\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [4/125], Loss: 1.2208\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [5/125], Loss: 1.7735\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [6/125], Loss: 1.6607\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [7/125], Loss: 1.3785\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [8/125], Loss: 1.5168\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [9/125], Loss: 1.6255\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [10/125], Loss: 1.6476\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [11/125], Loss: 1.5774\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [12/125], Loss: 1.6706\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [13/125], Loss: 2.0890\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [14/125], Loss: 1.4784\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [15/125], Loss: 1.8493\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [16/125], Loss: 1.8627\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [17/125], Loss: 1.2474\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [18/125], Loss: 1.5951\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [19/125], Loss: 1.8285\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [20/125], Loss: 1.8761\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [21/125], Loss: 1.6150\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [22/125], Loss: 1.2379\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [23/125], Loss: 1.4825\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [24/125], Loss: 1.7134\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [25/125], Loss: 1.5985\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [26/125], Loss: 1.5880\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [27/125], Loss: 1.5601\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [28/125], Loss: 1.8748\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [29/125], Loss: 1.4687\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [30/125], Loss: 1.4746\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [31/125], Loss: 1.6238\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [32/125], Loss: 1.6878\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [33/125], Loss: 1.5831\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [34/125], Loss: 1.7642\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [35/125], Loss: 1.5494\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [36/125], Loss: 1.7952\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [37/125], Loss: 1.8181\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [38/125], Loss: 1.4086\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [39/125], Loss: 1.7418\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [40/125], Loss: 2.2137\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [41/125], Loss: 1.4720\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [42/125], Loss: 1.3413\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [43/125], Loss: 1.6412\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [44/125], Loss: 1.6433\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [45/125], Loss: 1.8170\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [46/125], Loss: 1.5056\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [47/125], Loss: 1.6791\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [48/125], Loss: 1.5577\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [49/125], Loss: 1.5699\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [50/125], Loss: 1.5941\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [51/125], Loss: 1.7965\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [52/125], Loss: 1.5629\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [53/125], Loss: 1.5491\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [54/125], Loss: 1.6258\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [55/125], Loss: 1.8933\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [56/125], Loss: 1.6425\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [57/125], Loss: 1.6772\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [58/125], Loss: 1.3491\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [59/125], Loss: 1.3461\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [60/125], Loss: 1.7119\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [61/125], Loss: 1.7597\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [62/125], Loss: 1.5662\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [63/125], Loss: 1.4276\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [64/125], Loss: 1.6883\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [65/125], Loss: 1.5533\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [66/125], Loss: 1.4346\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [67/125], Loss: 1.3431\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [68/125], Loss: 1.6407\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [69/125], Loss: 1.6591\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [70/125], Loss: 1.6527\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [71/125], Loss: 1.9417\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [72/125], Loss: 1.5403\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [73/125], Loss: 1.3475\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [74/125], Loss: 1.5528\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [75/125], Loss: 1.6745\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [76/125], Loss: 1.2836\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [77/125], Loss: 2.1171\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [78/125], Loss: 1.6218\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [79/125], Loss: 1.1392\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [80/125], Loss: 1.0472\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [81/125], Loss: 1.6757\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [82/125], Loss: 1.9214\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [83/125], Loss: 1.6092\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [84/125], Loss: 1.4317\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [85/125], Loss: 1.7355\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [86/125], Loss: 1.4531\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [87/125], Loss: 1.5187\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [88/125], Loss: 1.5330\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [89/125], Loss: 1.8613\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [90/125], Loss: 1.8911\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [91/125], Loss: 1.6837\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [92/125], Loss: 1.5718\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [93/125], Loss: 1.1703\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [94/125], Loss: 1.5702\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [95/125], Loss: 1.5428\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [96/125], Loss: 1.6517\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [97/125], Loss: 1.3487\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [98/125], Loss: 1.6470\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [99/125], Loss: 2.0018\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [100/125], Loss: 1.6187\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [101/125], Loss: 1.7973\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [102/125], Loss: 1.8600\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [103/125], Loss: 1.4253\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [104/125], Loss: 1.6998\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [105/125], Loss: 1.2910\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [106/125], Loss: 1.7957\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [107/125], Loss: 1.4675\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [108/125], Loss: 1.1715\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [109/125], Loss: 1.7002\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [110/125], Loss: 1.6270\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [111/125], Loss: 1.4163\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [112/125], Loss: 1.3964\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [113/125], Loss: 1.6351\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [114/125], Loss: 1.3539\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [115/125], Loss: 1.3661\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [116/125], Loss: 1.6707\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [117/125], Loss: 1.7929\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [118/125], Loss: 1.3904\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [119/125], Loss: 1.6985\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [120/125], Loss: 1.3315\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [121/125], Loss: 1.7849\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [122/125], Loss: 1.6657\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [123/125], Loss: 1.4944\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [124/125], Loss: 1.8995\n",
      "Warmup: Updating learning rate to 0.0006666666666666666\n",
      "Epoch [2/60], Step [125/125], Loss: 1.7533\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [1/125], Loss: 1.4585\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [2/125], Loss: 1.0735\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [3/125], Loss: 1.6615\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [4/125], Loss: 1.4320\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [5/125], Loss: 1.3818\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [6/125], Loss: 1.6191\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [7/125], Loss: 1.8436\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [8/125], Loss: 1.6492\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [9/125], Loss: 1.6057\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [10/125], Loss: 1.5268\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [11/125], Loss: 1.2750\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [12/125], Loss: 1.6423\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [13/125], Loss: 1.6634\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [14/125], Loss: 1.3246\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [15/125], Loss: 1.1683\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [16/125], Loss: 1.5512\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [17/125], Loss: 1.6828\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [18/125], Loss: 1.5104\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [19/125], Loss: 1.6324\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [20/125], Loss: 1.2814\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [21/125], Loss: 1.3311\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [22/125], Loss: 1.6229\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [23/125], Loss: 1.8882\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [24/125], Loss: 1.1293\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [25/125], Loss: 1.2519\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [26/125], Loss: 2.0122\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [27/125], Loss: 1.7194\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [28/125], Loss: 1.7729\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [29/125], Loss: 1.5328\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [30/125], Loss: 1.0292\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [31/125], Loss: 1.5194\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [32/125], Loss: 1.3852\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [33/125], Loss: 1.6856\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [34/125], Loss: 1.5260\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [35/125], Loss: 1.4076\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [36/125], Loss: 1.4344\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [37/125], Loss: 1.3249\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [38/125], Loss: 1.7147\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [39/125], Loss: 1.4717\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [40/125], Loss: 1.5674\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [41/125], Loss: 2.0026\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [42/125], Loss: 1.5194\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [43/125], Loss: 1.2422\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [44/125], Loss: 1.1572\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [45/125], Loss: 1.2022\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [46/125], Loss: 1.3808\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [47/125], Loss: 1.0158\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [48/125], Loss: 1.7606\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [49/125], Loss: 1.3544\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [50/125], Loss: 1.5497\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [51/125], Loss: 2.0135\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [52/125], Loss: 1.1489\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [53/125], Loss: 2.2545\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [54/125], Loss: 1.4249\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [55/125], Loss: 1.3621\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [56/125], Loss: 1.1167\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [57/125], Loss: 1.3598\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [58/125], Loss: 1.1970\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [59/125], Loss: 1.3833\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [60/125], Loss: 1.7832\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [61/125], Loss: 1.7326\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [62/125], Loss: 1.9841\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [63/125], Loss: 1.5134\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [64/125], Loss: 1.7441\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [65/125], Loss: 1.6819\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [66/125], Loss: 1.3472\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [67/125], Loss: 1.7834\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [68/125], Loss: 1.7083\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [69/125], Loss: 1.2717\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [70/125], Loss: 1.7048\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [71/125], Loss: 1.3389\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [72/125], Loss: 1.7910\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [73/125], Loss: 1.5008\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [74/125], Loss: 1.3387\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [75/125], Loss: 1.3263\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [76/125], Loss: 1.5552\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [77/125], Loss: 1.6309\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [78/125], Loss: 1.7977\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [79/125], Loss: 1.5570\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [80/125], Loss: 1.3631\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [81/125], Loss: 1.2575\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [82/125], Loss: 1.5465\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [83/125], Loss: 1.5786\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [84/125], Loss: 2.1675\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [85/125], Loss: 1.1626\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [86/125], Loss: 1.3098\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [87/125], Loss: 1.2220\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [88/125], Loss: 1.3731\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [89/125], Loss: 1.6998\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [90/125], Loss: 1.5768\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [91/125], Loss: 1.7884\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [92/125], Loss: 1.4652\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [93/125], Loss: 1.4351\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [94/125], Loss: 1.5903\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [95/125], Loss: 1.2412\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [96/125], Loss: 1.4794\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [97/125], Loss: 1.5609\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [98/125], Loss: 1.2246\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [99/125], Loss: 1.3877\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [100/125], Loss: 1.3867\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [101/125], Loss: 1.4381\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [102/125], Loss: 1.5046\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [103/125], Loss: 1.5277\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [104/125], Loss: 1.5699\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [105/125], Loss: 1.6608\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [106/125], Loss: 1.4679\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [107/125], Loss: 1.3397\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [108/125], Loss: 1.2322\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [109/125], Loss: 1.5474\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [110/125], Loss: 1.8548\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [111/125], Loss: 1.5065\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [112/125], Loss: 1.3943\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [113/125], Loss: 1.1048\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [114/125], Loss: 1.6825\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [115/125], Loss: 1.2546\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [116/125], Loss: 1.7882\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [117/125], Loss: 1.1711\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [118/125], Loss: 1.4837\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [119/125], Loss: 1.2698\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [120/125], Loss: 1.5098\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [121/125], Loss: 1.2540\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [122/125], Loss: 1.0913\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [123/125], Loss: 1.3989\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [124/125], Loss: 1.4607\n",
      "Warmup: Updating learning rate to 0.0013333333333333333\n",
      "Epoch [3/60], Step [125/125], Loss: 1.2680\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [1/125], Loss: 1.3353\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [2/125], Loss: 1.4373\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [3/125], Loss: 1.3154\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [4/125], Loss: 1.2689\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [5/125], Loss: 1.3767\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [6/125], Loss: 1.5985\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [7/125], Loss: 1.5799\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [8/125], Loss: 1.5863\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [9/125], Loss: 1.5541\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [10/125], Loss: 1.5606\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [11/125], Loss: 1.9907\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [12/125], Loss: 1.7210\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [13/125], Loss: 1.6371\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [14/125], Loss: 1.4469\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [15/125], Loss: 1.4406\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [16/125], Loss: 1.5918\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [17/125], Loss: 1.7399\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [18/125], Loss: 1.6094\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [19/125], Loss: 1.5948\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [20/125], Loss: 1.3291\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [21/125], Loss: 1.3546\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [22/125], Loss: 1.6707\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [23/125], Loss: 1.4006\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [24/125], Loss: 1.6921\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [25/125], Loss: 1.7372\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [26/125], Loss: 1.1667\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [27/125], Loss: 1.4042\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [28/125], Loss: 1.5972\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [29/125], Loss: 1.5110\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [30/125], Loss: 1.5429\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [31/125], Loss: 1.2093\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [32/125], Loss: 1.1349\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [33/125], Loss: 1.5211\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [34/125], Loss: 1.5266\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [35/125], Loss: 1.1909\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [36/125], Loss: 1.3531\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [37/125], Loss: 1.2674\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [38/125], Loss: 1.5159\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [39/125], Loss: 1.5613\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [40/125], Loss: 1.6005\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [41/125], Loss: 1.0702\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [42/125], Loss: 1.1322\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [43/125], Loss: 1.5077\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [44/125], Loss: 1.6141\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [45/125], Loss: 1.5472\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [46/125], Loss: 1.3548\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [47/125], Loss: 1.4080\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [48/125], Loss: 1.9231\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [49/125], Loss: 1.5864\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [50/125], Loss: 1.6028\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [51/125], Loss: 1.2663\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [52/125], Loss: 1.3962\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [53/125], Loss: 1.3014\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [54/125], Loss: 1.7537\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [55/125], Loss: 1.6961\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [56/125], Loss: 1.2433\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [57/125], Loss: 1.7571\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [58/125], Loss: 1.5346\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [59/125], Loss: 1.0664\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [60/125], Loss: 1.8836\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [61/125], Loss: 1.5885\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [62/125], Loss: 1.2177\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [63/125], Loss: 1.3365\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [64/125], Loss: 1.3927\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [65/125], Loss: 1.7062\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [66/125], Loss: 1.1963\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [67/125], Loss: 1.4408\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [68/125], Loss: 1.4134\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [69/125], Loss: 1.2919\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [70/125], Loss: 1.0070\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [71/125], Loss: 1.3703\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [72/125], Loss: 1.7518\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [73/125], Loss: 1.7430\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [74/125], Loss: 1.4263\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [75/125], Loss: 1.4533\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [76/125], Loss: 1.2861\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [77/125], Loss: 1.2984\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [78/125], Loss: 1.6742\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [79/125], Loss: 1.3277\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [80/125], Loss: 1.3238\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [81/125], Loss: 1.3583\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [82/125], Loss: 1.4382\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [83/125], Loss: 1.7155\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [84/125], Loss: 1.7089\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [85/125], Loss: 1.6450\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [86/125], Loss: 1.8163\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [87/125], Loss: 1.5246\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [88/125], Loss: 1.5723\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [89/125], Loss: 1.7170\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [90/125], Loss: 1.5900\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [91/125], Loss: 1.2289\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [92/125], Loss: 1.4468\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [93/125], Loss: 1.6669\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [94/125], Loss: 1.6561\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [95/125], Loss: 1.3252\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [96/125], Loss: 1.3712\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [97/125], Loss: 1.5047\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [98/125], Loss: 0.9422\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [99/125], Loss: 1.1122\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [100/125], Loss: 1.5527\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [101/125], Loss: 1.5580\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [102/125], Loss: 1.2519\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [103/125], Loss: 1.6023\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [104/125], Loss: 1.7553\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [105/125], Loss: 0.9800\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [106/125], Loss: 1.0362\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [107/125], Loss: 1.3023\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [108/125], Loss: 1.4210\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [109/125], Loss: 1.1936\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [110/125], Loss: 1.3433\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [111/125], Loss: 1.3234\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [112/125], Loss: 1.1924\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [113/125], Loss: 1.4741\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [114/125], Loss: 1.2569\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [115/125], Loss: 1.3682\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [116/125], Loss: 1.5231\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [117/125], Loss: 1.2203\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [118/125], Loss: 1.6849\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [119/125], Loss: 1.5175\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [120/125], Loss: 1.3132\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [121/125], Loss: 1.4236\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [122/125], Loss: 1.5494\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [123/125], Loss: 1.3975\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [124/125], Loss: 1.3446\n",
      "Warmup: Updating learning rate to 0.002\n",
      "Epoch [4/60], Step [125/125], Loss: 1.1624\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [1/125], Loss: 1.5430\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [2/125], Loss: 1.2754\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [3/125], Loss: 1.4023\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [4/125], Loss: 0.9973\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [5/125], Loss: 1.5911\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [6/125], Loss: 1.4719\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [7/125], Loss: 1.6270\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [8/125], Loss: 1.1909\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [9/125], Loss: 0.9386\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [10/125], Loss: 1.8662\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [11/125], Loss: 1.3761\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [12/125], Loss: 1.3346\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [13/125], Loss: 1.4787\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [14/125], Loss: 1.1977\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [15/125], Loss: 1.4809\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [16/125], Loss: 1.8249\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [17/125], Loss: 1.5415\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [18/125], Loss: 1.3815\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [19/125], Loss: 1.5409\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [20/125], Loss: 1.1683\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [21/125], Loss: 1.4716\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [22/125], Loss: 1.3062\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [23/125], Loss: 1.2790\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [24/125], Loss: 1.4662\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [25/125], Loss: 1.5133\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [26/125], Loss: 1.5734\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [27/125], Loss: 1.6882\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [28/125], Loss: 1.2550\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [29/125], Loss: 1.6773\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [30/125], Loss: 1.4796\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [31/125], Loss: 1.4493\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [32/125], Loss: 0.8233\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [33/125], Loss: 1.4954\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [34/125], Loss: 1.6803\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [35/125], Loss: 1.3649\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [36/125], Loss: 1.6577\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [37/125], Loss: 1.1706\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [38/125], Loss: 1.6410\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [39/125], Loss: 1.6632\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [40/125], Loss: 1.1859\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [41/125], Loss: 1.3766\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [42/125], Loss: 1.3894\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [43/125], Loss: 0.9226\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [44/125], Loss: 1.9914\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [45/125], Loss: 1.1831\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [46/125], Loss: 1.6478\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [47/125], Loss: 1.7326\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [48/125], Loss: 1.3147\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [49/125], Loss: 1.2155\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [50/125], Loss: 1.4294\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [51/125], Loss: 1.1724\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [52/125], Loss: 1.1529\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [53/125], Loss: 1.3682\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [54/125], Loss: 1.3192\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [55/125], Loss: 1.6350\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [56/125], Loss: 1.2549\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [57/125], Loss: 1.5914\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [58/125], Loss: 1.2348\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [59/125], Loss: 1.5124\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [60/125], Loss: 1.4109\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [61/125], Loss: 1.4281\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [62/125], Loss: 1.3730\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [63/125], Loss: 1.3029\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [64/125], Loss: 0.9882\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [65/125], Loss: 1.1721\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [66/125], Loss: 1.7293\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [67/125], Loss: 1.8354\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [68/125], Loss: 1.0036\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [69/125], Loss: 1.6330\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [70/125], Loss: 1.2208\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [71/125], Loss: 1.2031\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [72/125], Loss: 1.5019\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [73/125], Loss: 1.1985\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [74/125], Loss: 1.9166\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [75/125], Loss: 1.2457\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [76/125], Loss: 1.8933\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [77/125], Loss: 1.4219\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [78/125], Loss: 1.6369\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [79/125], Loss: 0.8225\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [80/125], Loss: 1.1015\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [81/125], Loss: 1.5516\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [82/125], Loss: 1.3440\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [83/125], Loss: 1.0204\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [84/125], Loss: 1.3873\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [85/125], Loss: 1.2703\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [86/125], Loss: 1.5100\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [87/125], Loss: 1.4781\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [88/125], Loss: 1.3814\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [89/125], Loss: 1.3063\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [90/125], Loss: 1.5240\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [91/125], Loss: 1.1864\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [92/125], Loss: 1.4852\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [93/125], Loss: 1.1257\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [94/125], Loss: 1.7756\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [95/125], Loss: 1.3089\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [96/125], Loss: 1.3449\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [97/125], Loss: 1.4595\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [98/125], Loss: 1.3499\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [99/125], Loss: 1.0191\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [100/125], Loss: 1.5731\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [101/125], Loss: 1.3956\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [102/125], Loss: 1.4685\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [103/125], Loss: 1.2155\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [104/125], Loss: 1.7828\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [105/125], Loss: 1.6558\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [106/125], Loss: 1.3876\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [107/125], Loss: 1.5116\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [108/125], Loss: 1.2774\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [109/125], Loss: 1.5941\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [110/125], Loss: 1.1170\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [111/125], Loss: 1.4869\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [112/125], Loss: 1.7066\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [113/125], Loss: 1.0541\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [114/125], Loss: 1.2242\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [115/125], Loss: 1.0980\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [116/125], Loss: 1.6497\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [117/125], Loss: 1.3293\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [118/125], Loss: 1.4550\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [119/125], Loss: 1.1769\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [120/125], Loss: 1.1751\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [121/125], Loss: 1.2724\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [122/125], Loss: 1.4056\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [123/125], Loss: 1.3040\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [124/125], Loss: 1.1866\n",
      "Warmup: Updating learning rate to 0.0026666666666666666\n",
      "Epoch [5/60], Step [125/125], Loss: 1.7741\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [1/125], Loss: 1.2382\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [2/125], Loss: 1.4870\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [3/125], Loss: 1.3441\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [4/125], Loss: 1.1581\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [5/125], Loss: 1.5080\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [6/125], Loss: 1.4616\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [7/125], Loss: 1.7600\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [8/125], Loss: 1.3727\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [9/125], Loss: 1.6596\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [10/125], Loss: 1.4623\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [11/125], Loss: 0.7298\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [12/125], Loss: 1.2638\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [13/125], Loss: 1.0476\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [14/125], Loss: 1.3383\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [15/125], Loss: 0.9535\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [16/125], Loss: 1.4453\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [17/125], Loss: 1.5839\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [18/125], Loss: 1.5231\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [19/125], Loss: 1.6186\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [20/125], Loss: 1.2843\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [21/125], Loss: 1.2188\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [22/125], Loss: 1.5401\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [23/125], Loss: 1.1352\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [24/125], Loss: 1.3287\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [25/125], Loss: 1.0739\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [26/125], Loss: 1.2729\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [27/125], Loss: 1.2427\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [28/125], Loss: 1.6083\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [29/125], Loss: 0.8497\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [30/125], Loss: 1.0473\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [31/125], Loss: 2.1290\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [32/125], Loss: 1.3469\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [33/125], Loss: 1.6150\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [34/125], Loss: 1.0328\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [35/125], Loss: 1.4551\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [36/125], Loss: 1.2996\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [37/125], Loss: 1.3882\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [38/125], Loss: 1.0196\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [39/125], Loss: 1.4638\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [40/125], Loss: 1.3568\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [41/125], Loss: 1.4657\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [42/125], Loss: 1.4446\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [43/125], Loss: 1.2030\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [44/125], Loss: 1.4209\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [45/125], Loss: 1.4824\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [46/125], Loss: 1.6794\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [47/125], Loss: 1.7211\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [48/125], Loss: 1.5370\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [49/125], Loss: 1.2339\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [50/125], Loss: 1.6278\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [51/125], Loss: 1.1777\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [52/125], Loss: 1.2969\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [53/125], Loss: 1.2909\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [54/125], Loss: 1.2667\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [55/125], Loss: 1.6449\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [56/125], Loss: 1.1731\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [57/125], Loss: 0.9803\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [58/125], Loss: 1.1758\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [59/125], Loss: 1.1909\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [60/125], Loss: 1.1779\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [61/125], Loss: 1.2383\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [62/125], Loss: 1.0858\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [63/125], Loss: 1.4288\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [64/125], Loss: 1.2223\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [65/125], Loss: 1.2777\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [66/125], Loss: 0.7289\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [67/125], Loss: 1.5188\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [68/125], Loss: 1.5214\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [69/125], Loss: 1.2737\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [70/125], Loss: 0.9877\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [71/125], Loss: 1.7710\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [72/125], Loss: 1.5603\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [73/125], Loss: 1.1910\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [74/125], Loss: 1.2919\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [75/125], Loss: 1.6309\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [76/125], Loss: 1.2633\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [77/125], Loss: 1.4680\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [78/125], Loss: 1.7885\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [79/125], Loss: 1.5212\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [80/125], Loss: 1.2039\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [81/125], Loss: 1.8481\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [82/125], Loss: 1.4276\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [83/125], Loss: 1.6999\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [84/125], Loss: 1.3681\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [85/125], Loss: 1.0624\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [86/125], Loss: 1.5696\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [87/125], Loss: 1.6240\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [88/125], Loss: 1.7142\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [89/125], Loss: 1.4870\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [90/125], Loss: 1.1702\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [91/125], Loss: 1.8147\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [92/125], Loss: 1.4104\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [93/125], Loss: 1.3161\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [94/125], Loss: 1.1222\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [95/125], Loss: 1.4327\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [96/125], Loss: 1.4850\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [97/125], Loss: 1.6540\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [98/125], Loss: 1.5360\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [99/125], Loss: 1.2673\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [100/125], Loss: 0.9157\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [101/125], Loss: 1.2010\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [102/125], Loss: 1.1460\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [103/125], Loss: 1.0927\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [104/125], Loss: 1.3258\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [105/125], Loss: 0.9194\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [106/125], Loss: 1.5185\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [107/125], Loss: 1.3485\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [108/125], Loss: 1.1913\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [109/125], Loss: 1.4294\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [110/125], Loss: 1.2292\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [111/125], Loss: 1.1515\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [112/125], Loss: 1.4777\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [113/125], Loss: 1.3967\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [114/125], Loss: 0.8373\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [115/125], Loss: 1.2240\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [116/125], Loss: 1.4282\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [117/125], Loss: 1.4599\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [118/125], Loss: 1.4566\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [119/125], Loss: 1.3561\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [120/125], Loss: 1.0342\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [121/125], Loss: 1.4936\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [122/125], Loss: 1.2167\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [123/125], Loss: 1.4693\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [124/125], Loss: 1.5969\n",
      "Warmup: Updating learning rate to 0.003333333333333333\n",
      "Epoch [6/60], Step [125/125], Loss: 1.4762\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [1/125], Loss: 1.0865\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [2/125], Loss: 1.0106\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [3/125], Loss: 1.6348\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [4/125], Loss: 1.2488\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [5/125], Loss: 1.2991\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [6/125], Loss: 0.7420\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [7/125], Loss: 1.1978\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [8/125], Loss: 1.5285\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [9/125], Loss: 1.3321\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [10/125], Loss: 1.5055\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [11/125], Loss: 1.0923\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [12/125], Loss: 1.1639\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [13/125], Loss: 1.5386\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [14/125], Loss: 1.3741\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [15/125], Loss: 1.4222\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [16/125], Loss: 1.5771\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [17/125], Loss: 1.3867\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [18/125], Loss: 1.6979\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [19/125], Loss: 1.7569\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [20/125], Loss: 1.7022\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [21/125], Loss: 1.2092\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [22/125], Loss: 1.4920\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [23/125], Loss: 1.5739\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [24/125], Loss: 1.0553\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [25/125], Loss: 1.5711\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [26/125], Loss: 1.3274\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [27/125], Loss: 1.3521\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [28/125], Loss: 0.9900\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [29/125], Loss: 1.7251\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [30/125], Loss: 1.4078\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [31/125], Loss: 1.5490\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [32/125], Loss: 1.2079\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [33/125], Loss: 1.6226\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [34/125], Loss: 1.1333\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [35/125], Loss: 1.4223\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [36/125], Loss: 1.4353\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [37/125], Loss: 1.1200\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [38/125], Loss: 0.9970\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [39/125], Loss: 1.2416\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [40/125], Loss: 1.2184\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [41/125], Loss: 1.0780\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [42/125], Loss: 1.6652\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [43/125], Loss: 1.4396\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [44/125], Loss: 1.6153\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [45/125], Loss: 1.6645\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [46/125], Loss: 1.3899\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [47/125], Loss: 1.3179\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [48/125], Loss: 1.1518\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [49/125], Loss: 1.1202\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [50/125], Loss: 1.2418\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [51/125], Loss: 1.4383\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [52/125], Loss: 1.6214\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [53/125], Loss: 1.9290\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [54/125], Loss: 1.2062\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [55/125], Loss: 1.4578\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [56/125], Loss: 1.2206\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [57/125], Loss: 1.7735\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [58/125], Loss: 1.2832\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [59/125], Loss: 0.9024\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [60/125], Loss: 1.2080\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [61/125], Loss: 1.1197\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [62/125], Loss: 1.4562\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [63/125], Loss: 1.1695\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [64/125], Loss: 0.9726\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [65/125], Loss: 1.2714\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [66/125], Loss: 1.5127\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [67/125], Loss: 1.4005\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [68/125], Loss: 1.4463\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [69/125], Loss: 1.5806\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [70/125], Loss: 1.2311\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [71/125], Loss: 1.2295\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [72/125], Loss: 0.9785\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [73/125], Loss: 1.2913\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [74/125], Loss: 1.4710\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [75/125], Loss: 1.2103\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [76/125], Loss: 1.2962\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [77/125], Loss: 1.3330\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [78/125], Loss: 1.2171\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [79/125], Loss: 1.4934\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [80/125], Loss: 0.9235\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [81/125], Loss: 1.4684\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [82/125], Loss: 1.5800\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [83/125], Loss: 1.5412\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [84/125], Loss: 1.3146\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [85/125], Loss: 1.6146\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [86/125], Loss: 1.5726\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [87/125], Loss: 1.4092\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [88/125], Loss: 1.1405\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [89/125], Loss: 1.4245\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [90/125], Loss: 1.4951\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [91/125], Loss: 1.1747\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [92/125], Loss: 1.4928\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [93/125], Loss: 1.4863\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [94/125], Loss: 1.2948\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [95/125], Loss: 1.5450\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [96/125], Loss: 1.8277\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [97/125], Loss: 1.1245\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [98/125], Loss: 1.6849\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [99/125], Loss: 1.5770\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [100/125], Loss: 0.8583\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [101/125], Loss: 0.9121\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [102/125], Loss: 1.3340\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [103/125], Loss: 1.3940\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [104/125], Loss: 1.5932\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [105/125], Loss: 1.6113\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [106/125], Loss: 1.1845\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [107/125], Loss: 1.3068\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [108/125], Loss: 1.5394\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [109/125], Loss: 1.4528\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [110/125], Loss: 1.3750\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [111/125], Loss: 1.3923\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [112/125], Loss: 1.5121\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [113/125], Loss: 1.3747\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [114/125], Loss: 1.4024\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [115/125], Loss: 1.3129\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [116/125], Loss: 1.1006\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [117/125], Loss: 1.3908\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [118/125], Loss: 0.9855\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [119/125], Loss: 1.5623\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [120/125], Loss: 1.3768\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [121/125], Loss: 1.2562\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [122/125], Loss: 1.1436\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [123/125], Loss: 1.2434\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [124/125], Loss: 1.4433\n",
      "Warmup: Updating learning rate to 0.004\n",
      "Epoch [7/60], Step [125/125], Loss: 1.5024\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [1/125], Loss: 1.0520\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [2/125], Loss: 1.7690\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [3/125], Loss: 0.9955\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [4/125], Loss: 1.2619\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [5/125], Loss: 1.3537\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [6/125], Loss: 1.1184\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [7/125], Loss: 1.3460\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [8/125], Loss: 0.9876\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [9/125], Loss: 1.4977\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [10/125], Loss: 1.9222\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [11/125], Loss: 1.6766\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [12/125], Loss: 0.9999\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [13/125], Loss: 1.7182\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [14/125], Loss: 1.7878\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [15/125], Loss: 1.6283\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [16/125], Loss: 1.1439\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [17/125], Loss: 1.0450\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [18/125], Loss: 1.4264\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [19/125], Loss: 1.1962\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [20/125], Loss: 1.3786\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [21/125], Loss: 1.0499\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [22/125], Loss: 1.1631\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [23/125], Loss: 1.0066\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [24/125], Loss: 1.6148\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [25/125], Loss: 1.2531\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [26/125], Loss: 1.8947\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [27/125], Loss: 1.4577\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [28/125], Loss: 1.4695\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [29/125], Loss: 1.4690\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [30/125], Loss: 1.2931\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [31/125], Loss: 0.9683\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [32/125], Loss: 0.9460\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [33/125], Loss: 0.9094\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [34/125], Loss: 1.8095\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [35/125], Loss: 1.4481\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [36/125], Loss: 1.3104\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [37/125], Loss: 1.7268\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [38/125], Loss: 1.3009\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [39/125], Loss: 1.4796\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [40/125], Loss: 1.5911\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [41/125], Loss: 1.5253\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [42/125], Loss: 1.7068\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [43/125], Loss: 1.3651\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [44/125], Loss: 1.3245\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [45/125], Loss: 1.2396\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [46/125], Loss: 1.3880\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [47/125], Loss: 1.7248\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [48/125], Loss: 1.0677\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [49/125], Loss: 1.2344\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [50/125], Loss: 1.2127\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [51/125], Loss: 2.1346\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [52/125], Loss: 1.4366\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [53/125], Loss: 1.3443\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [54/125], Loss: 1.7319\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [55/125], Loss: 0.9285\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [56/125], Loss: 1.2521\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [57/125], Loss: 1.4516\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [58/125], Loss: 0.9562\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [59/125], Loss: 1.3344\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [60/125], Loss: 1.4211\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [61/125], Loss: 1.4375\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [62/125], Loss: 1.3467\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [63/125], Loss: 1.0750\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [64/125], Loss: 0.7169\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [65/125], Loss: 1.5581\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [66/125], Loss: 0.8838\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [67/125], Loss: 1.2849\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [68/125], Loss: 1.3040\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [69/125], Loss: 1.2824\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [70/125], Loss: 1.1392\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [71/125], Loss: 1.7254\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [72/125], Loss: 0.9791\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [73/125], Loss: 1.3570\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [74/125], Loss: 1.1372\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [75/125], Loss: 1.0051\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [76/125], Loss: 1.3157\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [77/125], Loss: 1.3934\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [78/125], Loss: 1.2818\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [79/125], Loss: 1.5422\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [80/125], Loss: 1.3208\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [81/125], Loss: 1.1495\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [82/125], Loss: 1.1406\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [83/125], Loss: 1.5568\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [84/125], Loss: 1.3562\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [85/125], Loss: 1.4775\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [86/125], Loss: 1.6273\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [87/125], Loss: 0.9993\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [88/125], Loss: 1.0512\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [89/125], Loss: 1.6801\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [90/125], Loss: 1.5755\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [91/125], Loss: 1.5302\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [92/125], Loss: 1.2715\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [93/125], Loss: 1.6539\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [94/125], Loss: 1.3040\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [95/125], Loss: 1.6181\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [96/125], Loss: 1.5329\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [97/125], Loss: 1.2712\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [98/125], Loss: 1.2071\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [99/125], Loss: 1.3085\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [100/125], Loss: 1.5669\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [101/125], Loss: 1.4050\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [102/125], Loss: 1.4598\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [103/125], Loss: 1.7333\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [104/125], Loss: 1.0756\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [105/125], Loss: 1.3444\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [106/125], Loss: 1.3778\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [107/125], Loss: 1.5839\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [108/125], Loss: 1.3782\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [109/125], Loss: 1.6345\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [110/125], Loss: 1.0458\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [111/125], Loss: 1.4541\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [112/125], Loss: 1.2124\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [113/125], Loss: 0.9943\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [114/125], Loss: 1.1938\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [115/125], Loss: 1.5392\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [116/125], Loss: 1.0138\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [117/125], Loss: 1.1817\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [118/125], Loss: 1.0719\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [119/125], Loss: 1.3182\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [120/125], Loss: 1.4801\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [121/125], Loss: 1.5207\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [122/125], Loss: 1.3426\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [123/125], Loss: 1.4498\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [124/125], Loss: 1.4007\n",
      "Warmup: Updating learning rate to 0.004666666666666667\n",
      "Epoch [8/60], Step [125/125], Loss: 1.5818\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [1/125], Loss: 1.2555\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [2/125], Loss: 0.8070\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [3/125], Loss: 1.0395\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [4/125], Loss: 1.5264\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [5/125], Loss: 0.9886\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [6/125], Loss: 1.0765\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [7/125], Loss: 1.0912\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [8/125], Loss: 1.2189\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [9/125], Loss: 1.3836\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [10/125], Loss: 1.3134\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [11/125], Loss: 1.2542\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [12/125], Loss: 1.6818\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [13/125], Loss: 0.9776\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [14/125], Loss: 1.3371\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [15/125], Loss: 0.8369\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [16/125], Loss: 0.9595\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [17/125], Loss: 1.3084\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [18/125], Loss: 1.5756\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [19/125], Loss: 1.3129\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [20/125], Loss: 0.8891\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [21/125], Loss: 1.3566\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [22/125], Loss: 1.3155\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [23/125], Loss: 1.4784\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [24/125], Loss: 1.0142\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [25/125], Loss: 1.2963\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [26/125], Loss: 1.7161\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [27/125], Loss: 1.4411\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [28/125], Loss: 1.4344\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [29/125], Loss: 1.2868\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [30/125], Loss: 1.4701\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [31/125], Loss: 1.3835\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [32/125], Loss: 1.3315\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [33/125], Loss: 1.3570\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [34/125], Loss: 1.5526\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [35/125], Loss: 1.2092\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [36/125], Loss: 1.2004\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [37/125], Loss: 1.3258\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [38/125], Loss: 1.1240\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [39/125], Loss: 1.5035\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [40/125], Loss: 1.1198\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [41/125], Loss: 1.1409\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [42/125], Loss: 1.2446\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [43/125], Loss: 1.4383\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [44/125], Loss: 1.3343\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [45/125], Loss: 1.5598\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [46/125], Loss: 1.1095\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [47/125], Loss: 1.1295\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [48/125], Loss: 1.0058\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [49/125], Loss: 1.3929\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [50/125], Loss: 1.2839\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [51/125], Loss: 1.2190\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [52/125], Loss: 1.3957\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [53/125], Loss: 0.9229\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [54/125], Loss: 1.3401\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [55/125], Loss: 1.5212\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [56/125], Loss: 1.6387\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [57/125], Loss: 1.4060\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [58/125], Loss: 1.2388\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [59/125], Loss: 1.3595\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [60/125], Loss: 1.2815\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [61/125], Loss: 1.2451\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [62/125], Loss: 1.0764\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [63/125], Loss: 1.2654\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [64/125], Loss: 1.2620\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [65/125], Loss: 1.1871\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [66/125], Loss: 1.3739\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [67/125], Loss: 1.2297\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [68/125], Loss: 0.8333\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [69/125], Loss: 1.4076\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [70/125], Loss: 1.1098\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [71/125], Loss: 1.0141\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [72/125], Loss: 1.0704\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [73/125], Loss: 1.3767\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [74/125], Loss: 0.8988\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [75/125], Loss: 1.2571\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [76/125], Loss: 1.1702\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [77/125], Loss: 1.4632\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [78/125], Loss: 1.0286\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [79/125], Loss: 1.2780\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [80/125], Loss: 1.3397\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [81/125], Loss: 1.4533\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [82/125], Loss: 1.1190\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [83/125], Loss: 1.3451\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [84/125], Loss: 1.2392\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [85/125], Loss: 1.4082\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [86/125], Loss: 1.0564\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [87/125], Loss: 0.9383\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [88/125], Loss: 1.2868\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [89/125], Loss: 1.4320\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [90/125], Loss: 1.3781\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [91/125], Loss: 1.4792\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [92/125], Loss: 1.1710\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [93/125], Loss: 1.4456\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [94/125], Loss: 0.6811\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [95/125], Loss: 1.1931\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [96/125], Loss: 1.0432\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [97/125], Loss: 1.2769\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [98/125], Loss: 1.2834\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [99/125], Loss: 1.4055\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [100/125], Loss: 1.2788\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [101/125], Loss: 1.0922\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [102/125], Loss: 1.2749\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [103/125], Loss: 1.1827\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [104/125], Loss: 1.0564\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [105/125], Loss: 1.0120\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [106/125], Loss: 1.5284\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [107/125], Loss: 1.3906\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [108/125], Loss: 1.7594\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [109/125], Loss: 1.5458\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [110/125], Loss: 1.0285\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [111/125], Loss: 1.2577\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [112/125], Loss: 1.3763\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [113/125], Loss: 1.3289\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [114/125], Loss: 0.9934\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [115/125], Loss: 1.2203\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [116/125], Loss: 1.0538\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [117/125], Loss: 1.4109\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [118/125], Loss: 1.5890\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [119/125], Loss: 0.7857\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [120/125], Loss: 1.3788\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [121/125], Loss: 1.3978\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [122/125], Loss: 1.2983\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [123/125], Loss: 1.5587\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [124/125], Loss: 0.8633\n",
      "Warmup: Updating learning rate to 0.005333333333333333\n",
      "Epoch [9/60], Step [125/125], Loss: 1.0332\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [1/125], Loss: 1.2854\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [2/125], Loss: 1.5073\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [3/125], Loss: 1.2198\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [4/125], Loss: 0.8880\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [5/125], Loss: 1.2586\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [6/125], Loss: 1.3370\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [7/125], Loss: 1.3516\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [8/125], Loss: 0.9110\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [9/125], Loss: 1.0595\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [10/125], Loss: 1.5321\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [11/125], Loss: 1.1662\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [12/125], Loss: 1.3921\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [13/125], Loss: 1.4058\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [14/125], Loss: 1.0138\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [15/125], Loss: 1.2234\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [16/125], Loss: 1.1420\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [17/125], Loss: 1.1781\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [18/125], Loss: 1.2599\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [19/125], Loss: 1.2456\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [20/125], Loss: 1.2479\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [21/125], Loss: 1.3394\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [22/125], Loss: 1.8576\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [23/125], Loss: 1.1195\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [24/125], Loss: 1.4423\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [25/125], Loss: 1.1550\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [26/125], Loss: 1.1669\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [27/125], Loss: 1.4018\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [28/125], Loss: 1.0675\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [29/125], Loss: 1.4966\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [30/125], Loss: 1.5854\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [31/125], Loss: 0.9622\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [32/125], Loss: 1.1587\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [33/125], Loss: 1.2664\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [34/125], Loss: 1.1587\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [35/125], Loss: 1.6466\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [36/125], Loss: 1.4820\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [37/125], Loss: 1.2650\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [38/125], Loss: 1.2017\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [39/125], Loss: 1.0565\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [40/125], Loss: 1.1961\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [41/125], Loss: 1.5066\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [42/125], Loss: 1.1013\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [43/125], Loss: 1.2567\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [44/125], Loss: 0.9634\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [45/125], Loss: 1.3035\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [46/125], Loss: 1.2925\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [47/125], Loss: 1.6072\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [48/125], Loss: 1.0777\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [49/125], Loss: 1.3076\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [50/125], Loss: 1.1924\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [51/125], Loss: 1.2719\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [52/125], Loss: 0.9382\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [53/125], Loss: 1.3885\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [54/125], Loss: 1.0816\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [55/125], Loss: 0.7617\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [56/125], Loss: 1.3916\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [57/125], Loss: 1.0375\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [58/125], Loss: 1.5925\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [59/125], Loss: 1.3597\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [60/125], Loss: 1.6608\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [61/125], Loss: 0.9460\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [62/125], Loss: 1.6390\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [63/125], Loss: 1.0229\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [64/125], Loss: 1.3328\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [65/125], Loss: 0.9987\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [66/125], Loss: 1.5123\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [67/125], Loss: 1.6181\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [68/125], Loss: 1.3010\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [69/125], Loss: 1.0017\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [70/125], Loss: 0.9997\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [71/125], Loss: 1.0692\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [72/125], Loss: 1.0129\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [73/125], Loss: 1.2921\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [74/125], Loss: 1.4923\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [75/125], Loss: 1.1627\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [76/125], Loss: 0.9701\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [77/125], Loss: 1.4604\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [78/125], Loss: 1.0647\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [79/125], Loss: 1.4334\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [80/125], Loss: 1.2114\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [81/125], Loss: 1.0198\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [82/125], Loss: 0.9240\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [83/125], Loss: 1.1746\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [84/125], Loss: 1.1319\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [85/125], Loss: 1.6933\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [86/125], Loss: 1.2886\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [87/125], Loss: 1.3992\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [88/125], Loss: 0.9291\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [89/125], Loss: 1.4358\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [90/125], Loss: 1.2421\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [91/125], Loss: 0.8439\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [92/125], Loss: 1.5031\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [93/125], Loss: 1.0247\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [94/125], Loss: 1.2031\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [95/125], Loss: 1.3300\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [96/125], Loss: 0.9439\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [97/125], Loss: 1.3385\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [98/125], Loss: 1.0576\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [99/125], Loss: 1.4199\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [100/125], Loss: 1.2246\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [101/125], Loss: 1.0968\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [102/125], Loss: 1.3216\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [103/125], Loss: 1.0313\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [104/125], Loss: 1.1495\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [105/125], Loss: 0.9331\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [106/125], Loss: 1.3297\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [107/125], Loss: 1.0406\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [108/125], Loss: 0.9045\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [109/125], Loss: 1.3337\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [110/125], Loss: 0.7929\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [111/125], Loss: 1.2915\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [112/125], Loss: 1.1326\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [113/125], Loss: 1.3092\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [114/125], Loss: 0.9662\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [115/125], Loss: 1.1737\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [116/125], Loss: 1.2454\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [117/125], Loss: 0.7839\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [118/125], Loss: 1.4626\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [119/125], Loss: 1.0726\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [120/125], Loss: 0.9913\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [121/125], Loss: 1.0770\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [122/125], Loss: 1.2065\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [123/125], Loss: 1.3989\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [124/125], Loss: 1.1343\n",
      "Warmup: Updating learning rate to 0.006\n",
      "Epoch [10/60], Step [125/125], Loss: 1.0805\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [1/125], Loss: 1.1975\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [2/125], Loss: 1.0680\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [3/125], Loss: 0.9760\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [4/125], Loss: 1.2642\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [5/125], Loss: 1.8383\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [6/125], Loss: 1.1699\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [7/125], Loss: 1.3450\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [8/125], Loss: 1.7814\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [9/125], Loss: 1.1063\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [10/125], Loss: 1.5428\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [11/125], Loss: 1.1909\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [12/125], Loss: 0.8982\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [13/125], Loss: 1.1003\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [14/125], Loss: 1.2539\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [15/125], Loss: 1.0283\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [16/125], Loss: 1.1694\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [17/125], Loss: 1.1853\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [18/125], Loss: 1.0730\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [19/125], Loss: 1.3992\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [20/125], Loss: 0.8337\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [21/125], Loss: 1.0546\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [22/125], Loss: 1.2806\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [23/125], Loss: 1.0245\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [24/125], Loss: 0.8304\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [25/125], Loss: 1.2448\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [26/125], Loss: 1.0972\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [27/125], Loss: 0.8788\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [28/125], Loss: 1.3029\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [29/125], Loss: 1.2375\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [30/125], Loss: 0.7438\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [31/125], Loss: 1.3519\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [32/125], Loss: 1.2558\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [33/125], Loss: 1.3357\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [34/125], Loss: 1.7114\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [35/125], Loss: 1.0866\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [36/125], Loss: 1.0292\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [37/125], Loss: 1.0796\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [38/125], Loss: 0.9274\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [39/125], Loss: 1.1356\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [40/125], Loss: 0.8615\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [41/125], Loss: 0.7646\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [42/125], Loss: 1.3072\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [43/125], Loss: 1.2797\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [44/125], Loss: 1.3271\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [45/125], Loss: 1.2820\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [46/125], Loss: 0.9217\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [47/125], Loss: 1.0027\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [48/125], Loss: 1.1425\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [49/125], Loss: 0.8281\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [50/125], Loss: 0.7656\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [51/125], Loss: 1.4530\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [52/125], Loss: 1.2961\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [53/125], Loss: 1.0381\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [54/125], Loss: 1.8767\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [55/125], Loss: 1.2454\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [56/125], Loss: 1.3497\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [57/125], Loss: 1.0929\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [58/125], Loss: 1.2176\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [59/125], Loss: 1.5643\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [60/125], Loss: 0.9552\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [61/125], Loss: 1.1829\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [62/125], Loss: 0.9110\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [63/125], Loss: 1.1530\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [64/125], Loss: 1.2706\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [65/125], Loss: 1.3778\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [66/125], Loss: 0.9070\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [67/125], Loss: 1.0322\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [68/125], Loss: 1.0437\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [69/125], Loss: 1.0736\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [70/125], Loss: 1.2462\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [71/125], Loss: 1.0037\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [72/125], Loss: 0.9364\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [73/125], Loss: 1.0574\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [74/125], Loss: 1.2657\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [75/125], Loss: 1.0856\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [76/125], Loss: 1.0684\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [77/125], Loss: 0.9030\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [78/125], Loss: 1.1665\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [79/125], Loss: 1.3208\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [80/125], Loss: 0.8450\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [81/125], Loss: 1.3620\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [82/125], Loss: 1.0736\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [83/125], Loss: 1.4929\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [84/125], Loss: 1.3928\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [85/125], Loss: 1.3458\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [86/125], Loss: 0.8097\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [87/125], Loss: 1.1603\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [88/125], Loss: 1.2778\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [89/125], Loss: 1.3506\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [90/125], Loss: 1.2205\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [91/125], Loss: 0.7215\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [92/125], Loss: 1.0195\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [93/125], Loss: 0.9618\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [94/125], Loss: 0.8140\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [95/125], Loss: 1.2575\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [96/125], Loss: 1.0966\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [97/125], Loss: 1.2151\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [98/125], Loss: 1.5178\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [99/125], Loss: 1.5073\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [100/125], Loss: 0.9998\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [101/125], Loss: 0.9071\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [102/125], Loss: 1.3220\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [103/125], Loss: 1.0619\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [104/125], Loss: 1.3469\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [105/125], Loss: 1.2972\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [106/125], Loss: 0.8846\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [107/125], Loss: 0.7185\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [108/125], Loss: 0.9657\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [109/125], Loss: 1.2051\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [110/125], Loss: 1.6136\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [111/125], Loss: 0.7552\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [112/125], Loss: 1.1384\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [113/125], Loss: 1.2153\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [114/125], Loss: 1.1464\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [115/125], Loss: 0.9149\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [116/125], Loss: 1.3962\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [117/125], Loss: 1.3647\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [118/125], Loss: 1.2251\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [119/125], Loss: 1.1055\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [120/125], Loss: 1.4543\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [121/125], Loss: 1.2531\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [122/125], Loss: 0.9420\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [123/125], Loss: 1.4057\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [124/125], Loss: 1.7561\n",
      "Warmup: Updating learning rate to 0.006666666666666666\n",
      "Epoch [11/60], Step [125/125], Loss: 1.4942\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [1/125], Loss: 1.0860\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [2/125], Loss: 1.3432\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [3/125], Loss: 1.2221\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [4/125], Loss: 1.1973\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [5/125], Loss: 1.2667\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [6/125], Loss: 1.4309\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [7/125], Loss: 1.0639\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [8/125], Loss: 1.4193\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [9/125], Loss: 1.0003\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [10/125], Loss: 1.2321\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [11/125], Loss: 0.7458\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [12/125], Loss: 1.6360\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [13/125], Loss: 1.7127\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [14/125], Loss: 0.8648\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [15/125], Loss: 1.0734\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [16/125], Loss: 1.4481\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [17/125], Loss: 0.9938\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [18/125], Loss: 1.5277\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [19/125], Loss: 0.9023\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [20/125], Loss: 1.5073\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [21/125], Loss: 1.2819\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [22/125], Loss: 1.1397\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [23/125], Loss: 0.7934\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [24/125], Loss: 1.2116\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [25/125], Loss: 1.0363\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [26/125], Loss: 0.9811\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [27/125], Loss: 0.8624\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [28/125], Loss: 1.2179\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [29/125], Loss: 1.3647\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [30/125], Loss: 0.8436\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [31/125], Loss: 1.4741\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [32/125], Loss: 1.2849\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [33/125], Loss: 1.1080\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [34/125], Loss: 1.2110\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [35/125], Loss: 0.9775\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [36/125], Loss: 1.2169\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [37/125], Loss: 1.1182\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [38/125], Loss: 1.2439\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [39/125], Loss: 1.1495\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [40/125], Loss: 1.3959\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [41/125], Loss: 0.8886\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [42/125], Loss: 1.2777\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [43/125], Loss: 1.3199\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [44/125], Loss: 1.4051\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [45/125], Loss: 0.8526\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [46/125], Loss: 1.3412\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [47/125], Loss: 1.0222\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [48/125], Loss: 1.5126\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [49/125], Loss: 0.7915\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [50/125], Loss: 1.2187\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [51/125], Loss: 1.2577\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [52/125], Loss: 1.1406\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [53/125], Loss: 1.0104\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [54/125], Loss: 0.9962\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [55/125], Loss: 1.2710\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [56/125], Loss: 0.9426\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [57/125], Loss: 1.0027\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [58/125], Loss: 1.1481\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [59/125], Loss: 0.9053\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [60/125], Loss: 0.9487\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [61/125], Loss: 0.8792\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [62/125], Loss: 1.0710\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [63/125], Loss: 1.1802\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [64/125], Loss: 1.7298\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [65/125], Loss: 1.2886\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [66/125], Loss: 1.4280\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [67/125], Loss: 1.4321\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [68/125], Loss: 1.0553\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [69/125], Loss: 1.2281\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [70/125], Loss: 1.6341\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [71/125], Loss: 0.9865\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [72/125], Loss: 1.3036\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [73/125], Loss: 1.1914\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [74/125], Loss: 1.2133\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [75/125], Loss: 1.2324\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [76/125], Loss: 1.1647\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [77/125], Loss: 1.0491\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [78/125], Loss: 1.3029\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [79/125], Loss: 1.3382\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [80/125], Loss: 1.2685\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [81/125], Loss: 0.9849\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [82/125], Loss: 1.2769\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [83/125], Loss: 1.8039\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [84/125], Loss: 1.1086\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [85/125], Loss: 1.2649\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [86/125], Loss: 1.0021\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [87/125], Loss: 1.3915\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [88/125], Loss: 1.0646\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [89/125], Loss: 1.0644\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [90/125], Loss: 1.3405\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [91/125], Loss: 0.9740\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [92/125], Loss: 1.1099\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [93/125], Loss: 1.4030\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [94/125], Loss: 1.1964\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [95/125], Loss: 1.1896\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [96/125], Loss: 1.5121\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [97/125], Loss: 0.8736\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [98/125], Loss: 1.3412\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [99/125], Loss: 0.7535\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [100/125], Loss: 1.2248\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [101/125], Loss: 0.9887\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [102/125], Loss: 0.7984\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [103/125], Loss: 0.9029\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [104/125], Loss: 1.3037\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [105/125], Loss: 1.2080\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [106/125], Loss: 0.8139\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [107/125], Loss: 1.3816\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [108/125], Loss: 1.0949\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [109/125], Loss: 1.1007\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [110/125], Loss: 1.0682\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [111/125], Loss: 0.9875\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [112/125], Loss: 1.2193\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [113/125], Loss: 1.1839\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [114/125], Loss: 0.9139\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [115/125], Loss: 1.2117\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [116/125], Loss: 0.9679\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [117/125], Loss: 1.1196\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [118/125], Loss: 0.9974\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [119/125], Loss: 1.1555\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [120/125], Loss: 1.0292\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [121/125], Loss: 1.2562\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [122/125], Loss: 0.8357\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [123/125], Loss: 0.8118\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [124/125], Loss: 1.6245\n",
      "Warmup: Updating learning rate to 0.007333333333333333\n",
      "Epoch [12/60], Step [125/125], Loss: 1.0325\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [1/125], Loss: 0.8587\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [2/125], Loss: 1.3227\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [3/125], Loss: 1.0385\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [4/125], Loss: 1.0088\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [5/125], Loss: 1.4028\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [6/125], Loss: 1.1026\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [7/125], Loss: 1.1165\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [8/125], Loss: 1.0742\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [9/125], Loss: 1.5733\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [10/125], Loss: 1.2199\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [11/125], Loss: 0.9068\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [12/125], Loss: 1.2824\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [13/125], Loss: 1.2532\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [14/125], Loss: 0.9940\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [15/125], Loss: 1.0351\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [16/125], Loss: 1.3863\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [17/125], Loss: 1.1043\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [18/125], Loss: 0.9610\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [19/125], Loss: 1.2974\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [20/125], Loss: 0.9262\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [21/125], Loss: 1.2764\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [22/125], Loss: 1.2709\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [23/125], Loss: 1.4540\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [24/125], Loss: 1.2158\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [25/125], Loss: 1.0056\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [26/125], Loss: 1.2013\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [27/125], Loss: 1.2407\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [28/125], Loss: 1.4139\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [29/125], Loss: 1.1740\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [30/125], Loss: 1.3644\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [31/125], Loss: 1.4977\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [32/125], Loss: 0.9940\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [33/125], Loss: 0.9892\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [34/125], Loss: 0.9789\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [35/125], Loss: 0.9538\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [36/125], Loss: 1.0301\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [37/125], Loss: 1.6390\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [38/125], Loss: 0.8842\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [39/125], Loss: 1.0109\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [40/125], Loss: 1.1899\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [41/125], Loss: 1.1479\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [42/125], Loss: 1.3968\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [43/125], Loss: 0.7475\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [44/125], Loss: 1.0356\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [45/125], Loss: 1.3767\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [46/125], Loss: 1.0683\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [47/125], Loss: 1.6218\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [48/125], Loss: 1.0307\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [49/125], Loss: 1.3192\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [50/125], Loss: 0.7357\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [51/125], Loss: 1.2615\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [52/125], Loss: 1.4293\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [53/125], Loss: 1.0816\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [54/125], Loss: 0.9692\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [55/125], Loss: 1.3293\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [56/125], Loss: 1.2132\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [57/125], Loss: 1.2413\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [58/125], Loss: 0.7225\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [59/125], Loss: 1.0572\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [60/125], Loss: 1.3780\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [61/125], Loss: 1.4878\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [62/125], Loss: 0.7053\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [63/125], Loss: 1.2871\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [64/125], Loss: 1.0104\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [65/125], Loss: 1.1092\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [66/125], Loss: 1.1938\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [67/125], Loss: 1.1162\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [68/125], Loss: 1.3490\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [69/125], Loss: 1.0287\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [70/125], Loss: 1.0989\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [71/125], Loss: 1.3044\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [72/125], Loss: 1.3553\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [73/125], Loss: 1.1181\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [74/125], Loss: 1.1791\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [75/125], Loss: 0.9784\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [76/125], Loss: 0.8821\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [77/125], Loss: 1.1451\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [78/125], Loss: 1.2229\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [79/125], Loss: 1.1360\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [80/125], Loss: 1.1820\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [81/125], Loss: 1.1305\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [82/125], Loss: 1.2183\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [83/125], Loss: 0.9968\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [84/125], Loss: 1.1871\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [85/125], Loss: 1.3058\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [86/125], Loss: 0.9143\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [87/125], Loss: 1.0531\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [88/125], Loss: 1.2007\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [89/125], Loss: 1.0286\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [90/125], Loss: 0.7262\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [91/125], Loss: 1.0013\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [92/125], Loss: 1.0256\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [93/125], Loss: 1.2777\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [94/125], Loss: 1.2929\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [95/125], Loss: 1.2964\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [96/125], Loss: 0.9883\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [97/125], Loss: 1.3262\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [98/125], Loss: 0.9978\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [99/125], Loss: 1.1218\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [100/125], Loss: 1.1474\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [101/125], Loss: 1.1112\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [102/125], Loss: 1.0960\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [103/125], Loss: 1.0497\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [104/125], Loss: 1.3919\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [105/125], Loss: 1.3002\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [106/125], Loss: 1.2739\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [107/125], Loss: 0.9655\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [108/125], Loss: 1.3487\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [109/125], Loss: 1.5354\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [110/125], Loss: 1.0124\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [111/125], Loss: 1.2354\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [112/125], Loss: 1.4106\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [113/125], Loss: 1.0385\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [114/125], Loss: 1.2878\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [115/125], Loss: 0.7681\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [116/125], Loss: 0.9110\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [117/125], Loss: 1.0994\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [118/125], Loss: 0.9656\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [119/125], Loss: 1.3320\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [120/125], Loss: 1.0175\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [121/125], Loss: 0.9688\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [122/125], Loss: 1.0760\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [123/125], Loss: 1.4267\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [124/125], Loss: 1.2322\n",
      "Warmup: Updating learning rate to 0.008\n",
      "Epoch [13/60], Step [125/125], Loss: 1.3426\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [1/125], Loss: 1.0340\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [2/125], Loss: 1.2416\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [3/125], Loss: 1.2269\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [4/125], Loss: 0.9979\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [5/125], Loss: 1.2162\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [6/125], Loss: 1.0685\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [7/125], Loss: 1.1157\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [8/125], Loss: 1.3215\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [9/125], Loss: 0.9467\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [10/125], Loss: 1.0016\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [11/125], Loss: 0.9767\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [12/125], Loss: 1.3311\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [13/125], Loss: 1.1321\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [14/125], Loss: 1.3546\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [15/125], Loss: 1.0041\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [16/125], Loss: 1.0601\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [17/125], Loss: 1.0311\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [18/125], Loss: 0.8970\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [19/125], Loss: 1.3573\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [20/125], Loss: 1.0128\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [21/125], Loss: 1.0768\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [22/125], Loss: 1.3337\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [23/125], Loss: 1.0270\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [24/125], Loss: 1.2435\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [25/125], Loss: 1.1037\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [26/125], Loss: 0.8621\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [27/125], Loss: 0.8148\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [28/125], Loss: 1.0413\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [29/125], Loss: 1.6122\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [30/125], Loss: 1.0937\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [31/125], Loss: 1.0498\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [32/125], Loss: 1.4594\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [33/125], Loss: 0.9011\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [34/125], Loss: 0.9938\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [35/125], Loss: 1.0720\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [36/125], Loss: 0.5996\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [37/125], Loss: 1.0507\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [38/125], Loss: 0.9530\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [39/125], Loss: 1.2805\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [40/125], Loss: 1.2403\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [41/125], Loss: 1.4202\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [42/125], Loss: 1.1316\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [43/125], Loss: 1.0932\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [44/125], Loss: 0.9782\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [45/125], Loss: 0.6562\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [46/125], Loss: 1.3289\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [47/125], Loss: 0.7132\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [48/125], Loss: 0.8091\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [49/125], Loss: 1.2362\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [50/125], Loss: 0.8497\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [51/125], Loss: 0.7486\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [52/125], Loss: 1.1659\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [53/125], Loss: 1.0426\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [54/125], Loss: 0.9793\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [55/125], Loss: 0.7081\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [56/125], Loss: 0.6923\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [57/125], Loss: 0.8336\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [58/125], Loss: 1.3454\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [59/125], Loss: 1.1620\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [60/125], Loss: 1.4788\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [61/125], Loss: 1.3223\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [62/125], Loss: 1.1198\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [63/125], Loss: 1.0868\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [64/125], Loss: 1.0933\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [65/125], Loss: 0.6100\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [66/125], Loss: 1.1783\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [67/125], Loss: 1.2441\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [68/125], Loss: 1.3229\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [69/125], Loss: 1.0719\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [70/125], Loss: 0.9772\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [71/125], Loss: 0.6614\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [72/125], Loss: 1.5031\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [73/125], Loss: 1.4495\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [74/125], Loss: 1.4546\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [75/125], Loss: 0.7343\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [76/125], Loss: 0.8699\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [77/125], Loss: 1.3298\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [78/125], Loss: 1.2603\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [79/125], Loss: 1.1378\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [80/125], Loss: 0.9687\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [81/125], Loss: 0.8920\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [82/125], Loss: 1.2301\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [83/125], Loss: 0.8597\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [84/125], Loss: 0.8192\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [85/125], Loss: 0.8971\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [86/125], Loss: 1.3305\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [87/125], Loss: 0.7885\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [88/125], Loss: 1.0435\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [89/125], Loss: 1.0106\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [90/125], Loss: 1.2536\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [91/125], Loss: 1.0872\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [92/125], Loss: 0.9501\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [93/125], Loss: 0.9988\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [94/125], Loss: 1.3279\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [95/125], Loss: 1.0880\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [96/125], Loss: 0.9451\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [97/125], Loss: 0.9449\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [98/125], Loss: 1.0570\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [99/125], Loss: 0.9821\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [100/125], Loss: 0.8633\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [101/125], Loss: 1.4060\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [102/125], Loss: 0.8818\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [103/125], Loss: 1.1144\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [104/125], Loss: 0.7864\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [105/125], Loss: 1.1214\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [106/125], Loss: 1.2755\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [107/125], Loss: 1.1267\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [108/125], Loss: 1.4608\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [109/125], Loss: 1.0016\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [110/125], Loss: 1.0214\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [111/125], Loss: 1.0177\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [112/125], Loss: 0.9901\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [113/125], Loss: 1.1037\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [114/125], Loss: 0.9733\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [115/125], Loss: 1.1782\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [116/125], Loss: 1.0579\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [117/125], Loss: 1.0961\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [118/125], Loss: 1.1347\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [119/125], Loss: 1.2243\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [120/125], Loss: 0.6615\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [121/125], Loss: 1.2049\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [122/125], Loss: 1.2712\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [123/125], Loss: 1.3589\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [124/125], Loss: 0.7023\n",
      "Warmup: Updating learning rate to 0.008666666666666668\n",
      "Epoch [14/60], Step [125/125], Loss: 0.7297\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [1/125], Loss: 1.4069\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [2/125], Loss: 0.8516\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [3/125], Loss: 0.9859\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [4/125], Loss: 0.9052\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [5/125], Loss: 0.9143\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [6/125], Loss: 1.0456\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [7/125], Loss: 0.7841\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [8/125], Loss: 1.3064\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [9/125], Loss: 1.1506\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [10/125], Loss: 1.3792\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [11/125], Loss: 0.8205\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [12/125], Loss: 0.8904\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [13/125], Loss: 0.7393\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [14/125], Loss: 1.1571\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [15/125], Loss: 1.2252\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [16/125], Loss: 1.2375\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [17/125], Loss: 1.1306\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [18/125], Loss: 1.2717\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [19/125], Loss: 0.5745\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [20/125], Loss: 1.5519\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [21/125], Loss: 0.9430\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [22/125], Loss: 0.8128\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [23/125], Loss: 1.1836\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [24/125], Loss: 1.1190\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [25/125], Loss: 0.9815\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [26/125], Loss: 1.2323\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [27/125], Loss: 1.0083\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [28/125], Loss: 0.9189\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [29/125], Loss: 0.9380\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [30/125], Loss: 1.0475\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [31/125], Loss: 1.0358\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [32/125], Loss: 1.3246\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [33/125], Loss: 1.0364\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [34/125], Loss: 0.9225\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [35/125], Loss: 1.0558\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [36/125], Loss: 0.8528\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [37/125], Loss: 1.0734\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [38/125], Loss: 1.0761\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [39/125], Loss: 0.9098\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [40/125], Loss: 0.9118\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [41/125], Loss: 0.9498\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [42/125], Loss: 1.1675\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [43/125], Loss: 1.1870\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [44/125], Loss: 1.0591\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [45/125], Loss: 1.1972\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [46/125], Loss: 1.1293\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [47/125], Loss: 0.9828\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [48/125], Loss: 0.7964\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [49/125], Loss: 1.0780\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [50/125], Loss: 1.6439\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [51/125], Loss: 0.9092\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [52/125], Loss: 0.8821\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [53/125], Loss: 1.0643\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [54/125], Loss: 1.0227\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [55/125], Loss: 1.5140\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [56/125], Loss: 1.1327\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [57/125], Loss: 0.9169\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [58/125], Loss: 1.0371\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [59/125], Loss: 1.2793\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [60/125], Loss: 0.8274\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [61/125], Loss: 0.9843\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [62/125], Loss: 1.1777\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [63/125], Loss: 0.8934\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [64/125], Loss: 1.2830\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [65/125], Loss: 1.0933\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [66/125], Loss: 1.0326\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [67/125], Loss: 0.8986\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [68/125], Loss: 1.3465\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [69/125], Loss: 0.9605\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [70/125], Loss: 0.7559\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [71/125], Loss: 1.0057\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [72/125], Loss: 1.3665\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [73/125], Loss: 1.1331\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [74/125], Loss: 0.9807\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [75/125], Loss: 0.8713\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [76/125], Loss: 1.4790\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [77/125], Loss: 0.8528\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [78/125], Loss: 1.0520\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [79/125], Loss: 1.0053\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [80/125], Loss: 1.2587\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [81/125], Loss: 1.0629\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [82/125], Loss: 1.0770\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [83/125], Loss: 0.9800\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [84/125], Loss: 0.9545\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [85/125], Loss: 1.4538\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [86/125], Loss: 0.9307\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [87/125], Loss: 1.2751\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [88/125], Loss: 0.9470\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [89/125], Loss: 1.0243\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [90/125], Loss: 1.2586\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [91/125], Loss: 0.8683\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [92/125], Loss: 1.0160\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [93/125], Loss: 0.8988\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [94/125], Loss: 1.2515\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [95/125], Loss: 1.1696\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [96/125], Loss: 1.0980\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [97/125], Loss: 1.1751\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [98/125], Loss: 0.9042\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [99/125], Loss: 1.0584\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [100/125], Loss: 0.9682\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [101/125], Loss: 1.0474\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [102/125], Loss: 0.8035\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [103/125], Loss: 0.9723\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [104/125], Loss: 1.0744\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [105/125], Loss: 1.2314\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [106/125], Loss: 1.1606\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [107/125], Loss: 1.1518\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [108/125], Loss: 1.0109\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [109/125], Loss: 1.5760\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [110/125], Loss: 0.8055\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [111/125], Loss: 1.2924\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [112/125], Loss: 1.2008\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [113/125], Loss: 1.0288\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [114/125], Loss: 1.2546\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [115/125], Loss: 1.2883\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [116/125], Loss: 0.7706\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [117/125], Loss: 1.3472\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [118/125], Loss: 1.0187\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [119/125], Loss: 0.7357\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [120/125], Loss: 1.1381\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [121/125], Loss: 1.2019\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [122/125], Loss: 1.1469\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [123/125], Loss: 1.3202\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [124/125], Loss: 0.9195\n",
      "Warmup: Updating learning rate to 0.009333333333333334\n",
      "Epoch [15/60], Step [125/125], Loss: 0.8101\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [1/125], Loss: 0.9808\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [2/125], Loss: 1.1165\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [3/125], Loss: 1.0536\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [4/125], Loss: 0.9218\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [5/125], Loss: 0.9819\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [6/125], Loss: 0.7586\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [7/125], Loss: 0.9680\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [8/125], Loss: 1.4109\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [9/125], Loss: 1.2161\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [10/125], Loss: 1.0153\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [11/125], Loss: 0.8126\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [12/125], Loss: 0.8215\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [13/125], Loss: 0.9352\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [14/125], Loss: 1.2364\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [15/125], Loss: 1.0276\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [16/125], Loss: 1.1669\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [17/125], Loss: 1.4641\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [18/125], Loss: 1.2021\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [19/125], Loss: 1.0203\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [20/125], Loss: 1.0734\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [21/125], Loss: 1.0181\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [22/125], Loss: 1.0512\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [23/125], Loss: 1.1009\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [24/125], Loss: 1.0736\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [25/125], Loss: 0.9894\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [26/125], Loss: 1.2273\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [27/125], Loss: 0.8630\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [28/125], Loss: 1.0168\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [29/125], Loss: 0.9622\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [30/125], Loss: 1.1970\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [31/125], Loss: 1.2363\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [32/125], Loss: 0.9134\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [33/125], Loss: 0.8316\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [34/125], Loss: 1.1589\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [35/125], Loss: 1.0227\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [36/125], Loss: 0.9475\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [37/125], Loss: 1.1586\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [38/125], Loss: 1.1620\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [39/125], Loss: 1.0085\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [40/125], Loss: 0.9286\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [41/125], Loss: 1.3679\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [42/125], Loss: 0.9965\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [43/125], Loss: 0.9137\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [44/125], Loss: 0.7944\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [45/125], Loss: 1.0650\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [46/125], Loss: 0.7562\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [47/125], Loss: 1.2446\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [48/125], Loss: 0.8702\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [49/125], Loss: 1.0313\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [50/125], Loss: 0.7281\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [51/125], Loss: 0.9009\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [52/125], Loss: 1.0098\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [53/125], Loss: 0.9949\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [54/125], Loss: 0.8407\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [55/125], Loss: 0.8035\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [56/125], Loss: 1.1218\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [57/125], Loss: 1.1062\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [58/125], Loss: 1.0891\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [59/125], Loss: 1.2062\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [60/125], Loss: 0.9852\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [61/125], Loss: 1.4167\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [62/125], Loss: 1.2222\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [63/125], Loss: 1.0842\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [64/125], Loss: 0.9921\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [65/125], Loss: 0.9567\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [66/125], Loss: 0.8169\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [67/125], Loss: 0.9279\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [68/125], Loss: 0.9171\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [69/125], Loss: 1.1730\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [70/125], Loss: 0.9180\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [71/125], Loss: 0.9296\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [72/125], Loss: 0.5878\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [73/125], Loss: 1.1211\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [74/125], Loss: 1.3009\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [75/125], Loss: 0.8115\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [76/125], Loss: 1.0313\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [77/125], Loss: 0.7993\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [78/125], Loss: 1.0811\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [79/125], Loss: 1.0160\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [80/125], Loss: 1.2855\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [81/125], Loss: 0.9099\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [82/125], Loss: 0.8620\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [83/125], Loss: 1.2908\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [84/125], Loss: 1.1984\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [85/125], Loss: 1.1126\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [86/125], Loss: 0.9908\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [87/125], Loss: 0.7595\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [88/125], Loss: 0.7238\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [89/125], Loss: 1.0609\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [90/125], Loss: 0.6043\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [91/125], Loss: 1.3526\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [92/125], Loss: 0.8873\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [93/125], Loss: 0.9624\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [94/125], Loss: 1.1412\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [95/125], Loss: 0.9847\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [96/125], Loss: 1.2628\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [97/125], Loss: 0.9965\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [98/125], Loss: 1.0149\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [99/125], Loss: 0.9801\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [100/125], Loss: 1.1782\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [101/125], Loss: 0.5140\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [102/125], Loss: 1.1203\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [103/125], Loss: 1.1510\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [104/125], Loss: 1.0800\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [105/125], Loss: 0.9282\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [106/125], Loss: 1.1341\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [107/125], Loss: 1.2856\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [108/125], Loss: 1.0193\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [109/125], Loss: 1.0246\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [110/125], Loss: 1.3499\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [111/125], Loss: 0.7907\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [112/125], Loss: 1.0627\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [113/125], Loss: 0.7862\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [114/125], Loss: 0.8130\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [115/125], Loss: 0.8549\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [116/125], Loss: 1.1037\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [117/125], Loss: 0.9176\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [118/125], Loss: 1.3535\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [119/125], Loss: 0.6193\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [120/125], Loss: 0.8263\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [121/125], Loss: 0.9055\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [122/125], Loss: 1.3796\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [123/125], Loss: 1.0570\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [124/125], Loss: 0.7086\n",
      "Warmup: Updating learning rate to 0.01\n",
      "Epoch [16/60], Step [125/125], Loss: 1.0905\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [1/125], Loss: 1.0103\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [2/125], Loss: 1.3598\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [3/125], Loss: 0.8040\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [4/125], Loss: 1.1029\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [5/125], Loss: 1.2308\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [6/125], Loss: 1.0710\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [7/125], Loss: 1.3390\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [8/125], Loss: 0.7979\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [9/125], Loss: 0.9894\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [10/125], Loss: 0.9463\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [11/125], Loss: 1.2314\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [12/125], Loss: 0.9519\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [13/125], Loss: 1.1054\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [14/125], Loss: 0.8429\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [15/125], Loss: 0.7777\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [16/125], Loss: 1.0056\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [17/125], Loss: 0.9654\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [18/125], Loss: 0.7866\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [19/125], Loss: 0.9403\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [20/125], Loss: 0.9432\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [21/125], Loss: 0.7899\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [22/125], Loss: 0.7787\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [23/125], Loss: 1.0488\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [24/125], Loss: 1.0902\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [25/125], Loss: 0.9295\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [26/125], Loss: 1.0512\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [27/125], Loss: 0.9866\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [28/125], Loss: 1.6656\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [29/125], Loss: 1.0612\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [30/125], Loss: 0.8582\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [31/125], Loss: 0.6638\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [32/125], Loss: 0.9820\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [33/125], Loss: 1.1849\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [34/125], Loss: 0.9391\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [35/125], Loss: 0.9677\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [36/125], Loss: 1.0168\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [37/125], Loss: 1.1461\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [38/125], Loss: 1.1262\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [39/125], Loss: 1.1457\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [40/125], Loss: 1.3490\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [41/125], Loss: 0.9632\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [42/125], Loss: 0.8918\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [43/125], Loss: 1.0082\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [44/125], Loss: 0.7841\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [45/125], Loss: 0.9025\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [46/125], Loss: 0.9513\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [47/125], Loss: 0.9603\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [48/125], Loss: 1.0037\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [49/125], Loss: 0.7291\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [50/125], Loss: 0.8929\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [51/125], Loss: 0.8731\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [52/125], Loss: 0.6322\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [53/125], Loss: 0.8706\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [54/125], Loss: 0.6510\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [55/125], Loss: 0.8633\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [56/125], Loss: 0.6730\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [57/125], Loss: 0.9937\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [58/125], Loss: 0.9147\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [59/125], Loss: 1.0275\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [60/125], Loss: 0.8193\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [61/125], Loss: 0.9342\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [62/125], Loss: 0.6932\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [63/125], Loss: 1.0944\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [64/125], Loss: 0.6039\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [65/125], Loss: 0.6917\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [66/125], Loss: 0.9312\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [67/125], Loss: 0.6148\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [68/125], Loss: 0.6031\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [69/125], Loss: 1.0396\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [70/125], Loss: 0.9489\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [71/125], Loss: 0.6234\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [72/125], Loss: 0.8458\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [73/125], Loss: 1.0645\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [74/125], Loss: 0.7081\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [75/125], Loss: 0.8226\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [76/125], Loss: 0.9047\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [77/125], Loss: 0.5172\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [78/125], Loss: 0.7902\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [79/125], Loss: 0.8146\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [80/125], Loss: 0.8020\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [81/125], Loss: 0.9789\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [82/125], Loss: 0.8571\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [83/125], Loss: 0.7791\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [84/125], Loss: 0.8887\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [85/125], Loss: 0.8435\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [86/125], Loss: 0.6718\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [87/125], Loss: 0.6970\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [88/125], Loss: 0.9541\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [89/125], Loss: 1.0336\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [90/125], Loss: 1.2323\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [91/125], Loss: 1.1828\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [92/125], Loss: 0.8855\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [93/125], Loss: 0.9825\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [94/125], Loss: 0.9142\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [95/125], Loss: 1.0897\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [96/125], Loss: 0.8260\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [97/125], Loss: 1.1802\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [98/125], Loss: 0.7364\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [99/125], Loss: 0.9401\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [100/125], Loss: 1.0375\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [101/125], Loss: 0.5826\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [102/125], Loss: 0.9799\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [103/125], Loss: 0.9449\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [104/125], Loss: 0.9728\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [105/125], Loss: 0.7127\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [106/125], Loss: 0.9801\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [107/125], Loss: 1.0154\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [108/125], Loss: 0.6820\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [109/125], Loss: 1.1650\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [110/125], Loss: 0.8870\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [111/125], Loss: 0.9121\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [112/125], Loss: 0.5474\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [113/125], Loss: 0.7200\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [114/125], Loss: 0.7837\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [115/125], Loss: 0.8845\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [116/125], Loss: 0.6281\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [117/125], Loss: 1.0747\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [118/125], Loss: 0.8634\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [119/125], Loss: 0.9235\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [120/125], Loss: 0.7785\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [121/125], Loss: 1.0577\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [122/125], Loss: 0.7167\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [123/125], Loss: 0.8202\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [124/125], Loss: 0.8171\n",
      "Decay: Updating learning rate to 0.009777776777777778\n",
      "Epoch [17/60], Step [125/125], Loss: 0.9087\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [1/125], Loss: 0.8241\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [2/125], Loss: 0.9217\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [3/125], Loss: 0.7217\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [4/125], Loss: 0.9161\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [5/125], Loss: 1.0038\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [6/125], Loss: 0.8962\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [7/125], Loss: 0.9966\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [8/125], Loss: 0.7660\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [9/125], Loss: 0.6659\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [10/125], Loss: 0.8368\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [11/125], Loss: 1.1683\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [12/125], Loss: 0.5586\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [13/125], Loss: 0.9794\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [14/125], Loss: 0.9662\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [15/125], Loss: 1.2894\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [16/125], Loss: 0.9550\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [17/125], Loss: 0.7120\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [18/125], Loss: 0.7528\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [19/125], Loss: 0.6418\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [20/125], Loss: 0.9656\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [21/125], Loss: 1.1042\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [22/125], Loss: 1.2204\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [23/125], Loss: 0.8541\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [24/125], Loss: 0.8489\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [25/125], Loss: 1.2854\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [26/125], Loss: 0.4992\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [27/125], Loss: 0.7997\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [28/125], Loss: 1.0263\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [29/125], Loss: 0.9257\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [30/125], Loss: 0.8651\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [31/125], Loss: 0.7291\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [32/125], Loss: 0.9275\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [33/125], Loss: 0.8467\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [34/125], Loss: 0.8148\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [35/125], Loss: 0.6978\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [36/125], Loss: 0.6489\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [37/125], Loss: 0.8030\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [38/125], Loss: 0.7633\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [39/125], Loss: 0.6442\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [40/125], Loss: 1.0028\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [41/125], Loss: 0.6098\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [42/125], Loss: 0.7234\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [43/125], Loss: 0.6610\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [44/125], Loss: 0.7426\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [45/125], Loss: 0.7958\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [46/125], Loss: 1.0853\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [47/125], Loss: 0.4899\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [48/125], Loss: 0.9169\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [49/125], Loss: 0.7381\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [50/125], Loss: 0.7755\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [51/125], Loss: 0.8634\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [52/125], Loss: 1.1229\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [53/125], Loss: 1.1231\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [54/125], Loss: 0.6439\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [55/125], Loss: 0.7903\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [56/125], Loss: 0.8504\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [57/125], Loss: 0.9888\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [58/125], Loss: 0.8522\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [59/125], Loss: 0.8752\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [60/125], Loss: 1.1461\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [61/125], Loss: 0.9856\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [62/125], Loss: 0.8561\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [63/125], Loss: 0.7970\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [64/125], Loss: 0.6591\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [65/125], Loss: 0.8589\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [66/125], Loss: 0.7466\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [67/125], Loss: 0.7642\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [68/125], Loss: 0.9621\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [69/125], Loss: 0.8716\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [70/125], Loss: 0.8704\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [71/125], Loss: 0.9396\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [72/125], Loss: 0.8109\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [73/125], Loss: 0.8628\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [74/125], Loss: 1.0570\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [75/125], Loss: 1.0011\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [76/125], Loss: 0.7504\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [77/125], Loss: 0.7168\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [78/125], Loss: 0.7492\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [79/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [80/125], Loss: 0.8475\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [81/125], Loss: 0.5994\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [82/125], Loss: 1.0790\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [83/125], Loss: 0.9132\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [84/125], Loss: 0.8884\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [85/125], Loss: 0.8031\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [86/125], Loss: 0.8925\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [87/125], Loss: 0.7646\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [88/125], Loss: 0.7019\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [89/125], Loss: 0.8068\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [90/125], Loss: 0.9691\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [91/125], Loss: 0.5398\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [92/125], Loss: 0.5837\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [93/125], Loss: 0.8618\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [94/125], Loss: 1.2013\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [95/125], Loss: 0.6726\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [96/125], Loss: 0.6805\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [97/125], Loss: 0.7998\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [98/125], Loss: 0.8926\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [99/125], Loss: 0.8796\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [100/125], Loss: 0.6304\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [101/125], Loss: 1.0253\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [102/125], Loss: 0.7781\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [103/125], Loss: 0.8598\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [104/125], Loss: 0.7945\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [105/125], Loss: 0.4642\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [106/125], Loss: 0.7499\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [107/125], Loss: 0.8979\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [108/125], Loss: 0.9914\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [109/125], Loss: 0.8740\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [110/125], Loss: 0.6592\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [111/125], Loss: 0.6552\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [112/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [113/125], Loss: 0.9426\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [114/125], Loss: 0.9344\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [115/125], Loss: 0.8164\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [116/125], Loss: 0.7352\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [117/125], Loss: 0.9235\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [118/125], Loss: 0.5491\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [119/125], Loss: 0.8403\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [120/125], Loss: 0.7074\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [121/125], Loss: 0.6599\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [122/125], Loss: 0.8736\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [123/125], Loss: 0.9657\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [124/125], Loss: 0.8044\n",
      "Decay: Updating learning rate to 0.009555554555555556\n",
      "Epoch [18/60], Step [125/125], Loss: 0.7631\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [1/125], Loss: 0.6991\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [2/125], Loss: 0.7959\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [3/125], Loss: 0.7100\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [4/125], Loss: 1.1019\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [5/125], Loss: 0.6135\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [6/125], Loss: 0.8708\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [7/125], Loss: 0.8826\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [8/125], Loss: 0.6909\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [9/125], Loss: 0.8165\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [10/125], Loss: 0.9577\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [11/125], Loss: 0.8296\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [12/125], Loss: 1.0709\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [13/125], Loss: 0.8482\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [14/125], Loss: 1.2009\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [15/125], Loss: 0.8801\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [16/125], Loss: 0.8856\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [17/125], Loss: 0.7201\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [18/125], Loss: 0.7603\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [19/125], Loss: 0.8627\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [20/125], Loss: 0.7731\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [21/125], Loss: 0.8515\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [22/125], Loss: 0.9559\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [23/125], Loss: 0.9037\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [24/125], Loss: 0.6245\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [25/125], Loss: 0.7669\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [26/125], Loss: 0.9449\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [27/125], Loss: 0.7151\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [28/125], Loss: 0.9478\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [29/125], Loss: 0.5306\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [30/125], Loss: 0.5912\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [31/125], Loss: 0.9381\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [32/125], Loss: 0.9674\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [33/125], Loss: 0.7151\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [34/125], Loss: 0.6134\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [35/125], Loss: 0.8179\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [36/125], Loss: 0.6886\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [37/125], Loss: 0.5294\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [38/125], Loss: 0.6800\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [39/125], Loss: 0.5792\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [40/125], Loss: 0.9136\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [41/125], Loss: 0.6464\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [42/125], Loss: 0.5715\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [43/125], Loss: 0.9250\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [44/125], Loss: 0.8208\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [45/125], Loss: 0.9537\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [46/125], Loss: 0.9033\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [47/125], Loss: 0.8414\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [48/125], Loss: 0.9637\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [49/125], Loss: 0.6335\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [50/125], Loss: 0.5893\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [51/125], Loss: 0.8152\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [52/125], Loss: 0.7260\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [53/125], Loss: 0.7777\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [54/125], Loss: 0.8780\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [55/125], Loss: 0.5972\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [56/125], Loss: 1.0012\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [57/125], Loss: 1.1785\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [58/125], Loss: 0.7430\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [59/125], Loss: 0.7456\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [60/125], Loss: 0.5072\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [61/125], Loss: 0.8157\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [62/125], Loss: 0.8014\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [63/125], Loss: 0.8331\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [64/125], Loss: 0.6210\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [65/125], Loss: 0.8858\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [66/125], Loss: 0.7634\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [67/125], Loss: 0.8270\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [68/125], Loss: 0.6784\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [69/125], Loss: 0.6585\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [70/125], Loss: 0.8884\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [71/125], Loss: 1.1025\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [72/125], Loss: 0.6969\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [73/125], Loss: 0.9122\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [74/125], Loss: 0.6297\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [75/125], Loss: 0.9123\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [76/125], Loss: 0.7895\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [77/125], Loss: 0.7249\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [78/125], Loss: 0.7878\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [79/125], Loss: 0.7955\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [80/125], Loss: 0.8864\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [81/125], Loss: 0.5665\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [82/125], Loss: 0.7681\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [83/125], Loss: 0.6713\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [84/125], Loss: 0.7082\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [85/125], Loss: 0.9521\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [86/125], Loss: 0.9411\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [87/125], Loss: 0.8237\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [88/125], Loss: 0.7626\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [89/125], Loss: 0.6771\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [90/125], Loss: 1.2832\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [91/125], Loss: 0.7477\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [92/125], Loss: 0.5659\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [93/125], Loss: 0.7722\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [94/125], Loss: 0.7318\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [95/125], Loss: 0.6086\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [96/125], Loss: 0.6519\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [97/125], Loss: 0.7884\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [98/125], Loss: 0.8309\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [99/125], Loss: 0.6237\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [100/125], Loss: 0.7525\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [101/125], Loss: 0.8148\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [102/125], Loss: 0.6415\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [103/125], Loss: 0.7354\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [104/125], Loss: 0.7877\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [105/125], Loss: 0.6921\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [106/125], Loss: 0.7262\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [107/125], Loss: 0.7119\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [108/125], Loss: 0.5899\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [109/125], Loss: 0.7989\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [110/125], Loss: 0.4468\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [111/125], Loss: 0.7587\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [112/125], Loss: 0.7831\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [113/125], Loss: 0.8599\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [114/125], Loss: 0.8456\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [115/125], Loss: 0.6072\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [116/125], Loss: 0.6612\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [117/125], Loss: 0.5469\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [118/125], Loss: 1.2237\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [119/125], Loss: 0.6960\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [120/125], Loss: 0.6778\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [121/125], Loss: 0.6166\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [122/125], Loss: 0.6699\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [123/125], Loss: 1.0033\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [124/125], Loss: 0.6505\n",
      "Decay: Updating learning rate to 0.009333332333333333\n",
      "Epoch [19/60], Step [125/125], Loss: 1.0840\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [1/125], Loss: 0.6854\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [2/125], Loss: 0.7048\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [3/125], Loss: 0.8214\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [4/125], Loss: 0.6813\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [5/125], Loss: 0.7703\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [6/125], Loss: 0.6356\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [7/125], Loss: 0.9047\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [8/125], Loss: 0.8481\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [9/125], Loss: 0.5093\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [10/125], Loss: 0.8725\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [11/125], Loss: 0.8410\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [12/125], Loss: 1.0434\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [13/125], Loss: 0.9402\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [14/125], Loss: 0.5933\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [15/125], Loss: 0.4556\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [16/125], Loss: 0.6093\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [17/125], Loss: 0.6202\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [18/125], Loss: 0.8228\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [19/125], Loss: 0.6441\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [20/125], Loss: 0.8476\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [21/125], Loss: 0.7977\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [22/125], Loss: 0.6385\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [23/125], Loss: 0.5487\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [24/125], Loss: 0.6633\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [25/125], Loss: 0.5480\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [26/125], Loss: 0.8096\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [27/125], Loss: 0.8178\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [28/125], Loss: 0.7553\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [29/125], Loss: 0.6075\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [30/125], Loss: 0.7064\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [31/125], Loss: 0.4934\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [32/125], Loss: 0.8058\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [33/125], Loss: 0.7131\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [34/125], Loss: 0.5261\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [35/125], Loss: 0.7375\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [36/125], Loss: 0.9151\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [37/125], Loss: 0.7685\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [38/125], Loss: 1.0354\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [39/125], Loss: 0.7906\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [40/125], Loss: 0.7845\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [41/125], Loss: 0.8677\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [42/125], Loss: 0.6647\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [43/125], Loss: 0.9600\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [44/125], Loss: 0.8551\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [45/125], Loss: 0.6596\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [46/125], Loss: 0.8411\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [47/125], Loss: 0.6183\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [48/125], Loss: 0.8944\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [49/125], Loss: 0.4649\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [50/125], Loss: 0.5680\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [51/125], Loss: 0.8631\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [52/125], Loss: 0.8433\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [53/125], Loss: 0.7761\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [54/125], Loss: 1.1335\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [55/125], Loss: 0.8566\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [56/125], Loss: 0.6823\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [57/125], Loss: 1.2214\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [58/125], Loss: 0.6130\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [59/125], Loss: 0.8799\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [60/125], Loss: 0.8344\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [61/125], Loss: 0.8188\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [62/125], Loss: 0.8663\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [63/125], Loss: 0.6119\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [64/125], Loss: 0.7714\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [65/125], Loss: 0.7765\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [66/125], Loss: 1.0258\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [67/125], Loss: 0.6304\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [68/125], Loss: 0.7543\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [69/125], Loss: 0.6108\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [70/125], Loss: 0.5568\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [71/125], Loss: 0.6581\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [72/125], Loss: 0.8741\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [73/125], Loss: 0.6126\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [74/125], Loss: 0.4227\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [75/125], Loss: 0.8280\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [76/125], Loss: 0.8513\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [77/125], Loss: 0.8892\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [78/125], Loss: 0.5551\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [79/125], Loss: 0.7733\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [80/125], Loss: 0.6331\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [81/125], Loss: 0.6497\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [82/125], Loss: 0.7649\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [83/125], Loss: 0.7930\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [84/125], Loss: 0.6230\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [85/125], Loss: 0.7420\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [86/125], Loss: 0.4176\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [87/125], Loss: 0.8744\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [88/125], Loss: 0.4846\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [89/125], Loss: 0.6682\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [90/125], Loss: 0.4632\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [91/125], Loss: 0.6847\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [92/125], Loss: 0.7916\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [93/125], Loss: 0.5222\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [94/125], Loss: 0.4325\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [95/125], Loss: 0.6521\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [96/125], Loss: 0.5286\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [97/125], Loss: 0.4856\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [98/125], Loss: 0.7349\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [99/125], Loss: 0.6496\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [100/125], Loss: 0.8165\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [101/125], Loss: 0.7789\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [102/125], Loss: 0.5254\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [103/125], Loss: 0.8210\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [104/125], Loss: 1.0393\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [105/125], Loss: 0.6226\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [106/125], Loss: 0.6953\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [107/125], Loss: 0.7048\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [108/125], Loss: 0.8986\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [109/125], Loss: 0.5579\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [110/125], Loss: 0.6196\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [111/125], Loss: 0.6559\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [112/125], Loss: 0.8231\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [113/125], Loss: 0.4965\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [114/125], Loss: 0.7852\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [115/125], Loss: 0.7059\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [116/125], Loss: 0.5654\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [117/125], Loss: 0.4543\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [118/125], Loss: 0.8079\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [119/125], Loss: 0.5265\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [120/125], Loss: 0.5959\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [121/125], Loss: 0.5407\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [122/125], Loss: 0.8597\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [123/125], Loss: 0.8617\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [124/125], Loss: 0.9645\n",
      "Decay: Updating learning rate to 0.009111110111111112\n",
      "Epoch [20/60], Step [125/125], Loss: 0.9580\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [1/125], Loss: 0.6571\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [2/125], Loss: 0.6550\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [3/125], Loss: 0.6489\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [4/125], Loss: 0.7851\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [5/125], Loss: 0.8401\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [6/125], Loss: 0.8311\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [7/125], Loss: 1.1898\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [8/125], Loss: 0.6146\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [9/125], Loss: 1.2308\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [10/125], Loss: 1.0029\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [11/125], Loss: 0.8138\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [12/125], Loss: 0.7211\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [13/125], Loss: 0.8449\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [14/125], Loss: 0.7305\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [15/125], Loss: 0.7658\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [16/125], Loss: 0.6627\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [17/125], Loss: 0.9950\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [18/125], Loss: 0.6923\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [19/125], Loss: 0.6179\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [20/125], Loss: 0.6315\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [21/125], Loss: 0.4541\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [22/125], Loss: 0.8964\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [23/125], Loss: 0.7979\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [24/125], Loss: 0.9523\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [25/125], Loss: 0.6745\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [26/125], Loss: 0.6329\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [27/125], Loss: 0.6157\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [28/125], Loss: 0.8272\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [29/125], Loss: 0.5080\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [30/125], Loss: 0.9122\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [31/125], Loss: 0.6204\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [32/125], Loss: 0.7374\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [33/125], Loss: 0.5619\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [34/125], Loss: 0.6543\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [35/125], Loss: 0.6030\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [36/125], Loss: 0.7160\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [37/125], Loss: 0.6366\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [38/125], Loss: 0.7335\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [39/125], Loss: 0.5240\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [40/125], Loss: 0.7635\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [41/125], Loss: 0.4321\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [42/125], Loss: 0.6376\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [43/125], Loss: 0.8426\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [44/125], Loss: 0.8679\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [45/125], Loss: 0.6840\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [46/125], Loss: 0.6578\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [47/125], Loss: 0.6767\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [48/125], Loss: 0.6486\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [49/125], Loss: 0.9383\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [50/125], Loss: 0.7418\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [51/125], Loss: 0.7342\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [52/125], Loss: 0.6820\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [53/125], Loss: 0.7765\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [54/125], Loss: 0.8311\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [55/125], Loss: 0.6410\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [56/125], Loss: 0.8631\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [57/125], Loss: 0.7902\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [58/125], Loss: 1.0578\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [59/125], Loss: 0.7014\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [60/125], Loss: 0.8539\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [61/125], Loss: 0.6658\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [62/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [63/125], Loss: 0.4964\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [64/125], Loss: 0.7802\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [65/125], Loss: 0.7086\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [66/125], Loss: 1.0998\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [67/125], Loss: 0.7877\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [68/125], Loss: 0.6332\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [69/125], Loss: 0.7672\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [70/125], Loss: 0.8280\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [71/125], Loss: 0.8303\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [72/125], Loss: 0.5747\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [73/125], Loss: 0.8223\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [74/125], Loss: 0.7711\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [75/125], Loss: 0.9033\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [76/125], Loss: 0.6729\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [77/125], Loss: 0.5687\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [78/125], Loss: 0.6700\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [79/125], Loss: 0.5595\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [80/125], Loss: 0.8776\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [81/125], Loss: 0.8571\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [82/125], Loss: 0.6357\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [83/125], Loss: 0.5303\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [84/125], Loss: 0.7041\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [85/125], Loss: 0.6926\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [86/125], Loss: 0.4443\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [87/125], Loss: 0.6030\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [88/125], Loss: 0.5967\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [89/125], Loss: 0.8024\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [90/125], Loss: 1.0134\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [91/125], Loss: 0.8151\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [92/125], Loss: 0.6407\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [93/125], Loss: 0.9456\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [94/125], Loss: 0.5918\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [95/125], Loss: 0.5149\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [96/125], Loss: 0.4858\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [97/125], Loss: 0.7906\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [98/125], Loss: 0.6830\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [99/125], Loss: 0.5901\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [100/125], Loss: 1.0467\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [101/125], Loss: 0.6852\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [102/125], Loss: 0.8748\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [103/125], Loss: 1.0960\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [104/125], Loss: 0.8640\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [105/125], Loss: 0.6051\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [106/125], Loss: 0.5751\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [107/125], Loss: 0.7159\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [108/125], Loss: 0.7108\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [109/125], Loss: 0.7900\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [110/125], Loss: 0.7027\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [111/125], Loss: 0.6483\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [112/125], Loss: 0.5317\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [113/125], Loss: 0.7466\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [114/125], Loss: 1.0369\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [115/125], Loss: 0.6122\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [116/125], Loss: 0.7400\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [117/125], Loss: 0.8743\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [118/125], Loss: 0.7376\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [119/125], Loss: 0.4275\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [120/125], Loss: 0.6322\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [121/125], Loss: 0.6445\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [122/125], Loss: 0.5106\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [123/125], Loss: 0.7925\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [124/125], Loss: 0.5764\n",
      "Decay: Updating learning rate to 0.00888888788888889\n",
      "Epoch [21/60], Step [125/125], Loss: 0.4468\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [1/125], Loss: 0.9542\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [2/125], Loss: 0.8051\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [3/125], Loss: 0.9234\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [4/125], Loss: 0.6797\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [5/125], Loss: 0.6796\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [6/125], Loss: 0.4832\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [7/125], Loss: 0.6057\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [8/125], Loss: 0.5754\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [9/125], Loss: 0.7206\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [10/125], Loss: 0.7611\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [11/125], Loss: 0.9181\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [12/125], Loss: 0.4606\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [13/125], Loss: 0.6844\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [14/125], Loss: 0.7594\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [15/125], Loss: 0.6332\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [16/125], Loss: 0.5110\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [17/125], Loss: 0.6637\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [18/125], Loss: 0.6859\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [19/125], Loss: 0.5602\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [20/125], Loss: 0.6871\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [21/125], Loss: 0.6171\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [22/125], Loss: 0.7993\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [23/125], Loss: 0.8161\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [24/125], Loss: 0.6329\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [25/125], Loss: 0.8279\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [26/125], Loss: 0.7600\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [27/125], Loss: 0.9005\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [28/125], Loss: 0.6050\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [29/125], Loss: 0.5597\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [30/125], Loss: 0.6640\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [31/125], Loss: 0.6344\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [32/125], Loss: 0.6432\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [33/125], Loss: 0.6490\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [34/125], Loss: 0.6509\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [35/125], Loss: 0.6393\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [36/125], Loss: 0.4587\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [37/125], Loss: 0.7671\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [38/125], Loss: 0.6351\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [39/125], Loss: 0.6264\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [40/125], Loss: 0.5523\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [41/125], Loss: 0.5794\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [42/125], Loss: 0.6438\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [43/125], Loss: 0.6251\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [44/125], Loss: 0.8201\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [45/125], Loss: 0.8700\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [46/125], Loss: 0.7214\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [47/125], Loss: 0.7488\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [48/125], Loss: 0.6759\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [49/125], Loss: 0.4032\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [50/125], Loss: 0.7526\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [51/125], Loss: 0.6122\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [52/125], Loss: 0.5771\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [53/125], Loss: 0.8406\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [54/125], Loss: 0.9128\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [55/125], Loss: 0.6083\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [56/125], Loss: 0.7644\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [57/125], Loss: 0.7575\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [58/125], Loss: 0.6134\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [59/125], Loss: 0.7350\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [60/125], Loss: 0.4676\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [61/125], Loss: 0.6493\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [62/125], Loss: 0.7330\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [63/125], Loss: 0.6691\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [64/125], Loss: 0.4213\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [65/125], Loss: 0.8832\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [66/125], Loss: 0.5096\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [67/125], Loss: 1.0116\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [68/125], Loss: 0.7829\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [69/125], Loss: 0.7640\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [70/125], Loss: 0.9931\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [71/125], Loss: 0.5795\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [72/125], Loss: 0.7306\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [73/125], Loss: 0.6671\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [74/125], Loss: 0.6707\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [75/125], Loss: 0.7277\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [76/125], Loss: 0.5072\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [77/125], Loss: 0.8115\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [78/125], Loss: 0.8041\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [79/125], Loss: 0.5746\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [80/125], Loss: 0.6873\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [81/125], Loss: 0.7040\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [82/125], Loss: 0.9003\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [83/125], Loss: 0.8051\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [84/125], Loss: 1.1079\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [85/125], Loss: 0.7199\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [86/125], Loss: 0.8874\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [87/125], Loss: 0.8365\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [88/125], Loss: 0.6697\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [89/125], Loss: 0.5213\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [90/125], Loss: 0.7764\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [91/125], Loss: 0.6921\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [92/125], Loss: 0.7213\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [93/125], Loss: 0.6511\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [94/125], Loss: 0.5782\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [95/125], Loss: 1.0355\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [96/125], Loss: 0.4620\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [97/125], Loss: 0.6826\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [98/125], Loss: 0.7425\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [99/125], Loss: 0.7577\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [100/125], Loss: 0.6791\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [101/125], Loss: 0.9674\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [102/125], Loss: 0.7467\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [103/125], Loss: 0.6952\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [104/125], Loss: 0.9802\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [105/125], Loss: 0.5796\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [106/125], Loss: 0.7088\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [107/125], Loss: 0.7582\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [108/125], Loss: 0.5317\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [109/125], Loss: 0.7081\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [110/125], Loss: 0.9070\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [111/125], Loss: 0.7084\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [112/125], Loss: 0.6074\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [113/125], Loss: 0.6334\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [114/125], Loss: 0.7819\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [115/125], Loss: 0.9144\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [116/125], Loss: 0.4740\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [117/125], Loss: 0.7675\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [118/125], Loss: 0.4463\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [119/125], Loss: 0.7095\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [120/125], Loss: 0.8937\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [121/125], Loss: 0.6303\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [122/125], Loss: 0.7983\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [123/125], Loss: 0.6835\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [124/125], Loss: 0.6721\n",
      "Decay: Updating learning rate to 0.008666665666666667\n",
      "Epoch [22/60], Step [125/125], Loss: 0.9367\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [1/125], Loss: 0.9282\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [2/125], Loss: 0.7374\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [3/125], Loss: 0.7027\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [4/125], Loss: 0.9246\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [5/125], Loss: 0.3652\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [6/125], Loss: 0.6394\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [7/125], Loss: 0.8251\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [8/125], Loss: 0.6708\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [9/125], Loss: 0.7382\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [10/125], Loss: 0.6441\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [11/125], Loss: 0.7486\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [12/125], Loss: 0.9294\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [13/125], Loss: 0.6206\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [14/125], Loss: 0.6245\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [15/125], Loss: 0.7833\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [16/125], Loss: 0.8301\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [17/125], Loss: 1.2551\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [18/125], Loss: 0.6903\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [19/125], Loss: 0.5453\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [20/125], Loss: 0.7754\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [21/125], Loss: 0.5937\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [22/125], Loss: 0.9858\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [23/125], Loss: 0.8983\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [24/125], Loss: 0.5982\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [25/125], Loss: 0.5567\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [26/125], Loss: 0.5741\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [27/125], Loss: 0.6862\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [28/125], Loss: 0.6658\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [29/125], Loss: 0.6992\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [30/125], Loss: 0.6648\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [31/125], Loss: 0.6001\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [32/125], Loss: 0.7997\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [33/125], Loss: 0.4878\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [34/125], Loss: 0.6090\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [35/125], Loss: 0.9154\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [36/125], Loss: 0.8601\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [37/125], Loss: 0.9018\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [38/125], Loss: 0.5400\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [39/125], Loss: 0.9296\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [40/125], Loss: 0.6335\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [41/125], Loss: 0.6273\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [42/125], Loss: 0.7885\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [43/125], Loss: 0.6199\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [44/125], Loss: 0.5852\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [45/125], Loss: 0.5292\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [46/125], Loss: 0.6407\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [47/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [48/125], Loss: 0.6661\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [49/125], Loss: 0.5391\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [50/125], Loss: 0.4149\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [51/125], Loss: 0.5725\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [52/125], Loss: 0.7425\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [53/125], Loss: 0.7097\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [54/125], Loss: 0.6651\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [55/125], Loss: 0.9651\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [56/125], Loss: 0.6872\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [57/125], Loss: 0.9898\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [58/125], Loss: 0.7037\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [59/125], Loss: 0.5411\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [60/125], Loss: 0.5993\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [61/125], Loss: 0.6787\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [62/125], Loss: 0.7323\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [63/125], Loss: 0.5740\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [64/125], Loss: 0.9347\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [65/125], Loss: 0.6607\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [66/125], Loss: 0.8915\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [67/125], Loss: 0.8833\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [68/125], Loss: 0.9803\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [69/125], Loss: 0.4881\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [70/125], Loss: 0.8764\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [71/125], Loss: 0.7157\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [72/125], Loss: 0.4656\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [73/125], Loss: 0.6326\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [74/125], Loss: 0.4561\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [75/125], Loss: 0.7377\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [76/125], Loss: 0.4932\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [77/125], Loss: 0.5391\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [78/125], Loss: 0.6876\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [79/125], Loss: 0.5023\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [80/125], Loss: 0.8873\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [81/125], Loss: 0.6478\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [82/125], Loss: 0.7077\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [83/125], Loss: 0.6978\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [84/125], Loss: 0.8131\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [85/125], Loss: 0.6214\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [86/125], Loss: 0.6050\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [87/125], Loss: 0.4838\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [88/125], Loss: 0.6879\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [89/125], Loss: 0.5241\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [90/125], Loss: 0.7302\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [91/125], Loss: 1.0328\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [92/125], Loss: 0.7751\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [93/125], Loss: 0.5718\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [94/125], Loss: 0.6808\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [95/125], Loss: 0.5781\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [96/125], Loss: 0.6427\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [97/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [98/125], Loss: 0.9066\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [99/125], Loss: 0.8579\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [100/125], Loss: 0.5334\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [101/125], Loss: 0.7599\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [102/125], Loss: 0.7303\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [103/125], Loss: 0.6875\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [104/125], Loss: 0.5506\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [105/125], Loss: 0.9264\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [106/125], Loss: 0.5110\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [107/125], Loss: 0.8085\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [108/125], Loss: 0.6186\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [109/125], Loss: 0.6740\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [110/125], Loss: 0.6166\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [111/125], Loss: 0.7488\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [112/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [113/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [114/125], Loss: 0.6308\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [115/125], Loss: 0.5899\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [116/125], Loss: 0.6250\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [117/125], Loss: 0.4562\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [118/125], Loss: 0.6868\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [119/125], Loss: 0.6568\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [120/125], Loss: 0.8071\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [121/125], Loss: 0.5476\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [122/125], Loss: 0.6002\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [123/125], Loss: 0.6224\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [124/125], Loss: 0.6092\n",
      "Decay: Updating learning rate to 0.008444443444444446\n",
      "Epoch [23/60], Step [125/125], Loss: 0.8179\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [1/125], Loss: 0.5407\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [2/125], Loss: 0.8565\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [3/125], Loss: 0.7775\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [4/125], Loss: 0.6869\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [5/125], Loss: 0.5204\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [6/125], Loss: 0.6239\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [7/125], Loss: 0.5141\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [8/125], Loss: 0.6350\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [9/125], Loss: 0.7164\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [10/125], Loss: 0.7507\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [11/125], Loss: 0.7975\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [12/125], Loss: 0.7526\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [13/125], Loss: 0.6394\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [14/125], Loss: 0.6705\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [15/125], Loss: 0.7229\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [16/125], Loss: 0.6170\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [17/125], Loss: 0.4877\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [18/125], Loss: 0.7895\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [19/125], Loss: 0.4191\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [20/125], Loss: 0.6785\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [21/125], Loss: 0.9408\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [22/125], Loss: 0.7857\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [23/125], Loss: 0.5991\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [24/125], Loss: 0.5245\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [25/125], Loss: 0.8934\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [26/125], Loss: 0.6632\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [27/125], Loss: 0.7463\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [28/125], Loss: 0.8817\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [29/125], Loss: 0.6598\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [30/125], Loss: 0.6260\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [31/125], Loss: 0.8794\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [32/125], Loss: 0.6307\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [33/125], Loss: 0.5806\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [34/125], Loss: 0.6384\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [35/125], Loss: 0.5415\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [36/125], Loss: 0.5065\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [37/125], Loss: 0.8991\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [38/125], Loss: 0.6091\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [39/125], Loss: 0.7691\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [40/125], Loss: 0.4930\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [41/125], Loss: 0.5305\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [42/125], Loss: 0.8652\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [43/125], Loss: 0.9820\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [44/125], Loss: 0.4609\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [45/125], Loss: 0.6012\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [46/125], Loss: 0.6433\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [47/125], Loss: 0.5039\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [48/125], Loss: 0.7680\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [49/125], Loss: 0.5394\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [50/125], Loss: 0.6752\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [51/125], Loss: 0.6926\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [52/125], Loss: 0.6446\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [53/125], Loss: 0.4534\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [54/125], Loss: 0.7946\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [55/125], Loss: 0.9308\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [56/125], Loss: 0.7864\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [57/125], Loss: 0.6661\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [58/125], Loss: 0.7101\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [59/125], Loss: 0.7743\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [60/125], Loss: 0.6280\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [61/125], Loss: 0.5130\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [62/125], Loss: 0.3945\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [63/125], Loss: 0.7473\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [64/125], Loss: 0.5547\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [65/125], Loss: 0.8293\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [66/125], Loss: 0.6191\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [67/125], Loss: 0.4632\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [68/125], Loss: 0.5721\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [69/125], Loss: 0.5493\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [70/125], Loss: 0.5435\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [71/125], Loss: 0.7895\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [72/125], Loss: 0.7335\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [73/125], Loss: 0.6023\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [74/125], Loss: 0.6325\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [75/125], Loss: 0.7835\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [76/125], Loss: 0.5769\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [77/125], Loss: 0.5118\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [78/125], Loss: 0.3693\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [79/125], Loss: 0.8165\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [80/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [81/125], Loss: 0.6429\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [82/125], Loss: 0.8017\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [83/125], Loss: 0.6370\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [84/125], Loss: 0.5438\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [85/125], Loss: 0.8465\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [86/125], Loss: 0.5194\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [87/125], Loss: 0.7496\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [88/125], Loss: 0.8303\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [89/125], Loss: 0.7304\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [90/125], Loss: 0.5953\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [91/125], Loss: 1.0084\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [92/125], Loss: 0.5891\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [93/125], Loss: 0.6457\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [94/125], Loss: 0.5739\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [95/125], Loss: 0.5773\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [96/125], Loss: 0.8671\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [97/125], Loss: 0.7289\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [98/125], Loss: 0.5706\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [99/125], Loss: 0.9709\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [100/125], Loss: 0.7178\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [101/125], Loss: 0.6137\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [102/125], Loss: 0.6258\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [103/125], Loss: 0.5462\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [104/125], Loss: 0.7425\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [105/125], Loss: 0.7438\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [106/125], Loss: 0.7366\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [107/125], Loss: 0.6722\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [108/125], Loss: 0.6751\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [109/125], Loss: 0.5512\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [110/125], Loss: 0.5421\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [111/125], Loss: 0.8422\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [112/125], Loss: 0.6730\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [113/125], Loss: 0.6803\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [114/125], Loss: 0.7913\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [115/125], Loss: 0.6737\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [116/125], Loss: 0.5239\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [117/125], Loss: 0.6505\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [118/125], Loss: 0.5721\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [119/125], Loss: 0.6226\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [120/125], Loss: 0.6449\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [121/125], Loss: 0.6395\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [122/125], Loss: 0.6546\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [123/125], Loss: 0.7188\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [124/125], Loss: 0.8528\n",
      "Decay: Updating learning rate to 0.008222221222222223\n",
      "Epoch [24/60], Step [125/125], Loss: 0.6601\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [1/125], Loss: 0.6819\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [2/125], Loss: 0.6924\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [3/125], Loss: 0.6349\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [4/125], Loss: 0.5059\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [5/125], Loss: 0.6976\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [6/125], Loss: 0.4284\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [7/125], Loss: 0.6966\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [8/125], Loss: 0.6860\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [9/125], Loss: 0.6754\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [10/125], Loss: 0.6378\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [11/125], Loss: 0.7570\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [12/125], Loss: 0.9064\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [13/125], Loss: 0.6204\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [14/125], Loss: 0.8145\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [15/125], Loss: 0.9100\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [16/125], Loss: 0.4993\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [17/125], Loss: 0.4813\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [18/125], Loss: 0.8689\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [19/125], Loss: 0.7243\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [20/125], Loss: 0.5113\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [21/125], Loss: 0.8093\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [22/125], Loss: 0.5498\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [23/125], Loss: 0.6986\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [24/125], Loss: 0.6593\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [25/125], Loss: 0.4828\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [26/125], Loss: 0.8051\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [27/125], Loss: 0.6924\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [28/125], Loss: 0.6904\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [29/125], Loss: 0.6810\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [30/125], Loss: 0.8340\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [31/125], Loss: 0.6941\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [32/125], Loss: 0.7346\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [33/125], Loss: 0.5910\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [34/125], Loss: 0.7189\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [35/125], Loss: 0.8182\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [36/125], Loss: 0.6312\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [37/125], Loss: 0.6540\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [38/125], Loss: 0.7711\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [39/125], Loss: 0.8391\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [40/125], Loss: 0.6127\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [41/125], Loss: 0.5614\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [42/125], Loss: 0.6557\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [43/125], Loss: 0.9535\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [44/125], Loss: 0.8868\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [45/125], Loss: 0.5273\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [46/125], Loss: 0.5881\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [47/125], Loss: 0.7219\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [48/125], Loss: 0.6908\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [49/125], Loss: 0.6906\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [50/125], Loss: 0.9593\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [51/125], Loss: 1.1133\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [52/125], Loss: 0.7222\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [53/125], Loss: 0.7701\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [54/125], Loss: 0.6752\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [55/125], Loss: 0.8203\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [56/125], Loss: 0.6628\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [57/125], Loss: 0.3741\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [58/125], Loss: 0.6157\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [59/125], Loss: 0.6194\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [60/125], Loss: 0.8241\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [61/125], Loss: 0.5573\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [62/125], Loss: 0.6224\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [63/125], Loss: 0.8630\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [64/125], Loss: 0.4572\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [65/125], Loss: 0.6951\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [66/125], Loss: 0.5772\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [67/125], Loss: 0.6721\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [68/125], Loss: 0.6962\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [69/125], Loss: 0.7854\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [70/125], Loss: 0.6796\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [71/125], Loss: 0.6134\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [72/125], Loss: 1.0229\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [73/125], Loss: 0.7370\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [74/125], Loss: 0.8025\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [75/125], Loss: 0.8426\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [76/125], Loss: 0.5321\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [77/125], Loss: 0.6250\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [78/125], Loss: 0.7535\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [79/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [80/125], Loss: 0.7805\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [81/125], Loss: 0.5405\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [82/125], Loss: 0.5290\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [83/125], Loss: 0.4427\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [84/125], Loss: 0.6794\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [85/125], Loss: 0.4201\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [86/125], Loss: 0.8377\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [87/125], Loss: 0.6141\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [88/125], Loss: 0.8142\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [89/125], Loss: 0.7158\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [90/125], Loss: 0.9621\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [91/125], Loss: 1.0535\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [92/125], Loss: 0.5508\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [93/125], Loss: 0.4834\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [94/125], Loss: 0.5754\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [95/125], Loss: 0.8717\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [96/125], Loss: 0.7563\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [97/125], Loss: 0.5975\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [98/125], Loss: 0.7969\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [99/125], Loss: 0.7805\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [100/125], Loss: 0.7424\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [101/125], Loss: 0.6664\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [102/125], Loss: 0.4628\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [103/125], Loss: 0.4884\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [104/125], Loss: 0.5163\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [105/125], Loss: 0.5586\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [106/125], Loss: 0.9663\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [107/125], Loss: 0.5757\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [108/125], Loss: 0.5215\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [109/125], Loss: 0.6375\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [110/125], Loss: 0.6921\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [111/125], Loss: 0.6517\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [112/125], Loss: 0.5684\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [113/125], Loss: 0.7440\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [114/125], Loss: 0.8862\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [115/125], Loss: 0.6333\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [116/125], Loss: 0.8858\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [117/125], Loss: 0.6532\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [118/125], Loss: 0.5410\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [119/125], Loss: 0.7533\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [120/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [121/125], Loss: 0.8835\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [122/125], Loss: 0.6684\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [123/125], Loss: 0.7068\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [124/125], Loss: 0.8020\n",
      "Decay: Updating learning rate to 0.007999999\n",
      "Epoch [25/60], Step [125/125], Loss: 0.4687\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [1/125], Loss: 0.5937\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [2/125], Loss: 0.4030\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [3/125], Loss: 0.6091\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [4/125], Loss: 0.6223\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [5/125], Loss: 0.9269\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [6/125], Loss: 0.4316\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [7/125], Loss: 0.5049\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [8/125], Loss: 0.4579\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [9/125], Loss: 0.4003\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [10/125], Loss: 0.8107\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [11/125], Loss: 0.6866\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [12/125], Loss: 0.6179\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [13/125], Loss: 0.4917\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [14/125], Loss: 0.7699\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [15/125], Loss: 0.6443\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [16/125], Loss: 0.5316\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [17/125], Loss: 0.9219\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [18/125], Loss: 0.6611\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [19/125], Loss: 0.6475\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [20/125], Loss: 0.5809\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [21/125], Loss: 0.8135\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [22/125], Loss: 0.8921\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [23/125], Loss: 0.6520\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [24/125], Loss: 0.6268\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [25/125], Loss: 0.7442\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [26/125], Loss: 0.7025\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [27/125], Loss: 0.8566\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [28/125], Loss: 0.5919\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [29/125], Loss: 0.5334\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [30/125], Loss: 0.6004\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [31/125], Loss: 1.0293\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [32/125], Loss: 0.5678\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [33/125], Loss: 0.7149\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [34/125], Loss: 0.3502\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [35/125], Loss: 0.8057\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [36/125], Loss: 0.3681\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [37/125], Loss: 0.5572\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [38/125], Loss: 0.6194\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [39/125], Loss: 0.6055\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [40/125], Loss: 0.4924\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [41/125], Loss: 0.5941\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [42/125], Loss: 0.6973\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [43/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [44/125], Loss: 0.4628\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [45/125], Loss: 0.7908\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [46/125], Loss: 0.8156\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [47/125], Loss: 0.7128\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [48/125], Loss: 0.5561\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [49/125], Loss: 0.4684\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [50/125], Loss: 0.7920\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [51/125], Loss: 0.5487\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [52/125], Loss: 0.7199\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [53/125], Loss: 0.4723\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [54/125], Loss: 0.7289\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [55/125], Loss: 0.9871\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [56/125], Loss: 0.7933\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [57/125], Loss: 0.6516\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [58/125], Loss: 0.4776\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [59/125], Loss: 0.6081\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [60/125], Loss: 0.5237\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [61/125], Loss: 0.6439\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [62/125], Loss: 0.4163\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [63/125], Loss: 0.4801\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [64/125], Loss: 0.6846\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [65/125], Loss: 0.7114\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [66/125], Loss: 0.6452\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [67/125], Loss: 0.6502\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [68/125], Loss: 0.5425\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [69/125], Loss: 0.9157\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [70/125], Loss: 0.8891\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [71/125], Loss: 0.7896\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [72/125], Loss: 0.5023\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [73/125], Loss: 0.7604\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [74/125], Loss: 0.4901\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [75/125], Loss: 0.5823\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [76/125], Loss: 0.4882\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [77/125], Loss: 0.7793\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [78/125], Loss: 0.6157\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [79/125], Loss: 0.6781\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [80/125], Loss: 0.6476\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [81/125], Loss: 0.8755\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [82/125], Loss: 0.6454\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [83/125], Loss: 0.5394\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [84/125], Loss: 0.5065\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [85/125], Loss: 0.4691\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [86/125], Loss: 0.6574\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [87/125], Loss: 0.6188\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [88/125], Loss: 0.3677\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [89/125], Loss: 0.7916\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [90/125], Loss: 0.7143\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [91/125], Loss: 0.5442\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [92/125], Loss: 0.4935\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [93/125], Loss: 0.7840\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [94/125], Loss: 0.4964\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [95/125], Loss: 0.6334\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [96/125], Loss: 0.5175\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [97/125], Loss: 0.7053\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [98/125], Loss: 0.9307\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [99/125], Loss: 0.4167\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [100/125], Loss: 0.6572\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [101/125], Loss: 0.6899\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [102/125], Loss: 0.5354\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [103/125], Loss: 0.5937\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [104/125], Loss: 0.6871\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [105/125], Loss: 0.5815\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [106/125], Loss: 0.8415\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [107/125], Loss: 0.4931\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [108/125], Loss: 0.5578\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [109/125], Loss: 0.7337\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [110/125], Loss: 0.6018\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [111/125], Loss: 0.4847\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [112/125], Loss: 0.8642\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [113/125], Loss: 0.5546\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [114/125], Loss: 0.7032\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [115/125], Loss: 0.6578\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [116/125], Loss: 0.7120\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [117/125], Loss: 0.6063\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [118/125], Loss: 0.7335\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [119/125], Loss: 0.6256\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [120/125], Loss: 0.6314\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [121/125], Loss: 0.8546\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [122/125], Loss: 0.8292\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [123/125], Loss: 0.5191\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [124/125], Loss: 0.4596\n",
      "Decay: Updating learning rate to 0.007777776777777779\n",
      "Epoch [26/60], Step [125/125], Loss: 0.4684\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [1/125], Loss: 0.7054\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [2/125], Loss: 0.7671\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [3/125], Loss: 0.5657\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [4/125], Loss: 0.5115\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [5/125], Loss: 0.7061\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [6/125], Loss: 0.6625\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [7/125], Loss: 0.6988\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [8/125], Loss: 0.6733\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [9/125], Loss: 0.8142\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [10/125], Loss: 0.6136\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [11/125], Loss: 0.8907\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [12/125], Loss: 0.8853\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [13/125], Loss: 0.6745\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [14/125], Loss: 0.8417\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [15/125], Loss: 0.5444\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [16/125], Loss: 0.5568\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [17/125], Loss: 0.8200\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [18/125], Loss: 0.5737\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [19/125], Loss: 0.6620\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [20/125], Loss: 0.7110\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [21/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [22/125], Loss: 0.5837\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [23/125], Loss: 0.4286\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [24/125], Loss: 0.9168\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [25/125], Loss: 0.8797\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [26/125], Loss: 0.8821\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [27/125], Loss: 0.6538\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [28/125], Loss: 0.5927\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [29/125], Loss: 0.9131\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [30/125], Loss: 0.7619\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [31/125], Loss: 0.6102\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [32/125], Loss: 0.7607\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [33/125], Loss: 0.7375\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [34/125], Loss: 0.6351\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [35/125], Loss: 0.7691\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [36/125], Loss: 0.5482\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [37/125], Loss: 0.4035\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [38/125], Loss: 0.4776\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [39/125], Loss: 0.7005\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [40/125], Loss: 0.5493\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [41/125], Loss: 0.5819\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [42/125], Loss: 0.6234\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [43/125], Loss: 0.7328\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [44/125], Loss: 0.7593\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [45/125], Loss: 0.6072\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [46/125], Loss: 0.8532\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [47/125], Loss: 0.6421\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [48/125], Loss: 0.6229\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [49/125], Loss: 0.7017\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [50/125], Loss: 0.6857\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [51/125], Loss: 0.7588\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [52/125], Loss: 0.6551\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [53/125], Loss: 0.6016\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [54/125], Loss: 0.8748\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [55/125], Loss: 0.6973\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [56/125], Loss: 0.6874\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [57/125], Loss: 0.6057\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [58/125], Loss: 0.5723\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [59/125], Loss: 0.5549\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [60/125], Loss: 0.8012\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [61/125], Loss: 0.6607\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [62/125], Loss: 0.3611\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [63/125], Loss: 0.6481\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [64/125], Loss: 0.9288\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [65/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [66/125], Loss: 0.8976\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [67/125], Loss: 0.5161\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [68/125], Loss: 0.7327\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [69/125], Loss: 0.6748\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [70/125], Loss: 0.6620\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [71/125], Loss: 0.8316\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [72/125], Loss: 0.9706\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [73/125], Loss: 0.7567\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [74/125], Loss: 0.7410\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [75/125], Loss: 0.7549\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [76/125], Loss: 0.6153\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [77/125], Loss: 0.5192\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [78/125], Loss: 0.8910\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [79/125], Loss: 0.6439\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [80/125], Loss: 0.7142\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [81/125], Loss: 0.5579\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [82/125], Loss: 0.5255\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [83/125], Loss: 0.5169\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [84/125], Loss: 0.5669\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [85/125], Loss: 0.7852\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [86/125], Loss: 0.5172\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [87/125], Loss: 0.5301\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [88/125], Loss: 0.7386\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [89/125], Loss: 0.6830\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [90/125], Loss: 0.5757\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [91/125], Loss: 0.7081\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [92/125], Loss: 0.6209\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [93/125], Loss: 0.8089\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [94/125], Loss: 0.8734\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [95/125], Loss: 0.7472\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [96/125], Loss: 0.8834\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [97/125], Loss: 0.6286\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [98/125], Loss: 0.6479\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [99/125], Loss: 0.6672\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [100/125], Loss: 0.6645\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [101/125], Loss: 0.5082\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [102/125], Loss: 0.7781\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [103/125], Loss: 0.6363\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [104/125], Loss: 0.6366\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [105/125], Loss: 0.7807\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [106/125], Loss: 0.6547\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [107/125], Loss: 0.4779\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [108/125], Loss: 0.5556\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [109/125], Loss: 0.5855\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [110/125], Loss: 0.7498\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [111/125], Loss: 0.7344\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [112/125], Loss: 0.6512\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [113/125], Loss: 0.7159\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [114/125], Loss: 0.6536\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [115/125], Loss: 0.6600\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [116/125], Loss: 0.6945\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [117/125], Loss: 0.5276\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [118/125], Loss: 0.7098\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [119/125], Loss: 0.5113\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [120/125], Loss: 0.5759\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [121/125], Loss: 0.5052\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [122/125], Loss: 0.6053\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [123/125], Loss: 0.6554\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [124/125], Loss: 0.6794\n",
      "Decay: Updating learning rate to 0.007555554555555556\n",
      "Epoch [27/60], Step [125/125], Loss: 0.7333\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [1/125], Loss: 0.8025\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [2/125], Loss: 0.6409\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [3/125], Loss: 0.6230\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [4/125], Loss: 0.7957\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [5/125], Loss: 0.8174\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [6/125], Loss: 0.6288\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [7/125], Loss: 0.8400\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [8/125], Loss: 0.6262\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [9/125], Loss: 0.5380\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [10/125], Loss: 0.5463\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [11/125], Loss: 0.7867\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [12/125], Loss: 0.5605\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [13/125], Loss: 0.6837\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [14/125], Loss: 0.7789\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [15/125], Loss: 0.5487\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [16/125], Loss: 0.6654\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [17/125], Loss: 0.6256\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [18/125], Loss: 0.7157\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [19/125], Loss: 0.5238\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [20/125], Loss: 0.7281\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [21/125], Loss: 0.7221\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [22/125], Loss: 0.4914\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [23/125], Loss: 0.6731\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [24/125], Loss: 0.6884\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [25/125], Loss: 0.7250\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [26/125], Loss: 0.7195\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [27/125], Loss: 0.6990\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [28/125], Loss: 0.4725\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [29/125], Loss: 0.5563\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [30/125], Loss: 0.4172\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [31/125], Loss: 0.6646\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [32/125], Loss: 0.4147\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [33/125], Loss: 0.4995\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [34/125], Loss: 0.6708\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [35/125], Loss: 0.6934\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [36/125], Loss: 0.9058\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [37/125], Loss: 0.3277\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [38/125], Loss: 0.7319\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [39/125], Loss: 0.5235\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [40/125], Loss: 0.5350\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [41/125], Loss: 0.5375\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [42/125], Loss: 0.8572\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [43/125], Loss: 0.6772\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [44/125], Loss: 0.9397\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [45/125], Loss: 0.7847\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [46/125], Loss: 0.7801\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [47/125], Loss: 0.8565\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [48/125], Loss: 0.7898\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [49/125], Loss: 0.6977\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [50/125], Loss: 0.4085\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [51/125], Loss: 0.7912\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [52/125], Loss: 0.4753\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [53/125], Loss: 0.6159\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [54/125], Loss: 0.6182\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [55/125], Loss: 0.7052\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [56/125], Loss: 0.6558\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [57/125], Loss: 0.6670\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [58/125], Loss: 0.5151\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [59/125], Loss: 0.7698\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [60/125], Loss: 0.6710\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [61/125], Loss: 0.7238\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [62/125], Loss: 0.6403\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [63/125], Loss: 0.5463\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [64/125], Loss: 0.7412\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [65/125], Loss: 0.7503\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [66/125], Loss: 0.6014\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [67/125], Loss: 0.6585\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [68/125], Loss: 0.5090\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [69/125], Loss: 1.0846\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [70/125], Loss: 0.6747\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [71/125], Loss: 0.6884\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [72/125], Loss: 0.4785\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [73/125], Loss: 0.5956\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [74/125], Loss: 0.5612\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [75/125], Loss: 0.6336\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [76/125], Loss: 0.6096\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [77/125], Loss: 0.6840\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [78/125], Loss: 0.3874\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [79/125], Loss: 0.5528\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [80/125], Loss: 0.5389\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [81/125], Loss: 0.7844\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [82/125], Loss: 0.5704\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [83/125], Loss: 0.9707\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [84/125], Loss: 0.7366\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [85/125], Loss: 0.6658\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [86/125], Loss: 0.6173\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [87/125], Loss: 0.5640\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [88/125], Loss: 0.5470\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [89/125], Loss: 0.8510\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [90/125], Loss: 0.6714\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [91/125], Loss: 0.6431\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [92/125], Loss: 0.4737\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [93/125], Loss: 0.5972\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [94/125], Loss: 0.6728\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [95/125], Loss: 0.7792\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [96/125], Loss: 0.6605\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [97/125], Loss: 1.0812\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [98/125], Loss: 0.6003\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [99/125], Loss: 0.7026\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [100/125], Loss: 0.6204\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [101/125], Loss: 0.7204\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [102/125], Loss: 0.4672\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [103/125], Loss: 0.7758\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [104/125], Loss: 0.6640\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [105/125], Loss: 0.5728\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [106/125], Loss: 0.5817\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [107/125], Loss: 0.6864\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [108/125], Loss: 0.4669\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [109/125], Loss: 0.6474\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [110/125], Loss: 0.4441\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [111/125], Loss: 0.5688\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [112/125], Loss: 0.9145\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [113/125], Loss: 0.5522\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [114/125], Loss: 0.7050\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [115/125], Loss: 0.5299\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [116/125], Loss: 0.6105\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [117/125], Loss: 0.6753\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [118/125], Loss: 0.6033\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [119/125], Loss: 0.6166\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [120/125], Loss: 0.6694\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [121/125], Loss: 0.7251\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [122/125], Loss: 0.7715\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [123/125], Loss: 0.6541\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [124/125], Loss: 0.4146\n",
      "Decay: Updating learning rate to 0.007333332333333334\n",
      "Epoch [28/60], Step [125/125], Loss: 0.8275\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [1/125], Loss: 0.7186\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [2/125], Loss: 0.7024\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [3/125], Loss: 0.6119\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [4/125], Loss: 0.7246\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [5/125], Loss: 0.7258\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [6/125], Loss: 0.6432\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [7/125], Loss: 0.6238\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [8/125], Loss: 0.5036\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [9/125], Loss: 0.6701\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [10/125], Loss: 0.7154\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [11/125], Loss: 0.6831\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [12/125], Loss: 0.7232\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [13/125], Loss: 0.9783\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [14/125], Loss: 0.7214\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [15/125], Loss: 0.5902\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [16/125], Loss: 0.8369\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [17/125], Loss: 0.7027\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [18/125], Loss: 0.5599\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [19/125], Loss: 0.9430\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [20/125], Loss: 0.7451\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [21/125], Loss: 0.6999\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [22/125], Loss: 0.6131\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [23/125], Loss: 0.4742\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [24/125], Loss: 0.5429\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [25/125], Loss: 0.6947\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [26/125], Loss: 0.8035\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [27/125], Loss: 0.6407\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [28/125], Loss: 0.6404\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [29/125], Loss: 0.5791\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [30/125], Loss: 0.4266\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [31/125], Loss: 0.8945\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [32/125], Loss: 0.7119\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [33/125], Loss: 0.7199\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [34/125], Loss: 0.7684\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [35/125], Loss: 0.6179\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [36/125], Loss: 0.5068\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [37/125], Loss: 0.5527\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [38/125], Loss: 0.4574\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [39/125], Loss: 0.5862\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [40/125], Loss: 0.5654\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [41/125], Loss: 0.5765\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [42/125], Loss: 0.5864\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [43/125], Loss: 0.8640\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [44/125], Loss: 0.5920\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [45/125], Loss: 0.9259\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [46/125], Loss: 0.6073\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [47/125], Loss: 0.6571\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [48/125], Loss: 0.5506\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [49/125], Loss: 0.5394\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [50/125], Loss: 0.7759\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [51/125], Loss: 0.8132\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [52/125], Loss: 0.6540\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [53/125], Loss: 0.5522\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [54/125], Loss: 0.8572\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [55/125], Loss: 0.8778\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [56/125], Loss: 0.6896\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [57/125], Loss: 0.5667\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [58/125], Loss: 0.7084\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [59/125], Loss: 0.4655\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [60/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [61/125], Loss: 0.4741\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [62/125], Loss: 0.6583\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [63/125], Loss: 0.6174\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [64/125], Loss: 0.7528\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [65/125], Loss: 0.5562\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [66/125], Loss: 0.5505\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [67/125], Loss: 0.6086\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [68/125], Loss: 0.7834\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [69/125], Loss: 0.5195\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [70/125], Loss: 0.7278\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [71/125], Loss: 0.6510\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [72/125], Loss: 0.3553\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [73/125], Loss: 0.4603\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [74/125], Loss: 0.7377\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [75/125], Loss: 1.0306\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [76/125], Loss: 0.6886\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [77/125], Loss: 0.5344\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [78/125], Loss: 0.7222\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [79/125], Loss: 0.7897\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [80/125], Loss: 0.6354\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [81/125], Loss: 0.5406\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [82/125], Loss: 0.7957\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [83/125], Loss: 0.5662\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [84/125], Loss: 0.7229\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [85/125], Loss: 0.6198\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [86/125], Loss: 0.5315\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [87/125], Loss: 0.7056\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [88/125], Loss: 0.4359\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [89/125], Loss: 0.4411\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [90/125], Loss: 0.7519\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [91/125], Loss: 0.8956\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [92/125], Loss: 0.4493\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [93/125], Loss: 0.5519\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [94/125], Loss: 0.8756\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [95/125], Loss: 0.7149\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [96/125], Loss: 0.7482\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [97/125], Loss: 0.6757\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [98/125], Loss: 0.7909\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [99/125], Loss: 0.5433\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [100/125], Loss: 0.4310\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [101/125], Loss: 0.7507\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [102/125], Loss: 0.5776\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [103/125], Loss: 0.6372\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [104/125], Loss: 0.7025\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [105/125], Loss: 0.6845\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [106/125], Loss: 0.6413\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [107/125], Loss: 0.6918\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [108/125], Loss: 0.6952\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [109/125], Loss: 0.5584\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [110/125], Loss: 0.4895\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [111/125], Loss: 0.8413\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [112/125], Loss: 0.8145\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [113/125], Loss: 0.5892\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [114/125], Loss: 0.5433\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [115/125], Loss: 0.9551\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [116/125], Loss: 0.6261\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [117/125], Loss: 0.3921\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [118/125], Loss: 0.5741\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [119/125], Loss: 0.5395\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [120/125], Loss: 0.5946\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [121/125], Loss: 0.5318\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [122/125], Loss: 0.4515\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [123/125], Loss: 0.5211\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [124/125], Loss: 0.8386\n",
      "Decay: Updating learning rate to 0.007111110111111112\n",
      "Epoch [29/60], Step [125/125], Loss: 0.6765\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [1/125], Loss: 0.6123\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [2/125], Loss: 0.6145\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [3/125], Loss: 0.4926\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [4/125], Loss: 0.4954\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [5/125], Loss: 0.7172\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [6/125], Loss: 0.7621\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [7/125], Loss: 0.7252\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [8/125], Loss: 0.7729\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [9/125], Loss: 0.8783\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [10/125], Loss: 0.7197\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [11/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [12/125], Loss: 0.5413\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [13/125], Loss: 0.8500\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [14/125], Loss: 0.5429\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [15/125], Loss: 0.7546\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [16/125], Loss: 0.6266\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [17/125], Loss: 0.6948\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [18/125], Loss: 0.6532\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [19/125], Loss: 0.8701\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [20/125], Loss: 0.5876\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [21/125], Loss: 0.3602\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [22/125], Loss: 0.9020\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [23/125], Loss: 0.6941\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [24/125], Loss: 0.9151\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [25/125], Loss: 0.6831\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [26/125], Loss: 0.7369\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [27/125], Loss: 0.6943\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [28/125], Loss: 0.5298\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [29/125], Loss: 0.5655\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [30/125], Loss: 0.3562\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [31/125], Loss: 0.5297\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [32/125], Loss: 0.6751\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [33/125], Loss: 0.9227\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [34/125], Loss: 0.6868\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [35/125], Loss: 0.6230\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [36/125], Loss: 0.6772\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [37/125], Loss: 0.6052\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [38/125], Loss: 0.9697\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [39/125], Loss: 0.4196\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [40/125], Loss: 0.5348\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [41/125], Loss: 0.7174\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [42/125], Loss: 0.8168\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [43/125], Loss: 0.4586\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [44/125], Loss: 0.7873\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [45/125], Loss: 0.6884\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [46/125], Loss: 0.5393\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [47/125], Loss: 0.5436\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [48/125], Loss: 0.7300\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [49/125], Loss: 0.6012\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [50/125], Loss: 0.4811\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [51/125], Loss: 0.7591\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [52/125], Loss: 0.6132\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [53/125], Loss: 0.8717\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [54/125], Loss: 0.7583\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [55/125], Loss: 0.7577\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [56/125], Loss: 0.7649\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [57/125], Loss: 0.4081\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [58/125], Loss: 0.6699\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [59/125], Loss: 0.8271\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [60/125], Loss: 0.8786\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [61/125], Loss: 0.6728\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [62/125], Loss: 0.5896\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [63/125], Loss: 0.4523\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [64/125], Loss: 0.7442\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [65/125], Loss: 0.7885\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [66/125], Loss: 0.9265\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [67/125], Loss: 0.8585\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [68/125], Loss: 0.7340\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [69/125], Loss: 0.5933\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [70/125], Loss: 0.7179\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [71/125], Loss: 0.5622\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [72/125], Loss: 0.7311\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [73/125], Loss: 0.4648\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [74/125], Loss: 0.4667\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [75/125], Loss: 0.6295\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [76/125], Loss: 0.5349\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [77/125], Loss: 0.6995\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [78/125], Loss: 0.6045\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [79/125], Loss: 0.4692\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [80/125], Loss: 0.6891\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [81/125], Loss: 0.5302\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [82/125], Loss: 0.8630\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [83/125], Loss: 0.6239\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [84/125], Loss: 0.9057\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [85/125], Loss: 0.7445\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [86/125], Loss: 0.6368\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [87/125], Loss: 0.5458\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [88/125], Loss: 0.4875\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [89/125], Loss: 0.6827\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [90/125], Loss: 0.8797\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [91/125], Loss: 0.4386\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [92/125], Loss: 0.7315\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [93/125], Loss: 0.6230\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [94/125], Loss: 0.7773\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [95/125], Loss: 0.9924\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [96/125], Loss: 0.9632\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [97/125], Loss: 0.6037\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [98/125], Loss: 0.7416\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [99/125], Loss: 0.7426\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [100/125], Loss: 0.5565\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [101/125], Loss: 0.7362\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [102/125], Loss: 0.6760\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [103/125], Loss: 0.6673\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [104/125], Loss: 0.5697\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [105/125], Loss: 0.5118\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [106/125], Loss: 0.8594\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [107/125], Loss: 0.8670\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [108/125], Loss: 0.7646\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [109/125], Loss: 0.4333\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [110/125], Loss: 0.7017\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [111/125], Loss: 0.7385\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [112/125], Loss: 0.6959\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [113/125], Loss: 0.6727\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [114/125], Loss: 0.6898\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [115/125], Loss: 0.6392\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [116/125], Loss: 0.5825\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [117/125], Loss: 0.6424\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [118/125], Loss: 0.8005\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [119/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [120/125], Loss: 0.7495\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [121/125], Loss: 0.7131\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [122/125], Loss: 0.3657\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [123/125], Loss: 0.8188\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [124/125], Loss: 0.5402\n",
      "Decay: Updating learning rate to 0.0068888878888888885\n",
      "Epoch [30/60], Step [125/125], Loss: 0.7755\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [1/125], Loss: 0.6449\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [2/125], Loss: 0.5523\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [3/125], Loss: 0.6669\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [4/125], Loss: 0.5835\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [5/125], Loss: 0.5020\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [6/125], Loss: 0.4382\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [7/125], Loss: 0.5420\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [8/125], Loss: 0.8012\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [9/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [10/125], Loss: 0.6635\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [11/125], Loss: 0.7521\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [12/125], Loss: 0.6292\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [13/125], Loss: 0.8563\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [14/125], Loss: 0.4400\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [15/125], Loss: 0.7472\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [16/125], Loss: 0.8382\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [17/125], Loss: 0.3964\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [18/125], Loss: 0.7549\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [19/125], Loss: 0.5346\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [20/125], Loss: 0.9180\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [21/125], Loss: 0.6512\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [22/125], Loss: 0.8319\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [23/125], Loss: 0.5752\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [24/125], Loss: 0.7874\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [25/125], Loss: 0.8434\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [26/125], Loss: 0.8407\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [27/125], Loss: 0.9120\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [28/125], Loss: 0.5574\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [29/125], Loss: 0.6406\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [30/125], Loss: 0.7477\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [31/125], Loss: 0.5306\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [32/125], Loss: 0.5993\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [33/125], Loss: 0.6861\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [34/125], Loss: 0.5005\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [35/125], Loss: 0.8666\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [36/125], Loss: 0.8320\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [37/125], Loss: 0.5702\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [38/125], Loss: 0.8322\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [39/125], Loss: 0.5515\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [40/125], Loss: 0.6512\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [41/125], Loss: 0.4731\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [42/125], Loss: 0.6437\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [43/125], Loss: 0.6356\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [44/125], Loss: 0.5984\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [45/125], Loss: 0.6170\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [46/125], Loss: 0.4722\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [47/125], Loss: 0.6437\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [48/125], Loss: 1.0148\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [49/125], Loss: 0.5826\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [50/125], Loss: 0.5827\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [51/125], Loss: 0.7732\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [52/125], Loss: 0.6657\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [53/125], Loss: 0.5720\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [54/125], Loss: 0.5180\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [55/125], Loss: 0.8014\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [56/125], Loss: 0.6817\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [57/125], Loss: 0.5942\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [58/125], Loss: 0.5774\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [59/125], Loss: 0.5549\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [60/125], Loss: 0.5562\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [61/125], Loss: 0.5342\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [62/125], Loss: 0.5405\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [63/125], Loss: 0.8556\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [64/125], Loss: 0.4459\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [65/125], Loss: 0.7065\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [66/125], Loss: 0.7046\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [67/125], Loss: 0.8714\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [68/125], Loss: 0.6246\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [69/125], Loss: 0.4752\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [70/125], Loss: 0.5417\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [71/125], Loss: 0.5908\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [72/125], Loss: 0.7060\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [73/125], Loss: 0.6292\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [74/125], Loss: 0.5572\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [75/125], Loss: 0.6048\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [76/125], Loss: 0.3915\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [77/125], Loss: 0.5142\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [78/125], Loss: 0.5971\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [79/125], Loss: 0.7611\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [80/125], Loss: 0.7444\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [81/125], Loss: 0.8576\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [82/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [83/125], Loss: 0.6128\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [84/125], Loss: 0.5294\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [85/125], Loss: 0.9734\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [86/125], Loss: 0.5545\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [87/125], Loss: 0.7196\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [88/125], Loss: 0.5758\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [89/125], Loss: 0.4849\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [90/125], Loss: 0.8399\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [91/125], Loss: 0.4073\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [92/125], Loss: 0.7864\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [93/125], Loss: 0.6156\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [94/125], Loss: 0.5361\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [95/125], Loss: 0.6793\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [96/125], Loss: 0.6549\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [97/125], Loss: 0.6234\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [98/125], Loss: 0.4629\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [99/125], Loss: 0.3287\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [100/125], Loss: 0.6778\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [101/125], Loss: 0.9139\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [102/125], Loss: 0.3175\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [103/125], Loss: 0.6852\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [104/125], Loss: 0.4749\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [105/125], Loss: 0.5238\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [106/125], Loss: 0.4608\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [107/125], Loss: 0.6751\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [108/125], Loss: 0.6048\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [109/125], Loss: 0.6480\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [110/125], Loss: 0.5681\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [111/125], Loss: 0.6058\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [112/125], Loss: 0.4663\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [113/125], Loss: 0.5376\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [114/125], Loss: 0.8806\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [115/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [116/125], Loss: 0.7454\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [117/125], Loss: 0.4736\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [118/125], Loss: 0.7816\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [119/125], Loss: 0.5118\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [120/125], Loss: 0.6561\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [121/125], Loss: 0.8375\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [122/125], Loss: 0.7716\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [123/125], Loss: 0.6654\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [124/125], Loss: 0.5547\n",
      "Decay: Updating learning rate to 0.006666665666666667\n",
      "Epoch [31/60], Step [125/125], Loss: 0.4269\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [1/125], Loss: 0.6730\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [2/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [3/125], Loss: 0.5458\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [4/125], Loss: 0.5337\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [5/125], Loss: 0.7607\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [6/125], Loss: 0.4997\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [7/125], Loss: 0.7284\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [8/125], Loss: 0.5396\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [9/125], Loss: 0.5973\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [10/125], Loss: 0.7095\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [11/125], Loss: 0.6670\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [12/125], Loss: 0.8272\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [13/125], Loss: 0.6401\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [14/125], Loss: 0.5048\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [15/125], Loss: 0.5659\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [16/125], Loss: 0.5635\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [17/125], Loss: 0.7031\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [18/125], Loss: 0.3848\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [19/125], Loss: 0.6447\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [20/125], Loss: 0.6166\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [21/125], Loss: 0.5331\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [22/125], Loss: 0.7968\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [23/125], Loss: 0.8028\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [24/125], Loss: 0.4310\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [25/125], Loss: 0.6506\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [26/125], Loss: 0.8851\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [27/125], Loss: 0.5792\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [28/125], Loss: 0.5665\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [29/125], Loss: 0.7070\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [30/125], Loss: 0.5534\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [31/125], Loss: 0.5529\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [32/125], Loss: 0.6014\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [33/125], Loss: 0.4040\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [34/125], Loss: 0.8375\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [35/125], Loss: 0.5970\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [36/125], Loss: 0.5500\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [37/125], Loss: 0.8674\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [38/125], Loss: 0.7218\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [39/125], Loss: 0.5973\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [40/125], Loss: 0.7165\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [41/125], Loss: 0.8382\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [42/125], Loss: 0.7223\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [43/125], Loss: 0.7100\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [44/125], Loss: 0.7285\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [45/125], Loss: 0.6225\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [46/125], Loss: 0.5849\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [47/125], Loss: 0.6551\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [48/125], Loss: 0.6782\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [49/125], Loss: 0.6566\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [50/125], Loss: 0.8484\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [51/125], Loss: 0.6754\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [52/125], Loss: 1.0441\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [53/125], Loss: 0.6461\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [54/125], Loss: 0.5467\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [55/125], Loss: 0.7911\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [56/125], Loss: 0.6651\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [57/125], Loss: 0.5511\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [58/125], Loss: 0.4589\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [59/125], Loss: 0.6727\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [60/125], Loss: 0.6186\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [61/125], Loss: 0.5543\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [62/125], Loss: 0.3822\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [63/125], Loss: 0.4561\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [64/125], Loss: 0.5666\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [65/125], Loss: 0.5916\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [66/125], Loss: 0.5778\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [67/125], Loss: 0.4949\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [68/125], Loss: 0.7997\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [69/125], Loss: 0.7338\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [70/125], Loss: 0.6525\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [71/125], Loss: 0.7879\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [72/125], Loss: 0.6612\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [73/125], Loss: 0.6981\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [74/125], Loss: 0.7028\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [75/125], Loss: 0.4089\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [76/125], Loss: 0.5279\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [77/125], Loss: 0.5531\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [78/125], Loss: 0.7219\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [79/125], Loss: 0.5987\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [80/125], Loss: 0.6233\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [81/125], Loss: 0.4419\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [82/125], Loss: 0.5902\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [83/125], Loss: 0.3677\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [84/125], Loss: 0.8060\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [85/125], Loss: 0.7413\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [86/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [87/125], Loss: 0.4416\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [88/125], Loss: 0.5551\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [89/125], Loss: 0.7347\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [90/125], Loss: 0.6506\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [91/125], Loss: 0.6284\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [92/125], Loss: 0.8551\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [93/125], Loss: 0.7650\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [94/125], Loss: 0.7380\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [95/125], Loss: 0.5813\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [96/125], Loss: 0.6506\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [97/125], Loss: 0.4030\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [98/125], Loss: 0.8723\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [99/125], Loss: 0.5125\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [100/125], Loss: 0.9298\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [101/125], Loss: 0.5549\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [102/125], Loss: 0.5311\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [103/125], Loss: 0.6237\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [104/125], Loss: 0.8532\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [105/125], Loss: 0.9014\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [106/125], Loss: 0.8763\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [107/125], Loss: 0.5544\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [108/125], Loss: 0.5229\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [109/125], Loss: 0.7191\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [110/125], Loss: 0.7176\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [111/125], Loss: 0.7516\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [112/125], Loss: 0.7876\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [113/125], Loss: 0.5203\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [114/125], Loss: 0.6568\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [115/125], Loss: 0.6861\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [116/125], Loss: 0.4105\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [117/125], Loss: 0.6298\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [118/125], Loss: 0.7864\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [119/125], Loss: 0.6826\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [120/125], Loss: 0.7158\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [121/125], Loss: 0.8186\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [122/125], Loss: 0.5585\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [123/125], Loss: 0.5801\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [124/125], Loss: 0.5527\n",
      "Decay: Updating learning rate to 0.006444443444444444\n",
      "Epoch [32/60], Step [125/125], Loss: 0.5284\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [1/125], Loss: 0.5910\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [2/125], Loss: 0.6039\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [3/125], Loss: 0.7760\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [4/125], Loss: 0.9770\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [5/125], Loss: 0.5248\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [6/125], Loss: 0.4654\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [7/125], Loss: 0.7733\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [8/125], Loss: 0.4745\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [9/125], Loss: 0.6346\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [10/125], Loss: 0.6507\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [11/125], Loss: 0.5244\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [12/125], Loss: 0.7195\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [13/125], Loss: 0.8623\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [14/125], Loss: 0.6473\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [15/125], Loss: 0.5744\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [16/125], Loss: 0.4642\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [17/125], Loss: 0.6745\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [18/125], Loss: 0.7120\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [19/125], Loss: 0.8828\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [20/125], Loss: 0.5002\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [21/125], Loss: 0.8493\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [22/125], Loss: 0.7001\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [23/125], Loss: 0.7677\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [24/125], Loss: 0.7708\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [25/125], Loss: 0.5869\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [26/125], Loss: 0.7298\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [27/125], Loss: 0.5707\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [28/125], Loss: 0.5408\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [29/125], Loss: 0.7462\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [30/125], Loss: 0.5548\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [31/125], Loss: 0.5822\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [32/125], Loss: 0.4390\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [33/125], Loss: 0.5317\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [34/125], Loss: 0.5224\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [35/125], Loss: 0.7132\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [36/125], Loss: 0.4787\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [37/125], Loss: 0.4557\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [38/125], Loss: 0.6443\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [39/125], Loss: 0.4776\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [40/125], Loss: 0.8393\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [41/125], Loss: 0.4813\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [42/125], Loss: 0.4974\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [43/125], Loss: 0.8716\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [44/125], Loss: 0.7201\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [45/125], Loss: 0.4832\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [46/125], Loss: 0.6798\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [47/125], Loss: 0.6807\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [48/125], Loss: 0.7303\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [49/125], Loss: 0.6534\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [50/125], Loss: 0.8346\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [51/125], Loss: 1.0039\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [52/125], Loss: 0.6565\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [53/125], Loss: 0.5568\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [54/125], Loss: 0.6895\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [55/125], Loss: 0.5045\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [56/125], Loss: 0.8194\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [57/125], Loss: 0.5203\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [58/125], Loss: 0.4716\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [59/125], Loss: 0.6329\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [60/125], Loss: 0.6552\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [61/125], Loss: 0.5592\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [62/125], Loss: 0.7574\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [63/125], Loss: 0.5205\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [64/125], Loss: 0.6539\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [65/125], Loss: 0.6905\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [66/125], Loss: 0.6989\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [67/125], Loss: 0.7016\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [68/125], Loss: 0.5653\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [69/125], Loss: 0.4622\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [70/125], Loss: 0.6421\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [71/125], Loss: 0.5736\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [72/125], Loss: 0.7814\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [73/125], Loss: 0.9671\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [74/125], Loss: 0.5509\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [75/125], Loss: 0.5204\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [76/125], Loss: 0.5066\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [77/125], Loss: 0.5841\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [78/125], Loss: 0.5101\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [79/125], Loss: 0.6214\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [80/125], Loss: 0.3735\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [81/125], Loss: 0.5921\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [82/125], Loss: 0.3863\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [83/125], Loss: 0.7208\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [84/125], Loss: 0.3988\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [85/125], Loss: 0.6412\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [86/125], Loss: 0.6184\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [87/125], Loss: 0.8970\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [88/125], Loss: 0.5434\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [89/125], Loss: 0.5165\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [90/125], Loss: 0.8263\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [91/125], Loss: 0.5180\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [92/125], Loss: 0.4301\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [93/125], Loss: 0.7113\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [94/125], Loss: 0.9327\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [95/125], Loss: 0.7046\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [96/125], Loss: 0.3997\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [97/125], Loss: 0.6954\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [98/125], Loss: 0.6923\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [99/125], Loss: 0.6713\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [100/125], Loss: 0.4942\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [101/125], Loss: 0.8506\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [102/125], Loss: 0.6380\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [103/125], Loss: 0.3956\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [104/125], Loss: 0.7853\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [105/125], Loss: 0.7864\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [106/125], Loss: 0.7264\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [107/125], Loss: 0.7586\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [108/125], Loss: 0.5754\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [109/125], Loss: 0.6978\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [110/125], Loss: 0.4897\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [111/125], Loss: 0.7237\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [112/125], Loss: 0.6641\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [113/125], Loss: 0.8064\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [114/125], Loss: 0.6895\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [115/125], Loss: 1.0594\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [116/125], Loss: 0.7546\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [117/125], Loss: 0.7459\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [118/125], Loss: 0.7271\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [119/125], Loss: 0.4441\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [120/125], Loss: 0.2448\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [121/125], Loss: 0.5472\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [122/125], Loss: 0.6477\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [123/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [124/125], Loss: 0.7907\n",
      "Decay: Updating learning rate to 0.0062222212222222215\n",
      "Epoch [33/60], Step [125/125], Loss: 0.7849\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [1/125], Loss: 0.8776\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [2/125], Loss: 0.4815\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [3/125], Loss: 0.6764\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [4/125], Loss: 0.6325\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [5/125], Loss: 0.5662\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [6/125], Loss: 0.6345\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [7/125], Loss: 0.5262\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [8/125], Loss: 0.4734\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [9/125], Loss: 0.6855\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [10/125], Loss: 0.5997\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [11/125], Loss: 0.4978\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [12/125], Loss: 0.5734\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [13/125], Loss: 0.6877\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [14/125], Loss: 0.6482\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [15/125], Loss: 0.7759\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [16/125], Loss: 0.7801\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [17/125], Loss: 0.7732\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [18/125], Loss: 0.9673\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [19/125], Loss: 0.7509\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [20/125], Loss: 0.4902\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [21/125], Loss: 0.7078\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [22/125], Loss: 0.7699\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [23/125], Loss: 0.5531\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [24/125], Loss: 0.5948\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [25/125], Loss: 0.6269\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [26/125], Loss: 0.6725\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [27/125], Loss: 0.6066\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [28/125], Loss: 0.5391\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [29/125], Loss: 0.4144\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [30/125], Loss: 0.8102\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [31/125], Loss: 0.4677\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [32/125], Loss: 0.4151\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [33/125], Loss: 0.6393\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [34/125], Loss: 0.4174\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [35/125], Loss: 0.6200\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [36/125], Loss: 0.5294\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [37/125], Loss: 1.0019\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [38/125], Loss: 0.6210\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [39/125], Loss: 0.6074\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [40/125], Loss: 0.9098\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [41/125], Loss: 0.4664\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [42/125], Loss: 0.9810\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [43/125], Loss: 0.4441\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [44/125], Loss: 0.4348\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [45/125], Loss: 0.6770\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [46/125], Loss: 0.5348\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [47/125], Loss: 0.4749\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [48/125], Loss: 0.8016\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [49/125], Loss: 0.3278\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [50/125], Loss: 0.6699\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [51/125], Loss: 0.5048\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [52/125], Loss: 0.7885\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [53/125], Loss: 0.5081\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [54/125], Loss: 0.6659\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [55/125], Loss: 0.4622\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [56/125], Loss: 0.5750\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [57/125], Loss: 0.5847\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [58/125], Loss: 0.4427\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [59/125], Loss: 0.4983\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [60/125], Loss: 0.4539\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [61/125], Loss: 0.4521\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [62/125], Loss: 0.5234\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [63/125], Loss: 0.4281\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [64/125], Loss: 0.5872\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [65/125], Loss: 0.6711\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [66/125], Loss: 0.7251\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [67/125], Loss: 0.5536\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [68/125], Loss: 0.8075\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [69/125], Loss: 0.6155\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [70/125], Loss: 0.8199\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [71/125], Loss: 0.8210\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [72/125], Loss: 0.6340\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [73/125], Loss: 0.5707\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [74/125], Loss: 0.4766\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [75/125], Loss: 0.5918\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [76/125], Loss: 0.5404\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [77/125], Loss: 0.6796\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [78/125], Loss: 0.6725\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [79/125], Loss: 0.5150\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [80/125], Loss: 0.6380\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [81/125], Loss: 0.4721\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [82/125], Loss: 0.7737\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [83/125], Loss: 0.3139\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [84/125], Loss: 0.3811\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [85/125], Loss: 0.8247\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [86/125], Loss: 0.6312\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [87/125], Loss: 0.5570\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [88/125], Loss: 0.8500\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [89/125], Loss: 0.6025\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [90/125], Loss: 0.4812\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [91/125], Loss: 0.6475\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [92/125], Loss: 0.4791\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [93/125], Loss: 0.7475\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [94/125], Loss: 0.6710\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [95/125], Loss: 0.6249\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [96/125], Loss: 0.4575\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [97/125], Loss: 0.5549\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [98/125], Loss: 0.7763\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [99/125], Loss: 0.5614\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [100/125], Loss: 0.7332\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [101/125], Loss: 0.5938\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [102/125], Loss: 0.5647\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [103/125], Loss: 0.7455\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [104/125], Loss: 0.6359\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [105/125], Loss: 0.6107\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [106/125], Loss: 0.7772\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [107/125], Loss: 0.4697\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [108/125], Loss: 0.6861\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [109/125], Loss: 0.7036\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [110/125], Loss: 0.6042\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [111/125], Loss: 0.6194\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [112/125], Loss: 0.7285\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [113/125], Loss: 0.5423\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [114/125], Loss: 0.6583\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [115/125], Loss: 0.6037\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [116/125], Loss: 0.6978\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [117/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [118/125], Loss: 0.5131\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [119/125], Loss: 0.5553\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [120/125], Loss: 0.5926\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [121/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [122/125], Loss: 0.4983\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [123/125], Loss: 0.7154\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [124/125], Loss: 0.6851\n",
      "Decay: Updating learning rate to 0.005999999000000001\n",
      "Epoch [34/60], Step [125/125], Loss: 0.8963\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [1/125], Loss: 0.5422\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [2/125], Loss: 0.4572\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [3/125], Loss: 0.6027\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [4/125], Loss: 0.5244\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [5/125], Loss: 0.7968\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [6/125], Loss: 0.7224\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [7/125], Loss: 0.7300\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [8/125], Loss: 0.7993\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [9/125], Loss: 0.5452\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [10/125], Loss: 0.4872\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [11/125], Loss: 0.8389\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [12/125], Loss: 0.5400\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [13/125], Loss: 0.7909\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [14/125], Loss: 0.7517\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [15/125], Loss: 0.4637\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [16/125], Loss: 0.5957\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [17/125], Loss: 0.5408\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [18/125], Loss: 0.6105\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [19/125], Loss: 0.7912\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [20/125], Loss: 0.8123\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [21/125], Loss: 0.6967\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [22/125], Loss: 0.7885\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [23/125], Loss: 0.4884\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [24/125], Loss: 0.5571\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [25/125], Loss: 0.6132\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [26/125], Loss: 0.6243\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [27/125], Loss: 0.5888\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [28/125], Loss: 0.5759\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [29/125], Loss: 0.7067\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [30/125], Loss: 0.5012\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [31/125], Loss: 0.6677\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [32/125], Loss: 0.7916\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [33/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [34/125], Loss: 0.5452\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [35/125], Loss: 0.4543\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [36/125], Loss: 0.5748\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [37/125], Loss: 0.5553\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [38/125], Loss: 0.8562\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [39/125], Loss: 0.6375\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [40/125], Loss: 0.4087\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [41/125], Loss: 0.5405\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [42/125], Loss: 0.5174\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [43/125], Loss: 0.5741\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [44/125], Loss: 0.5985\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [45/125], Loss: 1.0284\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [46/125], Loss: 0.7240\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [47/125], Loss: 0.4684\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [48/125], Loss: 0.6285\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [49/125], Loss: 0.7286\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [50/125], Loss: 0.5602\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [51/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [52/125], Loss: 0.7247\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [53/125], Loss: 0.8524\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [54/125], Loss: 0.5298\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [55/125], Loss: 0.5935\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [56/125], Loss: 0.4477\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [57/125], Loss: 0.5391\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [58/125], Loss: 0.8229\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [59/125], Loss: 0.8004\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [60/125], Loss: 0.6227\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [61/125], Loss: 0.8593\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [62/125], Loss: 0.5125\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [63/125], Loss: 0.5872\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [64/125], Loss: 0.6499\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [65/125], Loss: 0.6300\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [66/125], Loss: 0.5159\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [67/125], Loss: 0.5542\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [68/125], Loss: 0.4357\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [69/125], Loss: 0.5174\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [70/125], Loss: 0.4850\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [71/125], Loss: 0.4482\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [72/125], Loss: 0.4728\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [73/125], Loss: 0.4011\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [74/125], Loss: 0.5877\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [75/125], Loss: 0.5154\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [76/125], Loss: 0.5894\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [77/125], Loss: 0.6696\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [78/125], Loss: 0.7793\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [79/125], Loss: 0.9426\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [80/125], Loss: 0.6171\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [81/125], Loss: 0.4840\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [82/125], Loss: 0.6904\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [83/125], Loss: 0.3885\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [84/125], Loss: 0.7310\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [85/125], Loss: 0.6112\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [86/125], Loss: 0.6192\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [87/125], Loss: 0.6798\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [88/125], Loss: 0.5189\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [89/125], Loss: 0.7772\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [90/125], Loss: 0.6215\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [91/125], Loss: 0.6340\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [92/125], Loss: 0.7520\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [93/125], Loss: 0.6453\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [94/125], Loss: 0.5317\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [95/125], Loss: 0.4448\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [96/125], Loss: 0.4011\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [97/125], Loss: 0.5362\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [98/125], Loss: 0.7330\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [99/125], Loss: 0.5116\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [100/125], Loss: 0.6527\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [101/125], Loss: 0.6066\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [102/125], Loss: 0.4724\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [103/125], Loss: 0.6278\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [104/125], Loss: 0.9088\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [105/125], Loss: 0.6145\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [106/125], Loss: 0.9238\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [107/125], Loss: 0.4567\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [108/125], Loss: 0.7048\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [109/125], Loss: 0.5449\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [110/125], Loss: 0.9201\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [111/125], Loss: 0.6794\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [112/125], Loss: 0.7709\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [113/125], Loss: 0.4609\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [114/125], Loss: 0.7701\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [115/125], Loss: 0.7509\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [116/125], Loss: 0.7009\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [117/125], Loss: 0.4400\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [118/125], Loss: 0.7941\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [119/125], Loss: 0.7613\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [120/125], Loss: 0.6093\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [121/125], Loss: 0.4125\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [122/125], Loss: 0.8118\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [123/125], Loss: 0.6070\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [124/125], Loss: 0.5890\n",
      "Decay: Updating learning rate to 0.005777776777777778\n",
      "Epoch [35/60], Step [125/125], Loss: 0.5922\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [1/125], Loss: 0.6031\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [2/125], Loss: 0.5948\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [3/125], Loss: 0.7191\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [4/125], Loss: 0.5676\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [5/125], Loss: 0.6640\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [6/125], Loss: 0.7121\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [7/125], Loss: 0.8108\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [8/125], Loss: 0.6138\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [9/125], Loss: 0.4769\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [10/125], Loss: 0.6269\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [11/125], Loss: 0.3653\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [12/125], Loss: 0.6424\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [13/125], Loss: 0.5423\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [14/125], Loss: 0.6123\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [15/125], Loss: 0.5294\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [16/125], Loss: 0.8056\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [17/125], Loss: 0.7545\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [18/125], Loss: 0.5221\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [19/125], Loss: 0.6571\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [20/125], Loss: 0.8117\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [21/125], Loss: 0.7062\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [22/125], Loss: 0.6689\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [23/125], Loss: 0.4985\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [24/125], Loss: 0.7814\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [25/125], Loss: 0.6485\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [26/125], Loss: 0.7225\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [27/125], Loss: 0.6017\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [28/125], Loss: 0.8185\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [29/125], Loss: 0.5292\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [30/125], Loss: 0.5307\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [31/125], Loss: 0.5437\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [32/125], Loss: 0.6353\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [33/125], Loss: 0.4870\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [34/125], Loss: 0.6452\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [35/125], Loss: 0.5905\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [36/125], Loss: 0.4622\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [37/125], Loss: 0.6684\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [38/125], Loss: 0.5854\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [39/125], Loss: 0.7665\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [40/125], Loss: 0.4378\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [41/125], Loss: 0.6821\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [42/125], Loss: 0.6486\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [43/125], Loss: 0.5462\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [44/125], Loss: 0.6824\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [45/125], Loss: 0.5593\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [46/125], Loss: 0.5072\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [47/125], Loss: 0.7029\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [48/125], Loss: 0.6229\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [49/125], Loss: 0.6692\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [50/125], Loss: 0.8006\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [51/125], Loss: 0.6190\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [52/125], Loss: 0.6265\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [53/125], Loss: 1.0519\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [54/125], Loss: 0.8474\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [55/125], Loss: 0.6840\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [56/125], Loss: 0.5559\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [57/125], Loss: 0.4684\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [58/125], Loss: 0.5962\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [59/125], Loss: 0.7794\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [60/125], Loss: 0.5233\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [61/125], Loss: 0.7987\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [62/125], Loss: 0.6471\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [63/125], Loss: 0.7896\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [64/125], Loss: 0.6811\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [65/125], Loss: 0.6688\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [66/125], Loss: 0.6453\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [67/125], Loss: 0.4625\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [68/125], Loss: 0.5666\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [69/125], Loss: 0.5572\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [70/125], Loss: 0.4510\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [71/125], Loss: 0.3955\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [72/125], Loss: 0.3996\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [73/125], Loss: 0.5442\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [74/125], Loss: 0.7334\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [75/125], Loss: 0.6128\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [76/125], Loss: 0.4422\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [77/125], Loss: 0.7774\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [78/125], Loss: 0.4808\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [79/125], Loss: 0.7266\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [80/125], Loss: 0.6539\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [81/125], Loss: 0.5075\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [82/125], Loss: 0.6514\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [83/125], Loss: 0.6649\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [84/125], Loss: 0.7607\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [85/125], Loss: 0.5119\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [86/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [87/125], Loss: 0.4730\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [88/125], Loss: 0.3726\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [89/125], Loss: 1.0172\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [90/125], Loss: 0.5288\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [91/125], Loss: 0.6920\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [92/125], Loss: 0.6527\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [93/125], Loss: 0.7413\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [94/125], Loss: 0.7122\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [95/125], Loss: 1.0557\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [96/125], Loss: 0.5481\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [97/125], Loss: 0.6754\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [98/125], Loss: 0.6443\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [99/125], Loss: 0.4740\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [100/125], Loss: 0.9044\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [101/125], Loss: 0.5506\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [102/125], Loss: 0.6364\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [103/125], Loss: 0.4727\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [104/125], Loss: 0.8137\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [105/125], Loss: 0.6843\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [106/125], Loss: 0.5098\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [107/125], Loss: 0.6315\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [108/125], Loss: 0.7354\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [109/125], Loss: 0.4272\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [110/125], Loss: 0.4995\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [111/125], Loss: 0.3191\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [112/125], Loss: 0.5281\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [113/125], Loss: 0.8522\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [114/125], Loss: 0.3762\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [115/125], Loss: 0.5393\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [116/125], Loss: 0.5893\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [117/125], Loss: 0.5115\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [118/125], Loss: 0.5281\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [119/125], Loss: 0.6655\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [120/125], Loss: 0.5377\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [121/125], Loss: 0.7379\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [122/125], Loss: 0.6410\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [123/125], Loss: 0.7743\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [124/125], Loss: 0.5850\n",
      "Decay: Updating learning rate to 0.005555554555555555\n",
      "Epoch [36/60], Step [125/125], Loss: 0.6501\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [1/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [2/125], Loss: 0.4849\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [3/125], Loss: 0.6629\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [4/125], Loss: 0.7277\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [5/125], Loss: 0.4743\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [6/125], Loss: 0.6102\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [7/125], Loss: 0.4011\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [8/125], Loss: 0.5075\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [9/125], Loss: 0.4574\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [10/125], Loss: 0.8349\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [11/125], Loss: 0.5400\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [12/125], Loss: 0.6876\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [13/125], Loss: 0.5421\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [14/125], Loss: 0.6918\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [15/125], Loss: 1.1031\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [16/125], Loss: 0.5490\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [17/125], Loss: 0.5132\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [18/125], Loss: 0.6068\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [19/125], Loss: 0.4775\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [20/125], Loss: 0.5135\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [21/125], Loss: 0.5154\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [22/125], Loss: 0.8250\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [23/125], Loss: 0.8596\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [24/125], Loss: 0.5823\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [25/125], Loss: 0.7276\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [26/125], Loss: 0.5800\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [27/125], Loss: 0.7430\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [28/125], Loss: 0.7462\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [29/125], Loss: 0.7357\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [30/125], Loss: 0.5492\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [31/125], Loss: 0.5241\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [32/125], Loss: 0.5022\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [33/125], Loss: 0.5426\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [34/125], Loss: 0.7250\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [35/125], Loss: 0.7963\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [36/125], Loss: 0.7816\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [37/125], Loss: 0.4721\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [38/125], Loss: 0.7697\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [39/125], Loss: 0.7023\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [40/125], Loss: 0.5033\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [41/125], Loss: 0.6644\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [42/125], Loss: 0.4615\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [43/125], Loss: 0.7830\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [44/125], Loss: 0.5575\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [45/125], Loss: 0.7822\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [46/125], Loss: 0.9095\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [47/125], Loss: 0.6658\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [48/125], Loss: 0.5923\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [49/125], Loss: 0.6895\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [50/125], Loss: 0.5492\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [51/125], Loss: 0.6994\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [52/125], Loss: 0.7875\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [53/125], Loss: 0.7429\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [54/125], Loss: 1.2497\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [55/125], Loss: 0.6742\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [56/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [57/125], Loss: 0.5812\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [58/125], Loss: 0.4770\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [59/125], Loss: 0.6503\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [60/125], Loss: 0.6783\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [61/125], Loss: 0.5534\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [62/125], Loss: 0.5219\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [63/125], Loss: 0.5667\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [64/125], Loss: 0.7572\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [65/125], Loss: 0.5885\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [66/125], Loss: 0.6209\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [67/125], Loss: 0.6074\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [68/125], Loss: 0.4357\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [69/125], Loss: 0.6873\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [70/125], Loss: 0.4869\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [71/125], Loss: 0.5771\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [72/125], Loss: 0.8187\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [73/125], Loss: 0.5609\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [74/125], Loss: 0.4268\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [75/125], Loss: 0.6140\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [76/125], Loss: 0.6082\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [77/125], Loss: 0.4848\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [78/125], Loss: 0.4937\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [79/125], Loss: 0.3968\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [80/125], Loss: 0.8309\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [81/125], Loss: 0.5290\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [82/125], Loss: 0.5062\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [83/125], Loss: 0.4753\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [84/125], Loss: 0.7085\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [85/125], Loss: 0.5718\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [86/125], Loss: 0.9013\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [87/125], Loss: 0.6303\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [88/125], Loss: 0.8668\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [89/125], Loss: 0.7611\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [90/125], Loss: 0.8033\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [91/125], Loss: 0.6075\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [92/125], Loss: 0.5099\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [93/125], Loss: 0.6346\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [94/125], Loss: 0.6244\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [95/125], Loss: 0.6839\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [96/125], Loss: 0.7329\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [97/125], Loss: 0.9300\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [98/125], Loss: 0.6541\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [99/125], Loss: 0.4266\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [100/125], Loss: 0.5746\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [101/125], Loss: 0.6996\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [102/125], Loss: 0.6341\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [103/125], Loss: 0.4214\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [104/125], Loss: 0.6845\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [105/125], Loss: 0.5356\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [106/125], Loss: 0.7034\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [107/125], Loss: 0.5042\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [108/125], Loss: 0.6145\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [109/125], Loss: 0.3960\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [110/125], Loss: 0.8652\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [111/125], Loss: 0.5834\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [112/125], Loss: 0.5013\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [113/125], Loss: 0.7220\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [114/125], Loss: 0.5086\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [115/125], Loss: 0.5047\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [116/125], Loss: 0.8188\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [117/125], Loss: 0.4981\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [118/125], Loss: 0.5261\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [119/125], Loss: 0.4963\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [120/125], Loss: 0.6047\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [121/125], Loss: 0.5472\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [122/125], Loss: 0.5874\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [123/125], Loss: 0.5748\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [124/125], Loss: 0.5708\n",
      "Decay: Updating learning rate to 0.005333332333333334\n",
      "Epoch [37/60], Step [125/125], Loss: 0.6589\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [1/125], Loss: 0.4484\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [2/125], Loss: 0.7582\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [3/125], Loss: 0.5735\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [4/125], Loss: 0.5083\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [5/125], Loss: 0.5170\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [6/125], Loss: 0.6121\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [7/125], Loss: 0.7033\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [8/125], Loss: 0.5818\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [9/125], Loss: 0.5498\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [10/125], Loss: 0.7624\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [11/125], Loss: 0.7416\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [12/125], Loss: 0.7166\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [13/125], Loss: 0.5995\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [14/125], Loss: 0.6651\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [15/125], Loss: 0.6444\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [16/125], Loss: 0.5365\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [17/125], Loss: 1.0083\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [18/125], Loss: 0.6718\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [19/125], Loss: 0.4785\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [20/125], Loss: 0.7491\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [21/125], Loss: 0.4504\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [22/125], Loss: 0.5445\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [23/125], Loss: 0.5427\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [24/125], Loss: 0.8108\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [25/125], Loss: 0.6740\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [26/125], Loss: 0.6797\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [27/125], Loss: 0.5691\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [28/125], Loss: 0.7191\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [29/125], Loss: 0.4962\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [30/125], Loss: 0.8122\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [31/125], Loss: 0.5043\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [32/125], Loss: 0.6583\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [33/125], Loss: 0.5925\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [34/125], Loss: 0.4664\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [35/125], Loss: 0.4094\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [36/125], Loss: 0.5429\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [37/125], Loss: 0.8151\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [38/125], Loss: 0.6765\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [39/125], Loss: 0.4900\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [40/125], Loss: 0.5946\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [41/125], Loss: 0.5758\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [42/125], Loss: 0.5878\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [43/125], Loss: 0.7945\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [44/125], Loss: 0.5828\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [45/125], Loss: 0.7227\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [46/125], Loss: 0.7818\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [47/125], Loss: 0.5059\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [48/125], Loss: 0.7173\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [49/125], Loss: 0.7344\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [50/125], Loss: 0.6866\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [51/125], Loss: 0.8368\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [52/125], Loss: 0.6010\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [53/125], Loss: 0.6054\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [54/125], Loss: 0.6458\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [55/125], Loss: 0.6309\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [56/125], Loss: 0.4987\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [57/125], Loss: 0.6024\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [58/125], Loss: 0.6419\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [59/125], Loss: 0.7991\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [60/125], Loss: 0.6114\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [61/125], Loss: 0.5207\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [62/125], Loss: 0.4864\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [63/125], Loss: 0.4489\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [64/125], Loss: 0.6684\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [65/125], Loss: 0.6517\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [66/125], Loss: 0.7500\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [67/125], Loss: 0.4666\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [68/125], Loss: 0.5865\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [69/125], Loss: 0.6660\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [70/125], Loss: 1.0072\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [71/125], Loss: 0.6418\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [72/125], Loss: 0.8776\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [73/125], Loss: 0.9149\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [74/125], Loss: 0.5710\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [75/125], Loss: 0.5196\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [76/125], Loss: 0.6800\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [77/125], Loss: 0.4815\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [78/125], Loss: 0.4879\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [79/125], Loss: 0.4369\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [80/125], Loss: 0.5367\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [81/125], Loss: 0.8367\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [82/125], Loss: 0.6289\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [83/125], Loss: 0.5797\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [84/125], Loss: 0.6521\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [85/125], Loss: 0.5135\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [86/125], Loss: 0.5511\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [87/125], Loss: 0.6723\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [88/125], Loss: 0.5384\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [89/125], Loss: 0.5291\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [90/125], Loss: 0.8754\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [91/125], Loss: 0.4863\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [92/125], Loss: 0.6860\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [93/125], Loss: 0.5701\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [94/125], Loss: 0.3807\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [95/125], Loss: 0.6792\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [96/125], Loss: 0.5750\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [97/125], Loss: 0.6222\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [98/125], Loss: 0.8003\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [99/125], Loss: 0.6008\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [100/125], Loss: 0.3883\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [101/125], Loss: 0.5818\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [102/125], Loss: 0.4794\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [103/125], Loss: 0.6721\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [104/125], Loss: 0.5393\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [105/125], Loss: 0.4904\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [106/125], Loss: 0.9026\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [107/125], Loss: 0.4525\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [108/125], Loss: 0.4514\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [109/125], Loss: 0.6434\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [110/125], Loss: 0.6214\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [111/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [112/125], Loss: 0.4730\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [113/125], Loss: 0.5936\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [114/125], Loss: 0.6777\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [115/125], Loss: 0.7600\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [116/125], Loss: 0.6411\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [117/125], Loss: 0.7744\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [118/125], Loss: 0.6242\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [119/125], Loss: 0.5541\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [120/125], Loss: 0.6552\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [121/125], Loss: 0.7162\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [122/125], Loss: 0.8887\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [123/125], Loss: 0.8118\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [124/125], Loss: 0.7311\n",
      "Decay: Updating learning rate to 0.005111110111111111\n",
      "Epoch [38/60], Step [125/125], Loss: 0.4250\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [1/125], Loss: 0.5690\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [2/125], Loss: 0.6887\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [3/125], Loss: 0.5623\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [4/125], Loss: 0.6192\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [5/125], Loss: 0.8449\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [6/125], Loss: 0.5422\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [7/125], Loss: 0.7007\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [8/125], Loss: 0.6819\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [9/125], Loss: 0.7201\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [10/125], Loss: 0.6400\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [11/125], Loss: 0.7653\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [12/125], Loss: 0.7787\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [13/125], Loss: 0.6198\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [14/125], Loss: 0.5801\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [15/125], Loss: 0.7749\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [16/125], Loss: 0.6192\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [17/125], Loss: 0.7531\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [18/125], Loss: 0.5447\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [19/125], Loss: 0.6439\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [20/125], Loss: 0.6250\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [21/125], Loss: 0.5622\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [22/125], Loss: 0.5517\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [23/125], Loss: 0.4701\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [24/125], Loss: 0.6252\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [25/125], Loss: 0.7627\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [26/125], Loss: 0.5648\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [27/125], Loss: 0.5793\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [28/125], Loss: 0.8704\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [29/125], Loss: 0.3589\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [30/125], Loss: 0.7268\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [31/125], Loss: 0.7176\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [32/125], Loss: 0.7256\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [33/125], Loss: 0.5782\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [34/125], Loss: 0.7722\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [35/125], Loss: 0.4830\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [36/125], Loss: 0.5827\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [37/125], Loss: 0.6023\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [38/125], Loss: 0.6074\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [39/125], Loss: 0.4206\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [40/125], Loss: 0.4593\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [41/125], Loss: 0.5383\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [42/125], Loss: 0.7073\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [43/125], Loss: 0.6285\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [44/125], Loss: 0.6223\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [45/125], Loss: 0.5721\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [46/125], Loss: 0.7361\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [47/125], Loss: 0.5282\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [48/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [49/125], Loss: 0.6816\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [50/125], Loss: 0.6826\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [51/125], Loss: 0.6312\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [52/125], Loss: 0.5126\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [53/125], Loss: 0.6471\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [54/125], Loss: 0.5231\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [55/125], Loss: 0.6038\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [56/125], Loss: 0.5120\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [57/125], Loss: 0.5175\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [58/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [59/125], Loss: 0.5887\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [60/125], Loss: 0.6934\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [61/125], Loss: 0.6354\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [62/125], Loss: 0.8217\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [63/125], Loss: 0.6324\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [64/125], Loss: 0.9328\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [65/125], Loss: 0.5882\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [66/125], Loss: 0.7830\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [67/125], Loss: 0.5542\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [68/125], Loss: 0.6187\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [69/125], Loss: 0.5677\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [70/125], Loss: 0.6793\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [71/125], Loss: 0.5020\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [72/125], Loss: 0.4341\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [73/125], Loss: 0.6536\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [74/125], Loss: 0.5531\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [75/125], Loss: 0.7272\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [76/125], Loss: 0.9192\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [77/125], Loss: 0.7043\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [78/125], Loss: 0.6851\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [79/125], Loss: 0.6495\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [80/125], Loss: 0.5264\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [81/125], Loss: 0.4094\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [82/125], Loss: 0.4442\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [83/125], Loss: 0.4994\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [84/125], Loss: 0.5562\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [85/125], Loss: 0.5464\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [86/125], Loss: 0.7068\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [87/125], Loss: 0.6519\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [88/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [89/125], Loss: 0.7664\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [90/125], Loss: 0.4875\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [91/125], Loss: 0.5124\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [92/125], Loss: 0.7397\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [93/125], Loss: 0.5646\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [94/125], Loss: 0.8043\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [95/125], Loss: 0.8100\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [96/125], Loss: 0.7044\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [97/125], Loss: 0.6242\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [98/125], Loss: 0.6522\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [99/125], Loss: 0.7776\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [100/125], Loss: 0.4578\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [101/125], Loss: 0.8637\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [102/125], Loss: 0.5098\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [103/125], Loss: 0.7525\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [104/125], Loss: 0.6545\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [105/125], Loss: 0.5745\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [106/125], Loss: 0.5668\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [107/125], Loss: 0.5434\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [108/125], Loss: 0.5120\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [109/125], Loss: 0.4485\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [110/125], Loss: 0.4539\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [111/125], Loss: 0.5620\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [112/125], Loss: 0.9012\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [113/125], Loss: 0.5029\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [114/125], Loss: 0.3895\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [115/125], Loss: 0.6959\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [116/125], Loss: 0.5135\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [117/125], Loss: 0.5584\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [118/125], Loss: 0.5998\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [119/125], Loss: 0.7466\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [120/125], Loss: 0.4925\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [121/125], Loss: 0.4581\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [122/125], Loss: 0.4867\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [123/125], Loss: 0.5422\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [124/125], Loss: 0.7333\n",
      "Decay: Updating learning rate to 0.00488888788888889\n",
      "Epoch [39/60], Step [125/125], Loss: 0.4945\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [1/125], Loss: 0.6965\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [2/125], Loss: 0.5150\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [3/125], Loss: 0.4890\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [4/125], Loss: 0.6675\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [5/125], Loss: 0.4411\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [6/125], Loss: 0.3896\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [7/125], Loss: 0.5066\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [8/125], Loss: 0.6651\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [9/125], Loss: 0.4009\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [10/125], Loss: 0.5432\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [11/125], Loss: 0.5278\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [12/125], Loss: 0.4045\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [13/125], Loss: 0.6376\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [14/125], Loss: 0.7183\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [15/125], Loss: 0.4831\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [16/125], Loss: 0.6805\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [17/125], Loss: 0.4229\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [18/125], Loss: 0.7542\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [19/125], Loss: 0.8132\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [20/125], Loss: 0.6716\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [21/125], Loss: 0.7752\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [22/125], Loss: 0.4877\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [23/125], Loss: 0.5927\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [24/125], Loss: 0.7342\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [25/125], Loss: 0.5000\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [26/125], Loss: 0.4406\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [27/125], Loss: 0.5602\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [28/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [29/125], Loss: 0.5193\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [30/125], Loss: 0.5259\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [31/125], Loss: 0.5761\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [32/125], Loss: 0.5234\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [33/125], Loss: 0.5346\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [34/125], Loss: 0.6560\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [35/125], Loss: 0.5258\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [36/125], Loss: 0.3988\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [37/125], Loss: 0.5197\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [38/125], Loss: 0.4975\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [39/125], Loss: 0.7293\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [40/125], Loss: 0.6305\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [41/125], Loss: 0.5845\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [42/125], Loss: 0.6068\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [43/125], Loss: 0.6274\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [44/125], Loss: 0.5244\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [45/125], Loss: 0.5560\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [46/125], Loss: 0.5107\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [47/125], Loss: 0.8167\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [48/125], Loss: 0.4409\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [49/125], Loss: 0.7083\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [50/125], Loss: 0.4477\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [51/125], Loss: 0.5448\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [52/125], Loss: 0.5686\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [53/125], Loss: 0.6011\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [54/125], Loss: 0.7122\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [55/125], Loss: 0.7068\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [56/125], Loss: 0.5438\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [57/125], Loss: 0.6156\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [58/125], Loss: 0.6626\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [59/125], Loss: 0.6178\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [60/125], Loss: 0.5007\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [61/125], Loss: 0.8402\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [62/125], Loss: 0.5388\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [63/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [64/125], Loss: 0.5186\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [65/125], Loss: 0.3776\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [66/125], Loss: 0.8980\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [67/125], Loss: 0.5723\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [68/125], Loss: 0.5461\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [69/125], Loss: 0.6212\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [70/125], Loss: 0.5584\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [71/125], Loss: 0.4300\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [72/125], Loss: 0.8339\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [73/125], Loss: 0.4967\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [74/125], Loss: 0.6437\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [75/125], Loss: 0.7061\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [76/125], Loss: 0.5462\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [77/125], Loss: 0.5142\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [78/125], Loss: 0.5152\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [79/125], Loss: 0.8612\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [80/125], Loss: 0.5433\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [81/125], Loss: 0.4427\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [82/125], Loss: 0.5672\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [83/125], Loss: 0.5130\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [84/125], Loss: 0.6133\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [85/125], Loss: 0.5860\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [86/125], Loss: 0.5858\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [87/125], Loss: 0.5268\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [88/125], Loss: 0.7276\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [89/125], Loss: 0.8335\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [90/125], Loss: 0.5837\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [91/125], Loss: 0.5763\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [92/125], Loss: 0.4599\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [93/125], Loss: 0.7025\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [94/125], Loss: 0.4715\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [95/125], Loss: 0.5818\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [96/125], Loss: 0.7474\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [97/125], Loss: 0.4825\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [98/125], Loss: 0.6784\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [99/125], Loss: 0.6896\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [100/125], Loss: 0.5587\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [101/125], Loss: 0.5645\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [102/125], Loss: 0.7377\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [103/125], Loss: 0.6112\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [104/125], Loss: 0.6624\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [105/125], Loss: 0.7076\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [106/125], Loss: 0.6167\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [107/125], Loss: 0.5408\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [108/125], Loss: 0.4880\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [109/125], Loss: 0.8344\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [110/125], Loss: 0.6860\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [111/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [112/125], Loss: 0.4095\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [113/125], Loss: 0.7390\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [114/125], Loss: 0.4635\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [115/125], Loss: 0.7894\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [116/125], Loss: 0.5469\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [117/125], Loss: 0.6222\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [118/125], Loss: 0.6675\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [119/125], Loss: 0.5689\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [120/125], Loss: 0.5176\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [121/125], Loss: 0.4365\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [122/125], Loss: 0.6539\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [123/125], Loss: 0.5827\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [124/125], Loss: 0.5848\n",
      "Decay: Updating learning rate to 0.004666665666666668\n",
      "Epoch [40/60], Step [125/125], Loss: 0.3902\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [1/125], Loss: 0.6384\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [2/125], Loss: 0.4576\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [3/125], Loss: 0.4359\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [4/125], Loss: 0.5557\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [5/125], Loss: 0.5926\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [6/125], Loss: 0.4927\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [7/125], Loss: 0.5561\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [8/125], Loss: 0.4933\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [9/125], Loss: 0.8241\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [10/125], Loss: 0.4433\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [11/125], Loss: 0.5669\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [12/125], Loss: 0.6081\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [13/125], Loss: 0.6553\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [14/125], Loss: 0.6785\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [15/125], Loss: 0.5015\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [16/125], Loss: 0.6296\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [17/125], Loss: 0.7021\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [18/125], Loss: 0.7838\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [19/125], Loss: 0.5550\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [20/125], Loss: 0.5107\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [21/125], Loss: 0.8054\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [22/125], Loss: 0.8089\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [23/125], Loss: 0.8341\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [24/125], Loss: 0.6497\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [25/125], Loss: 0.4682\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [26/125], Loss: 0.6221\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [27/125], Loss: 0.5772\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [28/125], Loss: 0.4935\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [29/125], Loss: 0.6461\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [30/125], Loss: 0.6714\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [31/125], Loss: 0.6870\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [32/125], Loss: 0.4944\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [33/125], Loss: 0.4896\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [34/125], Loss: 0.6181\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [35/125], Loss: 0.9157\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [36/125], Loss: 0.4175\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [37/125], Loss: 0.6608\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [38/125], Loss: 0.7489\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [39/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [40/125], Loss: 0.4216\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [41/125], Loss: 0.7598\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [42/125], Loss: 0.4954\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [43/125], Loss: 0.4575\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [44/125], Loss: 0.6878\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [45/125], Loss: 0.5315\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [46/125], Loss: 0.5288\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [47/125], Loss: 0.5957\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [48/125], Loss: 0.5895\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [49/125], Loss: 0.9226\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [50/125], Loss: 0.7717\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [51/125], Loss: 0.6030\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [52/125], Loss: 0.4973\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [53/125], Loss: 0.6618\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [54/125], Loss: 0.6844\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [55/125], Loss: 0.8089\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [56/125], Loss: 0.4851\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [57/125], Loss: 0.9170\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [58/125], Loss: 0.6598\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [59/125], Loss: 0.6205\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [60/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [61/125], Loss: 0.9349\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [62/125], Loss: 0.8269\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [63/125], Loss: 0.4833\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [64/125], Loss: 0.7409\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [65/125], Loss: 0.8578\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [66/125], Loss: 0.9775\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [67/125], Loss: 0.5664\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [68/125], Loss: 0.5462\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [69/125], Loss: 0.4773\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [70/125], Loss: 0.7084\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [71/125], Loss: 0.7542\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [72/125], Loss: 0.4546\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [73/125], Loss: 0.8726\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [74/125], Loss: 0.5794\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [75/125], Loss: 1.0828\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [76/125], Loss: 0.4419\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [77/125], Loss: 0.7660\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [78/125], Loss: 0.6465\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [79/125], Loss: 0.5490\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [80/125], Loss: 0.7036\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [81/125], Loss: 0.4998\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [82/125], Loss: 0.5018\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [83/125], Loss: 0.5350\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [84/125], Loss: 0.7686\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [85/125], Loss: 0.6672\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [86/125], Loss: 0.6744\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [87/125], Loss: 0.5980\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [88/125], Loss: 0.5956\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [89/125], Loss: 0.4884\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [90/125], Loss: 0.5623\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [91/125], Loss: 0.4005\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [92/125], Loss: 0.4110\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [93/125], Loss: 0.3528\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [94/125], Loss: 0.5599\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [95/125], Loss: 0.5967\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [96/125], Loss: 0.6956\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [97/125], Loss: 0.5728\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [98/125], Loss: 0.7552\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [99/125], Loss: 0.6843\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [100/125], Loss: 0.4857\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [101/125], Loss: 0.6340\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [102/125], Loss: 0.5584\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [103/125], Loss: 0.5269\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [104/125], Loss: 0.7243\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [105/125], Loss: 0.7668\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [106/125], Loss: 0.6357\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [107/125], Loss: 0.4615\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [108/125], Loss: 0.7016\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [109/125], Loss: 0.5493\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [110/125], Loss: 0.5491\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [111/125], Loss: 0.3516\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [112/125], Loss: 0.4737\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [113/125], Loss: 0.3493\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [114/125], Loss: 0.6177\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [115/125], Loss: 0.4913\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [116/125], Loss: 0.6956\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [117/125], Loss: 0.7932\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [118/125], Loss: 0.9669\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [119/125], Loss: 0.8247\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [120/125], Loss: 0.5220\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [121/125], Loss: 0.5166\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [122/125], Loss: 0.9677\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [123/125], Loss: 0.7544\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [124/125], Loss: 0.5299\n",
      "Decay: Updating learning rate to 0.004444443444444445\n",
      "Epoch [41/60], Step [125/125], Loss: 0.6371\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [1/125], Loss: 0.4163\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [2/125], Loss: 0.8594\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [3/125], Loss: 0.6123\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [4/125], Loss: 0.5732\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [5/125], Loss: 0.6947\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [6/125], Loss: 0.5482\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [7/125], Loss: 0.6118\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [8/125], Loss: 0.6301\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [9/125], Loss: 0.5924\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [10/125], Loss: 0.4233\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [11/125], Loss: 0.5733\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [12/125], Loss: 0.5229\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [13/125], Loss: 0.5677\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [14/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [15/125], Loss: 0.5436\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [16/125], Loss: 0.4296\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [17/125], Loss: 0.4858\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [18/125], Loss: 0.6801\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [19/125], Loss: 0.7022\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [20/125], Loss: 0.5860\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [21/125], Loss: 0.7181\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [22/125], Loss: 0.4619\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [23/125], Loss: 0.6245\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [24/125], Loss: 0.5990\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [25/125], Loss: 0.5671\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [26/125], Loss: 0.3071\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [27/125], Loss: 0.6923\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [28/125], Loss: 0.6862\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [29/125], Loss: 0.3762\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [30/125], Loss: 0.7432\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [31/125], Loss: 0.5864\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [32/125], Loss: 0.6242\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [33/125], Loss: 0.6990\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [34/125], Loss: 0.7652\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [35/125], Loss: 0.4600\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [36/125], Loss: 0.5783\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [37/125], Loss: 0.5473\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [38/125], Loss: 0.5792\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [39/125], Loss: 0.6076\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [40/125], Loss: 0.6160\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [41/125], Loss: 0.6365\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [42/125], Loss: 0.4280\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [43/125], Loss: 0.5279\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [44/125], Loss: 0.6145\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [45/125], Loss: 0.4383\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [46/125], Loss: 0.4826\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [47/125], Loss: 0.6179\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [48/125], Loss: 0.6474\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [49/125], Loss: 0.2683\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [50/125], Loss: 0.6518\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [51/125], Loss: 0.6532\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [52/125], Loss: 0.6642\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [53/125], Loss: 0.4855\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [54/125], Loss: 0.6287\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [55/125], Loss: 0.6574\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [56/125], Loss: 0.6477\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [57/125], Loss: 0.4195\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [58/125], Loss: 0.4696\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [59/125], Loss: 0.7353\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [60/125], Loss: 0.5203\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [61/125], Loss: 0.4794\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [62/125], Loss: 0.5854\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [63/125], Loss: 0.7732\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [64/125], Loss: 0.5912\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [65/125], Loss: 0.7895\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [66/125], Loss: 0.5880\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [67/125], Loss: 0.5332\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [68/125], Loss: 0.4092\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [69/125], Loss: 0.4781\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [70/125], Loss: 0.7682\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [71/125], Loss: 0.4719\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [72/125], Loss: 0.3517\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [73/125], Loss: 0.5869\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [74/125], Loss: 0.3953\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [75/125], Loss: 0.4447\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [76/125], Loss: 0.6551\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [77/125], Loss: 0.4201\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [78/125], Loss: 0.6972\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [79/125], Loss: 0.5362\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [80/125], Loss: 0.5377\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [81/125], Loss: 0.4899\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [82/125], Loss: 0.6409\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [83/125], Loss: 0.3718\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [84/125], Loss: 0.6629\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [85/125], Loss: 0.5770\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [86/125], Loss: 0.4895\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [87/125], Loss: 0.6200\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [88/125], Loss: 0.5320\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [89/125], Loss: 0.6127\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [90/125], Loss: 0.4989\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [91/125], Loss: 0.6536\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [92/125], Loss: 0.6938\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [93/125], Loss: 0.8379\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [94/125], Loss: 0.4814\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [95/125], Loss: 0.4731\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [96/125], Loss: 0.4758\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [97/125], Loss: 0.7385\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [98/125], Loss: 0.6027\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [99/125], Loss: 0.4486\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [100/125], Loss: 0.6426\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [101/125], Loss: 0.7206\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [102/125], Loss: 0.7767\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [103/125], Loss: 0.5291\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [104/125], Loss: 0.5002\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [105/125], Loss: 0.7442\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [106/125], Loss: 0.8581\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [107/125], Loss: 0.5787\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [108/125], Loss: 0.5654\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [109/125], Loss: 0.4657\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [110/125], Loss: 0.5900\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [111/125], Loss: 0.4456\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [112/125], Loss: 0.5154\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [113/125], Loss: 0.4206\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [114/125], Loss: 0.7026\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [115/125], Loss: 0.5944\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [116/125], Loss: 0.5271\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [117/125], Loss: 0.7296\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [118/125], Loss: 0.4307\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [119/125], Loss: 0.5153\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [120/125], Loss: 0.8337\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [121/125], Loss: 0.7188\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [122/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [123/125], Loss: 0.5115\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [124/125], Loss: 0.5048\n",
      "Decay: Updating learning rate to 0.004222221222222223\n",
      "Epoch [42/60], Step [125/125], Loss: 0.4316\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [1/125], Loss: 0.4902\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [2/125], Loss: 0.6202\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [3/125], Loss: 0.5114\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [4/125], Loss: 0.6140\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [5/125], Loss: 0.4202\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [6/125], Loss: 0.6481\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [7/125], Loss: 0.6425\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [8/125], Loss: 0.3993\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [9/125], Loss: 0.7157\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [10/125], Loss: 0.7753\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [11/125], Loss: 0.5906\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [12/125], Loss: 0.5305\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [13/125], Loss: 0.5038\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [14/125], Loss: 0.6614\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [15/125], Loss: 0.8026\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [16/125], Loss: 0.8180\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [17/125], Loss: 0.5930\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [18/125], Loss: 0.6086\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [19/125], Loss: 0.7568\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [20/125], Loss: 0.6074\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [21/125], Loss: 0.6573\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [22/125], Loss: 0.5883\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [23/125], Loss: 0.4972\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [24/125], Loss: 0.5585\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [25/125], Loss: 0.8644\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [26/125], Loss: 0.5531\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [27/125], Loss: 0.6260\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [28/125], Loss: 0.5539\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [29/125], Loss: 0.4632\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [30/125], Loss: 0.6064\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [31/125], Loss: 0.6828\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [32/125], Loss: 0.6529\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [33/125], Loss: 0.4491\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [34/125], Loss: 0.6601\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [35/125], Loss: 0.5435\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [36/125], Loss: 0.5320\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [37/125], Loss: 0.7068\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [38/125], Loss: 0.6704\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [39/125], Loss: 0.8320\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [40/125], Loss: 0.5168\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [41/125], Loss: 0.8402\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [42/125], Loss: 0.8195\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [43/125], Loss: 0.7390\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [44/125], Loss: 0.7528\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [45/125], Loss: 0.5499\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [46/125], Loss: 0.6497\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [47/125], Loss: 0.8169\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [48/125], Loss: 0.8311\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [49/125], Loss: 0.4935\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [50/125], Loss: 0.8116\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [51/125], Loss: 0.5478\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [52/125], Loss: 0.5671\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [53/125], Loss: 0.4993\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [54/125], Loss: 0.5363\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [55/125], Loss: 0.7209\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [56/125], Loss: 0.5071\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [57/125], Loss: 0.7675\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [58/125], Loss: 0.6736\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [59/125], Loss: 0.6019\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [60/125], Loss: 0.5034\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [61/125], Loss: 0.4173\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [62/125], Loss: 0.5444\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [63/125], Loss: 0.6665\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [64/125], Loss: 0.5948\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [65/125], Loss: 0.4047\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [66/125], Loss: 0.5425\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [67/125], Loss: 0.7051\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [68/125], Loss: 0.3871\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [69/125], Loss: 0.5705\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [70/125], Loss: 0.7375\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [71/125], Loss: 0.4727\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [72/125], Loss: 0.6240\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [73/125], Loss: 0.5637\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [74/125], Loss: 0.4054\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [75/125], Loss: 0.6893\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [76/125], Loss: 0.3229\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [77/125], Loss: 0.5541\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [78/125], Loss: 0.9403\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [79/125], Loss: 0.7963\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [80/125], Loss: 0.4639\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [81/125], Loss: 0.5343\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [82/125], Loss: 0.5795\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [83/125], Loss: 0.5006\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [84/125], Loss: 0.7449\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [85/125], Loss: 0.4607\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [86/125], Loss: 0.6183\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [87/125], Loss: 0.6703\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [88/125], Loss: 0.6608\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [89/125], Loss: 0.6603\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [90/125], Loss: 0.6703\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [91/125], Loss: 0.4082\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [92/125], Loss: 0.5474\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [93/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [94/125], Loss: 0.5339\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [95/125], Loss: 0.4340\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [96/125], Loss: 0.5671\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [97/125], Loss: 0.5329\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [98/125], Loss: 0.6390\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [99/125], Loss: 0.4214\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [100/125], Loss: 0.6593\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [101/125], Loss: 0.4661\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [102/125], Loss: 0.5867\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [103/125], Loss: 0.4461\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [104/125], Loss: 0.4722\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [105/125], Loss: 0.7163\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [106/125], Loss: 0.7600\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [107/125], Loss: 0.9124\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [108/125], Loss: 0.4220\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [109/125], Loss: 0.8801\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [110/125], Loss: 0.5504\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [111/125], Loss: 0.7499\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [112/125], Loss: 0.6146\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [113/125], Loss: 0.7067\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [114/125], Loss: 0.6061\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [115/125], Loss: 0.7885\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [116/125], Loss: 0.6296\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [117/125], Loss: 0.4304\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [118/125], Loss: 0.5635\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [119/125], Loss: 0.5894\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [120/125], Loss: 0.5373\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [121/125], Loss: 0.5730\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [122/125], Loss: 0.4420\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [123/125], Loss: 0.5874\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [124/125], Loss: 0.6371\n",
      "Decay: Updating learning rate to 0.003999999000000001\n",
      "Epoch [43/60], Step [125/125], Loss: 0.5225\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [1/125], Loss: 0.6789\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [2/125], Loss: 0.4753\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [3/125], Loss: 0.5620\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [4/125], Loss: 0.7150\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [5/125], Loss: 0.6612\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [6/125], Loss: 0.7037\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [7/125], Loss: 0.6895\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [8/125], Loss: 0.5981\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [9/125], Loss: 0.5463\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [10/125], Loss: 0.5018\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [11/125], Loss: 0.4920\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [12/125], Loss: 0.6503\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [13/125], Loss: 0.4575\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [14/125], Loss: 0.4171\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [15/125], Loss: 0.5869\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [16/125], Loss: 0.7194\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [17/125], Loss: 0.6470\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [18/125], Loss: 0.3461\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [19/125], Loss: 0.4994\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [20/125], Loss: 0.5034\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [21/125], Loss: 0.6667\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [22/125], Loss: 0.6160\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [23/125], Loss: 0.5137\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [24/125], Loss: 0.3196\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [25/125], Loss: 0.5537\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [26/125], Loss: 0.8383\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [27/125], Loss: 0.5860\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [28/125], Loss: 0.6064\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [29/125], Loss: 0.7044\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [30/125], Loss: 0.5568\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [31/125], Loss: 0.6315\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [32/125], Loss: 0.6372\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [33/125], Loss: 0.7245\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [34/125], Loss: 0.5061\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [35/125], Loss: 0.5962\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [36/125], Loss: 0.3546\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [37/125], Loss: 0.5057\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [38/125], Loss: 0.6241\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [39/125], Loss: 0.5274\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [40/125], Loss: 0.5073\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [41/125], Loss: 0.6077\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [42/125], Loss: 0.7428\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [43/125], Loss: 0.7585\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [44/125], Loss: 0.6791\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [45/125], Loss: 0.4489\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [46/125], Loss: 0.5190\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [47/125], Loss: 0.8725\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [48/125], Loss: 0.6354\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [49/125], Loss: 0.6207\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [50/125], Loss: 0.6330\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [51/125], Loss: 0.7780\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [52/125], Loss: 0.8992\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [53/125], Loss: 0.6402\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [54/125], Loss: 0.5929\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [55/125], Loss: 0.6079\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [56/125], Loss: 0.7675\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [57/125], Loss: 0.4844\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [58/125], Loss: 0.7222\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [59/125], Loss: 0.7073\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [60/125], Loss: 0.6447\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [61/125], Loss: 0.7594\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [62/125], Loss: 0.5566\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [63/125], Loss: 0.6037\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [64/125], Loss: 0.6129\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [65/125], Loss: 0.8019\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [66/125], Loss: 0.7076\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [67/125], Loss: 0.4700\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [68/125], Loss: 0.4789\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [69/125], Loss: 0.5581\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [70/125], Loss: 0.6959\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [71/125], Loss: 0.5888\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [72/125], Loss: 0.6798\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [73/125], Loss: 0.4729\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [74/125], Loss: 0.3523\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [75/125], Loss: 0.6196\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [76/125], Loss: 0.4207\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [77/125], Loss: 0.5792\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [78/125], Loss: 0.7305\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [79/125], Loss: 0.8533\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [80/125], Loss: 0.4790\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [81/125], Loss: 0.5214\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [82/125], Loss: 0.5271\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [83/125], Loss: 0.5716\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [84/125], Loss: 0.5036\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [85/125], Loss: 0.5965\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [86/125], Loss: 0.4000\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [87/125], Loss: 0.5561\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [88/125], Loss: 0.6202\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [89/125], Loss: 0.6686\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [90/125], Loss: 0.7705\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [91/125], Loss: 0.5694\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [92/125], Loss: 0.5148\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [93/125], Loss: 0.5669\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [94/125], Loss: 0.7232\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [95/125], Loss: 0.8248\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [96/125], Loss: 0.6377\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [97/125], Loss: 0.5066\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [98/125], Loss: 0.7138\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [99/125], Loss: 0.9288\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [100/125], Loss: 0.5737\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [101/125], Loss: 0.6938\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [102/125], Loss: 0.6050\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [103/125], Loss: 0.3975\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [104/125], Loss: 0.7087\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [105/125], Loss: 0.9619\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [106/125], Loss: 0.5034\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [107/125], Loss: 0.3723\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [108/125], Loss: 0.6933\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [109/125], Loss: 0.8318\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [110/125], Loss: 0.5204\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [111/125], Loss: 0.6571\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [112/125], Loss: 0.5233\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [113/125], Loss: 0.5173\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [114/125], Loss: 0.4446\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [115/125], Loss: 0.4220\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [116/125], Loss: 0.3686\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [117/125], Loss: 0.4558\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [118/125], Loss: 0.3468\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [119/125], Loss: 0.6701\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [120/125], Loss: 0.5359\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [121/125], Loss: 0.7047\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [122/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [123/125], Loss: 0.6417\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [124/125], Loss: 0.5061\n",
      "Decay: Updating learning rate to 0.0037777767777777784\n",
      "Epoch [44/60], Step [125/125], Loss: 0.5793\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [1/125], Loss: 0.8735\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [2/125], Loss: 0.7793\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [3/125], Loss: 0.6130\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [4/125], Loss: 0.5608\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [5/125], Loss: 0.3792\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [6/125], Loss: 0.5870\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [7/125], Loss: 0.5168\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [8/125], Loss: 0.4678\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [9/125], Loss: 0.4592\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [10/125], Loss: 0.6546\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [11/125], Loss: 0.3656\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [12/125], Loss: 0.6520\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [13/125], Loss: 0.6330\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [14/125], Loss: 0.4698\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [15/125], Loss: 0.5884\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [16/125], Loss: 0.5527\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [17/125], Loss: 0.5547\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [18/125], Loss: 0.5578\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [19/125], Loss: 0.6035\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [20/125], Loss: 0.5939\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [21/125], Loss: 0.7943\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [22/125], Loss: 0.6098\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [23/125], Loss: 0.4677\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [24/125], Loss: 0.6430\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [25/125], Loss: 0.4187\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [26/125], Loss: 0.8267\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [27/125], Loss: 0.7217\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [28/125], Loss: 0.7231\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [29/125], Loss: 0.5537\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [30/125], Loss: 0.6537\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [31/125], Loss: 0.3779\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [32/125], Loss: 0.4323\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [33/125], Loss: 0.5253\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [34/125], Loss: 0.7710\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [35/125], Loss: 0.5037\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [36/125], Loss: 0.6617\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [37/125], Loss: 0.4423\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [38/125], Loss: 0.5715\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [39/125], Loss: 0.9017\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [40/125], Loss: 0.3854\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [41/125], Loss: 0.5902\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [42/125], Loss: 0.5044\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [43/125], Loss: 0.5668\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [44/125], Loss: 0.3807\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [45/125], Loss: 0.8032\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [46/125], Loss: 0.7081\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [47/125], Loss: 0.5438\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [48/125], Loss: 0.5069\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [49/125], Loss: 0.7636\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [50/125], Loss: 0.6723\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [51/125], Loss: 0.6934\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [52/125], Loss: 0.6942\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [53/125], Loss: 0.3567\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [54/125], Loss: 0.5720\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [55/125], Loss: 0.6311\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [56/125], Loss: 0.6332\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [57/125], Loss: 0.3652\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [58/125], Loss: 0.7021\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [59/125], Loss: 0.6733\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [60/125], Loss: 0.5782\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [61/125], Loss: 0.4370\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [62/125], Loss: 0.7990\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [63/125], Loss: 0.4830\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [64/125], Loss: 0.6049\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [65/125], Loss: 0.6401\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [66/125], Loss: 0.6406\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [67/125], Loss: 1.1520\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [68/125], Loss: 0.6064\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [69/125], Loss: 0.5745\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [70/125], Loss: 0.7740\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [71/125], Loss: 0.6449\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [72/125], Loss: 0.4633\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [73/125], Loss: 0.7305\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [74/125], Loss: 0.6103\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [75/125], Loss: 0.5705\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [76/125], Loss: 0.4799\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [77/125], Loss: 0.6206\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [78/125], Loss: 0.3693\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [79/125], Loss: 0.5398\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [80/125], Loss: 0.4363\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [81/125], Loss: 0.6065\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [82/125], Loss: 0.5452\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [83/125], Loss: 0.8010\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [84/125], Loss: 0.4648\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [85/125], Loss: 0.5453\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [86/125], Loss: 0.3876\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [87/125], Loss: 0.5987\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [88/125], Loss: 0.6905\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [89/125], Loss: 0.6400\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [90/125], Loss: 0.9166\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [91/125], Loss: 0.6003\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [92/125], Loss: 0.5072\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [93/125], Loss: 0.9600\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [94/125], Loss: 0.4512\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [95/125], Loss: 0.4425\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [96/125], Loss: 0.7817\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [97/125], Loss: 0.6404\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [98/125], Loss: 0.8407\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [99/125], Loss: 0.5201\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [100/125], Loss: 0.8665\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [101/125], Loss: 0.4940\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [102/125], Loss: 0.4551\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [103/125], Loss: 0.6422\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [104/125], Loss: 0.5118\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [105/125], Loss: 0.7530\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [106/125], Loss: 0.6073\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [107/125], Loss: 0.6560\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [108/125], Loss: 0.7243\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [109/125], Loss: 0.8583\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [110/125], Loss: 0.7662\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [111/125], Loss: 0.6956\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [112/125], Loss: 0.4236\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [113/125], Loss: 0.5487\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [114/125], Loss: 0.4815\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [115/125], Loss: 0.4786\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [116/125], Loss: 0.4835\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [117/125], Loss: 0.4560\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [118/125], Loss: 0.9146\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [119/125], Loss: 0.3579\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [120/125], Loss: 0.5701\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [121/125], Loss: 0.5717\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [122/125], Loss: 0.6027\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [123/125], Loss: 0.6777\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [124/125], Loss: 0.3359\n",
      "Decay: Updating learning rate to 0.003555554555555556\n",
      "Epoch [45/60], Step [125/125], Loss: 0.5445\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [1/125], Loss: 0.5371\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [2/125], Loss: 0.4273\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [3/125], Loss: 0.7936\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [4/125], Loss: 0.7424\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [5/125], Loss: 0.7355\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [6/125], Loss: 0.6615\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [7/125], Loss: 0.6461\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [8/125], Loss: 0.7379\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [9/125], Loss: 0.4164\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [10/125], Loss: 0.4658\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [11/125], Loss: 0.7106\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [12/125], Loss: 0.6511\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [13/125], Loss: 0.6759\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [14/125], Loss: 0.5964\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [15/125], Loss: 0.6128\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [16/125], Loss: 0.5861\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [17/125], Loss: 0.6431\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [18/125], Loss: 0.7849\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [19/125], Loss: 0.6500\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [20/125], Loss: 0.5432\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [21/125], Loss: 0.5234\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [22/125], Loss: 0.5073\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [23/125], Loss: 0.7258\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [24/125], Loss: 0.9197\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [25/125], Loss: 0.5769\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [26/125], Loss: 0.6114\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [27/125], Loss: 0.7305\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [28/125], Loss: 0.7017\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [29/125], Loss: 0.6061\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [30/125], Loss: 0.5243\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [31/125], Loss: 0.4436\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [32/125], Loss: 0.6504\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [33/125], Loss: 0.5755\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [34/125], Loss: 0.5200\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [35/125], Loss: 0.6850\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [36/125], Loss: 0.4498\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [37/125], Loss: 0.4949\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [38/125], Loss: 0.4720\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [39/125], Loss: 0.6639\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [40/125], Loss: 0.5373\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [41/125], Loss: 0.5717\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [42/125], Loss: 0.6412\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [43/125], Loss: 0.4186\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [44/125], Loss: 0.6587\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [45/125], Loss: 0.4369\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [46/125], Loss: 0.6228\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [47/125], Loss: 0.4620\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [48/125], Loss: 0.8216\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [49/125], Loss: 0.5201\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [50/125], Loss: 0.6227\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [51/125], Loss: 0.5221\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [52/125], Loss: 0.5969\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [53/125], Loss: 0.5979\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [54/125], Loss: 0.4962\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [55/125], Loss: 0.6698\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [56/125], Loss: 0.5965\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [57/125], Loss: 0.6463\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [58/125], Loss: 0.5189\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [59/125], Loss: 0.4296\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [60/125], Loss: 0.6860\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [61/125], Loss: 0.6821\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [62/125], Loss: 0.5046\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [63/125], Loss: 0.5054\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [64/125], Loss: 0.6185\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [65/125], Loss: 0.5437\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [66/125], Loss: 0.5749\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [67/125], Loss: 0.8894\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [68/125], Loss: 0.6568\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [69/125], Loss: 0.4745\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [70/125], Loss: 0.6027\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [71/125], Loss: 1.0026\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [72/125], Loss: 0.4610\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [73/125], Loss: 0.6892\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [74/125], Loss: 0.5517\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [75/125], Loss: 0.3586\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [76/125], Loss: 0.4565\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [77/125], Loss: 0.5863\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [78/125], Loss: 0.3956\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [79/125], Loss: 0.5436\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [80/125], Loss: 0.7093\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [81/125], Loss: 0.5844\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [82/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [83/125], Loss: 0.5559\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [84/125], Loss: 0.4635\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [85/125], Loss: 0.4746\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [86/125], Loss: 0.9091\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [87/125], Loss: 0.5295\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [88/125], Loss: 0.6289\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [89/125], Loss: 0.6132\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [90/125], Loss: 0.5599\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [91/125], Loss: 0.6022\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [92/125], Loss: 0.4776\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [93/125], Loss: 0.5296\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [94/125], Loss: 0.6131\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [95/125], Loss: 0.4714\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [96/125], Loss: 0.6370\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [97/125], Loss: 0.5929\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [98/125], Loss: 0.5404\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [99/125], Loss: 0.7483\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [100/125], Loss: 0.5079\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [101/125], Loss: 0.6113\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [102/125], Loss: 0.7464\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [103/125], Loss: 0.4775\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [104/125], Loss: 0.7482\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [105/125], Loss: 0.7644\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [106/125], Loss: 0.5700\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [107/125], Loss: 0.9586\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [108/125], Loss: 0.5611\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [109/125], Loss: 0.7639\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [110/125], Loss: 0.6285\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [111/125], Loss: 0.6866\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [112/125], Loss: 0.5984\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [113/125], Loss: 0.4610\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [114/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [115/125], Loss: 0.5133\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [116/125], Loss: 0.6481\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [117/125], Loss: 0.5090\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [118/125], Loss: 0.6877\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [119/125], Loss: 0.6566\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [120/125], Loss: 0.6037\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [121/125], Loss: 0.4875\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [122/125], Loss: 0.5611\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [123/125], Loss: 0.5173\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [124/125], Loss: 0.4567\n",
      "Decay: Updating learning rate to 0.0033333323333333345\n",
      "Epoch [46/60], Step [125/125], Loss: 0.6157\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [1/125], Loss: 0.6250\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [2/125], Loss: 0.3814\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [3/125], Loss: 0.6304\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [4/125], Loss: 0.4604\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [5/125], Loss: 0.7620\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [6/125], Loss: 0.4844\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [7/125], Loss: 0.4739\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [8/125], Loss: 0.4041\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [9/125], Loss: 0.7206\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [10/125], Loss: 0.8252\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [11/125], Loss: 0.7497\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [12/125], Loss: 0.5191\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [13/125], Loss: 0.6584\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [14/125], Loss: 0.5951\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [15/125], Loss: 0.5023\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [16/125], Loss: 0.6724\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [17/125], Loss: 0.6321\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [18/125], Loss: 0.6620\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [19/125], Loss: 0.7187\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [20/125], Loss: 0.5591\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [21/125], Loss: 0.6760\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [22/125], Loss: 0.6502\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [23/125], Loss: 0.6606\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [24/125], Loss: 0.6474\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [25/125], Loss: 0.8550\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [26/125], Loss: 0.5307\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [27/125], Loss: 0.5107\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [28/125], Loss: 0.4467\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [29/125], Loss: 0.4798\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [30/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [31/125], Loss: 0.5808\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [32/125], Loss: 0.6144\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [33/125], Loss: 0.6257\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [34/125], Loss: 0.4733\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [35/125], Loss: 0.6122\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [36/125], Loss: 0.5831\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [37/125], Loss: 0.6891\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [38/125], Loss: 0.5632\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [39/125], Loss: 0.4080\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [40/125], Loss: 0.5858\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [41/125], Loss: 0.6023\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [42/125], Loss: 0.7161\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [43/125], Loss: 0.7364\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [44/125], Loss: 0.6116\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [45/125], Loss: 0.6374\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [46/125], Loss: 0.6257\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [47/125], Loss: 0.5005\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [48/125], Loss: 0.4354\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [49/125], Loss: 0.5537\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [50/125], Loss: 0.4139\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [51/125], Loss: 0.6430\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [52/125], Loss: 0.5957\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [53/125], Loss: 0.4862\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [54/125], Loss: 0.5076\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [55/125], Loss: 0.3340\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [56/125], Loss: 0.4549\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [57/125], Loss: 0.5164\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [58/125], Loss: 0.6307\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [59/125], Loss: 0.7340\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [60/125], Loss: 0.6680\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [61/125], Loss: 0.4304\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [62/125], Loss: 0.5159\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [63/125], Loss: 0.5417\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [64/125], Loss: 0.4729\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [65/125], Loss: 0.5018\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [66/125], Loss: 0.5599\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [67/125], Loss: 0.5842\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [68/125], Loss: 0.5725\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [69/125], Loss: 0.4820\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [70/125], Loss: 0.5240\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [71/125], Loss: 0.6661\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [72/125], Loss: 0.9759\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [73/125], Loss: 0.7749\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [74/125], Loss: 0.6972\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [75/125], Loss: 0.7834\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [76/125], Loss: 0.5355\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [77/125], Loss: 0.5390\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [78/125], Loss: 0.4632\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [79/125], Loss: 0.6301\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [80/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [81/125], Loss: 0.5223\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [82/125], Loss: 0.6202\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [83/125], Loss: 0.7586\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [84/125], Loss: 0.6315\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [85/125], Loss: 0.6816\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [86/125], Loss: 0.6996\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [87/125], Loss: 0.6686\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [88/125], Loss: 0.8792\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [89/125], Loss: 0.5126\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [90/125], Loss: 0.4892\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [91/125], Loss: 0.5267\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [92/125], Loss: 0.5591\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [93/125], Loss: 0.3165\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [94/125], Loss: 0.6804\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [95/125], Loss: 0.7593\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [96/125], Loss: 0.5693\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [97/125], Loss: 0.5478\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [98/125], Loss: 0.9363\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [99/125], Loss: 0.4980\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [100/125], Loss: 0.4994\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [101/125], Loss: 0.5807\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [102/125], Loss: 0.6542\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [103/125], Loss: 0.6014\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [104/125], Loss: 0.5438\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [105/125], Loss: 0.4286\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [106/125], Loss: 0.4720\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [107/125], Loss: 0.7254\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [108/125], Loss: 0.3664\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [109/125], Loss: 0.6374\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [110/125], Loss: 0.5902\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [111/125], Loss: 0.8206\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [112/125], Loss: 0.7218\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [113/125], Loss: 0.4457\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [114/125], Loss: 0.7242\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [115/125], Loss: 0.6160\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [116/125], Loss: 0.6028\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [117/125], Loss: 0.4467\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [118/125], Loss: 0.6128\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [119/125], Loss: 0.8495\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [120/125], Loss: 0.3853\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [121/125], Loss: 0.3553\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [122/125], Loss: 0.5426\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [123/125], Loss: 0.9184\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [124/125], Loss: 0.6249\n",
      "Decay: Updating learning rate to 0.003111110111111112\n",
      "Epoch [47/60], Step [125/125], Loss: 0.6368\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [1/125], Loss: 0.6865\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [2/125], Loss: 0.5271\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [3/125], Loss: 0.5069\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [4/125], Loss: 0.6390\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [5/125], Loss: 0.6392\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [6/125], Loss: 0.5258\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [7/125], Loss: 0.4918\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [8/125], Loss: 0.4795\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [9/125], Loss: 0.5102\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [10/125], Loss: 0.4615\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [11/125], Loss: 0.6565\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [12/125], Loss: 0.6566\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [13/125], Loss: 0.5908\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [14/125], Loss: 0.4921\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [15/125], Loss: 0.6687\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [16/125], Loss: 0.5078\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [17/125], Loss: 0.4969\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [18/125], Loss: 0.5856\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [19/125], Loss: 0.6709\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [20/125], Loss: 0.4657\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [21/125], Loss: 0.4331\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [22/125], Loss: 0.3645\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [23/125], Loss: 0.8110\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [24/125], Loss: 0.5010\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [25/125], Loss: 0.6457\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [26/125], Loss: 0.9099\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [27/125], Loss: 0.3561\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [28/125], Loss: 0.5542\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [29/125], Loss: 0.6709\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [30/125], Loss: 0.6092\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [31/125], Loss: 0.4288\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [32/125], Loss: 0.5766\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [33/125], Loss: 0.6072\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [34/125], Loss: 0.6309\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [35/125], Loss: 0.9302\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [36/125], Loss: 0.4444\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [37/125], Loss: 0.6313\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [38/125], Loss: 0.4651\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [39/125], Loss: 0.4788\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [40/125], Loss: 0.4777\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [41/125], Loss: 0.6408\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [42/125], Loss: 0.4136\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [43/125], Loss: 0.7537\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [44/125], Loss: 0.5069\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [45/125], Loss: 0.6438\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [46/125], Loss: 0.4697\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [47/125], Loss: 0.6306\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [48/125], Loss: 0.7573\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [49/125], Loss: 0.6038\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [50/125], Loss: 0.3901\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [51/125], Loss: 0.5951\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [52/125], Loss: 0.5191\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [53/125], Loss: 0.6241\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [54/125], Loss: 0.5686\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [55/125], Loss: 0.7314\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [56/125], Loss: 0.6129\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [57/125], Loss: 0.4857\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [58/125], Loss: 0.5134\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [59/125], Loss: 0.5951\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [60/125], Loss: 0.5954\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [61/125], Loss: 0.9864\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [62/125], Loss: 0.5141\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [63/125], Loss: 0.5637\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [64/125], Loss: 0.7142\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [65/125], Loss: 0.7875\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [66/125], Loss: 0.5462\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [67/125], Loss: 0.6537\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [68/125], Loss: 0.4126\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [69/125], Loss: 0.4084\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [70/125], Loss: 0.4814\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [71/125], Loss: 0.6862\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [72/125], Loss: 0.4866\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [73/125], Loss: 0.6530\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [74/125], Loss: 0.7196\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [75/125], Loss: 0.7197\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [76/125], Loss: 0.5878\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [77/125], Loss: 0.5872\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [78/125], Loss: 0.8774\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [79/125], Loss: 0.5194\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [80/125], Loss: 0.8856\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [81/125], Loss: 0.4377\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [82/125], Loss: 0.5104\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [83/125], Loss: 0.4487\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [84/125], Loss: 0.6681\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [85/125], Loss: 0.7577\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [86/125], Loss: 0.4384\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [87/125], Loss: 0.3983\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [88/125], Loss: 0.6942\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [89/125], Loss: 0.6480\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [90/125], Loss: 0.6154\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [91/125], Loss: 0.5010\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [92/125], Loss: 0.5884\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [93/125], Loss: 0.4641\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [94/125], Loss: 0.5283\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [95/125], Loss: 0.5858\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [96/125], Loss: 0.4252\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [97/125], Loss: 0.9197\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [98/125], Loss: 0.5796\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [99/125], Loss: 0.7022\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [100/125], Loss: 0.7129\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [101/125], Loss: 0.5493\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [102/125], Loss: 0.7891\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [103/125], Loss: 0.6602\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [104/125], Loss: 0.6148\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [105/125], Loss: 0.5065\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [106/125], Loss: 0.5863\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [107/125], Loss: 0.4938\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [108/125], Loss: 0.4652\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [109/125], Loss: 0.7387\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [110/125], Loss: 0.6177\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [111/125], Loss: 0.5808\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [112/125], Loss: 0.6318\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [113/125], Loss: 0.3897\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [114/125], Loss: 0.4009\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [115/125], Loss: 0.4831\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [116/125], Loss: 0.6785\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [117/125], Loss: 0.7851\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [118/125], Loss: 0.5556\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [119/125], Loss: 0.4395\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [120/125], Loss: 0.9513\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [121/125], Loss: 0.5027\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [122/125], Loss: 0.5956\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [123/125], Loss: 0.7827\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [124/125], Loss: 0.6658\n",
      "Decay: Updating learning rate to 0.0028888878888888893\n",
      "Epoch [48/60], Step [125/125], Loss: 0.6374\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [1/125], Loss: 0.5486\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [2/125], Loss: 0.4719\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [3/125], Loss: 0.5761\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [4/125], Loss: 0.6802\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [5/125], Loss: 0.4573\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [6/125], Loss: 0.4656\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [7/125], Loss: 0.5086\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [8/125], Loss: 0.6125\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [9/125], Loss: 0.6227\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [10/125], Loss: 0.5092\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [11/125], Loss: 0.6830\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [12/125], Loss: 0.7202\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [13/125], Loss: 0.6437\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [14/125], Loss: 0.4930\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [15/125], Loss: 0.6037\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [16/125], Loss: 0.5090\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [17/125], Loss: 0.5655\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [18/125], Loss: 0.5627\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [19/125], Loss: 0.6387\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [20/125], Loss: 0.5210\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [21/125], Loss: 0.7627\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [22/125], Loss: 0.4665\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [23/125], Loss: 0.6717\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [24/125], Loss: 0.4992\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [25/125], Loss: 0.6219\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [26/125], Loss: 0.5425\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [27/125], Loss: 0.6079\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [28/125], Loss: 0.7074\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [29/125], Loss: 0.6047\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [30/125], Loss: 0.6021\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [31/125], Loss: 0.5757\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [32/125], Loss: 0.6452\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [33/125], Loss: 0.4857\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [34/125], Loss: 0.3243\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [35/125], Loss: 0.4872\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [36/125], Loss: 0.7289\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [37/125], Loss: 0.6988\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [38/125], Loss: 0.4530\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [39/125], Loss: 0.7013\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [40/125], Loss: 0.6401\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [41/125], Loss: 0.7517\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [42/125], Loss: 0.5799\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [43/125], Loss: 0.7079\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [44/125], Loss: 0.8745\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [45/125], Loss: 0.7056\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [46/125], Loss: 0.5284\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [47/125], Loss: 0.5938\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [48/125], Loss: 0.3402\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [49/125], Loss: 0.5510\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [50/125], Loss: 0.5590\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [51/125], Loss: 0.6891\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [52/125], Loss: 0.5270\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [53/125], Loss: 0.5178\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [54/125], Loss: 0.4622\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [55/125], Loss: 0.8737\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [56/125], Loss: 0.5989\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [57/125], Loss: 0.5255\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [58/125], Loss: 0.5077\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [59/125], Loss: 0.3764\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [60/125], Loss: 0.5500\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [61/125], Loss: 0.7777\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [62/125], Loss: 0.4193\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [63/125], Loss: 0.7098\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [64/125], Loss: 0.4593\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [65/125], Loss: 0.7574\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [66/125], Loss: 0.4632\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [67/125], Loss: 0.8328\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [68/125], Loss: 0.6359\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [69/125], Loss: 0.6334\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [70/125], Loss: 0.6154\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [71/125], Loss: 0.4604\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [72/125], Loss: 0.3708\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [73/125], Loss: 0.5876\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [74/125], Loss: 0.5526\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [75/125], Loss: 0.7296\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [76/125], Loss: 0.6704\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [77/125], Loss: 0.5198\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [78/125], Loss: 0.5636\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [79/125], Loss: 0.5257\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [80/125], Loss: 0.5179\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [81/125], Loss: 0.5846\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [82/125], Loss: 0.6224\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [83/125], Loss: 0.4998\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [84/125], Loss: 0.5607\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [85/125], Loss: 0.7043\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [86/125], Loss: 0.6130\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [87/125], Loss: 0.4576\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [88/125], Loss: 0.4712\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [89/125], Loss: 0.5468\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [90/125], Loss: 0.5917\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [91/125], Loss: 0.5884\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [92/125], Loss: 0.8446\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [93/125], Loss: 0.7330\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [94/125], Loss: 0.6432\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [95/125], Loss: 0.5351\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [96/125], Loss: 0.4813\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [97/125], Loss: 0.8015\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [98/125], Loss: 0.4617\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [99/125], Loss: 0.6993\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [100/125], Loss: 0.5046\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [101/125], Loss: 0.6806\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [102/125], Loss: 0.4764\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [103/125], Loss: 0.5979\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [104/125], Loss: 0.7345\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [105/125], Loss: 0.5106\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [106/125], Loss: 0.5113\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [107/125], Loss: 0.5400\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [108/125], Loss: 0.5565\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [109/125], Loss: 0.4231\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [110/125], Loss: 0.6503\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [111/125], Loss: 0.7165\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [112/125], Loss: 0.4002\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [113/125], Loss: 0.5170\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [114/125], Loss: 0.7630\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [115/125], Loss: 0.7120\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [116/125], Loss: 0.5451\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [117/125], Loss: 0.7008\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [118/125], Loss: 0.7527\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [119/125], Loss: 0.6370\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [120/125], Loss: 0.5144\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [121/125], Loss: 0.7511\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [122/125], Loss: 0.6342\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [123/125], Loss: 0.4603\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [124/125], Loss: 0.5476\n",
      "Decay: Updating learning rate to 0.002666665666666668\n",
      "Epoch [49/60], Step [125/125], Loss: 0.7030\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [1/125], Loss: 0.5323\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [2/125], Loss: 0.6652\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [3/125], Loss: 0.6641\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [4/125], Loss: 0.4772\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [5/125], Loss: 0.8431\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [6/125], Loss: 0.8293\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [7/125], Loss: 0.7947\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [8/125], Loss: 0.5267\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [9/125], Loss: 0.4511\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [10/125], Loss: 0.4588\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [11/125], Loss: 0.5533\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [12/125], Loss: 0.8770\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [13/125], Loss: 0.6018\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [14/125], Loss: 0.6066\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [15/125], Loss: 0.7052\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [16/125], Loss: 0.6892\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [17/125], Loss: 0.5569\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [18/125], Loss: 0.5973\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [19/125], Loss: 0.4638\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [20/125], Loss: 0.5173\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [21/125], Loss: 0.3519\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [22/125], Loss: 0.3896\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [23/125], Loss: 0.4458\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [24/125], Loss: 0.5977\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [25/125], Loss: 0.5933\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [26/125], Loss: 0.4256\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [27/125], Loss: 0.5356\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [28/125], Loss: 0.3967\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [29/125], Loss: 0.4218\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [30/125], Loss: 0.7116\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [31/125], Loss: 0.5443\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [32/125], Loss: 0.5289\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [33/125], Loss: 0.5016\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [34/125], Loss: 0.7033\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [35/125], Loss: 0.6655\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [36/125], Loss: 0.4191\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [37/125], Loss: 0.4037\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [38/125], Loss: 0.6593\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [39/125], Loss: 0.5723\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [40/125], Loss: 0.6136\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [41/125], Loss: 0.5968\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [42/125], Loss: 0.4564\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [43/125], Loss: 0.6377\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [44/125], Loss: 0.5281\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [45/125], Loss: 0.6491\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [46/125], Loss: 0.5314\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [47/125], Loss: 0.6753\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [48/125], Loss: 0.8341\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [49/125], Loss: 0.5871\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [50/125], Loss: 0.5998\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [51/125], Loss: 0.9432\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [52/125], Loss: 0.6815\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [53/125], Loss: 0.6749\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [54/125], Loss: 0.7798\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [55/125], Loss: 0.6439\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [56/125], Loss: 0.6035\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [57/125], Loss: 0.5479\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [58/125], Loss: 0.5756\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [59/125], Loss: 0.6832\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [60/125], Loss: 0.5984\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [61/125], Loss: 0.7406\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [62/125], Loss: 0.3238\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [63/125], Loss: 0.7963\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [64/125], Loss: 0.7690\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [65/125], Loss: 0.6922\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [66/125], Loss: 0.5344\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [67/125], Loss: 0.5591\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [68/125], Loss: 0.6206\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [69/125], Loss: 0.2977\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [70/125], Loss: 0.6606\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [71/125], Loss: 0.5605\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [72/125], Loss: 0.5482\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [73/125], Loss: 0.3828\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [74/125], Loss: 0.4613\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [75/125], Loss: 0.6067\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [76/125], Loss: 0.4746\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [77/125], Loss: 0.5855\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [78/125], Loss: 0.7207\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [79/125], Loss: 0.6949\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [80/125], Loss: 0.4124\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [81/125], Loss: 0.6482\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [82/125], Loss: 0.3760\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [83/125], Loss: 0.6385\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [84/125], Loss: 0.4989\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [85/125], Loss: 0.7779\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [86/125], Loss: 0.7836\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [87/125], Loss: 0.6679\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [88/125], Loss: 0.5829\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [89/125], Loss: 0.7144\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [90/125], Loss: 0.5297\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [91/125], Loss: 0.8603\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [92/125], Loss: 0.5862\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [93/125], Loss: 0.7051\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [94/125], Loss: 0.7516\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [95/125], Loss: 0.6253\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [96/125], Loss: 0.8613\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [97/125], Loss: 0.6968\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [98/125], Loss: 0.8028\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [99/125], Loss: 0.6153\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [100/125], Loss: 0.4314\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [101/125], Loss: 0.4033\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [102/125], Loss: 0.5220\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [103/125], Loss: 0.5993\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [104/125], Loss: 0.6048\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [105/125], Loss: 0.6122\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [106/125], Loss: 0.6443\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [107/125], Loss: 0.5579\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [108/125], Loss: 0.6379\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [109/125], Loss: 0.6022\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [110/125], Loss: 0.5859\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [111/125], Loss: 0.6419\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [112/125], Loss: 0.6696\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [113/125], Loss: 0.6087\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [114/125], Loss: 0.7288\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [115/125], Loss: 0.4693\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [116/125], Loss: 0.6925\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [117/125], Loss: 0.6364\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [118/125], Loss: 0.7944\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [119/125], Loss: 0.7401\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [120/125], Loss: 0.6362\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [121/125], Loss: 0.6429\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [122/125], Loss: 0.4476\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [123/125], Loss: 0.7685\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [124/125], Loss: 0.8358\n",
      "Decay: Updating learning rate to 0.0024444434444444454\n",
      "Epoch [50/60], Step [125/125], Loss: 0.5173\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [1/125], Loss: 0.8576\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [2/125], Loss: 0.5415\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [3/125], Loss: 0.6306\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [4/125], Loss: 0.7582\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [5/125], Loss: 0.6398\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [6/125], Loss: 0.6613\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [7/125], Loss: 0.5050\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [8/125], Loss: 0.8407\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [9/125], Loss: 0.6554\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [10/125], Loss: 0.6750\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [11/125], Loss: 0.4687\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [12/125], Loss: 0.5389\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [13/125], Loss: 0.8651\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [14/125], Loss: 0.5429\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [15/125], Loss: 0.8284\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [16/125], Loss: 0.6854\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [17/125], Loss: 0.3783\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [18/125], Loss: 0.5868\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [19/125], Loss: 0.5142\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [20/125], Loss: 1.0057\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [21/125], Loss: 0.6926\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [22/125], Loss: 0.5374\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [23/125], Loss: 0.5900\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [24/125], Loss: 0.6642\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [25/125], Loss: 0.5206\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [26/125], Loss: 0.4699\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [27/125], Loss: 0.5876\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [28/125], Loss: 0.6357\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [29/125], Loss: 0.6262\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [30/125], Loss: 0.5084\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [31/125], Loss: 0.7557\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [32/125], Loss: 0.4485\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [33/125], Loss: 0.3283\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [34/125], Loss: 0.5657\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [35/125], Loss: 0.4168\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [36/125], Loss: 0.5199\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [37/125], Loss: 0.6035\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [38/125], Loss: 0.5880\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [39/125], Loss: 0.7451\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [40/125], Loss: 0.5264\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [41/125], Loss: 0.7487\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [42/125], Loss: 0.4122\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [43/125], Loss: 0.3497\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [44/125], Loss: 0.4455\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [45/125], Loss: 0.5693\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [46/125], Loss: 0.4921\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [47/125], Loss: 0.8110\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [48/125], Loss: 0.4862\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [49/125], Loss: 0.6247\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [50/125], Loss: 0.6353\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [51/125], Loss: 0.5735\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [52/125], Loss: 0.4127\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [53/125], Loss: 0.3993\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [54/125], Loss: 0.7322\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [55/125], Loss: 0.5482\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [56/125], Loss: 0.5456\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [57/125], Loss: 0.4561\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [58/125], Loss: 0.6072\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [59/125], Loss: 0.7074\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [60/125], Loss: 0.5126\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [61/125], Loss: 0.5558\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [62/125], Loss: 0.4421\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [63/125], Loss: 0.5804\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [64/125], Loss: 0.6653\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [65/125], Loss: 0.5492\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [66/125], Loss: 0.8124\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [67/125], Loss: 0.5629\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [68/125], Loss: 0.6364\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [69/125], Loss: 0.7527\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [70/125], Loss: 0.5586\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [71/125], Loss: 0.5856\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [72/125], Loss: 0.5655\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [73/125], Loss: 0.4674\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [74/125], Loss: 0.5691\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [75/125], Loss: 0.5560\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [76/125], Loss: 0.5502\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [77/125], Loss: 0.4356\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [78/125], Loss: 0.6364\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [79/125], Loss: 0.6407\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [80/125], Loss: 0.6088\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [81/125], Loss: 0.6667\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [82/125], Loss: 0.6186\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [83/125], Loss: 0.6767\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [84/125], Loss: 0.6263\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [85/125], Loss: 0.5820\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [86/125], Loss: 0.6854\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [87/125], Loss: 0.5433\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [88/125], Loss: 0.4611\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [89/125], Loss: 0.5719\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [90/125], Loss: 0.4869\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [91/125], Loss: 0.5400\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [92/125], Loss: 0.5437\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [93/125], Loss: 0.5312\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [94/125], Loss: 0.7125\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [95/125], Loss: 0.6017\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [96/125], Loss: 0.6018\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [97/125], Loss: 0.6142\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [98/125], Loss: 0.4847\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [99/125], Loss: 0.5715\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [100/125], Loss: 0.7317\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [101/125], Loss: 0.6634\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [102/125], Loss: 0.5150\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [103/125], Loss: 0.4324\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [104/125], Loss: 0.4993\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [105/125], Loss: 0.5577\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [106/125], Loss: 0.4747\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [107/125], Loss: 0.5953\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [108/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [109/125], Loss: 0.5076\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [110/125], Loss: 0.6213\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [111/125], Loss: 0.5296\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [112/125], Loss: 0.6667\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [113/125], Loss: 0.8094\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [114/125], Loss: 0.6720\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [115/125], Loss: 0.5206\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [116/125], Loss: 0.4295\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [117/125], Loss: 0.5448\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [118/125], Loss: 0.4411\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [119/125], Loss: 0.7776\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [120/125], Loss: 0.5486\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [121/125], Loss: 0.5626\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [122/125], Loss: 0.5870\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [123/125], Loss: 0.5632\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [124/125], Loss: 0.4735\n",
      "Decay: Updating learning rate to 0.0022222212222222227\n",
      "Epoch [51/60], Step [125/125], Loss: 0.5653\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [1/125], Loss: 0.4919\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [2/125], Loss: 0.9268\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [3/125], Loss: 0.5829\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [4/125], Loss: 0.4595\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [5/125], Loss: 0.9095\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [6/125], Loss: 0.4112\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [7/125], Loss: 0.5063\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [8/125], Loss: 0.6661\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [9/125], Loss: 0.4745\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [10/125], Loss: 0.4503\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [11/125], Loss: 0.6546\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [12/125], Loss: 0.5476\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [13/125], Loss: 0.5058\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [14/125], Loss: 0.5216\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [15/125], Loss: 0.4778\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [16/125], Loss: 0.6200\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [17/125], Loss: 0.5849\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [18/125], Loss: 0.5823\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [19/125], Loss: 0.6565\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [20/125], Loss: 0.4711\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [21/125], Loss: 0.6400\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [22/125], Loss: 0.5746\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [23/125], Loss: 0.7423\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [24/125], Loss: 0.4412\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [25/125], Loss: 0.5209\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [26/125], Loss: 0.5999\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [27/125], Loss: 0.4425\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [28/125], Loss: 0.7305\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [29/125], Loss: 0.3795\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [30/125], Loss: 0.4911\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [31/125], Loss: 0.4338\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [32/125], Loss: 0.3712\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [33/125], Loss: 0.5416\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [34/125], Loss: 0.4264\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [35/125], Loss: 0.5537\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [36/125], Loss: 0.5821\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [37/125], Loss: 0.5515\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [38/125], Loss: 0.5839\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [39/125], Loss: 0.4794\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [40/125], Loss: 0.6319\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [41/125], Loss: 0.7288\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [42/125], Loss: 0.5907\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [43/125], Loss: 0.5447\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [44/125], Loss: 0.6901\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [45/125], Loss: 0.4934\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [46/125], Loss: 0.5321\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [47/125], Loss: 0.4749\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [48/125], Loss: 0.4848\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [49/125], Loss: 0.5151\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [50/125], Loss: 0.6893\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [51/125], Loss: 0.4118\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [52/125], Loss: 0.6445\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [53/125], Loss: 0.8655\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [54/125], Loss: 0.7552\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [55/125], Loss: 0.4639\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [56/125], Loss: 0.3956\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [57/125], Loss: 1.0574\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [58/125], Loss: 0.7127\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [59/125], Loss: 0.4462\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [60/125], Loss: 0.4627\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [61/125], Loss: 0.6944\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [62/125], Loss: 0.6191\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [63/125], Loss: 0.5757\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [64/125], Loss: 0.5223\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [65/125], Loss: 0.5920\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [66/125], Loss: 0.5402\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [67/125], Loss: 0.5376\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [68/125], Loss: 0.5825\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [69/125], Loss: 0.6734\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [70/125], Loss: 0.7360\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [71/125], Loss: 0.4609\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [72/125], Loss: 0.5106\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [73/125], Loss: 0.5244\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [74/125], Loss: 0.4846\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [75/125], Loss: 0.5860\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [76/125], Loss: 0.6498\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [77/125], Loss: 0.4392\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [78/125], Loss: 0.3164\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [79/125], Loss: 0.6919\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [80/125], Loss: 0.4925\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [81/125], Loss: 0.6432\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [82/125], Loss: 0.4566\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [83/125], Loss: 0.4240\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [84/125], Loss: 0.5698\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [85/125], Loss: 0.5330\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [86/125], Loss: 0.3809\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [87/125], Loss: 0.6641\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [88/125], Loss: 0.6035\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [89/125], Loss: 0.6214\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [90/125], Loss: 0.4510\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [91/125], Loss: 0.8241\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [92/125], Loss: 0.5961\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [93/125], Loss: 0.7424\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [94/125], Loss: 0.5402\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [95/125], Loss: 0.4301\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [96/125], Loss: 0.7188\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [97/125], Loss: 0.5755\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [98/125], Loss: 0.5455\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [99/125], Loss: 0.4206\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [100/125], Loss: 0.5049\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [101/125], Loss: 0.5256\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [102/125], Loss: 0.7471\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [103/125], Loss: 0.4607\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [104/125], Loss: 0.6776\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [105/125], Loss: 0.5338\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [106/125], Loss: 0.4540\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [107/125], Loss: 0.6437\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [108/125], Loss: 0.6245\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [109/125], Loss: 0.8949\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [110/125], Loss: 0.7418\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [111/125], Loss: 0.4952\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [112/125], Loss: 0.5277\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [113/125], Loss: 0.5475\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [114/125], Loss: 0.2846\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [115/125], Loss: 0.6912\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [116/125], Loss: 0.5448\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [117/125], Loss: 0.6138\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [118/125], Loss: 0.6724\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [119/125], Loss: 0.4479\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [120/125], Loss: 0.6448\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [121/125], Loss: 0.6138\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [122/125], Loss: 0.4312\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [123/125], Loss: 0.4616\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [124/125], Loss: 0.6026\n",
      "Decay: Updating learning rate to 0.001999999\n",
      "Epoch [52/60], Step [125/125], Loss: 0.5544\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [1/125], Loss: 0.7869\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [2/125], Loss: 0.7512\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [3/125], Loss: 0.4510\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [4/125], Loss: 0.5335\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [5/125], Loss: 0.4284\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [6/125], Loss: 0.4199\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [7/125], Loss: 0.6017\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [8/125], Loss: 0.6838\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [9/125], Loss: 0.4639\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [10/125], Loss: 0.5973\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [11/125], Loss: 0.4545\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [12/125], Loss: 0.6396\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [13/125], Loss: 0.5820\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [14/125], Loss: 0.4335\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [15/125], Loss: 0.9169\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [16/125], Loss: 0.6738\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [17/125], Loss: 0.5680\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [18/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [19/125], Loss: 0.8925\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [20/125], Loss: 0.5282\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [21/125], Loss: 0.6625\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [22/125], Loss: 0.3012\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [23/125], Loss: 0.5028\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [24/125], Loss: 0.3684\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [25/125], Loss: 0.3755\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [26/125], Loss: 0.6662\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [27/125], Loss: 0.6862\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [28/125], Loss: 0.3878\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [29/125], Loss: 0.5325\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [30/125], Loss: 0.4650\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [31/125], Loss: 0.4648\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [32/125], Loss: 0.6103\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [33/125], Loss: 0.6110\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [34/125], Loss: 0.5958\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [35/125], Loss: 0.6457\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [36/125], Loss: 0.6245\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [37/125], Loss: 0.5394\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [38/125], Loss: 0.4383\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [39/125], Loss: 0.6024\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [40/125], Loss: 0.6458\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [41/125], Loss: 0.4820\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [42/125], Loss: 0.2923\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [43/125], Loss: 0.6271\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [44/125], Loss: 0.6800\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [45/125], Loss: 0.4516\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [46/125], Loss: 0.5318\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [47/125], Loss: 0.5536\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [48/125], Loss: 0.4063\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [49/125], Loss: 0.6283\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [50/125], Loss: 0.7124\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [51/125], Loss: 0.3963\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [52/125], Loss: 0.6936\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [53/125], Loss: 0.4930\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [54/125], Loss: 0.4339\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [55/125], Loss: 0.3330\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [56/125], Loss: 0.5691\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [57/125], Loss: 0.7013\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [58/125], Loss: 0.4945\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [59/125], Loss: 0.6847\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [60/125], Loss: 0.4456\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [61/125], Loss: 0.7723\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [62/125], Loss: 0.8258\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [63/125], Loss: 0.7212\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [64/125], Loss: 0.6963\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [65/125], Loss: 0.4292\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [66/125], Loss: 0.5896\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [67/125], Loss: 0.7877\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [68/125], Loss: 0.5015\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [69/125], Loss: 0.4585\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [70/125], Loss: 0.6847\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [71/125], Loss: 0.6384\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [72/125], Loss: 0.7299\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [73/125], Loss: 0.5744\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [74/125], Loss: 0.7075\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [75/125], Loss: 0.6775\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [76/125], Loss: 0.7896\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [77/125], Loss: 0.5752\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [78/125], Loss: 0.5257\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [79/125], Loss: 0.6518\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [80/125], Loss: 0.5049\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [81/125], Loss: 0.6848\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [82/125], Loss: 0.4683\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [83/125], Loss: 0.3975\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [84/125], Loss: 0.7268\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [85/125], Loss: 0.5933\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [86/125], Loss: 0.6759\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [87/125], Loss: 0.3902\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [88/125], Loss: 0.4805\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [89/125], Loss: 0.4491\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [90/125], Loss: 0.5344\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [91/125], Loss: 0.5239\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [92/125], Loss: 0.4717\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [93/125], Loss: 0.5047\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [94/125], Loss: 0.5465\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [95/125], Loss: 0.4558\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [96/125], Loss: 0.3881\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [97/125], Loss: 0.5140\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [98/125], Loss: 0.7598\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [99/125], Loss: 0.3989\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [100/125], Loss: 0.6622\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [101/125], Loss: 0.4864\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [102/125], Loss: 0.8256\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [103/125], Loss: 0.7630\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [104/125], Loss: 0.5886\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [105/125], Loss: 0.5431\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [106/125], Loss: 0.8690\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [107/125], Loss: 0.2712\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [108/125], Loss: 0.7971\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [109/125], Loss: 0.5740\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [110/125], Loss: 0.4329\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [111/125], Loss: 0.5374\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [112/125], Loss: 0.7547\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [113/125], Loss: 0.7117\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [114/125], Loss: 0.5208\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [115/125], Loss: 0.6514\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [116/125], Loss: 0.3655\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [117/125], Loss: 0.7642\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [118/125], Loss: 0.6699\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [119/125], Loss: 0.7976\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [120/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [121/125], Loss: 0.4657\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [122/125], Loss: 0.5428\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [123/125], Loss: 0.4554\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [124/125], Loss: 0.4401\n",
      "Decay: Updating learning rate to 0.0017777767777777786\n",
      "Epoch [53/60], Step [125/125], Loss: 0.8278\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [1/125], Loss: 0.6662\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [2/125], Loss: 0.6890\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [3/125], Loss: 0.5133\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [4/125], Loss: 0.5779\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [5/125], Loss: 0.6492\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [6/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [7/125], Loss: 0.7689\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [8/125], Loss: 0.6010\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [9/125], Loss: 0.5570\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [10/125], Loss: 0.6924\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [11/125], Loss: 0.7380\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [12/125], Loss: 0.7058\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [13/125], Loss: 0.5977\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [14/125], Loss: 0.7569\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [15/125], Loss: 0.6745\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [16/125], Loss: 0.5339\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [17/125], Loss: 0.6256\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [18/125], Loss: 0.5737\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [19/125], Loss: 0.5580\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [20/125], Loss: 0.7785\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [21/125], Loss: 0.5876\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [22/125], Loss: 0.7092\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [23/125], Loss: 0.7435\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [24/125], Loss: 0.4536\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [25/125], Loss: 0.5747\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [26/125], Loss: 0.4708\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [27/125], Loss: 0.6235\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [28/125], Loss: 0.5748\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [29/125], Loss: 0.5167\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [30/125], Loss: 0.3991\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [31/125], Loss: 0.4520\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [32/125], Loss: 0.5556\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [33/125], Loss: 0.6802\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [34/125], Loss: 0.4525\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [35/125], Loss: 0.5700\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [36/125], Loss: 0.8247\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [37/125], Loss: 0.4636\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [38/125], Loss: 0.5545\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [39/125], Loss: 0.6835\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [40/125], Loss: 0.4158\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [41/125], Loss: 0.4701\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [42/125], Loss: 0.4820\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [43/125], Loss: 0.6495\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [44/125], Loss: 0.5695\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [45/125], Loss: 0.6659\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [46/125], Loss: 0.8121\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [47/125], Loss: 0.6504\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [48/125], Loss: 0.7565\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [49/125], Loss: 0.6898\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [50/125], Loss: 0.5737\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [51/125], Loss: 0.5139\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [52/125], Loss: 0.5016\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [53/125], Loss: 0.6709\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [54/125], Loss: 0.5907\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [55/125], Loss: 0.7263\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [56/125], Loss: 0.8448\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [57/125], Loss: 0.6369\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [58/125], Loss: 0.4743\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [59/125], Loss: 0.6906\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [60/125], Loss: 0.5084\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [61/125], Loss: 0.5459\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [62/125], Loss: 0.4801\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [63/125], Loss: 0.5288\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [64/125], Loss: 0.5321\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [65/125], Loss: 0.5252\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [66/125], Loss: 0.6106\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [67/125], Loss: 0.7254\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [68/125], Loss: 0.6697\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [69/125], Loss: 0.8119\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [70/125], Loss: 0.5424\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [71/125], Loss: 0.6494\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [72/125], Loss: 0.6410\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [73/125], Loss: 0.8310\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [74/125], Loss: 0.6182\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [75/125], Loss: 0.5651\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [76/125], Loss: 0.4352\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [77/125], Loss: 0.6416\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [78/125], Loss: 0.6071\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [79/125], Loss: 0.5975\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [80/125], Loss: 0.6957\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [81/125], Loss: 0.5974\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [82/125], Loss: 0.5778\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [83/125], Loss: 0.9914\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [84/125], Loss: 0.3586\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [85/125], Loss: 0.5560\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [86/125], Loss: 0.7188\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [87/125], Loss: 0.4929\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [88/125], Loss: 0.7522\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [89/125], Loss: 0.5047\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [90/125], Loss: 0.6005\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [91/125], Loss: 0.5753\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [92/125], Loss: 0.6519\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [93/125], Loss: 0.5276\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [94/125], Loss: 0.5427\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [95/125], Loss: 0.4524\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [96/125], Loss: 0.6557\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [97/125], Loss: 0.7187\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [98/125], Loss: 0.5913\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [99/125], Loss: 0.2961\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [100/125], Loss: 0.6964\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [101/125], Loss: 0.6613\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [102/125], Loss: 0.6298\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [103/125], Loss: 0.3898\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [104/125], Loss: 0.4391\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [105/125], Loss: 0.4397\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [106/125], Loss: 0.5649\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [107/125], Loss: 0.4725\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [108/125], Loss: 0.5528\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [109/125], Loss: 0.3865\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [110/125], Loss: 0.4362\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [111/125], Loss: 0.5982\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [112/125], Loss: 0.7539\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [113/125], Loss: 0.5319\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [114/125], Loss: 0.4129\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [115/125], Loss: 0.5279\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [116/125], Loss: 0.5253\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [117/125], Loss: 0.5038\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [118/125], Loss: 0.4861\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [119/125], Loss: 0.7774\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [120/125], Loss: 0.9635\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [121/125], Loss: 0.5924\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [122/125], Loss: 0.7444\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [123/125], Loss: 0.6276\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [124/125], Loss: 0.6249\n",
      "Decay: Updating learning rate to 0.0015555545555555562\n",
      "Epoch [54/60], Step [125/125], Loss: 0.6144\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [1/125], Loss: 0.5484\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [2/125], Loss: 0.6881\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [3/125], Loss: 0.7039\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [4/125], Loss: 0.7093\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [5/125], Loss: 0.6305\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [6/125], Loss: 0.4528\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [7/125], Loss: 0.4439\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [8/125], Loss: 0.5149\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [9/125], Loss: 0.7853\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [10/125], Loss: 0.7159\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [11/125], Loss: 0.5578\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [12/125], Loss: 0.4514\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [13/125], Loss: 0.5271\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [14/125], Loss: 0.4958\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [15/125], Loss: 0.4727\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [16/125], Loss: 0.6226\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [17/125], Loss: 0.3230\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [18/125], Loss: 0.4302\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [19/125], Loss: 0.4790\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [20/125], Loss: 0.7267\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [21/125], Loss: 0.3624\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [22/125], Loss: 0.6431\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [23/125], Loss: 0.6641\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [24/125], Loss: 0.5835\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [25/125], Loss: 0.4363\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [26/125], Loss: 0.7669\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [27/125], Loss: 0.5749\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [28/125], Loss: 0.6238\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [29/125], Loss: 0.4278\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [30/125], Loss: 0.7411\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [31/125], Loss: 0.3288\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [32/125], Loss: 0.5290\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [33/125], Loss: 0.4606\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [34/125], Loss: 0.6136\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [35/125], Loss: 0.7804\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [36/125], Loss: 0.4851\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [37/125], Loss: 0.3672\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [38/125], Loss: 0.5664\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [39/125], Loss: 0.7215\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [40/125], Loss: 0.5940\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [41/125], Loss: 0.6012\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [42/125], Loss: 0.5280\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [43/125], Loss: 0.5327\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [44/125], Loss: 0.5084\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [45/125], Loss: 0.5593\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [46/125], Loss: 0.6795\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [47/125], Loss: 0.4779\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [48/125], Loss: 0.4121\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [49/125], Loss: 0.6568\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [50/125], Loss: 0.6379\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [51/125], Loss: 0.5516\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [52/125], Loss: 0.5645\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [53/125], Loss: 0.5208\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [54/125], Loss: 0.5520\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [55/125], Loss: 0.6598\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [56/125], Loss: 0.7348\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [57/125], Loss: 0.6227\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [58/125], Loss: 0.5542\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [59/125], Loss: 0.6353\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [60/125], Loss: 0.4707\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [61/125], Loss: 0.4125\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [62/125], Loss: 0.6639\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [63/125], Loss: 0.4365\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [64/125], Loss: 0.4102\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [65/125], Loss: 0.4999\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [66/125], Loss: 0.4832\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [67/125], Loss: 0.5589\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [68/125], Loss: 0.5616\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [69/125], Loss: 0.7035\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [70/125], Loss: 0.5304\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [71/125], Loss: 0.4840\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [72/125], Loss: 0.5287\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [73/125], Loss: 0.5384\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [74/125], Loss: 0.5696\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [75/125], Loss: 0.4745\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [76/125], Loss: 0.8038\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [77/125], Loss: 0.6686\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [78/125], Loss: 0.5379\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [79/125], Loss: 0.6880\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [80/125], Loss: 0.5730\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [81/125], Loss: 0.5447\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [82/125], Loss: 0.6353\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [83/125], Loss: 0.6575\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [84/125], Loss: 0.4707\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [85/125], Loss: 0.4553\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [86/125], Loss: 0.4100\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [87/125], Loss: 0.2996\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [88/125], Loss: 0.7138\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [89/125], Loss: 0.6598\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [90/125], Loss: 0.9335\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [91/125], Loss: 0.5712\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [92/125], Loss: 0.4476\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [93/125], Loss: 0.8268\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [94/125], Loss: 0.5352\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [95/125], Loss: 0.4887\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [96/125], Loss: 0.5098\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [97/125], Loss: 0.5764\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [98/125], Loss: 0.7195\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [99/125], Loss: 0.7497\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [100/125], Loss: 0.7856\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [101/125], Loss: 0.5813\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [102/125], Loss: 0.7464\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [103/125], Loss: 0.4609\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [104/125], Loss: 0.5532\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [105/125], Loss: 0.6031\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [106/125], Loss: 0.8367\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [107/125], Loss: 0.4927\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [108/125], Loss: 0.4891\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [109/125], Loss: 0.4409\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [110/125], Loss: 0.5512\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [111/125], Loss: 0.4922\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [112/125], Loss: 0.3876\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [113/125], Loss: 0.4941\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [114/125], Loss: 0.7528\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [115/125], Loss: 0.6366\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [116/125], Loss: 0.5338\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [117/125], Loss: 0.7051\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [118/125], Loss: 0.8177\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [119/125], Loss: 0.5491\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [120/125], Loss: 0.9260\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [121/125], Loss: 0.6901\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [122/125], Loss: 0.5324\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [123/125], Loss: 0.5807\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [124/125], Loss: 0.5677\n",
      "Decay: Updating learning rate to 0.0013333323333333336\n",
      "Epoch [55/60], Step [125/125], Loss: 0.6716\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [1/125], Loss: 0.6854\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [2/125], Loss: 0.8234\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [3/125], Loss: 0.6880\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [4/125], Loss: 0.5300\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [5/125], Loss: 0.4580\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [6/125], Loss: 0.7129\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [7/125], Loss: 0.4530\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [8/125], Loss: 0.7056\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [9/125], Loss: 0.8341\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [10/125], Loss: 0.4420\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [11/125], Loss: 0.5389\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [12/125], Loss: 0.6638\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [13/125], Loss: 0.6292\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [14/125], Loss: 0.5478\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [15/125], Loss: 0.6003\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [16/125], Loss: 0.6131\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [17/125], Loss: 0.5270\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [18/125], Loss: 0.6235\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [19/125], Loss: 0.5413\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [20/125], Loss: 0.5565\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [21/125], Loss: 0.4898\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [22/125], Loss: 0.4364\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [23/125], Loss: 0.3264\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [24/125], Loss: 0.7142\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [25/125], Loss: 0.6868\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [26/125], Loss: 0.3799\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [27/125], Loss: 0.4259\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [28/125], Loss: 0.5125\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [29/125], Loss: 0.5555\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [30/125], Loss: 0.4961\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [31/125], Loss: 0.5719\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [32/125], Loss: 0.4806\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [33/125], Loss: 0.7336\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [34/125], Loss: 0.5306\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [35/125], Loss: 0.6116\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [36/125], Loss: 0.5605\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [37/125], Loss: 0.4569\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [38/125], Loss: 1.0187\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [39/125], Loss: 0.6816\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [40/125], Loss: 0.6063\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [41/125], Loss: 0.5835\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [42/125], Loss: 0.4850\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [43/125], Loss: 0.5769\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [44/125], Loss: 0.6655\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [45/125], Loss: 0.5482\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [46/125], Loss: 0.8091\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [47/125], Loss: 0.5303\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [48/125], Loss: 0.4642\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [49/125], Loss: 0.6764\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [50/125], Loss: 0.4354\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [51/125], Loss: 0.6764\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [52/125], Loss: 0.4418\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [53/125], Loss: 0.6685\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [54/125], Loss: 0.6844\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [55/125], Loss: 0.3172\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [56/125], Loss: 0.7016\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [57/125], Loss: 0.6059\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [58/125], Loss: 0.4816\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [59/125], Loss: 0.6884\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [60/125], Loss: 0.5330\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [61/125], Loss: 0.4742\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [62/125], Loss: 0.6082\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [63/125], Loss: 0.6811\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [64/125], Loss: 0.4436\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [65/125], Loss: 0.7159\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [66/125], Loss: 0.5350\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [67/125], Loss: 0.4897\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [68/125], Loss: 0.4711\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [69/125], Loss: 0.5166\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [70/125], Loss: 0.4627\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [71/125], Loss: 0.6567\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [72/125], Loss: 0.5592\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [73/125], Loss: 0.3396\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [74/125], Loss: 0.4556\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [75/125], Loss: 0.4899\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [76/125], Loss: 0.4326\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [77/125], Loss: 0.7814\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [78/125], Loss: 0.5168\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [79/125], Loss: 0.3644\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [80/125], Loss: 0.6705\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [81/125], Loss: 0.5269\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [82/125], Loss: 0.6417\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [83/125], Loss: 0.5898\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [84/125], Loss: 0.5937\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [85/125], Loss: 0.4092\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [86/125], Loss: 0.4795\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [87/125], Loss: 0.6327\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [88/125], Loss: 0.6128\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [89/125], Loss: 0.5178\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [90/125], Loss: 0.4731\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [91/125], Loss: 0.6303\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [92/125], Loss: 0.6100\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [93/125], Loss: 0.7026\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [94/125], Loss: 0.7228\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [95/125], Loss: 0.4679\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [96/125], Loss: 0.3790\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [97/125], Loss: 0.7175\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [98/125], Loss: 0.7208\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [99/125], Loss: 0.4908\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [100/125], Loss: 0.9200\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [101/125], Loss: 0.3436\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [102/125], Loss: 0.6266\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [103/125], Loss: 0.5738\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [104/125], Loss: 0.5079\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [105/125], Loss: 0.5978\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [106/125], Loss: 0.7180\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [107/125], Loss: 0.5011\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [108/125], Loss: 0.4752\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [109/125], Loss: 0.8071\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [110/125], Loss: 0.5574\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [111/125], Loss: 0.6087\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [112/125], Loss: 0.5416\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [113/125], Loss: 0.4018\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [114/125], Loss: 0.7484\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [115/125], Loss: 0.4849\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [116/125], Loss: 0.5217\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [117/125], Loss: 0.5124\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [118/125], Loss: 0.2119\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [119/125], Loss: 0.5540\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [120/125], Loss: 0.7083\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [121/125], Loss: 0.5624\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [122/125], Loss: 0.5617\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [123/125], Loss: 0.5790\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [124/125], Loss: 0.6409\n",
      "Decay: Updating learning rate to 0.001111110111111112\n",
      "Epoch [56/60], Step [125/125], Loss: 0.7596\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [1/125], Loss: 0.4602\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [2/125], Loss: 0.6169\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [3/125], Loss: 0.6894\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [4/125], Loss: 0.5239\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [5/125], Loss: 0.6843\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [6/125], Loss: 0.4137\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [7/125], Loss: 0.5554\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [8/125], Loss: 0.7261\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [9/125], Loss: 0.7393\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [10/125], Loss: 0.8071\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [11/125], Loss: 0.7392\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [12/125], Loss: 0.9486\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [13/125], Loss: 0.4626\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [14/125], Loss: 0.6353\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [15/125], Loss: 0.4016\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [16/125], Loss: 0.7289\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [17/125], Loss: 0.5041\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [18/125], Loss: 0.6025\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [19/125], Loss: 0.5450\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [20/125], Loss: 0.5987\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [21/125], Loss: 0.5841\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [22/125], Loss: 0.5673\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [23/125], Loss: 0.5899\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [24/125], Loss: 0.6533\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [25/125], Loss: 0.5867\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [26/125], Loss: 0.4582\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [27/125], Loss: 0.5897\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [28/125], Loss: 0.6275\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [29/125], Loss: 0.6822\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [30/125], Loss: 0.5143\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [31/125], Loss: 0.7072\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [32/125], Loss: 0.9048\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [33/125], Loss: 0.4772\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [34/125], Loss: 0.5594\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [35/125], Loss: 0.4496\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [36/125], Loss: 0.6359\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [37/125], Loss: 0.5082\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [38/125], Loss: 0.6805\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [39/125], Loss: 0.6362\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [40/125], Loss: 0.4039\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [41/125], Loss: 0.5256\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [42/125], Loss: 0.6655\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [43/125], Loss: 0.4808\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [44/125], Loss: 0.6297\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [45/125], Loss: 0.5838\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [46/125], Loss: 0.5189\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [47/125], Loss: 0.5788\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [48/125], Loss: 0.3491\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [49/125], Loss: 0.7040\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [50/125], Loss: 0.5183\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [51/125], Loss: 0.4820\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [52/125], Loss: 0.6462\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [53/125], Loss: 0.5972\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [54/125], Loss: 0.4823\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [55/125], Loss: 0.6255\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [56/125], Loss: 0.5310\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [57/125], Loss: 0.6889\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [58/125], Loss: 0.6148\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [59/125], Loss: 0.5888\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [60/125], Loss: 0.5401\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [61/125], Loss: 0.4713\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [62/125], Loss: 0.5564\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [63/125], Loss: 0.4441\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [64/125], Loss: 0.6603\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [65/125], Loss: 0.6090\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [66/125], Loss: 0.4980\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [67/125], Loss: 0.5165\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [68/125], Loss: 0.6575\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [69/125], Loss: 0.4961\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [70/125], Loss: 0.7543\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [71/125], Loss: 0.6488\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [72/125], Loss: 0.4271\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [73/125], Loss: 0.6445\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [74/125], Loss: 0.4546\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [75/125], Loss: 0.3562\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [76/125], Loss: 0.6080\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [77/125], Loss: 0.7085\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [78/125], Loss: 0.7803\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [79/125], Loss: 0.3555\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [80/125], Loss: 0.3557\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [81/125], Loss: 0.8910\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [82/125], Loss: 0.4652\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [83/125], Loss: 0.7430\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [84/125], Loss: 0.8338\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [85/125], Loss: 0.6247\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [86/125], Loss: 0.6892\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [87/125], Loss: 0.4425\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [88/125], Loss: 0.6087\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [89/125], Loss: 0.5461\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [90/125], Loss: 0.5460\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [91/125], Loss: 0.6116\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [92/125], Loss: 0.4709\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [93/125], Loss: 0.5837\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [94/125], Loss: 0.5252\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [95/125], Loss: 0.4850\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [96/125], Loss: 0.4573\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [97/125], Loss: 0.4713\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [98/125], Loss: 0.8479\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [99/125], Loss: 0.5191\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [100/125], Loss: 0.4799\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [101/125], Loss: 0.5721\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [102/125], Loss: 0.5584\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [103/125], Loss: 0.5552\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [104/125], Loss: 0.5624\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [105/125], Loss: 0.5220\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [106/125], Loss: 0.4342\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [107/125], Loss: 0.5412\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [108/125], Loss: 0.4932\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [109/125], Loss: 0.6173\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [110/125], Loss: 0.6388\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [111/125], Loss: 0.6771\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [112/125], Loss: 0.5312\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [113/125], Loss: 0.4940\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [114/125], Loss: 0.7400\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [115/125], Loss: 0.4949\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [116/125], Loss: 0.6648\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [117/125], Loss: 0.4164\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [118/125], Loss: 0.4420\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [119/125], Loss: 0.5625\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [120/125], Loss: 0.4816\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [121/125], Loss: 0.6115\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [122/125], Loss: 0.7905\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [123/125], Loss: 0.5250\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [124/125], Loss: 0.3831\n",
      "Decay: Updating learning rate to 0.0008888878888888896\n",
      "Epoch [57/60], Step [125/125], Loss: 0.8747\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [1/125], Loss: 0.4276\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [2/125], Loss: 0.4479\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [3/125], Loss: 0.4739\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [4/125], Loss: 0.4414\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [5/125], Loss: 0.4932\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [6/125], Loss: 0.3916\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [7/125], Loss: 0.5964\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [8/125], Loss: 0.5329\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [9/125], Loss: 0.6050\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [10/125], Loss: 0.5782\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [11/125], Loss: 0.6006\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [12/125], Loss: 0.3819\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [13/125], Loss: 0.5777\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [14/125], Loss: 0.5957\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [15/125], Loss: 0.6209\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [16/125], Loss: 0.5608\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [17/125], Loss: 0.5551\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [18/125], Loss: 0.4292\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [19/125], Loss: 0.6308\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [20/125], Loss: 0.4925\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [21/125], Loss: 0.7559\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [22/125], Loss: 0.4483\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [23/125], Loss: 0.6322\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [24/125], Loss: 0.6294\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [25/125], Loss: 0.4391\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [26/125], Loss: 0.4731\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [27/125], Loss: 0.4573\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [28/125], Loss: 0.5320\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [29/125], Loss: 0.5377\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [30/125], Loss: 0.5151\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [31/125], Loss: 0.6572\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [32/125], Loss: 0.6941\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [33/125], Loss: 0.6164\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [34/125], Loss: 0.6188\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [35/125], Loss: 0.9686\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [36/125], Loss: 0.4353\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [37/125], Loss: 0.5620\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [38/125], Loss: 0.5277\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [39/125], Loss: 0.5510\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [40/125], Loss: 0.8270\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [41/125], Loss: 0.6487\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [42/125], Loss: 0.3847\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [43/125], Loss: 0.6994\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [44/125], Loss: 0.7264\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [45/125], Loss: 0.5437\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [46/125], Loss: 0.4626\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [47/125], Loss: 0.7028\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [48/125], Loss: 0.7556\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [49/125], Loss: 0.3668\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [50/125], Loss: 0.5540\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [51/125], Loss: 0.7935\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [52/125], Loss: 0.6398\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [53/125], Loss: 0.4678\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [54/125], Loss: 0.4628\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [55/125], Loss: 0.5135\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [56/125], Loss: 0.5494\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [57/125], Loss: 0.5377\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [58/125], Loss: 0.7373\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [59/125], Loss: 0.6423\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [60/125], Loss: 0.7201\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [61/125], Loss: 0.5872\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [62/125], Loss: 0.7196\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [63/125], Loss: 0.7150\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [64/125], Loss: 0.4681\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [65/125], Loss: 0.5732\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [66/125], Loss: 0.5555\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [67/125], Loss: 0.4825\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [68/125], Loss: 0.4944\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [69/125], Loss: 0.3851\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [70/125], Loss: 0.6873\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [71/125], Loss: 0.5345\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [72/125], Loss: 0.5800\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [73/125], Loss: 0.4770\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [74/125], Loss: 0.3934\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [75/125], Loss: 0.4496\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [76/125], Loss: 0.6789\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [77/125], Loss: 0.5600\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [78/125], Loss: 0.6256\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [79/125], Loss: 0.5534\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [80/125], Loss: 0.5391\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [81/125], Loss: 0.6892\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [82/125], Loss: 0.4072\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [83/125], Loss: 0.3110\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [84/125], Loss: 0.6110\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [85/125], Loss: 0.6079\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [86/125], Loss: 0.5532\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [87/125], Loss: 0.5492\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [88/125], Loss: 0.4225\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [89/125], Loss: 0.5122\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [90/125], Loss: 0.4572\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [91/125], Loss: 0.5776\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [92/125], Loss: 0.5461\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [93/125], Loss: 0.6223\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [94/125], Loss: 0.6550\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [95/125], Loss: 0.4689\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [96/125], Loss: 0.4941\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [97/125], Loss: 0.4677\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [98/125], Loss: 0.5958\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [99/125], Loss: 0.6330\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [100/125], Loss: 0.6535\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [101/125], Loss: 0.4413\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [102/125], Loss: 0.5673\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [103/125], Loss: 0.4263\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [104/125], Loss: 0.7472\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [105/125], Loss: 0.8189\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [106/125], Loss: 0.6614\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [107/125], Loss: 0.6959\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [108/125], Loss: 0.6038\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [109/125], Loss: 0.4570\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [110/125], Loss: 0.6652\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [111/125], Loss: 0.6448\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [112/125], Loss: 0.6090\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [113/125], Loss: 0.4847\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [114/125], Loss: 0.6405\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [115/125], Loss: 0.8906\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [116/125], Loss: 0.4270\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [117/125], Loss: 0.9088\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [118/125], Loss: 0.4998\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [119/125], Loss: 0.5783\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [120/125], Loss: 0.5605\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [121/125], Loss: 0.6678\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [122/125], Loss: 0.5692\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [123/125], Loss: 0.6653\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [124/125], Loss: 0.5426\n",
      "Decay: Updating learning rate to 0.0006666656666666671\n",
      "Epoch [58/60], Step [125/125], Loss: 0.6814\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [1/125], Loss: 0.6510\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [2/125], Loss: 0.3893\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [3/125], Loss: 0.6292\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [4/125], Loss: 0.4755\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [5/125], Loss: 0.7217\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [6/125], Loss: 0.6574\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [7/125], Loss: 0.4465\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [8/125], Loss: 0.4616\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [9/125], Loss: 0.7585\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [10/125], Loss: 0.4067\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [11/125], Loss: 0.7829\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [12/125], Loss: 0.5676\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [13/125], Loss: 0.3523\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [14/125], Loss: 0.6125\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [15/125], Loss: 0.8873\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [16/125], Loss: 0.4871\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [17/125], Loss: 0.6592\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [18/125], Loss: 0.5053\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [19/125], Loss: 0.5667\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [20/125], Loss: 0.4606\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [21/125], Loss: 0.5438\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [22/125], Loss: 0.5630\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [23/125], Loss: 0.6721\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [24/125], Loss: 0.8145\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [25/125], Loss: 0.6038\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [26/125], Loss: 0.5359\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [27/125], Loss: 0.4726\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [28/125], Loss: 0.4830\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [29/125], Loss: 0.7464\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [30/125], Loss: 0.6774\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [31/125], Loss: 0.4261\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [32/125], Loss: 0.7247\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [33/125], Loss: 0.4878\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [34/125], Loss: 0.6582\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [35/125], Loss: 0.5911\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [36/125], Loss: 0.7087\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [37/125], Loss: 0.5324\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [38/125], Loss: 0.7174\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [39/125], Loss: 0.5702\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [40/125], Loss: 0.5226\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [41/125], Loss: 0.6735\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [42/125], Loss: 0.6264\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [43/125], Loss: 0.4107\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [44/125], Loss: 0.5102\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [45/125], Loss: 0.5922\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [46/125], Loss: 0.6452\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [47/125], Loss: 0.7355\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [48/125], Loss: 0.5177\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [49/125], Loss: 0.6716\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [50/125], Loss: 0.6756\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [51/125], Loss: 0.5648\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [52/125], Loss: 0.4721\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [53/125], Loss: 0.5673\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [54/125], Loss: 0.6423\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [55/125], Loss: 0.6385\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [56/125], Loss: 0.4463\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [57/125], Loss: 0.4421\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [58/125], Loss: 0.5349\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [59/125], Loss: 0.6021\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [60/125], Loss: 0.6688\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [61/125], Loss: 0.4494\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [62/125], Loss: 0.4990\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [63/125], Loss: 0.4283\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [64/125], Loss: 0.6809\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [65/125], Loss: 0.7723\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [66/125], Loss: 0.5450\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [67/125], Loss: 0.7692\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [68/125], Loss: 0.4131\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [69/125], Loss: 0.6224\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [70/125], Loss: 0.3310\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [71/125], Loss: 0.7172\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [72/125], Loss: 0.7496\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [73/125], Loss: 0.8194\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [74/125], Loss: 0.4168\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [75/125], Loss: 0.6303\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [76/125], Loss: 0.3986\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [77/125], Loss: 0.5480\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [78/125], Loss: 0.5287\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [79/125], Loss: 0.4976\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [80/125], Loss: 0.5477\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [81/125], Loss: 0.6547\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [82/125], Loss: 0.4955\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [83/125], Loss: 0.5481\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [84/125], Loss: 0.4350\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [85/125], Loss: 0.8333\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [86/125], Loss: 0.6428\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [87/125], Loss: 0.6011\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [88/125], Loss: 0.4433\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [89/125], Loss: 0.5121\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [90/125], Loss: 0.6359\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [91/125], Loss: 0.3490\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [92/125], Loss: 0.5245\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [93/125], Loss: 0.5947\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [94/125], Loss: 0.6546\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [95/125], Loss: 0.4462\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [96/125], Loss: 0.5816\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [97/125], Loss: 0.6433\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [98/125], Loss: 0.6150\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [99/125], Loss: 0.5622\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [100/125], Loss: 0.6130\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [101/125], Loss: 0.4606\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [102/125], Loss: 0.4074\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [103/125], Loss: 0.5896\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [104/125], Loss: 0.6780\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [105/125], Loss: 0.5299\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [106/125], Loss: 0.7424\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [107/125], Loss: 0.6622\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [108/125], Loss: 0.5631\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [109/125], Loss: 0.5928\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [110/125], Loss: 0.3662\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [111/125], Loss: 0.5273\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [112/125], Loss: 0.5925\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [113/125], Loss: 0.7050\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [114/125], Loss: 0.6899\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [115/125], Loss: 0.4828\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [116/125], Loss: 0.5864\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [117/125], Loss: 0.4876\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [118/125], Loss: 0.7836\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [119/125], Loss: 0.5265\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [120/125], Loss: 0.6768\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [121/125], Loss: 0.5448\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [122/125], Loss: 0.5717\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [123/125], Loss: 0.6375\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [124/125], Loss: 0.5149\n",
      "Decay: Updating learning rate to 0.0004444434444444445\n",
      "Epoch [59/60], Step [125/125], Loss: 0.5809\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [1/125], Loss: 0.7316\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [2/125], Loss: 0.8137\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [3/125], Loss: 0.4812\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [4/125], Loss: 0.8374\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [5/125], Loss: 0.5087\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [6/125], Loss: 0.9041\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [7/125], Loss: 0.5510\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [8/125], Loss: 0.5011\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [9/125], Loss: 0.7283\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [10/125], Loss: 0.5346\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [11/125], Loss: 0.3918\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [12/125], Loss: 0.5571\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [13/125], Loss: 0.3613\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [14/125], Loss: 0.6299\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [15/125], Loss: 0.6086\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [16/125], Loss: 0.4974\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [17/125], Loss: 0.7262\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [18/125], Loss: 0.4661\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [19/125], Loss: 0.6159\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [20/125], Loss: 0.6975\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [21/125], Loss: 0.4779\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [22/125], Loss: 0.4584\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [23/125], Loss: 0.6021\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [24/125], Loss: 0.4927\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [25/125], Loss: 0.7098\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [26/125], Loss: 0.6137\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [27/125], Loss: 0.4834\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [28/125], Loss: 0.7199\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [29/125], Loss: 0.5719\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [30/125], Loss: 0.5800\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [31/125], Loss: 0.5556\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [32/125], Loss: 0.7605\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [33/125], Loss: 0.5028\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [34/125], Loss: 0.6314\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [35/125], Loss: 0.7424\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [36/125], Loss: 0.6566\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [37/125], Loss: 0.5256\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [38/125], Loss: 0.5129\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [39/125], Loss: 0.6177\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [40/125], Loss: 0.7013\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [41/125], Loss: 0.7726\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [42/125], Loss: 0.5682\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [43/125], Loss: 0.4803\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [44/125], Loss: 0.5257\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [45/125], Loss: 0.5816\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [46/125], Loss: 0.6518\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [47/125], Loss: 0.6847\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [48/125], Loss: 0.3663\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [49/125], Loss: 0.4057\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [50/125], Loss: 0.5739\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [51/125], Loss: 0.6194\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [52/125], Loss: 0.6320\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [53/125], Loss: 0.7213\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [54/125], Loss: 0.6271\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [55/125], Loss: 0.6259\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [56/125], Loss: 0.5253\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [57/125], Loss: 0.6130\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [58/125], Loss: 0.5653\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [59/125], Loss: 0.5848\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [60/125], Loss: 0.5779\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [61/125], Loss: 0.4351\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [62/125], Loss: 0.4188\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [63/125], Loss: 0.3667\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [64/125], Loss: 0.5175\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [65/125], Loss: 0.7673\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [66/125], Loss: 0.5844\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [67/125], Loss: 0.6033\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [68/125], Loss: 0.6372\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [69/125], Loss: 0.5048\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [70/125], Loss: 0.6262\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [71/125], Loss: 0.4055\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [72/125], Loss: 0.7008\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [73/125], Loss: 0.5276\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [74/125], Loss: 0.5866\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [75/125], Loss: 0.4096\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [76/125], Loss: 0.9130\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [77/125], Loss: 0.4615\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [78/125], Loss: 0.6114\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [79/125], Loss: 0.9273\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [80/125], Loss: 0.4077\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [81/125], Loss: 0.4609\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [82/125], Loss: 0.5592\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [83/125], Loss: 0.6351\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [84/125], Loss: 0.5448\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [85/125], Loss: 0.5338\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [86/125], Loss: 0.5582\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [87/125], Loss: 0.7350\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [88/125], Loss: 0.4419\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [89/125], Loss: 0.3537\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [90/125], Loss: 0.5061\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [91/125], Loss: 0.5979\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [92/125], Loss: 0.5874\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [93/125], Loss: 0.3819\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [94/125], Loss: 0.4393\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [95/125], Loss: 0.5533\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [96/125], Loss: 0.5366\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [97/125], Loss: 0.6419\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [98/125], Loss: 0.7999\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [99/125], Loss: 0.7865\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [100/125], Loss: 0.5978\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [101/125], Loss: 0.5334\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [102/125], Loss: 0.6527\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [103/125], Loss: 0.7920\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [104/125], Loss: 0.6150\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [105/125], Loss: 0.6029\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [106/125], Loss: 0.4887\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [107/125], Loss: 0.5919\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [108/125], Loss: 0.5398\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [109/125], Loss: 0.6793\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [110/125], Loss: 0.8468\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [111/125], Loss: 0.5377\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [112/125], Loss: 1.1037\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [113/125], Loss: 0.6714\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [114/125], Loss: 0.4132\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [115/125], Loss: 0.4166\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [116/125], Loss: 0.6234\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [117/125], Loss: 0.6751\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [118/125], Loss: 0.4619\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [119/125], Loss: 0.4137\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [120/125], Loss: 0.6161\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [121/125], Loss: 0.6533\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [122/125], Loss: 0.4068\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [123/125], Loss: 0.3621\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [124/125], Loss: 0.4595\n",
      "Decay: Updating learning rate to 0.00022222122222222308\n",
      "Epoch [60/60], Step [125/125], Loss: 0.4875\n",
      "Entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "modelo.cuda()\n",
    "modelo.train()\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 60\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        # Forward\n",
    "        inputs=inputs.float().to(\"cuda:0\")\n",
    "        labels=labels.float().to(\"cuda:0\")\n",
    "        outputs, series, prior, _ = modelo(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward y optimizaci√≥n\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        warmup_and_decay_learning_rate(optimizer, epoch, 1e-2,15 , num_epochs)\n",
    "        # Printear resultados\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=next(iter(dataloader))\n",
    "a1=a[0].float().to(\"cuda:0\")\n",
    "modelo.eval()\n",
    "y=modelo(a1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=y[0].squeeze().cpu().detach().numpy()\n",
    "z1=y[1][0].squeeze().cpu().detach().numpy()\n",
    "z2=y[2][0].squeeze().cpu().detach().numpy()\n",
    "b=a[1].squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd2d41c8bd0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z[18])\n",
    "plt.plot(b[18],\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 4, 600, 600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=2\n",
    "\n",
    "plt.plot(z[n])\n",
    "plt.plot(b[n],\"--\")\n",
    "plt.plot(a[0][n],\"--\")\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(z1[n][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
