{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a construir un transformer desde 0 en pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.randn(3, 3)\n",
    "K = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=Q.masked_fill_(torch.triu(torch.ones(3,3,dtype=bool),diagonal=1),-1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3972, 0.0000, 0.0000],\n",
       "        [0.1297, 0.8657, 0.0000],\n",
       "        [0.4731, 0.1343, 1.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(aux,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msqrt(Q\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[0;31mTypeError\u001b[0m: sqrt(): argument 'input' (position 1) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "torch.sqrt(Q.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotProdAttention(nn.Module):\n",
    "    def __init__(self,mask:bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.bool_mask=mask\n",
    "\n",
    "    def forward(self, Q,K,V):\n",
    "        #le pasamos la query, el value y la key.\n",
    "        d_k=Q.shape[1]\n",
    "        wi= Q.shape[0]\n",
    "        wo= K.shape[0]\n",
    "        aux1=torch.mm(Q,K.T) / math.sqrt(d_k)\n",
    "        #si mask, entonces ponemos a -inf los que toquen\n",
    "        if self.bool_mask ==True:\n",
    "            aux1=aux1.masked_fill_(torch.triu(torch.ones(wi,wo,dtype=bool),diagonal=1),-1e9)\n",
    "        e=F.softmax(aux1,dim=1)\n",
    "        return torch.mm(e, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.randn(4, 3)\n",
    "K = torch.randn(4, 3)\n",
    "V = torch.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=dotProdAttention(mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4359,  1.2106, -1.1034],\n",
       "        [-1.3597,  0.6453, -1.0730],\n",
       "        [-1.2111,  0.1597, -0.8245],\n",
       "        [-1.0443, -0.9619, -0.9149]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(Q,K,V)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiHead AttentionLayer\n",
    "\n",
    "Para esto, metemos un vector de (w, d_model) contra 3 mult de matrices, W_Q, W_K, W_V, y estos son parametros entrenables de la red. Los aÃ±adimos como parameters, o como Linear nn.\n",
    "Luego de hacer las multiplicaciones, tenemos el dotAttention. Y cuando obtenemos el resultado, concatenamos y otra linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self,heads,d_model) -> None:\n",
    "        super().__init__()\n",
    "        self.h=heads\n",
    "        self.d_model=d_model\n",
    "        self.d_k=int(self.d_model/self.h)\n",
    "        self.d_v=int(self.d_model/self.h)\n",
    "\n",
    "        #matrices entrenables\n",
    "        #podrimos tener una de estas matrices para cada una de las cabezas, pero entonces tendrimos mucho lio\n",
    "        \"\"\"        \n",
    "        self.W_Q=nn.Linear(self.d_model,self.d_k,bias=False)\n",
    "        self.W_K=nn.Linear(self.d_model,self.d_k,bias=False)\n",
    "        self.W_V=nn.Linear(self.d_model,self.d_v,bias=False)\n",
    "        \"\"\"\n",
    "        self.W_Q=nn.Linear(self.d_model,self.d_model,bias=False)\n",
    "        self.W_K=nn.Linear(self.d_model,self.d_model,bias=False)\n",
    "        self.W_V=nn.Linear(self.d_model,self.d_model,bias=False)\n",
    "\n",
    "        self.W0=nn.Linear(self.d_model,self.d_model)\n",
    "\n",
    "    def forward(self,Q,K):#,K,V):\n",
    "        #calculamos las matrices iniciales, y tenemos que separarlo en las h cabezas\n",
    "\n",
    "        #si recibimos un tensor de forma  w x d_model, lo queremo poner de forma:  w x h x d_k\n",
    "        #separando por la tercera dimension de las matrices\n",
    "\n",
    "        #shapes\n",
    "        batch_size=Q.size(0)\n",
    "        leng_w=Q.size(1)\n",
    "\n",
    "        #aplicar las matrices\n",
    "        new_Q= torch.stack([torch.stack(torch.hsplit(i,self.h)) for i in self.W_Q(Q)])\n",
    "        new_K=torch.stack([torch.stack(torch.hsplit(i,self.h)) for i in self.W_K(K)])\n",
    "        #new_V=torch.stack([torch.stack(torch.hsplit(i,self.h)) for i in self.W_V(V)])\n",
    "\n",
    "        #calculamos las multiplicaciones entre Q y K\n",
    "        #a=torch.bmm(new_Q.view(batch_size*self.h,leng_w,self.d_k),new_K.view(batch_size*self.h,leng_w,self.d_k).transpose(1,2)).view(batch_size,self.h,leng_w,leng_w)\n",
    "\n",
    "        #tenemos la formas, palabras (w), y d_model\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=multiHeadAttentionLayer(8,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=torch.randn(3,4,64)\n",
    "K=torch.randn(3,4,64)\n",
    "\n",
    "b=a(Q,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3054, -0.2492, -0.3284,  0.2086, -0.0101, -0.1504,  0.1591, -0.6483],\n",
       "        [ 0.8844, -0.3297, -0.2822, -0.5534, -0.1382, -0.3535,  0.1239,  0.7043],\n",
       "        [-0.6641, -0.8684, -0.6955, -0.6724,  0.0105,  0.0629,  1.1549, -0.2911],\n",
       "        [-0.3545,  0.2846,  0.5444, -0.7253,  0.1173,  0.1221,  0.7952,  0.0420]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9261,  1.2334],\n",
       "         [-0.1365, -0.3900],\n",
       "         [-0.2071, -0.9569],\n",
       "         [-2.0184, -0.2192]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1, 4, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
